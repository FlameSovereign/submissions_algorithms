python submission_runner.py --framework=jax --workload=criteo1tb --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_2 --overwrite=True --save_checkpoints=False --rng_seed=-49041762 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=3 --hparam_end_index=4 2>&1 | tee -a /logs/criteo1tb_jax_03-06-2025-13-26-34.log
2025-03-06 13:26:35.588285: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741267595.612504       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741267595.620324       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0306 13:26:41.455307 139741583713472 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax.
I0306 13:26:42.383085 139741583713472 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0306 13:26:42.385939 139741583713472 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0306 13:26:42.387884 139741583713472 submission_runner.py:606] Using RNG seed -49041762
I0306 13:26:42.910301 139741583713472 submission_runner.py:615] --- Tuning run 4/5 ---
I0306 13:26:42.910490 139741583713472 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_4.
I0306 13:26:42.910705 139741583713472 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_4/hparams.json.
I0306 13:26:43.136817 139741583713472 submission_runner.py:218] Initializing dataset.
I0306 13:26:43.136998 139741583713472 submission_runner.py:229] Initializing model.
I0306 13:26:51.698690 139741583713472 submission_runner.py:272] Initializing optimizer.
I0306 13:26:52.189139 139741583713472 submission_runner.py:279] Initializing metrics bundle.
I0306 13:26:52.189371 139741583713472 submission_runner.py:301] Initializing checkpoint and logger.
I0306 13:26:52.190058 139741583713472 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_4 with prefix checkpoint_
I0306 13:26:52.190170 139741583713472 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_4/meta_data_0.json.
I0306 13:26:52.190326 139741583713472 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0306 13:26:52.190372 139741583713472 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0306 13:26:52.377742 139741583713472 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_4/flags_0.json.
I0306 13:26:52.691468 139741583713472 submission_runner.py:337] Starting training loop.
I0306 13:27:05.987348 139599724672768 logging_writer.py:48] [0] global_step=0, grad_norm=3.782411575317383, loss=0.2834300100803375
I0306 13:27:06.033299 139741583713472 spec.py:321] Evaluating on the training split.
I0306 13:33:23.142222 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 13:39:30.461687 139741583713472 spec.py:349] Evaluating on the test split.
I0306 13:46:09.604700 139741583713472 submission_runner.py:469] Time since start: 1156.91s, 	Step: 1, 	{'train/loss': 0.282272958202557, 'validation/loss': 0.28264771428140917, 'validation/num_examples': 83274637, 'test/loss': 0.28344227619243423, 'test/num_examples': 95000000, 'score': 13.341683387756348, 'total_duration': 1156.9131562709808, 'accumulated_submission_time': 13.341683387756348, 'accumulated_eval_time': 1143.5713276863098, 'accumulated_logging_time': 0}
I0306 13:46:09.612422 139586403546880 logging_writer.py:48] [1] accumulated_eval_time=1143.57, accumulated_logging_time=0, accumulated_submission_time=13.3417, global_step=1, preemption_count=0, score=13.3417, test/loss=0.283442, test/num_examples=95000000, total_duration=1156.91, train/loss=0.282273, validation/loss=0.282648, validation/num_examples=83274637
I0306 13:47:39.987832 139586395154176 logging_writer.py:48] [100] global_step=100, grad_norm=0.10234659910202026, loss=0.13983729481697083
I0306 13:48:11.363519 139741583713472 spec.py:321] Evaluating on the training split.
I0306 13:54:02.992330 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 13:58:48.716705 139741583713472 spec.py:349] Evaluating on the test split.
I0306 14:05:11.622863 139741583713472 submission_runner.py:469] Time since start: 2298.93s, 	Step: 126, 	{'train/loss': 0.12999672429788411, 'validation/loss': 0.13111632172806334, 'validation/num_examples': 83274637, 'test/loss': 0.13411261984991776, 'test/num_examples': 95000000, 'score': 135.0787901878357, 'total_duration': 2298.9313271045685, 'accumulated_submission_time': 135.0787901878357, 'accumulated_eval_time': 2163.8306090831757, 'accumulated_logging_time': 0.014921903610229492}
I0306 14:05:11.631699 139586403546880 logging_writer.py:48] [126] accumulated_eval_time=2163.83, accumulated_logging_time=0.0149219, accumulated_submission_time=135.079, global_step=126, preemption_count=0, score=135.079, test/loss=0.134113, test/num_examples=95000000, total_duration=2298.93, train/loss=0.129997, validation/loss=0.131116, validation/num_examples=83274637
I0306 14:06:08.281984 139586395154176 logging_writer.py:48] [200] global_step=200, grad_norm=0.02555765211582184, loss=0.12751586735248566
I0306 14:07:12.244630 139741583713472 spec.py:321] Evaluating on the training split.
I0306 14:13:06.708397 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 14:18:37.846322 139741583713472 spec.py:349] Evaluating on the test split.
I0306 14:24:20.155096 139741583713472 submission_runner.py:469] Time since start: 3447.46s, 	Step: 256, 	{'train/loss': 0.13006798455597096, 'validation/loss': 0.12835991370623784, 'validation/num_examples': 83274637, 'test/loss': 0.1312226576069079, 'test/num_examples': 95000000, 'score': 255.67853450775146, 'total_duration': 3447.463562965393, 'accumulated_submission_time': 255.67853450775146, 'accumulated_eval_time': 3191.741019010544, 'accumulated_logging_time': 0.030080080032348633}
I0306 14:24:20.164299 139586403546880 logging_writer.py:48] [256] accumulated_eval_time=3191.74, accumulated_logging_time=0.0300801, accumulated_submission_time=255.679, global_step=256, preemption_count=0, score=255.679, test/loss=0.131223, test/num_examples=95000000, total_duration=3447.46, train/loss=0.130068, validation/loss=0.12836, validation/num_examples=83274637
I0306 14:24:43.399655 139586395154176 logging_writer.py:48] [300] global_step=300, grad_norm=0.043240856379270554, loss=0.1264645755290985
I0306 14:26:21.945046 139741583713472 spec.py:321] Evaluating on the training split.
I0306 14:31:59.848206 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 14:37:23.428990 139741583713472 spec.py:349] Evaluating on the test split.
I0306 14:43:05.827437 139741583713472 submission_runner.py:469] Time since start: 4573.14s, 	Step: 386, 	{'train/loss': 0.1261218050787659, 'validation/loss': 0.12815289094710908, 'validation/num_examples': 83274637, 'test/loss': 0.1307500091899671, 'test/num_examples': 95000000, 'score': 377.446439743042, 'total_duration': 4573.135908842087, 'accumulated_submission_time': 377.446439743042, 'accumulated_eval_time': 4195.623357057571, 'accumulated_logging_time': 0.046097517013549805}
I0306 14:43:05.835389 139586403546880 logging_writer.py:48] [386] accumulated_eval_time=4195.62, accumulated_logging_time=0.0460975, accumulated_submission_time=377.446, global_step=386, preemption_count=0, score=377.446, test/loss=0.13075, test/num_examples=95000000, total_duration=4573.14, train/loss=0.126122, validation/loss=0.128153, validation/num_examples=83274637
I0306 14:43:07.381396 139586395154176 logging_writer.py:48] [400] global_step=400, grad_norm=0.010093716904520988, loss=0.12067386507987976
I0306 14:44:48.642521 139586403546880 logging_writer.py:48] [500] global_step=500, grad_norm=0.0330033116042614, loss=0.12356695532798767
I0306 14:45:06.145023 139741583713472 spec.py:321] Evaluating on the training split.
I0306 14:50:48.987888 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 14:55:45.589067 139741583713472 spec.py:349] Evaluating on the test split.
I0306 15:01:18.810739 139741583713472 submission_runner.py:469] Time since start: 5666.12s, 	Step: 515, 	{'train/loss': 0.1260364472561475, 'validation/loss': 0.12732653542011987, 'validation/num_examples': 83274637, 'test/loss': 0.1299051206928454, 'test/num_examples': 95000000, 'score': 497.7419390678406, 'total_duration': 5666.119196653366, 'accumulated_submission_time': 497.7419390678406, 'accumulated_eval_time': 5168.289000034332, 'accumulated_logging_time': 0.060677289962768555}
I0306 15:01:18.818481 139586395154176 logging_writer.py:48] [515] accumulated_eval_time=5168.29, accumulated_logging_time=0.0606773, accumulated_submission_time=497.742, global_step=515, preemption_count=0, score=497.742, test/loss=0.129905, test/num_examples=95000000, total_duration=5666.12, train/loss=0.126036, validation/loss=0.127327, validation/num_examples=83274637
I0306 15:02:31.607319 139586403546880 logging_writer.py:48] [600] global_step=600, grad_norm=0.009917749091982841, loss=0.12138628214597702
I0306 15:03:19.774605 139741583713472 spec.py:321] Evaluating on the training split.
I0306 15:08:46.524458 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 15:13:39.936102 139741583713472 spec.py:349] Evaluating on the test split.
I0306 15:19:32.483842 139741583713472 submission_runner.py:469] Time since start: 6759.79s, 	Step: 641, 	{'train/loss': 0.1244807955252487, 'validation/loss': 0.12762718188929556, 'validation/num_examples': 83274637, 'test/loss': 0.13005131616981908, 'test/num_examples': 95000000, 'score': 618.6847295761108, 'total_duration': 6759.792283773422, 'accumulated_submission_time': 618.6847295761108, 'accumulated_eval_time': 6140.9981598854065, 'accumulated_logging_time': 0.0747370719909668}
I0306 15:19:32.491639 139586395154176 logging_writer.py:48] [641] accumulated_eval_time=6141, accumulated_logging_time=0.0747371, accumulated_submission_time=618.685, global_step=641, preemption_count=0, score=618.685, test/loss=0.130051, test/num_examples=95000000, total_duration=6759.79, train/loss=0.124481, validation/loss=0.127627, validation/num_examples=83274637
I0306 15:20:16.181577 139586403546880 logging_writer.py:48] [700] global_step=700, grad_norm=0.010362070053815842, loss=0.1311635673046112
I0306 15:21:32.488382 139741583713472 spec.py:321] Evaluating on the training split.
I0306 15:26:37.928493 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 15:31:19.802276 139741583713472 spec.py:349] Evaluating on the test split.
I0306 15:36:31.783203 139741583713472 submission_runner.py:469] Time since start: 7779.09s, 	Step: 762, 	{'train/loss': 0.12789656356586226, 'validation/loss': 0.12799306240802796, 'validation/num_examples': 83274637, 'test/loss': 0.1305214832236842, 'test/num_examples': 95000000, 'score': 738.6686789989471, 'total_duration': 7779.091667175293, 'accumulated_submission_time': 738.6686789989471, 'accumulated_eval_time': 7040.29291844368, 'accumulated_logging_time': 0.08887553215026855}
I0306 15:36:31.791723 139586395154176 logging_writer.py:48] [762] accumulated_eval_time=7040.29, accumulated_logging_time=0.0888755, accumulated_submission_time=738.669, global_step=762, preemption_count=0, score=738.669, test/loss=0.130521, test/num_examples=95000000, total_duration=7779.09, train/loss=0.127897, validation/loss=0.127993, validation/num_examples=83274637
I0306 15:36:46.130195 139586403546880 logging_writer.py:48] [800] global_step=800, grad_norm=0.010695347562432289, loss=0.12312432378530502
I0306 15:38:32.703509 139741583713472 spec.py:321] Evaluating on the training split.
I0306 15:43:10.340501 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 15:47:04.692923 139741583713472 spec.py:349] Evaluating on the test split.
I0306 15:51:52.448808 139741583713472 submission_runner.py:469] Time since start: 8699.76s, 	Step: 886, 	{'train/loss': 0.12371010316898988, 'validation/loss': 0.1270597441544818, 'validation/num_examples': 83274637, 'test/loss': 0.1294516341694079, 'test/num_examples': 95000000, 'score': 859.5674810409546, 'total_duration': 8699.75725889206, 'accumulated_submission_time': 859.5674810409546, 'accumulated_eval_time': 7840.038144350052, 'accumulated_logging_time': 0.10348677635192871}
I0306 15:51:52.473905 139586395154176 logging_writer.py:48] [886] accumulated_eval_time=7840.04, accumulated_logging_time=0.103487, accumulated_submission_time=859.567, global_step=886, preemption_count=0, score=859.567, test/loss=0.129452, test/num_examples=95000000, total_duration=8699.76, train/loss=0.12371, validation/loss=0.12706, validation/num_examples=83274637
I0306 15:51:54.078313 139586403546880 logging_writer.py:48] [900] global_step=900, grad_norm=0.014471521601080894, loss=0.11603175103664398
I0306 15:53:38.024732 139586395154176 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.03405788540840149, loss=0.12779968976974487
I0306 15:53:53.386326 139741583713472 spec.py:321] Evaluating on the training split.
I0306 15:57:11.165480 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 16:00:08.589763 139741583713472 spec.py:349] Evaluating on the test split.
I0306 16:03:55.240457 139741583713472 submission_runner.py:469] Time since start: 9422.55s, 	Step: 1014, 	{'train/loss': 0.12528246717304928, 'validation/loss': 0.12663186698561502, 'validation/num_examples': 83274637, 'test/loss': 0.12914055090460527, 'test/num_examples': 95000000, 'score': 980.4659984111786, 'total_duration': 9422.548312664032, 'accumulated_submission_time': 980.4659984111786, 'accumulated_eval_time': 8441.891604661942, 'accumulated_logging_time': 0.13507342338562012}
I0306 16:03:55.253922 139586403546880 logging_writer.py:48] [1014] accumulated_eval_time=8441.89, accumulated_logging_time=0.135073, accumulated_submission_time=980.466, global_step=1014, preemption_count=0, score=980.466, test/loss=0.129141, test/num_examples=95000000, total_duration=9422.55, train/loss=0.125282, validation/loss=0.126632, validation/num_examples=83274637
I0306 16:05:12.298441 139586395154176 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.0746942013502121, loss=0.12434229254722595
I0306 16:05:55.867800 139741583713472 spec.py:321] Evaluating on the training split.
I0306 16:06:51.730211 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 16:07:42.579099 139741583713472 spec.py:349] Evaluating on the test split.
I0306 16:10:08.045449 139741583713472 submission_runner.py:469] Time since start: 9795.35s, 	Step: 1138, 	{'train/loss': 0.127204049214627, 'validation/loss': 0.12650956181188833, 'validation/num_examples': 83274637, 'test/loss': 0.1288860939555921, 'test/num_examples': 95000000, 'score': 1101.0632538795471, 'total_duration': 9795.353886604309, 'accumulated_submission_time': 1101.0632538795471, 'accumulated_eval_time': 8694.069162368774, 'accumulated_logging_time': 0.15488100051879883}
I0306 16:10:08.053952 139586403546880 logging_writer.py:48] [1138] accumulated_eval_time=8694.07, accumulated_logging_time=0.154881, accumulated_submission_time=1101.06, global_step=1138, preemption_count=0, score=1101.06, test/loss=0.128886, test/num_examples=95000000, total_duration=9795.35, train/loss=0.127204, validation/loss=0.12651, validation/num_examples=83274637
I0306 16:10:55.642498 139586395154176 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.0076395608484745026, loss=0.1225147470831871
I0306 16:12:08.772922 139741583713472 spec.py:321] Evaluating on the training split.
I0306 16:13:14.075725 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 16:13:25.410307 139741583713472 spec.py:349] Evaluating on the test split.
I0306 16:16:28.811073 139741583713472 submission_runner.py:469] Time since start: 10176.12s, 	Step: 1259, 	{'train/loss': 0.1242175400139963, 'validation/loss': 0.12635788981870053, 'validation/num_examples': 83274637, 'test/loss': 0.12854995285773027, 'test/num_examples': 95000000, 'score': 1221.76620054245, 'total_duration': 10176.119544267654, 'accumulated_submission_time': 1221.76620054245, 'accumulated_eval_time': 8954.107259511948, 'accumulated_logging_time': 0.1698441505432129}
I0306 16:16:28.819224 139586403546880 logging_writer.py:48] [1259] accumulated_eval_time=8954.11, accumulated_logging_time=0.169844, accumulated_submission_time=1221.77, global_step=1259, preemption_count=0, score=1221.77, test/loss=0.12855, test/num_examples=95000000, total_duration=10176.1, train/loss=0.124218, validation/loss=0.126358, validation/num_examples=83274637
I0306 16:16:50.563441 139586395154176 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.017831701785326004, loss=0.1189342513680458
I0306 16:18:29.214788 139741583713472 spec.py:321] Evaluating on the training split.
I0306 16:19:45.209235 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 16:19:52.647625 139741583713472 spec.py:349] Evaluating on the test split.
I0306 16:22:49.408540 139741583713472 submission_runner.py:469] Time since start: 10556.72s, 	Step: 1378, 	{'train/loss': 0.12451034486762383, 'validation/loss': 0.12635626809048903, 'validation/num_examples': 83274637, 'test/loss': 0.12881774642269736, 'test/num_examples': 95000000, 'score': 1342.1446273326874, 'total_duration': 10556.717004299164, 'accumulated_submission_time': 1342.1446273326874, 'accumulated_eval_time': 9214.300951957703, 'accumulated_logging_time': 0.18499755859375}
I0306 16:22:49.416627 139586403546880 logging_writer.py:48] [1378] accumulated_eval_time=9214.3, accumulated_logging_time=0.184998, accumulated_submission_time=1342.14, global_step=1378, preemption_count=0, score=1342.14, test/loss=0.128818, test/num_examples=95000000, total_duration=10556.7, train/loss=0.12451, validation/loss=0.126356, validation/num_examples=83274637
I0306 16:22:51.846706 139586395154176 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.053835347294807434, loss=0.12306727468967438
I0306 16:24:50.317160 139741583713472 spec.py:321] Evaluating on the training split.
I0306 16:26:09.957248 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 16:26:17.395713 139741583713472 spec.py:349] Evaluating on the test split.
I0306 16:29:11.533339 139741583713472 submission_runner.py:469] Time since start: 10938.84s, 	Step: 1500, 	{'train/loss': 0.12772886069643796, 'validation/loss': 0.12668955456938263, 'validation/num_examples': 83274637, 'test/loss': 0.12908647073396382, 'test/num_examples': 95000000, 'score': 1463.0276458263397, 'total_duration': 10938.84181022644, 'accumulated_submission_time': 1463.0276458263397, 'accumulated_eval_time': 9475.517084121704, 'accumulated_logging_time': 0.20026516914367676}
I0306 16:29:11.552100 139586403546880 logging_writer.py:48] [1500] accumulated_eval_time=9475.52, accumulated_logging_time=0.200265, accumulated_submission_time=1463.03, global_step=1500, preemption_count=0, score=1463.03, test/loss=0.129086, test/num_examples=95000000, total_duration=10938.8, train/loss=0.127729, validation/loss=0.12669, validation/num_examples=83274637
I0306 16:29:11.667621 139586395154176 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.004813515115529299, loss=0.12945927679538727
I0306 16:30:45.080988 139586403546880 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.017927205190062523, loss=0.12748265266418457
I0306 16:31:12.621337 139741583713472 spec.py:321] Evaluating on the training split.
I0306 16:32:28.246662 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 16:32:35.824692 139741583713472 spec.py:349] Evaluating on the test split.
I0306 16:35:36.395326 139741583713472 submission_runner.py:469] Time since start: 11323.70s, 	Step: 1624, 	{'train/loss': 0.1250373355505414, 'validation/loss': 0.12631070111034753, 'validation/num_examples': 83274637, 'test/loss': 0.12871096724917763, 'test/num_examples': 95000000, 'score': 1584.081259727478, 'total_duration': 11323.703803539276, 'accumulated_submission_time': 1584.081259727478, 'accumulated_eval_time': 9739.291018009186, 'accumulated_logging_time': 0.22556781768798828}
I0306 16:35:36.403517 139586395154176 logging_writer.py:48] [1624] accumulated_eval_time=9739.29, accumulated_logging_time=0.225568, accumulated_submission_time=1584.08, global_step=1624, preemption_count=0, score=1584.08, test/loss=0.128711, test/num_examples=95000000, total_duration=11323.7, train/loss=0.125037, validation/loss=0.126311, validation/num_examples=83274637
I0306 16:36:41.792993 139586403546880 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.03338930010795593, loss=0.13330574333667755
I0306 16:37:37.320928 139741583713472 spec.py:321] Evaluating on the training split.
I0306 16:38:53.278467 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 16:39:00.720056 139741583713472 spec.py:349] Evaluating on the test split.
I0306 16:41:58.123989 139741583713472 submission_runner.py:469] Time since start: 11705.43s, 	Step: 1745, 	{'train/loss': 0.12366106210030475, 'validation/loss': 0.12613881593261628, 'validation/num_examples': 83274637, 'test/loss': 0.12859395484169409, 'test/num_examples': 95000000, 'score': 1704.983387708664, 'total_duration': 11705.432455062866, 'accumulated_submission_time': 1704.983387708664, 'accumulated_eval_time': 10000.094016551971, 'accumulated_logging_time': 0.24012470245361328}
I0306 16:41:58.132857 139586395154176 logging_writer.py:48] [1745] accumulated_eval_time=10000.1, accumulated_logging_time=0.240125, accumulated_submission_time=1704.98, global_step=1745, preemption_count=0, score=1704.98, test/loss=0.128594, test/num_examples=95000000, total_duration=11705.4, train/loss=0.123661, validation/loss=0.126139, validation/num_examples=83274637
I0306 16:42:35.981937 139586403546880 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.022775107994675636, loss=0.12175671011209488
I0306 16:43:58.477176 139741583713472 spec.py:321] Evaluating on the training split.
I0306 16:45:07.377143 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 16:45:14.790364 139741583713472 spec.py:349] Evaluating on the test split.
I0306 16:48:21.580452 139741583713472 submission_runner.py:469] Time since start: 12088.89s, 	Step: 1866, 	{'train/loss': 0.12498618575668186, 'validation/loss': 0.12615725013560777, 'validation/num_examples': 83274637, 'test/loss': 0.1285923769120066, 'test/num_examples': 95000000, 'score': 1825.2816543579102, 'total_duration': 12088.88893032074, 'accumulated_submission_time': 1825.2816543579102, 'accumulated_eval_time': 10263.197251558304, 'accumulated_logging_time': 0.2848172187805176}
I0306 16:48:21.589506 139586395154176 logging_writer.py:48] [1866] accumulated_eval_time=10263.2, accumulated_logging_time=0.284817, accumulated_submission_time=1825.28, global_step=1866, preemption_count=0, score=1825.28, test/loss=0.128592, test/num_examples=95000000, total_duration=12088.9, train/loss=0.124986, validation/loss=0.126157, validation/num_examples=83274637
I0306 16:48:32.281833 139586403546880 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.0627126693725586, loss=0.11985418200492859
I0306 16:50:22.437033 139741583713472 spec.py:321] Evaluating on the training split.
I0306 16:51:33.164892 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 16:51:40.616464 139741583713472 spec.py:349] Evaluating on the test split.
I0306 16:54:44.181459 139741583713472 submission_runner.py:469] Time since start: 12471.49s, 	Step: 1987, 	{'train/loss': 0.12436646300385583, 'validation/loss': 0.12613992440478156, 'validation/num_examples': 83274637, 'test/loss': 0.12854697703536183, 'test/num_examples': 95000000, 'score': 1946.1127998828888, 'total_duration': 12471.489869832993, 'accumulated_submission_time': 1946.1127998828888, 'accumulated_eval_time': 10524.941573619843, 'accumulated_logging_time': 0.3011343479156494}
I0306 16:54:44.190337 139586395154176 logging_writer.py:48] [1987] accumulated_eval_time=10524.9, accumulated_logging_time=0.301134, accumulated_submission_time=1946.11, global_step=1987, preemption_count=0, score=1946.11, test/loss=0.128547, test/num_examples=95000000, total_duration=12471.5, train/loss=0.124366, validation/loss=0.12614, validation/num_examples=83274637
I0306 16:54:45.690129 139586403546880 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.027599507942795753, loss=0.12045915424823761
I0306 16:56:37.389893 139586395154176 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.0220932736992836, loss=0.12435263395309448
I0306 16:56:45.060585 139741583713472 spec.py:321] Evaluating on the training split.
I0306 16:57:54.932607 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 16:58:02.321602 139741583713472 spec.py:349] Evaluating on the test split.
I0306 17:01:05.699090 139741583713472 submission_runner.py:469] Time since start: 12853.01s, 	Step: 2107, 	{'train/loss': 0.12745250719335843, 'validation/loss': 0.12627126545079162, 'validation/num_examples': 83274637, 'test/loss': 0.12851190673314145, 'test/num_examples': 95000000, 'score': 2066.966822862625, 'total_duration': 12853.007566690445, 'accumulated_submission_time': 2066.966822862625, 'accumulated_eval_time': 10785.580021381378, 'accumulated_logging_time': 0.3164823055267334}
I0306 17:01:05.707816 139586403546880 logging_writer.py:48] [2107] accumulated_eval_time=10785.6, accumulated_logging_time=0.316482, accumulated_submission_time=2066.97, global_step=2107, preemption_count=0, score=2066.97, test/loss=0.128512, test/num_examples=95000000, total_duration=12853, train/loss=0.127453, validation/loss=0.126271, validation/num_examples=83274637
I0306 17:02:30.892901 139586395154176 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.05489540100097656, loss=0.1234135553240776
I0306 17:03:06.442262 139741583713472 spec.py:321] Evaluating on the training split.
I0306 17:04:11.593009 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 17:04:19.088861 139741583713472 spec.py:349] Evaluating on the test split.
I0306 17:07:25.697754 139741583713472 submission_runner.py:469] Time since start: 13233.01s, 	Step: 2230, 	{'train/loss': 0.1264003168955539, 'validation/loss': 0.12670095754449595, 'validation/num_examples': 83274637, 'test/loss': 0.12896157864925986, 'test/num_examples': 95000000, 'score': 2187.684054851532, 'total_duration': 13233.006223678589, 'accumulated_submission_time': 2187.684054851532, 'accumulated_eval_time': 11044.835451602936, 'accumulated_logging_time': 0.3327782154083252}
I0306 17:07:25.706075 139586403546880 logging_writer.py:48] [2230] accumulated_eval_time=11044.8, accumulated_logging_time=0.332778, accumulated_submission_time=2187.68, global_step=2230, preemption_count=0, score=2187.68, test/loss=0.128962, test/num_examples=95000000, total_duration=13233, train/loss=0.1264, validation/loss=0.126701, validation/num_examples=83274637
I0306 17:08:23.164844 139586395154176 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.031834207475185394, loss=0.12015021592378616
I0306 17:09:26.344408 139741583713472 spec.py:321] Evaluating on the training split.
I0306 17:10:31.921991 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 17:10:39.478667 139741583713472 spec.py:349] Evaluating on the test split.
I0306 17:13:48.092163 139741583713472 submission_runner.py:469] Time since start: 13615.40s, 	Step: 2350, 	{'train/loss': 0.12688149005736946, 'validation/loss': 0.12603120770452142, 'validation/num_examples': 83274637, 'test/loss': 0.1283598838096217, 'test/num_examples': 95000000, 'score': 2308.306625366211, 'total_duration': 13615.400626659393, 'accumulated_submission_time': 2308.306625366211, 'accumulated_eval_time': 11306.583141088486, 'accumulated_logging_time': 0.3474009037017822}
I0306 17:13:48.101021 139586403546880 logging_writer.py:48] [2350] accumulated_eval_time=11306.6, accumulated_logging_time=0.347401, accumulated_submission_time=2308.31, global_step=2350, preemption_count=0, score=2308.31, test/loss=0.12836, test/num_examples=95000000, total_duration=13615.4, train/loss=0.126881, validation/loss=0.126031, validation/num_examples=83274637
I0306 17:14:20.362530 139586395154176 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.010276056826114655, loss=0.12114398181438446
I0306 17:15:48.290291 139741583713472 spec.py:321] Evaluating on the training split.
I0306 17:17:00.214219 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 17:17:07.634701 139741583713472 spec.py:349] Evaluating on the test split.
I0306 17:20:05.838919 139741583713472 submission_runner.py:469] Time since start: 13993.15s, 	Step: 2470, 	{'train/loss': 0.12308485828246335, 'validation/loss': 0.1260623209923993, 'validation/num_examples': 83274637, 'test/loss': 0.12824631155427632, 'test/num_examples': 95000000, 'score': 2428.4787361621857, 'total_duration': 13993.147387742996, 'accumulated_submission_time': 2428.4787361621857, 'accumulated_eval_time': 11564.131711959839, 'accumulated_logging_time': 0.36328577995300293}
I0306 17:20:05.848088 139586403546880 logging_writer.py:48] [2470] accumulated_eval_time=11564.1, accumulated_logging_time=0.363286, accumulated_submission_time=2428.48, global_step=2470, preemption_count=0, score=2428.48, test/loss=0.128246, test/num_examples=95000000, total_duration=13993.1, train/loss=0.123085, validation/loss=0.126062, validation/num_examples=83274637
I0306 17:20:11.922135 139586395154176 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.06905890256166458, loss=0.12354332953691483
I0306 17:22:06.362667 139741583713472 spec.py:321] Evaluating on the training split.
I0306 17:23:28.977711 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 17:23:36.398350 139741583713472 spec.py:349] Evaluating on the test split.
I0306 17:26:25.034827 139741583713472 submission_runner.py:469] Time since start: 14372.34s, 	Step: 2592, 	{'train/loss': 0.12699587688834038, 'validation/loss': 0.1268362669168705, 'validation/num_examples': 83274637, 'test/loss': 0.12897636655016448, 'test/num_examples': 95000000, 'score': 2548.917779445648, 'total_duration': 14372.343301057816, 'accumulated_submission_time': 2548.917779445648, 'accumulated_eval_time': 11822.803822278976, 'accumulated_logging_time': 0.43771815299987793}
I0306 17:26:25.043913 139586403546880 logging_writer.py:48] [2592] accumulated_eval_time=11822.8, accumulated_logging_time=0.437718, accumulated_submission_time=2548.92, global_step=2592, preemption_count=0, score=2548.92, test/loss=0.128976, test/num_examples=95000000, total_duration=14372.3, train/loss=0.126996, validation/loss=0.126836, validation/num_examples=83274637
I0306 17:26:26.017664 139586395154176 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.04470556974411011, loss=0.12742571532726288
I0306 17:28:16.564925 139586403546880 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.04004962369799614, loss=0.12298831343650818
I0306 17:28:25.663339 139741583713472 spec.py:321] Evaluating on the training split.
I0306 17:29:52.865064 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 17:30:00.327261 139741583713472 spec.py:349] Evaluating on the test split.
I0306 17:32:41.748812 139741583713472 submission_runner.py:469] Time since start: 14749.06s, 	Step: 2708, 	{'train/loss': 0.12393083546380952, 'validation/loss': 0.1258454674514785, 'validation/num_examples': 83274637, 'test/loss': 0.12830010633223685, 'test/num_examples': 95000000, 'score': 2669.5208237171173, 'total_duration': 14749.057276248932, 'accumulated_submission_time': 2669.5208237171173, 'accumulated_eval_time': 12078.889225244522, 'accumulated_logging_time': 0.4545304775238037}
I0306 17:32:41.759613 139586395154176 logging_writer.py:48] [2708] accumulated_eval_time=12078.9, accumulated_logging_time=0.45453, accumulated_submission_time=2669.52, global_step=2708, preemption_count=0, score=2669.52, test/loss=0.1283, test/num_examples=95000000, total_duration=14749.1, train/loss=0.123931, validation/loss=0.125845, validation/num_examples=83274637
I0306 17:34:05.681646 139586403546880 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.036362599581480026, loss=0.12689270079135895
I0306 17:34:42.749104 139741583713472 spec.py:321] Evaluating on the training split.
I0306 17:36:17.932601 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 17:36:25.496491 139741583713472 spec.py:349] Evaluating on the test split.
I0306 17:38:59.733991 139741583713472 submission_runner.py:469] Time since start: 15127.04s, 	Step: 2830, 	{'train/loss': 0.1258178987780457, 'validation/loss': 0.1263542623554719, 'validation/num_examples': 83274637, 'test/loss': 0.12866970249794407, 'test/num_examples': 95000000, 'score': 2790.493356704712, 'total_duration': 15127.042461633682, 'accumulated_submission_time': 2790.493356704712, 'accumulated_eval_time': 12335.874051809311, 'accumulated_logging_time': 0.47228503227233887}
I0306 17:38:59.743151 139586395154176 logging_writer.py:48] [2830] accumulated_eval_time=12335.9, accumulated_logging_time=0.472285, accumulated_submission_time=2790.49, global_step=2830, preemption_count=0, score=2790.49, test/loss=0.12867, test/num_examples=95000000, total_duration=15127, train/loss=0.125818, validation/loss=0.126354, validation/num_examples=83274637
I0306 17:39:55.757368 139586403546880 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.06270190328359604, loss=0.12480918318033218
I0306 17:41:01.228034 139741583713472 spec.py:321] Evaluating on the training split.
I0306 17:42:45.193614 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 17:42:52.631705 139741583713472 spec.py:349] Evaluating on the test split.
I0306 17:45:16.295655 139741583713472 submission_runner.py:469] Time since start: 15503.60s, 	Step: 2952, 	{'train/loss': 0.12568868303074027, 'validation/loss': 0.1257793649523335, 'validation/num_examples': 83274637, 'test/loss': 0.12820666162623356, 'test/num_examples': 95000000, 'score': 2911.9611904621124, 'total_duration': 15503.60411477089, 'accumulated_submission_time': 2911.9611904621124, 'accumulated_eval_time': 12590.941601514816, 'accumulated_logging_time': 0.4888918399810791}
I0306 17:45:16.304216 139586395154176 logging_writer.py:48] [2952] accumulated_eval_time=12590.9, accumulated_logging_time=0.488892, accumulated_submission_time=2911.96, global_step=2952, preemption_count=0, score=2911.96, test/loss=0.128207, test/num_examples=95000000, total_duration=15503.6, train/loss=0.125689, validation/loss=0.125779, validation/num_examples=83274637
I0306 17:45:45.641462 139586403546880 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.009928268380463123, loss=0.12329092621803284
I0306 17:47:16.998034 139741583713472 spec.py:321] Evaluating on the training split.
I0306 17:49:11.810474 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 17:49:19.312199 139741583713472 spec.py:349] Evaluating on the test split.
I0306 17:51:33.583258 139741583713472 submission_runner.py:469] Time since start: 15880.89s, 	Step: 3074, 	{'train/loss': 0.12481504094160203, 'validation/loss': 0.12642507119690108, 'validation/num_examples': 83274637, 'test/loss': 0.12891772701480264, 'test/num_examples': 95000000, 'score': 3032.6177990436554, 'total_duration': 15880.891729354858, 'accumulated_submission_time': 3032.6177990436554, 'accumulated_eval_time': 12847.526772022247, 'accumulated_logging_time': 0.5255701541900635}
I0306 17:51:33.592355 139586395154176 logging_writer.py:48] [3074] accumulated_eval_time=12847.5, accumulated_logging_time=0.52557, accumulated_submission_time=3032.62, global_step=3074, preemption_count=0, score=3032.62, test/loss=0.128918, test/num_examples=95000000, total_duration=15880.9, train/loss=0.124815, validation/loss=0.126425, validation/num_examples=83274637
I0306 17:51:36.437559 139586403546880 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.05143587663769722, loss=0.1252705603837967
I0306 17:53:33.802211 139741583713472 spec.py:321] Evaluating on the training split.
I0306 17:55:43.177505 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 17:55:50.695793 139741583713472 spec.py:349] Evaluating on the test split.
I0306 17:57:54.763806 139741583713472 submission_runner.py:469] Time since start: 16262.07s, 	Step: 3194, 	{'train/loss': 0.12504799496499622, 'validation/loss': 0.12603062306030188, 'validation/num_examples': 83274637, 'test/loss': 0.12838224242393093, 'test/num_examples': 95000000, 'score': 3152.8113322257996, 'total_duration': 16262.072271823883, 'accumulated_submission_time': 3152.8113322257996, 'accumulated_eval_time': 13108.48831152916, 'accumulated_logging_time': 0.541447639465332}
I0306 17:57:54.774771 139586395154176 logging_writer.py:48] [3194] accumulated_eval_time=13108.5, accumulated_logging_time=0.541448, accumulated_submission_time=3152.81, global_step=3194, preemption_count=0, score=3152.81, test/loss=0.128382, test/num_examples=95000000, total_duration=16262.1, train/loss=0.125048, validation/loss=0.126031, validation/num_examples=83274637
I0306 17:57:55.526506 139586403546880 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.038045208901166916, loss=0.12326934933662415
I0306 17:59:35.732508 139586395154176 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.007270034868270159, loss=0.126854807138443
I0306 17:59:55.085948 139741583713472 spec.py:321] Evaluating on the training split.
I0306 18:02:04.978969 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 18:02:12.625012 139741583713472 spec.py:349] Evaluating on the test split.
I0306 18:04:12.060571 139741583713472 submission_runner.py:469] Time since start: 16639.37s, 	Step: 3316, 	{'train/loss': 0.1236658809976008, 'validation/loss': 0.1258818195054846, 'validation/num_examples': 83274637, 'test/loss': 0.12836212906044409, 'test/num_examples': 95000000, 'score': 3273.1058309078217, 'total_duration': 16639.369038820267, 'accumulated_submission_time': 3273.1058309078217, 'accumulated_eval_time': 13365.462871551514, 'accumulated_logging_time': 0.5596010684967041}
I0306 18:04:12.070656 139586403546880 logging_writer.py:48] [3316] accumulated_eval_time=13365.5, accumulated_logging_time=0.559601, accumulated_submission_time=3273.11, global_step=3316, preemption_count=0, score=3273.11, test/loss=0.128362, test/num_examples=95000000, total_duration=16639.4, train/loss=0.123666, validation/loss=0.125882, validation/num_examples=83274637
I0306 18:05:27.260910 139586395154176 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.0489339753985405, loss=0.12502512335777283
I0306 18:06:12.958248 139741583713472 spec.py:321] Evaluating on the training split.
I0306 18:08:22.370250 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 18:08:29.823652 139741583713472 spec.py:349] Evaluating on the test split.
I0306 18:10:33.005998 139741583713472 submission_runner.py:469] Time since start: 17020.31s, 	Step: 3437, 	{'train/loss': 0.12459053244418318, 'validation/loss': 0.12578239763334242, 'validation/num_examples': 83274637, 'test/loss': 0.12809279498355264, 'test/num_examples': 95000000, 'score': 3393.880096435547, 'total_duration': 17020.314460754395, 'accumulated_submission_time': 3393.880096435547, 'accumulated_eval_time': 13625.510554552078, 'accumulated_logging_time': 0.6732621192932129}
I0306 18:10:33.014958 139586403546880 logging_writer.py:48] [3437] accumulated_eval_time=13625.5, accumulated_logging_time=0.673262, accumulated_submission_time=3393.88, global_step=3437, preemption_count=0, score=3393.88, test/loss=0.128093, test/num_examples=95000000, total_duration=17020.3, train/loss=0.124591, validation/loss=0.125782, validation/num_examples=83274637
I0306 18:11:19.511723 139586395154176 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.05432049185037613, loss=0.12186303734779358
I0306 18:12:33.017869 139741583713472 spec.py:321] Evaluating on the training split.
I0306 18:14:44.592683 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 18:14:52.012431 139741583713472 spec.py:349] Evaluating on the test split.
I0306 18:16:51.191213 139741583713472 submission_runner.py:469] Time since start: 17398.50s, 	Step: 3562, 	{'train/loss': 0.1244047453638705, 'validation/loss': 0.1268226731193414, 'validation/num_examples': 83274637, 'test/loss': 0.12918453678042763, 'test/num_examples': 95000000, 'score': 3513.8658657073975, 'total_duration': 17398.49969315529, 'accumulated_submission_time': 3513.8658657073975, 'accumulated_eval_time': 13883.683850049973, 'accumulated_logging_time': 0.6898338794708252}
I0306 18:16:51.200784 139586403546880 logging_writer.py:48] [3562] accumulated_eval_time=13883.7, accumulated_logging_time=0.689834, accumulated_submission_time=3513.87, global_step=3562, preemption_count=0, score=3513.87, test/loss=0.129185, test/num_examples=95000000, total_duration=17398.5, train/loss=0.124405, validation/loss=0.126823, validation/num_examples=83274637
I0306 18:17:07.933201 139586395154176 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.024479923769831657, loss=0.12231916934251785
I0306 18:18:51.211547 139741583713472 spec.py:321] Evaluating on the training split.
I0306 18:21:03.430212 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 18:21:10.858994 139741583713472 spec.py:349] Evaluating on the test split.
I0306 18:23:09.240973 139741583713472 submission_runner.py:469] Time since start: 17776.55s, 	Step: 3683, 	{'train/loss': 0.12535061730575636, 'validation/loss': 0.12631383837869506, 'validation/num_examples': 83274637, 'test/loss': 0.1287052408408717, 'test/num_examples': 95000000, 'score': 3633.8595695495605, 'total_duration': 17776.54945230484, 'accumulated_submission_time': 3633.8595695495605, 'accumulated_eval_time': 14141.713231086731, 'accumulated_logging_time': 0.7070825099945068}
I0306 18:23:09.250464 139586403546880 logging_writer.py:48] [3683] accumulated_eval_time=14141.7, accumulated_logging_time=0.707083, accumulated_submission_time=3633.86, global_step=3683, preemption_count=0, score=3633.86, test/loss=0.128705, test/num_examples=95000000, total_duration=17776.5, train/loss=0.125351, validation/loss=0.126314, validation/num_examples=83274637
I0306 18:23:11.134854 139586395154176 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.0051637087017297745, loss=0.13810089230537415
I0306 18:25:03.816544 139586403546880 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.031488217413425446, loss=0.13011687994003296
I0306 18:25:10.093819 139741583713472 spec.py:321] Evaluating on the training split.
I0306 18:27:25.716534 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 18:27:33.232330 139741583713472 spec.py:349] Evaluating on the test split.
I0306 18:29:26.442624 139741583713472 submission_runner.py:469] Time since start: 18153.75s, 	Step: 3806, 	{'train/loss': 0.12470675744819192, 'validation/loss': 0.12597128101237437, 'validation/num_examples': 83274637, 'test/loss': 0.1283021312705592, 'test/num_examples': 95000000, 'score': 3754.6869356632233, 'total_duration': 18153.75105881691, 'accumulated_submission_time': 3754.6869356632233, 'accumulated_eval_time': 14398.061934947968, 'accumulated_logging_time': 0.723304033279419}
I0306 18:29:26.452233 139586395154176 logging_writer.py:48] [3806] accumulated_eval_time=14398.1, accumulated_logging_time=0.723304, accumulated_submission_time=3754.69, global_step=3806, preemption_count=0, score=3754.69, test/loss=0.128302, test/num_examples=95000000, total_duration=18153.8, train/loss=0.124707, validation/loss=0.125971, validation/num_examples=83274637
I0306 18:30:52.020005 139586403546880 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.011240484192967415, loss=0.13065704703330994
I0306 18:31:26.708268 139741583713472 spec.py:321] Evaluating on the training split.
I0306 18:33:53.336813 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 18:34:00.754765 139741583713472 spec.py:349] Evaluating on the test split.
I0306 18:35:48.682317 139741583713472 submission_runner.py:469] Time since start: 18535.99s, 	Step: 3928, 	{'train/loss': 0.12653499000571058, 'validation/loss': 0.1258085412489268, 'validation/num_examples': 83274637, 'test/loss': 0.12824011981907896, 'test/num_examples': 95000000, 'score': 3874.865843296051, 'total_duration': 18535.9907913208, 'accumulated_submission_time': 3874.865843296051, 'accumulated_eval_time': 14660.035930156708, 'accumulated_logging_time': 0.8000786304473877}
I0306 18:35:48.691722 139586395154176 logging_writer.py:48] [3928] accumulated_eval_time=14660, accumulated_logging_time=0.800079, accumulated_submission_time=3874.87, global_step=3928, preemption_count=0, score=3874.87, test/loss=0.12824, test/num_examples=95000000, total_duration=18536, train/loss=0.126535, validation/loss=0.125809, validation/num_examples=83274637
I0306 18:36:46.704297 139586403546880 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.0403255969285965, loss=0.12116686999797821
I0306 18:37:49.274736 139741583713472 spec.py:321] Evaluating on the training split.
I0306 18:40:13.062232 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 18:40:20.526289 139741583713472 spec.py:349] Evaluating on the test split.
I0306 18:42:11.292166 139741583713472 submission_runner.py:469] Time since start: 18918.60s, 	Step: 4052, 	{'train/loss': 0.12568389242456393, 'validation/loss': 0.12575782390085838, 'validation/num_examples': 83274637, 'test/loss': 0.12810407335526316, 'test/num_examples': 95000000, 'score': 3995.431747674942, 'total_duration': 18918.600642442703, 'accumulated_submission_time': 3995.431747674942, 'accumulated_eval_time': 14922.053304195404, 'accumulated_logging_time': 0.8160898685455322}
I0306 18:42:11.302336 139586395154176 logging_writer.py:48] [4052] accumulated_eval_time=14922.1, accumulated_logging_time=0.81609, accumulated_submission_time=3995.43, global_step=4052, preemption_count=0, score=3995.43, test/loss=0.128104, test/num_examples=95000000, total_duration=18918.6, train/loss=0.125684, validation/loss=0.125758, validation/num_examples=83274637
I0306 18:42:39.731517 139586403546880 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.007209801115095615, loss=0.1161300465464592
I0306 18:44:11.495801 139741583713472 spec.py:321] Evaluating on the training split.
I0306 18:46:36.924308 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 18:46:44.376144 139741583713472 spec.py:349] Evaluating on the test split.
I0306 18:48:35.572791 139741583713472 submission_runner.py:469] Time since start: 19302.88s, 	Step: 4173, 	{'train/loss': 0.12269307045066881, 'validation/loss': 0.1254695758481755, 'validation/num_examples': 83274637, 'test/loss': 0.12779053110608551, 'test/num_examples': 95000000, 'score': 4115.607710599899, 'total_duration': 19302.88126850128, 'accumulated_submission_time': 4115.607710599899, 'accumulated_eval_time': 15186.130242109299, 'accumulated_logging_time': 0.8333010673522949}
I0306 18:48:35.582167 139586395154176 logging_writer.py:48] [4173] accumulated_eval_time=15186.1, accumulated_logging_time=0.833301, accumulated_submission_time=4115.61, global_step=4173, preemption_count=0, score=4115.61, test/loss=0.127791, test/num_examples=95000000, total_duration=19302.9, train/loss=0.122693, validation/loss=0.12547, validation/num_examples=83274637
I0306 18:48:38.981369 139586403546880 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.06659530103206635, loss=0.11833201348781586
I0306 18:50:36.959253 139741583713472 spec.py:321] Evaluating on the training split.
I0306 18:53:04.331648 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 18:53:11.808167 139741583713472 spec.py:349] Evaluating on the test split.
I0306 18:54:54.683762 139741583713472 submission_runner.py:469] Time since start: 19681.99s, 	Step: 4297, 	{'train/loss': 0.12698364667828727, 'validation/loss': 0.1259272388249798, 'validation/num_examples': 83274637, 'test/loss': 0.12821790416324014, 'test/num_examples': 95000000, 'score': 4236.967695236206, 'total_duration': 19681.99223923683, 'accumulated_submission_time': 4236.967695236206, 'accumulated_eval_time': 15443.85470032692, 'accumulated_logging_time': 0.8502106666564941}
I0306 18:54:54.693585 139586395154176 logging_writer.py:48] [4297] accumulated_eval_time=15443.9, accumulated_logging_time=0.850211, accumulated_submission_time=4236.97, global_step=4297, preemption_count=0, score=4236.97, test/loss=0.128218, test/num_examples=95000000, total_duration=19682, train/loss=0.126984, validation/loss=0.125927, validation/num_examples=83274637
I0306 18:54:55.147072 139586403546880 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.025802072137594223, loss=0.13194288313388824
I0306 18:56:31.603493 139586395154176 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.03345349431037903, loss=0.12459073215723038
I0306 18:56:55.421935 139741583713472 spec.py:321] Evaluating on the training split.
I0306 18:59:36.974542 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 18:59:44.440670 139741583713472 spec.py:349] Evaluating on the test split.
I0306 19:01:14.797812 139741583713472 submission_runner.py:469] Time since start: 20062.11s, 	Step: 4420, 	{'train/loss': 0.12696912171283983, 'validation/loss': 0.1257354805284043, 'validation/num_examples': 83274637, 'test/loss': 0.12808818682154605, 'test/num_examples': 95000000, 'score': 4357.671516895294, 'total_duration': 20062.106290340424, 'accumulated_submission_time': 4357.671516895294, 'accumulated_eval_time': 15703.23052930832, 'accumulated_logging_time': 0.875063419342041}
I0306 19:01:14.808228 139586403546880 logging_writer.py:48] [4420] accumulated_eval_time=15703.2, accumulated_logging_time=0.875063, accumulated_submission_time=4357.67, global_step=4420, preemption_count=0, score=4357.67, test/loss=0.128088, test/num_examples=95000000, total_duration=20062.1, train/loss=0.126969, validation/loss=0.125735, validation/num_examples=83274637
I0306 19:02:25.766336 139586395154176 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.015436745248734951, loss=0.12129908055067062
I0306 19:03:15.910419 139741583713472 spec.py:321] Evaluating on the training split.
I0306 19:06:03.883191 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 19:06:11.299478 139741583713472 spec.py:349] Evaluating on the test split.
I0306 19:07:32.846379 139741583713472 submission_runner.py:469] Time since start: 20440.15s, 	Step: 4542, 	{'train/loss': 0.12638715940451473, 'validation/loss': 0.12589122267944786, 'validation/num_examples': 83274637, 'test/loss': 0.12824855442023025, 'test/num_examples': 95000000, 'score': 4478.7572503089905, 'total_duration': 20440.154856204987, 'accumulated_submission_time': 4478.7572503089905, 'accumulated_eval_time': 15960.16644001007, 'accumulated_logging_time': 0.8923861980438232}
I0306 19:07:32.855657 139586403546880 logging_writer.py:48] [4542] accumulated_eval_time=15960.2, accumulated_logging_time=0.892386, accumulated_submission_time=4478.76, global_step=4542, preemption_count=0, score=4478.76, test/loss=0.128249, test/num_examples=95000000, total_duration=20440.2, train/loss=0.126387, validation/loss=0.125891, validation/num_examples=83274637
I0306 19:08:19.549391 139586395154176 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.034467339515686035, loss=0.12195787578821182
I0306 19:09:33.083583 139741583713472 spec.py:321] Evaluating on the training split.
I0306 19:12:19.077376 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 19:12:26.651659 139741583713472 spec.py:349] Evaluating on the test split.
I0306 19:13:55.396915 139741583713472 submission_runner.py:469] Time since start: 20822.71s, 	Step: 4659, 	{'train/loss': 0.12477994132669842, 'validation/loss': 0.12618308752964377, 'validation/num_examples': 83274637, 'test/loss': 0.12864559777960527, 'test/num_examples': 95000000, 'score': 4598.968495607376, 'total_duration': 20822.70534968376, 'accumulated_submission_time': 4598.968495607376, 'accumulated_eval_time': 16222.479678153992, 'accumulated_logging_time': 0.9090416431427002}
I0306 19:13:55.415340 139586403546880 logging_writer.py:48] [4659] accumulated_eval_time=16222.5, accumulated_logging_time=0.909042, accumulated_submission_time=4598.97, global_step=4659, preemption_count=0, score=4598.97, test/loss=0.128646, test/num_examples=95000000, total_duration=20822.7, train/loss=0.12478, validation/loss=0.126183, validation/num_examples=83274637
I0306 19:14:16.812370 139586395154176 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.027599232271313667, loss=0.1320759803056717
I0306 19:15:56.380707 139741583713472 spec.py:321] Evaluating on the training split.
I0306 19:18:35.488772 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 19:18:42.934153 139741583713472 spec.py:349] Evaluating on the test split.
I0306 19:20:16.880982 139741583713472 submission_runner.py:469] Time since start: 21204.19s, 	Step: 4778, 	{'train/loss': 0.12265969064297541, 'validation/loss': 0.12614884013384756, 'validation/num_examples': 83274637, 'test/loss': 0.12849038349095396, 'test/num_examples': 95000000, 'score': 4719.909432649612, 'total_duration': 21204.189455986023, 'accumulated_submission_time': 4719.909432649612, 'accumulated_eval_time': 16482.97989845276, 'accumulated_logging_time': 0.9426331520080566}
I0306 19:20:16.892146 139586403546880 logging_writer.py:48] [4778] accumulated_eval_time=16483, accumulated_logging_time=0.942633, accumulated_submission_time=4719.91, global_step=4778, preemption_count=0, score=4719.91, test/loss=0.12849, test/num_examples=95000000, total_duration=21204.2, train/loss=0.12266, validation/loss=0.126149, validation/num_examples=83274637
I0306 19:20:19.327739 139586395154176 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.0283310916274786, loss=0.12700144946575165
I0306 19:22:15.498611 139586403546880 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.031361211091279984, loss=0.1329144388437271
I0306 19:22:16.913474 139741583713472 spec.py:321] Evaluating on the training split.
I0306 19:24:54.783781 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 19:25:02.244871 139741583713472 spec.py:349] Evaluating on the test split.
I0306 19:26:35.195274 139741583713472 submission_runner.py:469] Time since start: 21582.50s, 	Step: 4902, 	{'train/loss': 0.12464921948435546, 'validation/loss': 0.12577629679711932, 'validation/num_examples': 83274637, 'test/loss': 0.12821805612664475, 'test/num_examples': 95000000, 'score': 4839.901934862137, 'total_duration': 21582.503754615784, 'accumulated_submission_time': 4839.901934862137, 'accumulated_eval_time': 16741.261640310287, 'accumulated_logging_time': 0.9735267162322998}
I0306 19:26:35.204791 139586395154176 logging_writer.py:48] [4902] accumulated_eval_time=16741.3, accumulated_logging_time=0.973527, accumulated_submission_time=4839.9, global_step=4902, preemption_count=0, score=4839.9, test/loss=0.128218, test/num_examples=95000000, total_duration=21582.5, train/loss=0.124649, validation/loss=0.125776, validation/num_examples=83274637
I0306 19:28:07.930015 139586403546880 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.009159944951534271, loss=0.12784503400325775
I0306 19:28:36.010946 139741583713472 spec.py:321] Evaluating on the training split.
I0306 19:31:20.476999 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 19:31:27.870634 139741583713472 spec.py:349] Evaluating on the test split.
I0306 19:32:55.848473 139741583713472 submission_runner.py:469] Time since start: 21963.16s, 	Step: 5023, 	{'train/loss': 0.12327688707495635, 'validation/loss': 0.12574381298531095, 'validation/num_examples': 83274637, 'test/loss': 0.12800796879111842, 'test/num_examples': 95000000, 'score': 4960.692188978195, 'total_duration': 21963.156934976578, 'accumulated_submission_time': 4960.692188978195, 'accumulated_eval_time': 17001.099102020264, 'accumulated_logging_time': 0.9897208213806152}
I0306 19:32:55.858249 139586395154176 logging_writer.py:48] [5023] accumulated_eval_time=17001.1, accumulated_logging_time=0.989721, accumulated_submission_time=4960.69, global_step=5023, preemption_count=0, score=4960.69, test/loss=0.128008, test/num_examples=95000000, total_duration=21963.2, train/loss=0.123277, validation/loss=0.125744, validation/num_examples=83274637
I0306 19:34:01.224686 139586403546880 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.02897896058857441, loss=0.12692978978157043
I0306 19:34:56.784867 139741583713472 spec.py:321] Evaluating on the training split.
I0306 19:37:44.054798 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 19:37:51.548779 139741583713472 spec.py:349] Evaluating on the test split.
I0306 19:39:16.158445 139741583713472 submission_runner.py:469] Time since start: 22343.47s, 	Step: 5145, 	{'train/loss': 0.12485084012619355, 'validation/loss': 0.12624917103689612, 'validation/num_examples': 83274637, 'test/loss': 0.12868462138157893, 'test/num_examples': 95000000, 'score': 5081.601266384125, 'total_duration': 22343.466903686523, 'accumulated_submission_time': 5081.601266384125, 'accumulated_eval_time': 17260.472615003586, 'accumulated_logging_time': 1.0068590641021729}
I0306 19:39:16.168511 139586395154176 logging_writer.py:48] [5145] accumulated_eval_time=17260.5, accumulated_logging_time=1.00686, accumulated_submission_time=5081.6, global_step=5145, preemption_count=0, score=5081.6, test/loss=0.128685, test/num_examples=95000000, total_duration=22343.5, train/loss=0.124851, validation/loss=0.126249, validation/num_examples=83274637
I0306 19:39:54.267616 139586403546880 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.01550528034567833, loss=0.11850082874298096
I0306 19:41:17.780235 139741583713472 spec.py:321] Evaluating on the training split.
I0306 19:44:07.059795 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 19:44:14.595810 139741583713472 spec.py:349] Evaluating on the test split.
I0306 19:45:35.656014 139741583713472 submission_runner.py:469] Time since start: 22722.96s, 	Step: 5267, 	{'train/loss': 0.12632506168535296, 'validation/loss': 0.12599038413574268, 'validation/num_examples': 83274637, 'test/loss': 0.12832354808799343, 'test/num_examples': 95000000, 'score': 5203.159546613693, 'total_duration': 22722.964490175247, 'accumulated_submission_time': 5203.159546613693, 'accumulated_eval_time': 17518.348359823227, 'accumulated_logging_time': 1.0604655742645264}
I0306 19:45:35.666499 139586395154176 logging_writer.py:48] [5267] accumulated_eval_time=17518.3, accumulated_logging_time=1.06047, accumulated_submission_time=5203.16, global_step=5267, preemption_count=0, score=5203.16, test/loss=0.128324, test/num_examples=95000000, total_duration=22723, train/loss=0.126325, validation/loss=0.12599, validation/num_examples=83274637
I0306 19:45:46.170231 139586403546880 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.0318300761282444, loss=0.11912743747234344
I0306 19:47:36.332233 139741583713472 spec.py:321] Evaluating on the training split.
I0306 19:50:32.913830 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 19:50:40.303853 139741583713472 spec.py:349] Evaluating on the test split.
I0306 19:51:54.565535 139741583713472 submission_runner.py:469] Time since start: 23101.87s, 	Step: 5388, 	{'train/loss': 0.12526775143290841, 'validation/loss': 0.12561764606615006, 'validation/num_examples': 83274637, 'test/loss': 0.12812283112664474, 'test/num_examples': 95000000, 'score': 5323.804430961609, 'total_duration': 23101.873996973038, 'accumulated_submission_time': 5323.804430961609, 'accumulated_eval_time': 17776.58159661293, 'accumulated_logging_time': 1.0821373462677002}
I0306 19:51:54.575159 139586395154176 logging_writer.py:48] [5388] accumulated_eval_time=17776.6, accumulated_logging_time=1.08214, accumulated_submission_time=5323.8, global_step=5388, preemption_count=0, score=5323.8, test/loss=0.128123, test/num_examples=95000000, total_duration=23101.9, train/loss=0.125268, validation/loss=0.125618, validation/num_examples=83274637
I0306 19:51:55.948922 139586403546880 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.014112924225628376, loss=0.12951821088790894
I0306 19:53:45.065889 139586395154176 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.03251267224550247, loss=0.12748782336711884
I0306 19:53:55.132394 139741583713472 spec.py:321] Evaluating on the training split.
I0306 19:56:59.679043 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 19:57:07.117563 139741583713472 spec.py:349] Evaluating on the test split.
I0306 19:58:15.537844 139741583713472 submission_runner.py:469] Time since start: 23482.85s, 	Step: 5509, 	{'train/loss': 0.12680104903220754, 'validation/loss': 0.12569544929505555, 'validation/num_examples': 83274637, 'test/loss': 0.12809435543791117, 'test/num_examples': 95000000, 'score': 5444.345999240875, 'total_duration': 23482.84630703926, 'accumulated_submission_time': 5444.345999240875, 'accumulated_eval_time': 18036.986972332, 'accumulated_logging_time': 1.0977916717529297}
I0306 19:58:15.547452 139586403546880 logging_writer.py:48] [5509] accumulated_eval_time=18037, accumulated_logging_time=1.09779, accumulated_submission_time=5444.35, global_step=5509, preemption_count=0, score=5444.35, test/loss=0.128094, test/num_examples=95000000, total_duration=23482.8, train/loss=0.126801, validation/loss=0.125695, validation/num_examples=83274637
I0306 19:59:39.983990 139586395154176 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.03102133981883526, loss=0.11994870752096176
I0306 20:00:17.360359 139741583713472 spec.py:321] Evaluating on the training split.
I0306 20:03:22.014398 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 20:03:29.452335 139741583713472 spec.py:349] Evaluating on the test split.
I0306 20:04:32.426836 139741583713472 submission_runner.py:469] Time since start: 23859.74s, 	Step: 5630, 	{'train/loss': 0.12456868281997975, 'validation/loss': 0.1256574490567034, 'validation/num_examples': 83274637, 'test/loss': 0.12803843530016448, 'test/num_examples': 95000000, 'score': 5566.09533572197, 'total_duration': 23859.735318422318, 'accumulated_submission_time': 5566.09533572197, 'accumulated_eval_time': 18292.05339884758, 'accumulated_logging_time': 1.1607139110565186}
I0306 20:04:32.436137 139586403546880 logging_writer.py:48] [5630] accumulated_eval_time=18292.1, accumulated_logging_time=1.16071, accumulated_submission_time=5566.1, global_step=5630, preemption_count=0, score=5566.1, test/loss=0.128038, test/num_examples=95000000, total_duration=23859.7, train/loss=0.124569, validation/loss=0.125657, validation/num_examples=83274637
I0306 20:05:28.266727 139586395154176 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.04468163847923279, loss=0.12244921177625656
I0306 20:06:32.549132 139741583713472 spec.py:321] Evaluating on the training split.
I0306 20:09:46.083242 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 20:09:53.571056 139741583713472 spec.py:349] Evaluating on the test split.
I0306 20:10:48.875218 139741583713472 submission_runner.py:469] Time since start: 24236.18s, 	Step: 5750, 	{'train/loss': 0.12382096513730925, 'validation/loss': 0.12567398914822236, 'validation/num_examples': 83274637, 'test/loss': 0.12803714524054277, 'test/num_examples': 95000000, 'score': 5686.1911833286285, 'total_duration': 24236.183702230453, 'accumulated_submission_time': 5686.1911833286285, 'accumulated_eval_time': 18548.379441976547, 'accumulated_logging_time': 1.177520513534546}
I0306 20:10:48.884750 139586403546880 logging_writer.py:48] [5750] accumulated_eval_time=18548.4, accumulated_logging_time=1.17752, accumulated_submission_time=5686.19, global_step=5750, preemption_count=0, score=5686.19, test/loss=0.128037, test/num_examples=95000000, total_duration=24236.2, train/loss=0.123821, validation/loss=0.125674, validation/num_examples=83274637
I0306 20:11:20.820230 139586395154176 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.012531454674899578, loss=0.12245222926139832
I0306 20:12:49.850327 139741583713472 spec.py:321] Evaluating on the training split.
I0306 20:16:20.830660 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 20:16:28.763441 139741583713472 spec.py:349] Evaluating on the test split.
I0306 20:17:08.476475 139741583713472 submission_runner.py:469] Time since start: 24615.78s, 	Step: 5871, 	{'train/loss': 0.12510254119271003, 'validation/loss': 0.12578198269068447, 'validation/num_examples': 83274637, 'test/loss': 0.1282051566509046, 'test/num_examples': 95000000, 'score': 5807.14034986496, 'total_duration': 24615.78493642807, 'accumulated_submission_time': 5807.14034986496, 'accumulated_eval_time': 18807.005523443222, 'accumulated_logging_time': 1.1936192512512207}
I0306 20:17:08.502381 139586403546880 logging_writer.py:48] [5871] accumulated_eval_time=18807, accumulated_logging_time=1.19362, accumulated_submission_time=5807.14, global_step=5871, preemption_count=0, score=5807.14, test/loss=0.128205, test/num_examples=95000000, total_duration=24615.8, train/loss=0.125103, validation/loss=0.125782, validation/num_examples=83274637
I0306 20:17:14.185875 139586395154176 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.011519315652549267, loss=0.13422754406929016
I0306 20:19:08.915027 139741583713472 spec.py:321] Evaluating on the training split.
I0306 20:22:47.408792 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 20:22:54.801226 139741583713472 spec.py:349] Evaluating on the test split.
I0306 20:23:23.606312 139741583713472 submission_runner.py:469] Time since start: 24990.91s, 	Step: 5993, 	{'train/loss': 0.12448980490554054, 'validation/loss': 0.1256967051815999, 'validation/num_examples': 83274637, 'test/loss': 0.12812944578536184, 'test/num_examples': 95000000, 'score': 5927.53692984581, 'total_duration': 24990.914792060852, 'accumulated_submission_time': 5927.53692984581, 'accumulated_eval_time': 19061.69675898552, 'accumulated_logging_time': 1.2263460159301758}
I0306 20:23:23.616647 139586403546880 logging_writer.py:48] [5993] accumulated_eval_time=19061.7, accumulated_logging_time=1.22635, accumulated_submission_time=5927.54, global_step=5993, preemption_count=0, score=5927.54, test/loss=0.128129, test/num_examples=95000000, total_duration=24990.9, train/loss=0.12449, validation/loss=0.125697, validation/num_examples=83274637
I0306 20:23:24.485574 139586395154176 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.014663511887192726, loss=0.11950024962425232
I0306 20:25:08.194601 139586403546880 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.02327781543135643, loss=0.12034071236848831
I0306 20:25:24.968457 139741583713472 spec.py:321] Evaluating on the training split.
I0306 20:29:19.382443 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 20:29:26.879433 139741583713472 spec.py:349] Evaluating on the test split.
I0306 20:29:43.929385 139741583713472 submission_runner.py:469] Time since start: 25371.24s, 	Step: 6114, 	{'train/loss': 0.12465095833974814, 'validation/loss': 0.1252764553421196, 'validation/num_examples': 83274637, 'test/loss': 0.1276398462890625, 'test/num_examples': 95000000, 'score': 6048.871542692184, 'total_duration': 25371.23785686493, 'accumulated_submission_time': 6048.871542692184, 'accumulated_eval_time': 19320.657624959946, 'accumulated_logging_time': 1.2442617416381836}
I0306 20:29:43.939035 139586395154176 logging_writer.py:48] [6114] accumulated_eval_time=19320.7, accumulated_logging_time=1.24426, accumulated_submission_time=6048.87, global_step=6114, preemption_count=0, score=6048.87, test/loss=0.12764, test/num_examples=95000000, total_duration=25371.2, train/loss=0.124651, validation/loss=0.125276, validation/num_examples=83274637
I0306 20:31:03.098199 139586403546880 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.005271908827126026, loss=0.12148716300725937
I0306 20:31:44.456646 139741583713472 spec.py:321] Evaluating on the training split.
I0306 20:35:49.746460 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 20:35:57.184432 139741583713472 spec.py:349] Evaluating on the test split.
I0306 20:36:05.660820 139741583713472 submission_runner.py:469] Time since start: 25752.97s, 	Step: 6233, 	{'train/loss': 0.1253449093761309, 'validation/loss': 0.12557887151678232, 'validation/num_examples': 83274637, 'test/loss': 0.12790004544613487, 'test/num_examples': 95000000, 'score': 6169.373729944229, 'total_duration': 25752.969297647476, 'accumulated_submission_time': 6169.373729944229, 'accumulated_eval_time': 19581.861757278442, 'accumulated_logging_time': 1.2604591846466064}
I0306 20:36:05.675400 139586395154176 logging_writer.py:48] [6233] accumulated_eval_time=19581.9, accumulated_logging_time=1.26046, accumulated_submission_time=6169.37, global_step=6233, preemption_count=0, score=6169.37, test/loss=0.1279, test/num_examples=95000000, total_duration=25753, train/loss=0.125345, validation/loss=0.125579, validation/num_examples=83274637
I0306 20:37:01.893798 139586403546880 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.025251280516386032, loss=0.12081287056207657
I0306 20:38:05.983199 139741583713472 spec.py:321] Evaluating on the training split.
I0306 20:42:22.890450 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 20:42:30.407008 139741583713472 spec.py:349] Evaluating on the test split.
I0306 20:42:38.985682 139741583713472 submission_runner.py:469] Time since start: 26146.29s, 	Step: 6353, 	{'train/loss': 0.12655389035975784, 'validation/loss': 0.12529855346761373, 'validation/num_examples': 83274637, 'test/loss': 0.12749788304893092, 'test/num_examples': 95000000, 'score': 6289.65657043457, 'total_duration': 26146.294159412384, 'accumulated_submission_time': 6289.65657043457, 'accumulated_eval_time': 19854.864185094833, 'accumulated_logging_time': 1.2909252643585205}
I0306 20:42:38.995850 139586395154176 logging_writer.py:48] [6353] accumulated_eval_time=19854.9, accumulated_logging_time=1.29093, accumulated_submission_time=6289.66, global_step=6353, preemption_count=0, score=6289.66, test/loss=0.127498, test/num_examples=95000000, total_duration=26146.3, train/loss=0.126554, validation/loss=0.125299, validation/num_examples=83274637
I0306 20:43:06.742046 139586403546880 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.03496379405260086, loss=0.13024140894412994
I0306 20:44:40.133603 139741583713472 spec.py:321] Evaluating on the training split.
I0306 20:48:51.617487 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 20:48:59.147891 139741583713472 spec.py:349] Evaluating on the test split.
I0306 20:49:07.613455 139741583713472 submission_runner.py:469] Time since start: 26534.92s, 	Step: 6474, 	{'train/loss': 0.1229663066355125, 'validation/loss': 0.12601454799163708, 'validation/num_examples': 83274637, 'test/loss': 0.12841258800370065, 'test/num_examples': 95000000, 'score': 6410.774411439896, 'total_duration': 26534.9219455719, 'accumulated_submission_time': 6410.774411439896, 'accumulated_eval_time': 20122.344017744064, 'accumulated_logging_time': 1.3115222454071045}
I0306 20:49:07.625431 139586395154176 logging_writer.py:48] [6474] accumulated_eval_time=20122.3, accumulated_logging_time=1.31152, accumulated_submission_time=6410.77, global_step=6474, preemption_count=0, score=6410.77, test/loss=0.128413, test/num_examples=95000000, total_duration=26534.9, train/loss=0.122966, validation/loss=0.126015, validation/num_examples=83274637
I0306 20:49:10.482061 139586403546880 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.008466620929539204, loss=0.12201017886400223
I0306 20:51:07.695333 139741583713472 spec.py:321] Evaluating on the training split.
I0306 20:55:28.846156 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 20:55:36.339579 139741583713472 spec.py:349] Evaluating on the test split.
I0306 20:55:44.749252 139741583713472 submission_runner.py:469] Time since start: 26932.06s, 	Step: 6596, 	{'train/loss': 0.12507717116917455, 'validation/loss': 0.12557887685843538, 'validation/num_examples': 83274637, 'test/loss': 0.12789581968544408, 'test/num_examples': 95000000, 'score': 6530.813458442688, 'total_duration': 26932.057738780975, 'accumulated_submission_time': 6530.813458442688, 'accumulated_eval_time': 20399.39789223671, 'accumulated_logging_time': 1.344653844833374}
I0306 20:55:44.758823 139586395154176 logging_writer.py:48] [6596] accumulated_eval_time=20399.4, accumulated_logging_time=1.34465, accumulated_submission_time=6530.81, global_step=6596, preemption_count=0, score=6530.81, test/loss=0.127896, test/num_examples=95000000, total_duration=26932.1, train/loss=0.125077, validation/loss=0.125579, validation/num_examples=83274637
I0306 20:55:45.283976 139586403546880 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.009441154077649117, loss=0.11963877081871033
I0306 20:57:27.490283 139586395154176 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.012517987750470638, loss=0.12028777599334717
I0306 20:57:45.189880 139741583713472 spec.py:321] Evaluating on the training split.
I0306 21:02:02.318259 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 21:02:09.802037 139741583713472 spec.py:349] Evaluating on the test split.
I0306 21:02:18.270116 139741583713472 submission_runner.py:469] Time since start: 27325.58s, 	Step: 6715, 	{'train/loss': 0.12509108167258823, 'validation/loss': 0.1256729983155578, 'validation/num_examples': 83274637, 'test/loss': 0.1279736484683388, 'test/num_examples': 95000000, 'score': 6651.228821992874, 'total_duration': 27325.578598976135, 'accumulated_submission_time': 6651.228821992874, 'accumulated_eval_time': 20672.478076457977, 'accumulated_logging_time': 1.3604135513305664}
I0306 21:02:18.293409 139586403546880 logging_writer.py:48] [6715] accumulated_eval_time=20672.5, accumulated_logging_time=1.36041, accumulated_submission_time=6651.23, global_step=6715, preemption_count=0, score=6651.23, test/loss=0.127974, test/num_examples=95000000, total_duration=27325.6, train/loss=0.125091, validation/loss=0.125673, validation/num_examples=83274637
I0306 21:03:35.163106 139586395154176 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.00819792877882719, loss=0.11787345260381699
I0306 21:04:18.535422 139741583713472 spec.py:321] Evaluating on the training split.
I0306 21:08:28.241256 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 21:08:35.701127 139741583713472 spec.py:349] Evaluating on the test split.
I0306 21:08:44.172365 139741583713472 submission_runner.py:469] Time since start: 27711.48s, 	Step: 6835, 	{'train/loss': 0.12510103577712797, 'validation/loss': 0.12551450005917242, 'validation/num_examples': 83274637, 'test/loss': 0.1278249972861842, 'test/num_examples': 95000000, 'score': 6771.454652786255, 'total_duration': 27711.4808447361, 'accumulated_submission_time': 6771.454652786255, 'accumulated_eval_time': 20938.114963054657, 'accumulated_logging_time': 1.3909761905670166}
I0306 21:08:44.182837 139586403546880 logging_writer.py:48] [6835] accumulated_eval_time=20938.1, accumulated_logging_time=1.39098, accumulated_submission_time=6771.45, global_step=6835, preemption_count=0, score=6771.45, test/loss=0.127825, test/num_examples=95000000, total_duration=27711.5, train/loss=0.125101, validation/loss=0.125515, validation/num_examples=83274637
I0306 21:09:36.516972 139586395154176 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.006404617335647345, loss=0.12195061147212982
I0306 21:10:44.334309 139741583713472 spec.py:321] Evaluating on the training split.
I0306 21:14:57.040064 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 21:15:04.525546 139741583713472 spec.py:349] Evaluating on the test split.
I0306 21:15:13.132541 139741583713472 submission_runner.py:469] Time since start: 28100.44s, 	Step: 6956, 	{'train/loss': 0.12403672261151878, 'validation/loss': 0.12553594497848314, 'validation/num_examples': 83274637, 'test/loss': 0.12780348682154605, 'test/num_examples': 95000000, 'score': 6891.583950281143, 'total_duration': 28100.441013097763, 'accumulated_submission_time': 6891.583950281143, 'accumulated_eval_time': 21206.91313648224, 'accumulated_logging_time': 1.4142823219299316}
I0306 21:15:13.159728 139586403546880 logging_writer.py:48] [6956] accumulated_eval_time=21206.9, accumulated_logging_time=1.41428, accumulated_submission_time=6891.58, global_step=6956, preemption_count=0, score=6891.58, test/loss=0.127803, test/num_examples=95000000, total_duration=28100.4, train/loss=0.124037, validation/loss=0.125536, validation/num_examples=83274637
I0306 21:15:37.196758 139586395154176 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.01772688701748848, loss=0.12015671283006668
I0306 21:17:13.857678 139741583713472 spec.py:321] Evaluating on the training split.
I0306 21:21:22.785272 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 21:21:30.316472 139741583713472 spec.py:349] Evaluating on the test split.
I0306 21:21:38.898763 139741583713472 submission_runner.py:469] Time since start: 28486.21s, 	Step: 7079, 	{'train/loss': 0.12467854129115366, 'validation/loss': 0.12548431712776859, 'validation/num_examples': 83274637, 'test/loss': 0.12781018659539473, 'test/num_examples': 95000000, 'score': 7012.263591766357, 'total_duration': 28486.207248449326, 'accumulated_submission_time': 7012.263591766357, 'accumulated_eval_time': 21471.954178094864, 'accumulated_logging_time': 1.4502265453338623}
I0306 21:21:38.909595 139586403546880 logging_writer.py:48] [7079] accumulated_eval_time=21472, accumulated_logging_time=1.45023, accumulated_submission_time=7012.26, global_step=7079, preemption_count=0, score=7012.26, test/loss=0.12781, test/num_examples=95000000, total_duration=28486.2, train/loss=0.124679, validation/loss=0.125484, validation/num_examples=83274637
I0306 21:21:41.216508 139586395154176 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.007893680594861507, loss=0.12811024487018585
I0306 21:23:38.256932 139586403546880 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.026102909818291664, loss=0.11508511751890182
I0306 21:23:40.141398 139741583713472 spec.py:321] Evaluating on the training split.
I0306 21:27:49.490342 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 21:27:57.014948 139741583713472 spec.py:349] Evaluating on the test split.
I0306 21:28:05.474067 139741583713472 submission_runner.py:469] Time since start: 28872.78s, 	Step: 7202, 	{'train/loss': 0.12509194849375285, 'validation/loss': 0.1256185042135601, 'validation/num_examples': 83274637, 'test/loss': 0.12794321899671052, 'test/num_examples': 95000000, 'score': 7133.479174852371, 'total_duration': 28872.78255701065, 'accumulated_submission_time': 7133.479174852371, 'accumulated_eval_time': 21737.286844730377, 'accumulated_logging_time': 1.4676928520202637}
I0306 21:28:05.483824 139586395154176 logging_writer.py:48] [7202] accumulated_eval_time=21737.3, accumulated_logging_time=1.46769, accumulated_submission_time=7133.48, global_step=7202, preemption_count=0, score=7133.48, test/loss=0.127943, test/num_examples=95000000, total_duration=28872.8, train/loss=0.125092, validation/loss=0.125619, validation/num_examples=83274637
I0306 21:29:38.388964 139586403546880 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.010131104849278927, loss=0.11984706670045853
I0306 21:30:05.849611 139741583713472 spec.py:321] Evaluating on the training split.
I0306 21:34:20.627859 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 21:34:28.187767 139741583713472 spec.py:349] Evaluating on the test split.
I0306 21:34:36.628943 139741583713472 submission_runner.py:469] Time since start: 29263.94s, 	Step: 7323, 	{'train/loss': 0.12339738007845744, 'validation/loss': 0.12556163948476592, 'validation/num_examples': 83274637, 'test/loss': 0.12801922367393093, 'test/num_examples': 95000000, 'score': 7253.829390287399, 'total_duration': 29263.937425851822, 'accumulated_submission_time': 7253.829390287399, 'accumulated_eval_time': 22008.066123962402, 'accumulated_logging_time': 1.4838595390319824}
I0306 21:34:36.656330 139586395154176 logging_writer.py:48] [7323] accumulated_eval_time=22008.1, accumulated_logging_time=1.48386, accumulated_submission_time=7253.83, global_step=7323, preemption_count=0, score=7253.83, test/loss=0.128019, test/num_examples=95000000, total_duration=29263.9, train/loss=0.123397, validation/loss=0.125562, validation/num_examples=83274637
I0306 21:35:40.182579 139586403546880 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.009511128067970276, loss=0.12560001015663147
I0306 21:36:37.135692 139741583713472 spec.py:321] Evaluating on the training split.
I0306 21:41:02.939411 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 21:41:10.442996 139741583713472 spec.py:349] Evaluating on the test split.
I0306 21:41:18.967356 139741583713472 submission_runner.py:469] Time since start: 29666.28s, 	Step: 7446, 	{'train/loss': 0.12241017094479417, 'validation/loss': 0.1256024924238412, 'validation/num_examples': 83274637, 'test/loss': 0.12792433690378288, 'test/num_examples': 95000000, 'score': 7374.260226011276, 'total_duration': 29666.27584171295, 'accumulated_submission_time': 7374.260226011276, 'accumulated_eval_time': 22289.89774608612, 'accumulated_logging_time': 1.5477709770202637}
I0306 21:41:19.025635 139586395154176 logging_writer.py:48] [7446] accumulated_eval_time=22289.9, accumulated_logging_time=1.54777, accumulated_submission_time=7374.26, global_step=7446, preemption_count=0, score=7374.26, test/loss=0.127924, test/num_examples=95000000, total_duration=29666.3, train/loss=0.12241, validation/loss=0.125602, validation/num_examples=83274637
I0306 21:41:54.982881 139586403546880 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.008468435145914555, loss=0.12290572375059128
I0306 21:43:18.979096 139741583713472 spec.py:321] Evaluating on the training split.
I0306 21:47:37.940213 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 21:47:45.488903 139741583713472 spec.py:349] Evaluating on the test split.
I0306 21:47:54.113722 139741583713472 submission_runner.py:469] Time since start: 30061.42s, 	Step: 7568, 	{'train/loss': 0.12426576821965242, 'validation/loss': 0.12551228774701084, 'validation/num_examples': 83274637, 'test/loss': 0.12794969594983552, 'test/num_examples': 95000000, 'score': 7494.196544647217, 'total_duration': 30061.42221236229, 'accumulated_submission_time': 7494.196544647217, 'accumulated_eval_time': 22565.032333374023, 'accumulated_logging_time': 1.6129395961761475}
I0306 21:47:54.124755 139586395154176 logging_writer.py:48] [7568] accumulated_eval_time=22565, accumulated_logging_time=1.61294, accumulated_submission_time=7494.2, global_step=7568, preemption_count=0, score=7494.2, test/loss=0.12795, test/num_examples=95000000, total_duration=30061.4, train/loss=0.124266, validation/loss=0.125512, validation/num_examples=83274637
I0306 21:48:03.734326 139586403546880 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.008571543730795383, loss=0.12512582540512085
I0306 21:49:54.294019 139741583713472 spec.py:321] Evaluating on the training split.
I0306 21:54:08.548753 139741583713472 spec.py:333] Evaluating on the validation split.
I0306 21:54:16.061918 139741583713472 spec.py:349] Evaluating on the test split.
I0306 21:54:24.707084 139741583713472 submission_runner.py:469] Time since start: 30452.02s, 	Step: 7688, 	{'train/loss': 0.12274564336399613, 'validation/loss': 0.12584037783532684, 'validation/num_examples': 83274637, 'test/loss': 0.12809429192023025, 'test/num_examples': 95000000, 'score': 7614.344521284103, 'total_duration': 30452.01557445526, 'accumulated_submission_time': 7614.344521284103, 'accumulated_eval_time': 22835.4453625679, 'accumulated_logging_time': 1.6359503269195557}
I0306 21:54:24.717490 139586395154176 logging_writer.py:48] [7688] accumulated_eval_time=22835.4, accumulated_logging_time=1.63595, accumulated_submission_time=7614.34, global_step=7688, preemption_count=0, score=7614.34, test/loss=0.128094, test/num_examples=95000000, total_duration=30452, train/loss=0.122746, validation/loss=0.12584, validation/num_examples=83274637
I0306 21:54:26.124157 139586403546880 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.006375252269208431, loss=0.12452562153339386
I0306 21:56:15.357537 139586395154176 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.006307602860033512, loss=0.12616045773029327
I0306 21:56:26.092602 139586403546880 logging_writer.py:48] [7810] global_step=7810, preemption_count=0, score=7735.67
I0306 21:56:38.044940 139741583713472 submission_runner.py:646] Tuning trial 4/5
I0306 21:56:38.060455 139741583713472 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.0, learning_rate=0.004958460849689891, one_minus_beta1=0.13625575743, beta2=0.6291854735396584, weight_decay=0.1147386261512052, warmup_factor=0.02)
I0306 21:56:38.061930 139741583713472 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/loss': 0.282272958202557, 'validation/loss': 0.28264771428140917, 'validation/num_examples': 83274637, 'test/loss': 0.28344227619243423, 'test/num_examples': 95000000, 'score': 13.341683387756348, 'total_duration': 1156.9131562709808, 'accumulated_submission_time': 13.341683387756348, 'accumulated_eval_time': 1143.5713276863098, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (126, {'train/loss': 0.12999672429788411, 'validation/loss': 0.13111632172806334, 'validation/num_examples': 83274637, 'test/loss': 0.13411261984991776, 'test/num_examples': 95000000, 'score': 135.0787901878357, 'total_duration': 2298.9313271045685, 'accumulated_submission_time': 135.0787901878357, 'accumulated_eval_time': 2163.8306090831757, 'accumulated_logging_time': 0.014921903610229492, 'global_step': 126, 'preemption_count': 0}), (256, {'train/loss': 0.13006798455597096, 'validation/loss': 0.12835991370623784, 'validation/num_examples': 83274637, 'test/loss': 0.1312226576069079, 'test/num_examples': 95000000, 'score': 255.67853450775146, 'total_duration': 3447.463562965393, 'accumulated_submission_time': 255.67853450775146, 'accumulated_eval_time': 3191.741019010544, 'accumulated_logging_time': 0.030080080032348633, 'global_step': 256, 'preemption_count': 0}), (386, {'train/loss': 0.1261218050787659, 'validation/loss': 0.12815289094710908, 'validation/num_examples': 83274637, 'test/loss': 0.1307500091899671, 'test/num_examples': 95000000, 'score': 377.446439743042, 'total_duration': 4573.135908842087, 'accumulated_submission_time': 377.446439743042, 'accumulated_eval_time': 4195.623357057571, 'accumulated_logging_time': 0.046097517013549805, 'global_step': 386, 'preemption_count': 0}), (515, {'train/loss': 0.1260364472561475, 'validation/loss': 0.12732653542011987, 'validation/num_examples': 83274637, 'test/loss': 0.1299051206928454, 'test/num_examples': 95000000, 'score': 497.7419390678406, 'total_duration': 5666.119196653366, 'accumulated_submission_time': 497.7419390678406, 'accumulated_eval_time': 5168.289000034332, 'accumulated_logging_time': 0.060677289962768555, 'global_step': 515, 'preemption_count': 0}), (641, {'train/loss': 0.1244807955252487, 'validation/loss': 0.12762718188929556, 'validation/num_examples': 83274637, 'test/loss': 0.13005131616981908, 'test/num_examples': 95000000, 'score': 618.6847295761108, 'total_duration': 6759.792283773422, 'accumulated_submission_time': 618.6847295761108, 'accumulated_eval_time': 6140.9981598854065, 'accumulated_logging_time': 0.0747370719909668, 'global_step': 641, 'preemption_count': 0}), (762, {'train/loss': 0.12789656356586226, 'validation/loss': 0.12799306240802796, 'validation/num_examples': 83274637, 'test/loss': 0.1305214832236842, 'test/num_examples': 95000000, 'score': 738.6686789989471, 'total_duration': 7779.091667175293, 'accumulated_submission_time': 738.6686789989471, 'accumulated_eval_time': 7040.29291844368, 'accumulated_logging_time': 0.08887553215026855, 'global_step': 762, 'preemption_count': 0}), (886, {'train/loss': 0.12371010316898988, 'validation/loss': 0.1270597441544818, 'validation/num_examples': 83274637, 'test/loss': 0.1294516341694079, 'test/num_examples': 95000000, 'score': 859.5674810409546, 'total_duration': 8699.75725889206, 'accumulated_submission_time': 859.5674810409546, 'accumulated_eval_time': 7840.038144350052, 'accumulated_logging_time': 0.10348677635192871, 'global_step': 886, 'preemption_count': 0}), (1014, {'train/loss': 0.12528246717304928, 'validation/loss': 0.12663186698561502, 'validation/num_examples': 83274637, 'test/loss': 0.12914055090460527, 'test/num_examples': 95000000, 'score': 980.4659984111786, 'total_duration': 9422.548312664032, 'accumulated_submission_time': 980.4659984111786, 'accumulated_eval_time': 8441.891604661942, 'accumulated_logging_time': 0.13507342338562012, 'global_step': 1014, 'preemption_count': 0}), (1138, {'train/loss': 0.127204049214627, 'validation/loss': 0.12650956181188833, 'validation/num_examples': 83274637, 'test/loss': 0.1288860939555921, 'test/num_examples': 95000000, 'score': 1101.0632538795471, 'total_duration': 9795.353886604309, 'accumulated_submission_time': 1101.0632538795471, 'accumulated_eval_time': 8694.069162368774, 'accumulated_logging_time': 0.15488100051879883, 'global_step': 1138, 'preemption_count': 0}), (1259, {'train/loss': 0.1242175400139963, 'validation/loss': 0.12635788981870053, 'validation/num_examples': 83274637, 'test/loss': 0.12854995285773027, 'test/num_examples': 95000000, 'score': 1221.76620054245, 'total_duration': 10176.119544267654, 'accumulated_submission_time': 1221.76620054245, 'accumulated_eval_time': 8954.107259511948, 'accumulated_logging_time': 0.1698441505432129, 'global_step': 1259, 'preemption_count': 0}), (1378, {'train/loss': 0.12451034486762383, 'validation/loss': 0.12635626809048903, 'validation/num_examples': 83274637, 'test/loss': 0.12881774642269736, 'test/num_examples': 95000000, 'score': 1342.1446273326874, 'total_duration': 10556.717004299164, 'accumulated_submission_time': 1342.1446273326874, 'accumulated_eval_time': 9214.300951957703, 'accumulated_logging_time': 0.18499755859375, 'global_step': 1378, 'preemption_count': 0}), (1500, {'train/loss': 0.12772886069643796, 'validation/loss': 0.12668955456938263, 'validation/num_examples': 83274637, 'test/loss': 0.12908647073396382, 'test/num_examples': 95000000, 'score': 1463.0276458263397, 'total_duration': 10938.84181022644, 'accumulated_submission_time': 1463.0276458263397, 'accumulated_eval_time': 9475.517084121704, 'accumulated_logging_time': 0.20026516914367676, 'global_step': 1500, 'preemption_count': 0}), (1624, {'train/loss': 0.1250373355505414, 'validation/loss': 0.12631070111034753, 'validation/num_examples': 83274637, 'test/loss': 0.12871096724917763, 'test/num_examples': 95000000, 'score': 1584.081259727478, 'total_duration': 11323.703803539276, 'accumulated_submission_time': 1584.081259727478, 'accumulated_eval_time': 9739.291018009186, 'accumulated_logging_time': 0.22556781768798828, 'global_step': 1624, 'preemption_count': 0}), (1745, {'train/loss': 0.12366106210030475, 'validation/loss': 0.12613881593261628, 'validation/num_examples': 83274637, 'test/loss': 0.12859395484169409, 'test/num_examples': 95000000, 'score': 1704.983387708664, 'total_duration': 11705.432455062866, 'accumulated_submission_time': 1704.983387708664, 'accumulated_eval_time': 10000.094016551971, 'accumulated_logging_time': 0.24012470245361328, 'global_step': 1745, 'preemption_count': 0}), (1866, {'train/loss': 0.12498618575668186, 'validation/loss': 0.12615725013560777, 'validation/num_examples': 83274637, 'test/loss': 0.1285923769120066, 'test/num_examples': 95000000, 'score': 1825.2816543579102, 'total_duration': 12088.88893032074, 'accumulated_submission_time': 1825.2816543579102, 'accumulated_eval_time': 10263.197251558304, 'accumulated_logging_time': 0.2848172187805176, 'global_step': 1866, 'preemption_count': 0}), (1987, {'train/loss': 0.12436646300385583, 'validation/loss': 0.12613992440478156, 'validation/num_examples': 83274637, 'test/loss': 0.12854697703536183, 'test/num_examples': 95000000, 'score': 1946.1127998828888, 'total_duration': 12471.489869832993, 'accumulated_submission_time': 1946.1127998828888, 'accumulated_eval_time': 10524.941573619843, 'accumulated_logging_time': 0.3011343479156494, 'global_step': 1987, 'preemption_count': 0}), (2107, {'train/loss': 0.12745250719335843, 'validation/loss': 0.12627126545079162, 'validation/num_examples': 83274637, 'test/loss': 0.12851190673314145, 'test/num_examples': 95000000, 'score': 2066.966822862625, 'total_duration': 12853.007566690445, 'accumulated_submission_time': 2066.966822862625, 'accumulated_eval_time': 10785.580021381378, 'accumulated_logging_time': 0.3164823055267334, 'global_step': 2107, 'preemption_count': 0}), (2230, {'train/loss': 0.1264003168955539, 'validation/loss': 0.12670095754449595, 'validation/num_examples': 83274637, 'test/loss': 0.12896157864925986, 'test/num_examples': 95000000, 'score': 2187.684054851532, 'total_duration': 13233.006223678589, 'accumulated_submission_time': 2187.684054851532, 'accumulated_eval_time': 11044.835451602936, 'accumulated_logging_time': 0.3327782154083252, 'global_step': 2230, 'preemption_count': 0}), (2350, {'train/loss': 0.12688149005736946, 'validation/loss': 0.12603120770452142, 'validation/num_examples': 83274637, 'test/loss': 0.1283598838096217, 'test/num_examples': 95000000, 'score': 2308.306625366211, 'total_duration': 13615.400626659393, 'accumulated_submission_time': 2308.306625366211, 'accumulated_eval_time': 11306.583141088486, 'accumulated_logging_time': 0.3474009037017822, 'global_step': 2350, 'preemption_count': 0}), (2470, {'train/loss': 0.12308485828246335, 'validation/loss': 0.1260623209923993, 'validation/num_examples': 83274637, 'test/loss': 0.12824631155427632, 'test/num_examples': 95000000, 'score': 2428.4787361621857, 'total_duration': 13993.147387742996, 'accumulated_submission_time': 2428.4787361621857, 'accumulated_eval_time': 11564.131711959839, 'accumulated_logging_time': 0.36328577995300293, 'global_step': 2470, 'preemption_count': 0}), (2592, {'train/loss': 0.12699587688834038, 'validation/loss': 0.1268362669168705, 'validation/num_examples': 83274637, 'test/loss': 0.12897636655016448, 'test/num_examples': 95000000, 'score': 2548.917779445648, 'total_duration': 14372.343301057816, 'accumulated_submission_time': 2548.917779445648, 'accumulated_eval_time': 11822.803822278976, 'accumulated_logging_time': 0.43771815299987793, 'global_step': 2592, 'preemption_count': 0}), (2708, {'train/loss': 0.12393083546380952, 'validation/loss': 0.1258454674514785, 'validation/num_examples': 83274637, 'test/loss': 0.12830010633223685, 'test/num_examples': 95000000, 'score': 2669.5208237171173, 'total_duration': 14749.057276248932, 'accumulated_submission_time': 2669.5208237171173, 'accumulated_eval_time': 12078.889225244522, 'accumulated_logging_time': 0.4545304775238037, 'global_step': 2708, 'preemption_count': 0}), (2830, {'train/loss': 0.1258178987780457, 'validation/loss': 0.1263542623554719, 'validation/num_examples': 83274637, 'test/loss': 0.12866970249794407, 'test/num_examples': 95000000, 'score': 2790.493356704712, 'total_duration': 15127.042461633682, 'accumulated_submission_time': 2790.493356704712, 'accumulated_eval_time': 12335.874051809311, 'accumulated_logging_time': 0.47228503227233887, 'global_step': 2830, 'preemption_count': 0}), (2952, {'train/loss': 0.12568868303074027, 'validation/loss': 0.1257793649523335, 'validation/num_examples': 83274637, 'test/loss': 0.12820666162623356, 'test/num_examples': 95000000, 'score': 2911.9611904621124, 'total_duration': 15503.60411477089, 'accumulated_submission_time': 2911.9611904621124, 'accumulated_eval_time': 12590.941601514816, 'accumulated_logging_time': 0.4888918399810791, 'global_step': 2952, 'preemption_count': 0}), (3074, {'train/loss': 0.12481504094160203, 'validation/loss': 0.12642507119690108, 'validation/num_examples': 83274637, 'test/loss': 0.12891772701480264, 'test/num_examples': 95000000, 'score': 3032.6177990436554, 'total_duration': 15880.891729354858, 'accumulated_submission_time': 3032.6177990436554, 'accumulated_eval_time': 12847.526772022247, 'accumulated_logging_time': 0.5255701541900635, 'global_step': 3074, 'preemption_count': 0}), (3194, {'train/loss': 0.12504799496499622, 'validation/loss': 0.12603062306030188, 'validation/num_examples': 83274637, 'test/loss': 0.12838224242393093, 'test/num_examples': 95000000, 'score': 3152.8113322257996, 'total_duration': 16262.072271823883, 'accumulated_submission_time': 3152.8113322257996, 'accumulated_eval_time': 13108.48831152916, 'accumulated_logging_time': 0.541447639465332, 'global_step': 3194, 'preemption_count': 0}), (3316, {'train/loss': 0.1236658809976008, 'validation/loss': 0.1258818195054846, 'validation/num_examples': 83274637, 'test/loss': 0.12836212906044409, 'test/num_examples': 95000000, 'score': 3273.1058309078217, 'total_duration': 16639.369038820267, 'accumulated_submission_time': 3273.1058309078217, 'accumulated_eval_time': 13365.462871551514, 'accumulated_logging_time': 0.5596010684967041, 'global_step': 3316, 'preemption_count': 0}), (3437, {'train/loss': 0.12459053244418318, 'validation/loss': 0.12578239763334242, 'validation/num_examples': 83274637, 'test/loss': 0.12809279498355264, 'test/num_examples': 95000000, 'score': 3393.880096435547, 'total_duration': 17020.314460754395, 'accumulated_submission_time': 3393.880096435547, 'accumulated_eval_time': 13625.510554552078, 'accumulated_logging_time': 0.6732621192932129, 'global_step': 3437, 'preemption_count': 0}), (3562, {'train/loss': 0.1244047453638705, 'validation/loss': 0.1268226731193414, 'validation/num_examples': 83274637, 'test/loss': 0.12918453678042763, 'test/num_examples': 95000000, 'score': 3513.8658657073975, 'total_duration': 17398.49969315529, 'accumulated_submission_time': 3513.8658657073975, 'accumulated_eval_time': 13883.683850049973, 'accumulated_logging_time': 0.6898338794708252, 'global_step': 3562, 'preemption_count': 0}), (3683, {'train/loss': 0.12535061730575636, 'validation/loss': 0.12631383837869506, 'validation/num_examples': 83274637, 'test/loss': 0.1287052408408717, 'test/num_examples': 95000000, 'score': 3633.8595695495605, 'total_duration': 17776.54945230484, 'accumulated_submission_time': 3633.8595695495605, 'accumulated_eval_time': 14141.713231086731, 'accumulated_logging_time': 0.7070825099945068, 'global_step': 3683, 'preemption_count': 0}), (3806, {'train/loss': 0.12470675744819192, 'validation/loss': 0.12597128101237437, 'validation/num_examples': 83274637, 'test/loss': 0.1283021312705592, 'test/num_examples': 95000000, 'score': 3754.6869356632233, 'total_duration': 18153.75105881691, 'accumulated_submission_time': 3754.6869356632233, 'accumulated_eval_time': 14398.061934947968, 'accumulated_logging_time': 0.723304033279419, 'global_step': 3806, 'preemption_count': 0}), (3928, {'train/loss': 0.12653499000571058, 'validation/loss': 0.1258085412489268, 'validation/num_examples': 83274637, 'test/loss': 0.12824011981907896, 'test/num_examples': 95000000, 'score': 3874.865843296051, 'total_duration': 18535.9907913208, 'accumulated_submission_time': 3874.865843296051, 'accumulated_eval_time': 14660.035930156708, 'accumulated_logging_time': 0.8000786304473877, 'global_step': 3928, 'preemption_count': 0}), (4052, {'train/loss': 0.12568389242456393, 'validation/loss': 0.12575782390085838, 'validation/num_examples': 83274637, 'test/loss': 0.12810407335526316, 'test/num_examples': 95000000, 'score': 3995.431747674942, 'total_duration': 18918.600642442703, 'accumulated_submission_time': 3995.431747674942, 'accumulated_eval_time': 14922.053304195404, 'accumulated_logging_time': 0.8160898685455322, 'global_step': 4052, 'preemption_count': 0}), (4173, {'train/loss': 0.12269307045066881, 'validation/loss': 0.1254695758481755, 'validation/num_examples': 83274637, 'test/loss': 0.12779053110608551, 'test/num_examples': 95000000, 'score': 4115.607710599899, 'total_duration': 19302.88126850128, 'accumulated_submission_time': 4115.607710599899, 'accumulated_eval_time': 15186.130242109299, 'accumulated_logging_time': 0.8333010673522949, 'global_step': 4173, 'preemption_count': 0}), (4297, {'train/loss': 0.12698364667828727, 'validation/loss': 0.1259272388249798, 'validation/num_examples': 83274637, 'test/loss': 0.12821790416324014, 'test/num_examples': 95000000, 'score': 4236.967695236206, 'total_duration': 19681.99223923683, 'accumulated_submission_time': 4236.967695236206, 'accumulated_eval_time': 15443.85470032692, 'accumulated_logging_time': 0.8502106666564941, 'global_step': 4297, 'preemption_count': 0}), (4420, {'train/loss': 0.12696912171283983, 'validation/loss': 0.1257354805284043, 'validation/num_examples': 83274637, 'test/loss': 0.12808818682154605, 'test/num_examples': 95000000, 'score': 4357.671516895294, 'total_duration': 20062.106290340424, 'accumulated_submission_time': 4357.671516895294, 'accumulated_eval_time': 15703.23052930832, 'accumulated_logging_time': 0.875063419342041, 'global_step': 4420, 'preemption_count': 0}), (4542, {'train/loss': 0.12638715940451473, 'validation/loss': 0.12589122267944786, 'validation/num_examples': 83274637, 'test/loss': 0.12824855442023025, 'test/num_examples': 95000000, 'score': 4478.7572503089905, 'total_duration': 20440.154856204987, 'accumulated_submission_time': 4478.7572503089905, 'accumulated_eval_time': 15960.16644001007, 'accumulated_logging_time': 0.8923861980438232, 'global_step': 4542, 'preemption_count': 0}), (4659, {'train/loss': 0.12477994132669842, 'validation/loss': 0.12618308752964377, 'validation/num_examples': 83274637, 'test/loss': 0.12864559777960527, 'test/num_examples': 95000000, 'score': 4598.968495607376, 'total_duration': 20822.70534968376, 'accumulated_submission_time': 4598.968495607376, 'accumulated_eval_time': 16222.479678153992, 'accumulated_logging_time': 0.9090416431427002, 'global_step': 4659, 'preemption_count': 0}), (4778, {'train/loss': 0.12265969064297541, 'validation/loss': 0.12614884013384756, 'validation/num_examples': 83274637, 'test/loss': 0.12849038349095396, 'test/num_examples': 95000000, 'score': 4719.909432649612, 'total_duration': 21204.189455986023, 'accumulated_submission_time': 4719.909432649612, 'accumulated_eval_time': 16482.97989845276, 'accumulated_logging_time': 0.9426331520080566, 'global_step': 4778, 'preemption_count': 0}), (4902, {'train/loss': 0.12464921948435546, 'validation/loss': 0.12577629679711932, 'validation/num_examples': 83274637, 'test/loss': 0.12821805612664475, 'test/num_examples': 95000000, 'score': 4839.901934862137, 'total_duration': 21582.503754615784, 'accumulated_submission_time': 4839.901934862137, 'accumulated_eval_time': 16741.261640310287, 'accumulated_logging_time': 0.9735267162322998, 'global_step': 4902, 'preemption_count': 0}), (5023, {'train/loss': 0.12327688707495635, 'validation/loss': 0.12574381298531095, 'validation/num_examples': 83274637, 'test/loss': 0.12800796879111842, 'test/num_examples': 95000000, 'score': 4960.692188978195, 'total_duration': 21963.156934976578, 'accumulated_submission_time': 4960.692188978195, 'accumulated_eval_time': 17001.099102020264, 'accumulated_logging_time': 0.9897208213806152, 'global_step': 5023, 'preemption_count': 0}), (5145, {'train/loss': 0.12485084012619355, 'validation/loss': 0.12624917103689612, 'validation/num_examples': 83274637, 'test/loss': 0.12868462138157893, 'test/num_examples': 95000000, 'score': 5081.601266384125, 'total_duration': 22343.466903686523, 'accumulated_submission_time': 5081.601266384125, 'accumulated_eval_time': 17260.472615003586, 'accumulated_logging_time': 1.0068590641021729, 'global_step': 5145, 'preemption_count': 0}), (5267, {'train/loss': 0.12632506168535296, 'validation/loss': 0.12599038413574268, 'validation/num_examples': 83274637, 'test/loss': 0.12832354808799343, 'test/num_examples': 95000000, 'score': 5203.159546613693, 'total_duration': 22722.964490175247, 'accumulated_submission_time': 5203.159546613693, 'accumulated_eval_time': 17518.348359823227, 'accumulated_logging_time': 1.0604655742645264, 'global_step': 5267, 'preemption_count': 0}), (5388, {'train/loss': 0.12526775143290841, 'validation/loss': 0.12561764606615006, 'validation/num_examples': 83274637, 'test/loss': 0.12812283112664474, 'test/num_examples': 95000000, 'score': 5323.804430961609, 'total_duration': 23101.873996973038, 'accumulated_submission_time': 5323.804430961609, 'accumulated_eval_time': 17776.58159661293, 'accumulated_logging_time': 1.0821373462677002, 'global_step': 5388, 'preemption_count': 0}), (5509, {'train/loss': 0.12680104903220754, 'validation/loss': 0.12569544929505555, 'validation/num_examples': 83274637, 'test/loss': 0.12809435543791117, 'test/num_examples': 95000000, 'score': 5444.345999240875, 'total_duration': 23482.84630703926, 'accumulated_submission_time': 5444.345999240875, 'accumulated_eval_time': 18036.986972332, 'accumulated_logging_time': 1.0977916717529297, 'global_step': 5509, 'preemption_count': 0}), (5630, {'train/loss': 0.12456868281997975, 'validation/loss': 0.1256574490567034, 'validation/num_examples': 83274637, 'test/loss': 0.12803843530016448, 'test/num_examples': 95000000, 'score': 5566.09533572197, 'total_duration': 23859.735318422318, 'accumulated_submission_time': 5566.09533572197, 'accumulated_eval_time': 18292.05339884758, 'accumulated_logging_time': 1.1607139110565186, 'global_step': 5630, 'preemption_count': 0}), (5750, {'train/loss': 0.12382096513730925, 'validation/loss': 0.12567398914822236, 'validation/num_examples': 83274637, 'test/loss': 0.12803714524054277, 'test/num_examples': 95000000, 'score': 5686.1911833286285, 'total_duration': 24236.183702230453, 'accumulated_submission_time': 5686.1911833286285, 'accumulated_eval_time': 18548.379441976547, 'accumulated_logging_time': 1.177520513534546, 'global_step': 5750, 'preemption_count': 0}), (5871, {'train/loss': 0.12510254119271003, 'validation/loss': 0.12578198269068447, 'validation/num_examples': 83274637, 'test/loss': 0.1282051566509046, 'test/num_examples': 95000000, 'score': 5807.14034986496, 'total_duration': 24615.78493642807, 'accumulated_submission_time': 5807.14034986496, 'accumulated_eval_time': 18807.005523443222, 'accumulated_logging_time': 1.1936192512512207, 'global_step': 5871, 'preemption_count': 0}), (5993, {'train/loss': 0.12448980490554054, 'validation/loss': 0.1256967051815999, 'validation/num_examples': 83274637, 'test/loss': 0.12812944578536184, 'test/num_examples': 95000000, 'score': 5927.53692984581, 'total_duration': 24990.914792060852, 'accumulated_submission_time': 5927.53692984581, 'accumulated_eval_time': 19061.69675898552, 'accumulated_logging_time': 1.2263460159301758, 'global_step': 5993, 'preemption_count': 0}), (6114, {'train/loss': 0.12465095833974814, 'validation/loss': 0.1252764553421196, 'validation/num_examples': 83274637, 'test/loss': 0.1276398462890625, 'test/num_examples': 95000000, 'score': 6048.871542692184, 'total_duration': 25371.23785686493, 'accumulated_submission_time': 6048.871542692184, 'accumulated_eval_time': 19320.657624959946, 'accumulated_logging_time': 1.2442617416381836, 'global_step': 6114, 'preemption_count': 0}), (6233, {'train/loss': 0.1253449093761309, 'validation/loss': 0.12557887151678232, 'validation/num_examples': 83274637, 'test/loss': 0.12790004544613487, 'test/num_examples': 95000000, 'score': 6169.373729944229, 'total_duration': 25752.969297647476, 'accumulated_submission_time': 6169.373729944229, 'accumulated_eval_time': 19581.861757278442, 'accumulated_logging_time': 1.2604591846466064, 'global_step': 6233, 'preemption_count': 0}), (6353, {'train/loss': 0.12655389035975784, 'validation/loss': 0.12529855346761373, 'validation/num_examples': 83274637, 'test/loss': 0.12749788304893092, 'test/num_examples': 95000000, 'score': 6289.65657043457, 'total_duration': 26146.294159412384, 'accumulated_submission_time': 6289.65657043457, 'accumulated_eval_time': 19854.864185094833, 'accumulated_logging_time': 1.2909252643585205, 'global_step': 6353, 'preemption_count': 0}), (6474, {'train/loss': 0.1229663066355125, 'validation/loss': 0.12601454799163708, 'validation/num_examples': 83274637, 'test/loss': 0.12841258800370065, 'test/num_examples': 95000000, 'score': 6410.774411439896, 'total_duration': 26534.9219455719, 'accumulated_submission_time': 6410.774411439896, 'accumulated_eval_time': 20122.344017744064, 'accumulated_logging_time': 1.3115222454071045, 'global_step': 6474, 'preemption_count': 0}), (6596, {'train/loss': 0.12507717116917455, 'validation/loss': 0.12557887685843538, 'validation/num_examples': 83274637, 'test/loss': 0.12789581968544408, 'test/num_examples': 95000000, 'score': 6530.813458442688, 'total_duration': 26932.057738780975, 'accumulated_submission_time': 6530.813458442688, 'accumulated_eval_time': 20399.39789223671, 'accumulated_logging_time': 1.344653844833374, 'global_step': 6596, 'preemption_count': 0}), (6715, {'train/loss': 0.12509108167258823, 'validation/loss': 0.1256729983155578, 'validation/num_examples': 83274637, 'test/loss': 0.1279736484683388, 'test/num_examples': 95000000, 'score': 6651.228821992874, 'total_duration': 27325.578598976135, 'accumulated_submission_time': 6651.228821992874, 'accumulated_eval_time': 20672.478076457977, 'accumulated_logging_time': 1.3604135513305664, 'global_step': 6715, 'preemption_count': 0}), (6835, {'train/loss': 0.12510103577712797, 'validation/loss': 0.12551450005917242, 'validation/num_examples': 83274637, 'test/loss': 0.1278249972861842, 'test/num_examples': 95000000, 'score': 6771.454652786255, 'total_duration': 27711.4808447361, 'accumulated_submission_time': 6771.454652786255, 'accumulated_eval_time': 20938.114963054657, 'accumulated_logging_time': 1.3909761905670166, 'global_step': 6835, 'preemption_count': 0}), (6956, {'train/loss': 0.12403672261151878, 'validation/loss': 0.12553594497848314, 'validation/num_examples': 83274637, 'test/loss': 0.12780348682154605, 'test/num_examples': 95000000, 'score': 6891.583950281143, 'total_duration': 28100.441013097763, 'accumulated_submission_time': 6891.583950281143, 'accumulated_eval_time': 21206.91313648224, 'accumulated_logging_time': 1.4142823219299316, 'global_step': 6956, 'preemption_count': 0}), (7079, {'train/loss': 0.12467854129115366, 'validation/loss': 0.12548431712776859, 'validation/num_examples': 83274637, 'test/loss': 0.12781018659539473, 'test/num_examples': 95000000, 'score': 7012.263591766357, 'total_duration': 28486.207248449326, 'accumulated_submission_time': 7012.263591766357, 'accumulated_eval_time': 21471.954178094864, 'accumulated_logging_time': 1.4502265453338623, 'global_step': 7079, 'preemption_count': 0}), (7202, {'train/loss': 0.12509194849375285, 'validation/loss': 0.1256185042135601, 'validation/num_examples': 83274637, 'test/loss': 0.12794321899671052, 'test/num_examples': 95000000, 'score': 7133.479174852371, 'total_duration': 28872.78255701065, 'accumulated_submission_time': 7133.479174852371, 'accumulated_eval_time': 21737.286844730377, 'accumulated_logging_time': 1.4676928520202637, 'global_step': 7202, 'preemption_count': 0}), (7323, {'train/loss': 0.12339738007845744, 'validation/loss': 0.12556163948476592, 'validation/num_examples': 83274637, 'test/loss': 0.12801922367393093, 'test/num_examples': 95000000, 'score': 7253.829390287399, 'total_duration': 29263.937425851822, 'accumulated_submission_time': 7253.829390287399, 'accumulated_eval_time': 22008.066123962402, 'accumulated_logging_time': 1.4838595390319824, 'global_step': 7323, 'preemption_count': 0}), (7446, {'train/loss': 0.12241017094479417, 'validation/loss': 0.1256024924238412, 'validation/num_examples': 83274637, 'test/loss': 0.12792433690378288, 'test/num_examples': 95000000, 'score': 7374.260226011276, 'total_duration': 29666.27584171295, 'accumulated_submission_time': 7374.260226011276, 'accumulated_eval_time': 22289.89774608612, 'accumulated_logging_time': 1.5477709770202637, 'global_step': 7446, 'preemption_count': 0}), (7568, {'train/loss': 0.12426576821965242, 'validation/loss': 0.12551228774701084, 'validation/num_examples': 83274637, 'test/loss': 0.12794969594983552, 'test/num_examples': 95000000, 'score': 7494.196544647217, 'total_duration': 30061.42221236229, 'accumulated_submission_time': 7494.196544647217, 'accumulated_eval_time': 22565.032333374023, 'accumulated_logging_time': 1.6129395961761475, 'global_step': 7568, 'preemption_count': 0}), (7688, {'train/loss': 0.12274564336399613, 'validation/loss': 0.12584037783532684, 'validation/num_examples': 83274637, 'test/loss': 0.12809429192023025, 'test/num_examples': 95000000, 'score': 7614.344521284103, 'total_duration': 30452.01557445526, 'accumulated_submission_time': 7614.344521284103, 'accumulated_eval_time': 22835.4453625679, 'accumulated_logging_time': 1.6359503269195557, 'global_step': 7688, 'preemption_count': 0})], 'global_step': 7810}
I0306 21:56:38.062071 139741583713472 submission_runner.py:649] Timing: 7735.667217254639
I0306 21:56:38.062110 139741583713472 submission_runner.py:651] Total number of evals: 64
I0306 21:56:38.062138 139741583713472 submission_runner.py:652] ====================
I0306 21:56:38.062312 139741583713472 submission_runner.py:750] Final criteo1tb score: 3
