python submission_runner.py --framework=jax --workload=criteo1tb --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_2 --overwrite=True --save_checkpoints=False --rng_seed=1251262266 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=2 --hparam_end_index=3 2>&1 | tee -a /logs/criteo1tb_jax_03-06-2025-13-09-49.log
2025-03-06 13:10:06.837222: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741266607.276604       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741266607.494759       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0306 13:10:55.602226 140509305742528 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax.
I0306 13:10:58.675977 140509305742528 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0306 13:10:58.678876 140509305742528 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0306 13:10:58.720003 140509305742528 submission_runner.py:606] Using RNG seed 1251262266
I0306 13:11:01.747947 140509305742528 submission_runner.py:615] --- Tuning run 3/5 ---
I0306 13:11:01.748142 140509305742528 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_3.
I0306 13:11:01.748329 140509305742528 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_3/hparams.json.
I0306 13:11:01.989122 140509305742528 submission_runner.py:218] Initializing dataset.
I0306 13:11:01.989314 140509305742528 submission_runner.py:229] Initializing model.
I0306 13:11:11.949101 140509305742528 submission_runner.py:272] Initializing optimizer.
I0306 13:11:12.623272 140509305742528 submission_runner.py:279] Initializing metrics bundle.
I0306 13:11:12.623531 140509305742528 submission_runner.py:301] Initializing checkpoint and logger.
I0306 13:11:12.624349 140509305742528 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_3 with prefix checkpoint_
I0306 13:11:12.624454 140509305742528 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_3/meta_data_0.json.
I0306 13:11:12.624611 140509305742528 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0306 13:11:12.624656 140509305742528 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0306 13:11:13.150689 140509305742528 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_3/flags_0.json.
I0306 13:11:13.813729 140509305742528 submission_runner.py:337] Starting training loop.
I0306 13:11:31.195231 140369144551168 logging_writer.py:48] [0] global_step=0, grad_norm=6.449529647827148, loss=0.9864252805709839
I0306 13:11:31.541724 140509305742528 spec.py:321] Evaluating on the training split.
I0306 13:17:45.440914 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 13:24:01.136237 140509305742528 spec.py:349] Evaluating on the test split.
I0306 13:31:04.305598 140509305742528 submission_runner.py:469] Time since start: 1190.49s, 	Step: 1, 	{'train/loss': 0.9870146346167199, 'validation/loss': 0.9862271805163347, 'validation/num_examples': 83274637, 'test/loss': 0.985843563569079, 'test/num_examples': 95000000, 'score': 17.72789716720581, 'total_duration': 1190.4917731285095, 'accumulated_submission_time': 17.72789716720581, 'accumulated_eval_time': 1172.76375746727, 'accumulated_logging_time': 0}
I0306 13:31:04.341090 140356637157120 logging_writer.py:48] [1] accumulated_eval_time=1172.76, accumulated_logging_time=0, accumulated_submission_time=17.7279, global_step=1, preemption_count=0, score=17.7279, test/loss=0.985844, test/num_examples=95000000, total_duration=1190.49, train/loss=0.987015, validation/loss=0.986227, validation/num_examples=83274637
I0306 13:32:35.662721 140356628764416 logging_writer.py:48] [100] global_step=100, grad_norm=0.16795314848423004, loss=0.15203344821929932
I0306 13:33:05.081266 140509305742528 spec.py:321] Evaluating on the training split.
I0306 13:38:55.758690 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 13:44:22.134735 140509305742528 spec.py:349] Evaluating on the test split.
I0306 13:50:34.760996 140509305742528 submission_runner.py:469] Time since start: 2360.95s, 	Step: 124, 	{'train/loss': 0.14307794647303018, 'validation/loss': 0.14277844433636086, 'validation/num_examples': 83274637, 'test/loss': 0.14598290960115132, 'test/num_examples': 95000000, 'score': 138.4297993183136, 'total_duration': 2360.947211265564, 'accumulated_submission_time': 138.4297993183136, 'accumulated_eval_time': 2222.443418979645, 'accumulated_logging_time': 0.06685161590576172}
I0306 13:50:34.772026 140356637157120 logging_writer.py:48] [124] accumulated_eval_time=2222.44, accumulated_logging_time=0.0668516, accumulated_submission_time=138.43, global_step=124, preemption_count=0, score=138.43, test/loss=0.145983, test/num_examples=95000000, total_duration=2360.95, train/loss=0.143078, validation/loss=0.142778, validation/num_examples=83274637
I0306 13:51:39.309980 140356628764416 logging_writer.py:48] [200] global_step=200, grad_norm=0.009324003010988235, loss=0.12800461053848267
I0306 13:52:35.654899 140509305742528 spec.py:321] Evaluating on the training split.
I0306 13:58:36.370888 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 14:03:47.060041 140509305742528 spec.py:349] Evaluating on the test split.
I0306 14:09:51.843123 140509305742528 submission_runner.py:469] Time since start: 3518.03s, 	Step: 245, 	{'train/loss': 0.13053450523729218, 'validation/loss': 0.13068818285337813, 'validation/num_examples': 83274637, 'test/loss': 0.13347282935855262, 'test/num_examples': 95000000, 'score': 259.29946541786194, 'total_duration': 3518.0293073654175, 'accumulated_submission_time': 259.29946541786194, 'accumulated_eval_time': 3258.631545305252, 'accumulated_logging_time': 0.08512091636657715}
I0306 14:09:51.852499 140356637157120 logging_writer.py:48] [245] accumulated_eval_time=3258.63, accumulated_logging_time=0.0851209, accumulated_submission_time=259.299, global_step=245, preemption_count=0, score=259.299, test/loss=0.133473, test/num_examples=95000000, total_duration=3518.03, train/loss=0.130535, validation/loss=0.130688, validation/num_examples=83274637
I0306 14:10:28.030801 140356628764416 logging_writer.py:48] [300] global_step=300, grad_norm=0.010302708484232426, loss=0.12253127992153168
I0306 14:11:52.765037 140509305742528 spec.py:321] Evaluating on the training split.
I0306 14:17:42.301513 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 14:22:43.955632 140509305742528 spec.py:349] Evaluating on the test split.
I0306 14:28:42.109070 140509305742528 submission_runner.py:469] Time since start: 4648.30s, 	Step: 369, 	{'train/loss': 0.12754434197203918, 'validation/loss': 0.1282757396677488, 'validation/num_examples': 83274637, 'test/loss': 0.13091664190995067, 'test/num_examples': 95000000, 'score': 380.1980209350586, 'total_duration': 4648.295297622681, 'accumulated_submission_time': 380.1980209350586, 'accumulated_eval_time': 4267.975531101227, 'accumulated_logging_time': 0.10165786743164062}
I0306 14:28:42.117297 140356637157120 logging_writer.py:48] [369] accumulated_eval_time=4267.98, accumulated_logging_time=0.101658, accumulated_submission_time=380.198, global_step=369, preemption_count=0, score=380.198, test/loss=0.130917, test/num_examples=95000000, total_duration=4648.3, train/loss=0.127544, validation/loss=0.128276, validation/num_examples=83274637
I0306 14:28:49.467566 140356628764416 logging_writer.py:48] [400] global_step=400, grad_norm=0.022562628611922264, loss=0.12786021828651428
I0306 14:30:42.133984 140509305742528 spec.py:321] Evaluating on the training split.
I0306 14:36:35.949857 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 14:41:54.868183 140509305742528 spec.py:349] Evaluating on the test split.
I0306 14:47:59.689252 140509305742528 submission_runner.py:469] Time since start: 5805.88s, 	Step: 494, 	{'train/loss': 0.12870058463007775, 'validation/loss': 0.12785489244265258, 'validation/num_examples': 83274637, 'test/loss': 0.13028595790501646, 'test/num_examples': 95000000, 'score': 500.134396314621, 'total_duration': 5805.875465869904, 'accumulated_submission_time': 500.134396314621, 'accumulated_eval_time': 5305.530732870102, 'accumulated_logging_time': 0.1841130256652832}
I0306 14:47:59.697950 140356637157120 logging_writer.py:48] [494] accumulated_eval_time=5305.53, accumulated_logging_time=0.184113, accumulated_submission_time=500.134, global_step=494, preemption_count=0, score=500.134, test/loss=0.130286, test/num_examples=95000000, total_duration=5805.88, train/loss=0.128701, validation/loss=0.127855, validation/num_examples=83274637
I0306 14:48:00.441287 140356628764416 logging_writer.py:48] [500] global_step=500, grad_norm=0.028590843081474304, loss=0.12668904662132263
I0306 14:49:38.098955 140356637157120 logging_writer.py:48] [600] global_step=600, grad_norm=0.028087323531508446, loss=0.13053369522094727
I0306 14:50:00.367568 140509305742528 spec.py:321] Evaluating on the training split.
I0306 14:55:43.480980 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 15:00:47.922407 140509305742528 spec.py:349] Evaluating on the test split.
I0306 15:06:28.601114 140509305742528 submission_runner.py:469] Time since start: 6914.79s, 	Step: 620, 	{'train/loss': 0.12362088646107125, 'validation/loss': 0.12737766259786992, 'validation/num_examples': 83274637, 'test/loss': 0.1299505213096217, 'test/num_examples': 95000000, 'score': 620.7894442081451, 'total_duration': 6914.787329912186, 'accumulated_submission_time': 620.7894442081451, 'accumulated_eval_time': 6293.76421046257, 'accumulated_logging_time': 0.20059657096862793}
I0306 15:06:28.610294 140356628764416 logging_writer.py:48] [620] accumulated_eval_time=6293.76, accumulated_logging_time=0.200597, accumulated_submission_time=620.789, global_step=620, preemption_count=0, score=620.789, test/loss=0.129951, test/num_examples=95000000, total_duration=6914.79, train/loss=0.123621, validation/loss=0.127378, validation/num_examples=83274637
I0306 15:07:34.991168 140356637157120 logging_writer.py:48] [700] global_step=700, grad_norm=0.008149120956659317, loss=0.1171075776219368
I0306 15:08:28.689997 140509305742528 spec.py:321] Evaluating on the training split.
I0306 15:13:56.444822 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 15:18:40.223413 140509305742528 spec.py:349] Evaluating on the test split.
I0306 15:24:53.089055 140509305742528 submission_runner.py:469] Time since start: 8019.28s, 	Step: 745, 	{'train/loss': 0.12734343246234664, 'validation/loss': 0.12696358962668197, 'validation/num_examples': 83274637, 'test/loss': 0.1295415900390625, 'test/num_examples': 95000000, 'score': 740.8555519580841, 'total_duration': 8019.275276660919, 'accumulated_submission_time': 740.8555519580841, 'accumulated_eval_time': 7278.1632380485535, 'accumulated_logging_time': 0.2167654037475586}
I0306 15:24:53.097391 140356628764416 logging_writer.py:48] [745] accumulated_eval_time=7278.16, accumulated_logging_time=0.216765, accumulated_submission_time=740.856, global_step=745, preemption_count=0, score=740.856, test/loss=0.129542, test/num_examples=95000000, total_duration=8019.28, train/loss=0.127343, validation/loss=0.126964, validation/num_examples=83274637
I0306 15:25:29.886291 140356637157120 logging_writer.py:48] [800] global_step=800, grad_norm=0.00856375228613615, loss=0.12080518901348114
I0306 15:26:53.320345 140509305742528 spec.py:321] Evaluating on the training split.
I0306 15:31:21.951084 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 15:35:37.594905 140509305742528 spec.py:349] Evaluating on the test split.
I0306 15:41:34.967117 140509305742528 submission_runner.py:469] Time since start: 9021.15s, 	Step: 872, 	{'train/loss': 0.12576120418244563, 'validation/loss': 0.12676201601037712, 'validation/num_examples': 83274637, 'test/loss': 0.12933615482113486, 'test/num_examples': 95000000, 'score': 861.0649273395538, 'total_duration': 9021.15331864357, 'accumulated_submission_time': 861.0649273395538, 'accumulated_eval_time': 8159.809928417206, 'accumulated_logging_time': 0.2318553924560547}
I0306 15:41:34.975635 140356628764416 logging_writer.py:48] [872] accumulated_eval_time=8159.81, accumulated_logging_time=0.231855, accumulated_submission_time=861.065, global_step=872, preemption_count=0, score=861.065, test/loss=0.129336, test/num_examples=95000000, total_duration=9021.15, train/loss=0.125761, validation/loss=0.126762, validation/num_examples=83274637
I0306 15:41:39.514290 140356637157120 logging_writer.py:48] [900] global_step=900, grad_norm=0.01288421917706728, loss=0.12841713428497314
I0306 15:43:36.424006 140509305742528 spec.py:321] Evaluating on the training split.
I0306 15:47:01.711445 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 15:50:08.875037 140509305742528 spec.py:349] Evaluating on the test split.
I0306 15:56:07.123047 140509305742528 submission_runner.py:469] Time since start: 9893.31s, 	Step: 996, 	{'train/loss': 0.12408440759253202, 'validation/loss': 0.12664844259824723, 'validation/num_examples': 83274637, 'test/loss': 0.1291295396587171, 'test/num_examples': 95000000, 'score': 982.4999506473541, 'total_duration': 9893.30924987793, 'accumulated_submission_time': 982.4999506473541, 'accumulated_eval_time': 8910.508894443512, 'accumulated_logging_time': 0.24726533889770508}
I0306 15:56:07.130965 140356628764416 logging_writer.py:48] [996] accumulated_eval_time=8910.51, accumulated_logging_time=0.247265, accumulated_submission_time=982.5, global_step=996, preemption_count=0, score=982.5, test/loss=0.12913, test/num_examples=95000000, total_duration=9893.31, train/loss=0.124084, validation/loss=0.126648, validation/num_examples=83274637
I0306 15:56:07.668737 140356637157120 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.02549515850841999, loss=0.13368356227874756
I0306 15:57:38.081984 140356628764416 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.029664762318134308, loss=0.12777145206928253
I0306 15:58:07.561867 140509305742528 spec.py:321] Evaluating on the training split.
I0306 15:59:08.039422 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 16:02:15.099631 140509305742528 spec.py:349] Evaluating on the test split.
I0306 16:08:15.015385 140509305742528 submission_runner.py:469] Time since start: 10621.20s, 	Step: 1126, 	{'train/loss': 0.12540010775222718, 'validation/loss': 0.12641072524654176, 'validation/num_examples': 83274637, 'test/loss': 0.12866692138157895, 'test/num_examples': 95000000, 'score': 1102.9177012443542, 'total_duration': 10621.201610565186, 'accumulated_submission_time': 1102.9177012443542, 'accumulated_eval_time': 9517.962346792221, 'accumulated_logging_time': 0.2617225646972656}
I0306 16:08:15.024464 140356637157120 logging_writer.py:48] [1126] accumulated_eval_time=9517.96, accumulated_logging_time=0.261723, accumulated_submission_time=1102.92, global_step=1126, preemption_count=0, score=1102.92, test/loss=0.128667, test/num_examples=95000000, total_duration=10621.2, train/loss=0.1254, validation/loss=0.126411, validation/num_examples=83274637
I0306 16:09:13.407590 140356628764416 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.009739366360008717, loss=0.12781693041324615
I0306 16:10:15.434173 140509305742528 spec.py:321] Evaluating on the training split.
I0306 16:11:14.378407 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 16:14:26.438022 140509305742528 spec.py:349] Evaluating on the test split.
I0306 16:20:14.950727 140509305742528 submission_runner.py:469] Time since start: 11341.14s, 	Step: 1253, 	{'train/loss': 0.12415934215832806, 'validation/loss': 0.1262083578406577, 'validation/num_examples': 83274637, 'test/loss': 0.1285697015625, 'test/num_examples': 95000000, 'score': 1223.3134772777557, 'total_duration': 11341.136915922165, 'accumulated_submission_time': 1223.3134772777557, 'accumulated_eval_time': 10117.478810071945, 'accumulated_logging_time': 0.2776312828063965}
I0306 16:20:14.959420 140356637157120 logging_writer.py:48] [1253] accumulated_eval_time=10117.5, accumulated_logging_time=0.277631, accumulated_submission_time=1223.31, global_step=1253, preemption_count=0, score=1223.31, test/loss=0.12857, test/num_examples=95000000, total_duration=11341.1, train/loss=0.124159, validation/loss=0.126208, validation/num_examples=83274637
I0306 16:20:42.636234 140356628764416 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.023098653182387352, loss=0.12448248267173767
I0306 16:22:15.207460 140509305742528 spec.py:321] Evaluating on the training split.
I0306 16:23:12.081038 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 16:26:19.155959 140509305742528 spec.py:349] Evaluating on the test split.
I0306 16:32:30.330335 140509305742528 submission_runner.py:469] Time since start: 12076.52s, 	Step: 1379, 	{'train/loss': 0.12402049420436598, 'validation/loss': 0.1259793766774953, 'validation/num_examples': 83274637, 'test/loss': 0.1284818775287829, 'test/num_examples': 95000000, 'score': 1343.547863960266, 'total_duration': 12076.516550064087, 'accumulated_submission_time': 1343.547863960266, 'accumulated_eval_time': 10732.60162115097, 'accumulated_logging_time': 0.29361414909362793}
I0306 16:32:30.339048 140356637157120 logging_writer.py:48] [1379] accumulated_eval_time=10732.6, accumulated_logging_time=0.293614, accumulated_submission_time=1343.55, global_step=1379, preemption_count=0, score=1343.55, test/loss=0.128482, test/num_examples=95000000, total_duration=12076.5, train/loss=0.12402, validation/loss=0.125979, validation/num_examples=83274637
I0306 16:32:32.708840 140356628764416 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.012822753749787807, loss=0.12251418828964233
I0306 16:34:24.223601 140356637157120 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.03173473849892616, loss=0.11829020082950592
I0306 16:34:30.625375 140509305742528 spec.py:321] Evaluating on the training split.
I0306 16:35:29.851479 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 16:38:43.229155 140509305742528 spec.py:349] Evaluating on the test split.
I0306 16:44:46.105185 140509305742528 submission_runner.py:469] Time since start: 12812.29s, 	Step: 1506, 	{'train/loss': 0.12453832281694847, 'validation/loss': 0.12591303304170737, 'validation/num_examples': 83274637, 'test/loss': 0.12836292896792764, 'test/num_examples': 95000000, 'score': 1463.8219027519226, 'total_duration': 12812.291413068771, 'accumulated_submission_time': 1463.8219027519226, 'accumulated_eval_time': 11348.081369161606, 'accumulated_logging_time': 0.30875658988952637}
I0306 16:44:46.128224 140356628764416 logging_writer.py:48] [1506] accumulated_eval_time=11348.1, accumulated_logging_time=0.308757, accumulated_submission_time=1463.82, global_step=1506, preemption_count=0, score=1463.82, test/loss=0.128363, test/num_examples=95000000, total_duration=12812.3, train/loss=0.124538, validation/loss=0.125913, validation/num_examples=83274637
I0306 16:46:03.967419 140356637157120 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.014369861222803593, loss=0.11993385851383209
I0306 16:46:47.595411 140509305742528 spec.py:321] Evaluating on the training split.
I0306 16:47:41.864042 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 16:50:50.710449 140509305742528 spec.py:349] Evaluating on the test split.
I0306 16:56:59.803388 140509305742528 submission_runner.py:469] Time since start: 13545.99s, 	Step: 1638, 	{'train/loss': 0.1244377020113873, 'validation/loss': 0.12603723070857922, 'validation/num_examples': 83274637, 'test/loss': 0.12857375151110198, 'test/num_examples': 95000000, 'score': 1585.2758927345276, 'total_duration': 13545.989592790604, 'accumulated_submission_time': 1585.2758927345276, 'accumulated_eval_time': 11960.289261102676, 'accumulated_logging_time': 0.33843469619750977}
I0306 16:56:59.811949 140356628764416 logging_writer.py:48] [1638] accumulated_eval_time=11960.3, accumulated_logging_time=0.338435, accumulated_submission_time=1585.28, global_step=1638, preemption_count=0, score=1585.28, test/loss=0.128574, test/num_examples=95000000, total_duration=13546, train/loss=0.124438, validation/loss=0.126037, validation/num_examples=83274637
I0306 16:57:48.797031 140356637157120 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.01758490316569805, loss=0.1222095713019371
I0306 16:59:01.448709 140509305742528 spec.py:321] Evaluating on the training split.
I0306 16:59:55.285794 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 17:03:03.544497 140509305742528 spec.py:349] Evaluating on the test split.
I0306 17:09:06.894278 140509305742528 submission_runner.py:469] Time since start: 14273.08s, 	Step: 1762, 	{'train/loss': 0.1251332244525353, 'validation/loss': 0.12573872166874284, 'validation/num_examples': 83274637, 'test/loss': 0.12816010159333882, 'test/num_examples': 95000000, 'score': 1706.8995563983917, 'total_duration': 14273.08050584793, 'accumulated_submission_time': 1706.8995563983917, 'accumulated_eval_time': 12565.73476433754, 'accumulated_logging_time': 0.35353922843933105}
I0306 17:09:06.903540 140356628764416 logging_writer.py:48] [1762] accumulated_eval_time=12565.7, accumulated_logging_time=0.353539, accumulated_submission_time=1706.9, global_step=1762, preemption_count=0, score=1706.9, test/loss=0.12816, test/num_examples=95000000, total_duration=14273.1, train/loss=0.125133, validation/loss=0.125739, validation/num_examples=83274637
I0306 17:09:22.390396 140356637157120 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.007409748621284962, loss=0.1256473958492279
I0306 17:11:07.424740 140509305742528 spec.py:321] Evaluating on the training split.
I0306 17:12:03.743255 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 17:15:11.663225 140509305742528 spec.py:349] Evaluating on the test split.
I0306 17:21:17.018186 140509305742528 submission_runner.py:469] Time since start: 15003.20s, 	Step: 1889, 	{'train/loss': 0.12469019265201106, 'validation/loss': 0.12567573237412086, 'validation/num_examples': 83274637, 'test/loss': 0.12812983347039475, 'test/num_examples': 95000000, 'score': 1827.4074356555939, 'total_duration': 15003.204395532608, 'accumulated_submission_time': 1827.4074356555939, 'accumulated_eval_time': 13175.328134536743, 'accumulated_logging_time': 0.36960649490356445}
I0306 17:21:17.026975 140356628764416 logging_writer.py:48] [1889] accumulated_eval_time=13175.3, accumulated_logging_time=0.369606, accumulated_submission_time=1827.41, global_step=1889, preemption_count=0, score=1827.41, test/loss=0.12813, test/num_examples=95000000, total_duration=15003.2, train/loss=0.12469, validation/loss=0.125676, validation/num_examples=83274637
I0306 17:21:18.309532 140356637157120 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.014782807789742947, loss=0.11444596201181412
I0306 17:22:55.362822 140356628764416 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.00686743063852191, loss=0.12708568572998047
I0306 17:23:17.300086 140509305742528 spec.py:321] Evaluating on the training split.
I0306 17:24:16.101927 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 17:27:24.558496 140509305742528 spec.py:349] Evaluating on the test split.
I0306 17:33:38.239909 140509305742528 submission_runner.py:469] Time since start: 15744.43s, 	Step: 2020, 	{'train/loss': 0.12386352577065148, 'validation/loss': 0.12573673768146573, 'validation/num_examples': 83274637, 'test/loss': 0.12822271802014804, 'test/num_examples': 95000000, 'score': 1947.667148590088, 'total_duration': 15744.426137924194, 'accumulated_submission_time': 1947.667148590088, 'accumulated_eval_time': 13796.267896413803, 'accumulated_logging_time': 0.38542675971984863}
I0306 17:33:38.248778 140356637157120 logging_writer.py:48] [2020] accumulated_eval_time=13796.3, accumulated_logging_time=0.385427, accumulated_submission_time=1947.67, global_step=2020, preemption_count=0, score=1947.67, test/loss=0.128223, test/num_examples=95000000, total_duration=15744.4, train/loss=0.123864, validation/loss=0.125737, validation/num_examples=83274637
I0306 17:34:45.387107 140356628764416 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.008441738784313202, loss=0.1213110014796257
I0306 17:35:39.265612 140509305742528 spec.py:321] Evaluating on the training split.
I0306 17:36:38.533046 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 17:39:44.566296 140509305742528 spec.py:349] Evaluating on the test split.
I0306 17:45:56.342127 140509305742528 submission_runner.py:469] Time since start: 16482.53s, 	Step: 2146, 	{'train/loss': 0.12481278964792783, 'validation/loss': 0.12566271305935714, 'validation/num_examples': 83274637, 'test/loss': 0.1280357357319079, 'test/num_examples': 95000000, 'score': 2068.6708986759186, 'total_duration': 16482.5283536911, 'accumulated_submission_time': 2068.6708986759186, 'accumulated_eval_time': 14413.344351291656, 'accumulated_logging_time': 0.40079474449157715}
I0306 17:45:56.351097 140356637157120 logging_writer.py:48] [2146] accumulated_eval_time=14413.3, accumulated_logging_time=0.400795, accumulated_submission_time=2068.67, global_step=2146, preemption_count=0, score=2068.67, test/loss=0.128036, test/num_examples=95000000, total_duration=16482.5, train/loss=0.124813, validation/loss=0.125663, validation/num_examples=83274637
I0306 17:46:31.775503 140356628764416 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.02433669939637184, loss=0.1205316111445427
I0306 17:47:57.064715 140509305742528 spec.py:321] Evaluating on the training split.
I0306 17:48:53.990755 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 17:52:00.791013 140509305742528 spec.py:349] Evaluating on the test split.
I0306 17:57:54.764938 140509305742528 submission_runner.py:469] Time since start: 17200.95s, 	Step: 2269, 	{'train/loss': 0.12229088147949872, 'validation/loss': 0.12551327272203391, 'validation/num_examples': 83274637, 'test/loss': 0.1279012245990954, 'test/num_examples': 95000000, 'score': 2189.3716802597046, 'total_duration': 17200.951144456863, 'accumulated_submission_time': 2189.3716802597046, 'accumulated_eval_time': 15011.04449892044, 'accumulated_logging_time': 0.416607141494751}
I0306 17:57:54.774851 140356637157120 logging_writer.py:48] [2269] accumulated_eval_time=15011, accumulated_logging_time=0.416607, accumulated_submission_time=2189.37, global_step=2269, preemption_count=0, score=2189.37, test/loss=0.127901, test/num_examples=95000000, total_duration=17201, train/loss=0.122291, validation/loss=0.125513, validation/num_examples=83274637
I0306 17:58:02.954772 140356628764416 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.015073723159730434, loss=0.1255597025156021
I0306 17:59:55.609880 140509305742528 spec.py:321] Evaluating on the training split.
I0306 18:00:53.787514 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 18:04:00.400460 140509305742528 spec.py:349] Evaluating on the test split.
I0306 18:10:15.161723 140509305742528 submission_runner.py:469] Time since start: 17941.35s, 	Step: 2394, 	{'train/loss': 0.1255097726371678, 'validation/loss': 0.12545194623533942, 'validation/num_examples': 83274637, 'test/loss': 0.12780543392269736, 'test/num_examples': 95000000, 'score': 2310.1929738521576, 'total_duration': 17941.347943782806, 'accumulated_submission_time': 2310.1929738521576, 'accumulated_eval_time': 15630.59628033638, 'accumulated_logging_time': 0.4338719844818115}
I0306 18:10:15.170450 140356637157120 logging_writer.py:48] [2394] accumulated_eval_time=15630.6, accumulated_logging_time=0.433872, accumulated_submission_time=2310.19, global_step=2394, preemption_count=0, score=2310.19, test/loss=0.127805, test/num_examples=95000000, total_duration=17941.3, train/loss=0.12551, validation/loss=0.125452, validation/num_examples=83274637
I0306 18:10:15.929222 140356628764416 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.01754714921116829, loss=0.12543101608753204
I0306 18:11:54.087491 140356637157120 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.02110743150115013, loss=0.1252962052822113
I0306 18:12:15.461556 140509305742528 spec.py:321] Evaluating on the training split.
I0306 18:13:11.048221 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 18:16:21.786442 140509305742528 spec.py:349] Evaluating on the test split.
I0306 18:22:30.207658 140509305742528 submission_runner.py:469] Time since start: 18676.39s, 	Step: 2520, 	{'train/loss': 0.12342998578722747, 'validation/loss': 0.12537710428754256, 'validation/num_examples': 83274637, 'test/loss': 0.1278700271587171, 'test/num_examples': 95000000, 'score': 2430.4706349372864, 'total_duration': 18676.393878221512, 'accumulated_submission_time': 2430.4706349372864, 'accumulated_eval_time': 16245.342309951782, 'accumulated_logging_time': 0.44905972480773926}
I0306 18:22:30.217376 140356628764416 logging_writer.py:48] [2520] accumulated_eval_time=16245.3, accumulated_logging_time=0.44906, accumulated_submission_time=2430.47, global_step=2520, preemption_count=0, score=2430.47, test/loss=0.12787, test/num_examples=95000000, total_duration=18676.4, train/loss=0.12343, validation/loss=0.125377, validation/num_examples=83274637
I0306 18:23:37.285790 140356637157120 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.008190463297069073, loss=0.12333525717258453
I0306 18:24:30.653306 140509305742528 spec.py:321] Evaluating on the training split.
I0306 18:25:27.916628 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 18:28:35.009258 140509305742528 spec.py:349] Evaluating on the test split.
I0306 18:34:23.925830 140509305742528 submission_runner.py:469] Time since start: 19390.11s, 	Step: 2646, 	{'train/loss': 0.12457071734393167, 'validation/loss': 0.12535613442354304, 'validation/num_examples': 83274637, 'test/loss': 0.12776033624588815, 'test/num_examples': 95000000, 'score': 2550.893527507782, 'total_duration': 19390.1120364666, 'accumulated_submission_time': 2550.893527507782, 'accumulated_eval_time': 16838.614748239517, 'accumulated_logging_time': 0.4656243324279785}
I0306 18:34:23.935847 140356628764416 logging_writer.py:48] [2646] accumulated_eval_time=16838.6, accumulated_logging_time=0.465624, accumulated_submission_time=2550.89, global_step=2646, preemption_count=0, score=2550.89, test/loss=0.12776, test/num_examples=95000000, total_duration=19390.1, train/loss=0.124571, validation/loss=0.125356, validation/num_examples=83274637
I0306 18:34:57.806484 140356637157120 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.010629706084728241, loss=0.12392188608646393
I0306 18:36:25.161270 140509305742528 spec.py:321] Evaluating on the training split.
I0306 18:37:20.499296 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 18:40:32.510631 140509305742528 spec.py:349] Evaluating on the test split.
I0306 18:46:34.025124 140509305742528 submission_runner.py:469] Time since start: 20120.21s, 	Step: 2777, 	{'train/loss': 0.1248374111692673, 'validation/loss': 0.1253156425004703, 'validation/num_examples': 83274637, 'test/loss': 0.12763420406044407, 'test/num_examples': 95000000, 'score': 2672.1050760746, 'total_duration': 20120.211345672607, 'accumulated_submission_time': 2672.1050760746, 'accumulated_eval_time': 17447.478541135788, 'accumulated_logging_time': 0.4826650619506836}
I0306 18:46:34.034122 140356628764416 logging_writer.py:48] [2777] accumulated_eval_time=17447.5, accumulated_logging_time=0.482665, accumulated_submission_time=2672.11, global_step=2777, preemption_count=0, score=2672.11, test/loss=0.127634, test/num_examples=95000000, total_duration=20120.2, train/loss=0.124837, validation/loss=0.125316, validation/num_examples=83274637
I0306 18:46:36.581710 140356637157120 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.006325988564640284, loss=0.11287444084882736
I0306 18:48:32.073051 140356628764416 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.032841794192790985, loss=0.1407848447561264
I0306 18:48:34.821964 140509305742528 spec.py:321] Evaluating on the training split.
I0306 18:49:28.776150 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 18:52:36.749020 140509305742528 spec.py:349] Evaluating on the test split.
I0306 18:58:29.617608 140509305742528 submission_runner.py:469] Time since start: 20835.80s, 	Step: 2903, 	{'train/loss': 0.12232806869788365, 'validation/loss': 0.12529738888170566, 'validation/num_examples': 83274637, 'test/loss': 0.12758772689144737, 'test/num_examples': 95000000, 'score': 2792.8801906108856, 'total_duration': 20835.803799152374, 'accumulated_submission_time': 2792.8801906108856, 'accumulated_eval_time': 18042.274082183838, 'accumulated_logging_time': 0.4982187747955322}
I0306 18:58:29.627544 140356637157120 logging_writer.py:48] [2903] accumulated_eval_time=18042.3, accumulated_logging_time=0.498219, accumulated_submission_time=2792.88, global_step=2903, preemption_count=0, score=2792.88, test/loss=0.127588, test/num_examples=95000000, total_duration=20835.8, train/loss=0.122328, validation/loss=0.125297, validation/num_examples=83274637
I0306 18:59:54.415546 140356628764416 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.016519660130143166, loss=0.12484541535377502
I0306 19:00:31.185560 140509305742528 spec.py:321] Evaluating on the training split.
I0306 19:01:26.240050 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 19:04:37.531135 140509305742528 spec.py:349] Evaluating on the test split.
I0306 19:10:34.889069 140509305742528 submission_runner.py:469] Time since start: 21561.08s, 	Step: 3034, 	{'train/loss': 0.12495799123678568, 'validation/loss': 0.12498687539427708, 'validation/num_examples': 83274637, 'test/loss': 0.12727283682154605, 'test/num_examples': 95000000, 'score': 2914.4242186546326, 'total_duration': 21561.07530117035, 'accumulated_submission_time': 2914.4242186546326, 'accumulated_eval_time': 18645.97753882408, 'accumulated_logging_time': 0.5151445865631104}
I0306 19:10:34.898334 140356637157120 logging_writer.py:48] [3034] accumulated_eval_time=18646, accumulated_logging_time=0.515145, accumulated_submission_time=2914.42, global_step=3034, preemption_count=0, score=2914.42, test/loss=0.127273, test/num_examples=95000000, total_duration=21561.1, train/loss=0.124958, validation/loss=0.124987, validation/num_examples=83274637
I0306 19:11:26.951711 140356628764416 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.018167831003665924, loss=0.12317761778831482
I0306 19:12:35.065536 140509305742528 spec.py:321] Evaluating on the training split.
I0306 19:13:31.516494 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 19:16:43.233610 140509305742528 spec.py:349] Evaluating on the test split.
I0306 19:22:51.073423 140509305742528 submission_runner.py:469] Time since start: 22297.26s, 	Step: 3158, 	{'train/loss': 0.12223682494002318, 'validation/loss': 0.1251790931726945, 'validation/num_examples': 83274637, 'test/loss': 0.12739330848067434, 'test/num_examples': 95000000, 'score': 3034.578158378601, 'total_duration': 22297.25963997841, 'accumulated_submission_time': 3034.578158378601, 'accumulated_eval_time': 19261.985355854034, 'accumulated_logging_time': 0.5316812992095947}
I0306 19:22:51.082813 140356637157120 logging_writer.py:48] [3158] accumulated_eval_time=19262, accumulated_logging_time=0.531681, accumulated_submission_time=3034.58, global_step=3158, preemption_count=0, score=3034.58, test/loss=0.127393, test/num_examples=95000000, total_duration=22297.3, train/loss=0.122237, validation/loss=0.125179, validation/num_examples=83274637
I0306 19:23:11.526029 140356628764416 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.010350503027439117, loss=0.12858057022094727
I0306 19:24:51.293663 140509305742528 spec.py:321] Evaluating on the training split.
I0306 19:25:48.121742 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 19:28:57.108310 140509305742528 spec.py:349] Evaluating on the test split.
I0306 19:34:48.045397 140509305742528 submission_runner.py:469] Time since start: 23014.23s, 	Step: 3286, 	{'train/loss': 0.12176444657943533, 'validation/loss': 0.12488338053806977, 'validation/num_examples': 83274637, 'test/loss': 0.12720145108963815, 'test/num_examples': 95000000, 'score': 3154.7752990722656, 'total_duration': 23014.231615543365, 'accumulated_submission_time': 3154.7752990722656, 'accumulated_eval_time': 19858.737021684647, 'accumulated_logging_time': 0.5480880737304688}
I0306 19:34:48.055024 140356637157120 logging_writer.py:48] [3286] accumulated_eval_time=19858.7, accumulated_logging_time=0.548088, accumulated_submission_time=3154.78, global_step=3286, preemption_count=0, score=3154.78, test/loss=0.127201, test/num_examples=95000000, total_duration=23014.2, train/loss=0.121764, validation/loss=0.124883, validation/num_examples=83274637
I0306 19:34:49.635235 140356628764416 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.007187988143414259, loss=0.11689826101064682
I0306 19:36:26.732420 140356637157120 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.016821103170514107, loss=0.12166392058134079
I0306 19:36:48.353790 140509305742528 spec.py:321] Evaluating on the training split.
I0306 19:37:47.807464 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 19:41:00.402175 140509305742528 spec.py:349] Evaluating on the test split.
I0306 19:47:06.996750 140509305742528 submission_runner.py:469] Time since start: 23753.18s, 	Step: 3421, 	{'train/loss': 0.12635828938874058, 'validation/loss': 0.12499612892572937, 'validation/num_examples': 83274637, 'test/loss': 0.12740704832442434, 'test/num_examples': 95000000, 'score': 3275.061017513275, 'total_duration': 23753.182981729507, 'accumulated_submission_time': 3275.061017513275, 'accumulated_eval_time': 20477.37991976738, 'accumulated_logging_time': 0.5642910003662109}
I0306 19:47:07.006084 140356628764416 logging_writer.py:48] [3421] accumulated_eval_time=20477.4, accumulated_logging_time=0.564291, accumulated_submission_time=3275.06, global_step=3421, preemption_count=0, score=3275.06, test/loss=0.127407, test/num_examples=95000000, total_duration=23753.2, train/loss=0.126358, validation/loss=0.124996, validation/num_examples=83274637
I0306 19:48:12.976603 140356637157120 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.00889851525425911, loss=0.12925173342227936
I0306 19:49:07.207244 140509305742528 spec.py:321] Evaluating on the training split.
I0306 19:50:07.938290 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 19:53:15.684386 140509305742528 spec.py:349] Evaluating on the test split.
I0306 19:59:21.546014 140509305742528 submission_runner.py:469] Time since start: 24487.73s, 	Step: 3546, 	{'train/loss': 0.12344441868645965, 'validation/loss': 0.12503607968247207, 'validation/num_examples': 83274637, 'test/loss': 0.12738980991981907, 'test/num_examples': 95000000, 'score': 3395.2496240139008, 'total_duration': 24487.732225179672, 'accumulated_submission_time': 3395.2496240139008, 'accumulated_eval_time': 21091.718608617783, 'accumulated_logging_time': 0.5803818702697754}
I0306 19:59:21.555799 140356628764416 logging_writer.py:48] [3546] accumulated_eval_time=21091.7, accumulated_logging_time=0.580382, accumulated_submission_time=3395.25, global_step=3546, preemption_count=0, score=3395.25, test/loss=0.12739, test/num_examples=95000000, total_duration=24487.7, train/loss=0.123444, validation/loss=0.125036, validation/num_examples=83274637
I0306 19:59:55.974479 140356637157120 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.007491544354707003, loss=0.12354723364114761
I0306 20:01:22.229734 140509305742528 spec.py:321] Evaluating on the training split.
I0306 20:02:18.023729 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 20:05:29.405209 140509305742528 spec.py:349] Evaluating on the test split.
I0306 20:11:40.953647 140509305742528 submission_runner.py:469] Time since start: 25227.14s, 	Step: 3672, 	{'train/loss': 0.12589199657100927, 'validation/loss': 0.12511885724515753, 'validation/num_examples': 83274637, 'test/loss': 0.12739400322779607, 'test/num_examples': 95000000, 'score': 3515.8456337451935, 'total_duration': 25227.13987517357, 'accumulated_submission_time': 3515.8456337451935, 'accumulated_eval_time': 21710.44246172905, 'accumulated_logging_time': 0.6616146564483643}
I0306 20:11:40.962769 140356628764416 logging_writer.py:48] [3672] accumulated_eval_time=21710.4, accumulated_logging_time=0.661615, accumulated_submission_time=3515.85, global_step=3672, preemption_count=0, score=3515.85, test/loss=0.127394, test/num_examples=95000000, total_duration=25227.1, train/loss=0.125892, validation/loss=0.125119, validation/num_examples=83274637
I0306 20:11:45.721548 140356637157120 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.00748923746868968, loss=0.12577754259109497
I0306 20:13:41.058412 140509305742528 spec.py:321] Evaluating on the training split.
I0306 20:14:41.358317 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 20:17:51.365193 140509305742528 spec.py:349] Evaluating on the test split.
I0306 20:24:00.762696 140509305742528 submission_runner.py:469] Time since start: 25966.95s, 	Step: 3798, 	{'train/loss': 0.12451382979469479, 'validation/loss': 0.12495096226466439, 'validation/num_examples': 83274637, 'test/loss': 0.12723812987253288, 'test/num_examples': 95000000, 'score': 3635.9283056259155, 'total_duration': 25966.948876142502, 'accumulated_submission_time': 3635.9283056259155, 'accumulated_eval_time': 22330.14664196968, 'accumulated_logging_time': 0.6772773265838623}
I0306 20:24:00.772590 140356628764416 logging_writer.py:48] [3798] accumulated_eval_time=22330.1, accumulated_logging_time=0.677277, accumulated_submission_time=3635.93, global_step=3798, preemption_count=0, score=3635.93, test/loss=0.127238, test/num_examples=95000000, total_duration=25966.9, train/loss=0.124514, validation/loss=0.124951, validation/num_examples=83274637
I0306 20:24:01.114784 140356637157120 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.010800667107105255, loss=0.12753582000732422
I0306 20:25:36.564935 140356628764416 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.006241692695766687, loss=0.12109231948852539
I0306 20:26:01.795030 140509305742528 spec.py:321] Evaluating on the training split.
I0306 20:26:59.997371 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 20:30:06.032643 140509305742528 spec.py:349] Evaluating on the test split.
I0306 20:35:56.875161 140509305742528 submission_runner.py:469] Time since start: 26683.06s, 	Step: 3922, 	{'train/loss': 0.12472169059065152, 'validation/loss': 0.12493386829473661, 'validation/num_examples': 83274637, 'test/loss': 0.12725148337787828, 'test/num_examples': 95000000, 'score': 3756.9378538131714, 'total_duration': 26683.06137418747, 'accumulated_submission_time': 3756.9378538131714, 'accumulated_eval_time': 22925.226697444916, 'accumulated_logging_time': 0.694007396697998}
I0306 20:35:56.884385 140356637157120 logging_writer.py:48] [3922] accumulated_eval_time=22925.2, accumulated_logging_time=0.694007, accumulated_submission_time=3756.94, global_step=3922, preemption_count=0, score=3756.94, test/loss=0.127251, test/num_examples=95000000, total_duration=26683.1, train/loss=0.124722, validation/loss=0.124934, validation/num_examples=83274637
I0306 20:37:02.323286 140356628764416 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.009640349075198174, loss=0.12294602394104004
I0306 20:37:57.781283 140509305742528 spec.py:321] Evaluating on the training split.
I0306 20:38:59.905523 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 20:42:06.163656 140509305742528 spec.py:349] Evaluating on the test split.
I0306 20:48:13.148478 140509305742528 submission_runner.py:469] Time since start: 27419.33s, 	Step: 4045, 	{'train/loss': 0.12494791117526076, 'validation/loss': 0.12502411575169942, 'validation/num_examples': 83274637, 'test/loss': 0.12738166315789473, 'test/num_examples': 95000000, 'score': 3877.821049451828, 'total_duration': 27419.334699630737, 'accumulated_submission_time': 3877.821049451828, 'accumulated_eval_time': 23540.59383225441, 'accumulated_logging_time': 0.7106015682220459}
I0306 20:48:13.157728 140356637157120 logging_writer.py:48] [4045] accumulated_eval_time=23540.6, accumulated_logging_time=0.710602, accumulated_submission_time=3877.82, global_step=4045, preemption_count=0, score=3877.82, test/loss=0.127382, test/num_examples=95000000, total_duration=27419.3, train/loss=0.124948, validation/loss=0.125024, validation/num_examples=83274637
I0306 20:48:50.811517 140356628764416 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.00546602439135313, loss=0.12660856544971466
I0306 20:50:13.575272 140509305742528 spec.py:321] Evaluating on the training split.
I0306 20:51:13.105978 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 20:54:20.475066 140509305742528 spec.py:349] Evaluating on the test split.
I0306 21:00:10.410883 140509305742528 submission_runner.py:469] Time since start: 28136.60s, 	Step: 4170, 	{'train/loss': 0.12198711483030573, 'validation/loss': 0.12487012539313516, 'validation/num_examples': 83274637, 'test/loss': 0.1272055441200658, 'test/num_examples': 95000000, 'score': 3998.225067138672, 'total_duration': 28136.597107172012, 'accumulated_submission_time': 3998.225067138672, 'accumulated_eval_time': 24137.429384946823, 'accumulated_logging_time': 0.7264842987060547}
I0306 21:00:10.420258 140356637157120 logging_writer.py:48] [4170] accumulated_eval_time=24137.4, accumulated_logging_time=0.726484, accumulated_submission_time=3998.23, global_step=4170, preemption_count=0, score=3998.23, test/loss=0.127206, test/num_examples=95000000, total_duration=28136.6, train/loss=0.121987, validation/loss=0.12487, validation/num_examples=83274637
I0306 21:00:16.698272 140356628764416 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.007302311714738607, loss=0.11843059211969376
I0306 21:02:10.574652 140509305742528 spec.py:321] Evaluating on the training split.
I0306 21:03:06.027069 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 21:06:15.134946 140509305742528 spec.py:349] Evaluating on the test split.
I0306 21:12:11.425940 140509305742528 submission_runner.py:469] Time since start: 28857.61s, 	Step: 4298, 	{'train/loss': 0.12330603847901027, 'validation/loss': 0.12483316138856676, 'validation/num_examples': 83274637, 'test/loss': 0.12727790523231908, 'test/num_examples': 95000000, 'score': 4118.365837574005, 'total_duration': 28857.612138032913, 'accumulated_submission_time': 4118.365837574005, 'accumulated_eval_time': 24738.2805891037, 'accumulated_logging_time': 0.7425436973571777}
I0306 21:12:11.435348 140356637157120 logging_writer.py:48] [4298] accumulated_eval_time=24738.3, accumulated_logging_time=0.742544, accumulated_submission_time=4118.37, global_step=4298, preemption_count=0, score=4118.37, test/loss=0.127278, test/num_examples=95000000, total_duration=28857.6, train/loss=0.123306, validation/loss=0.124833, validation/num_examples=83274637
I0306 21:12:11.773250 140356628764416 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.005357752554118633, loss=0.13044100999832153
I0306 21:13:40.840719 140356637157120 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.009475902654230595, loss=0.124465212225914
I0306 21:14:11.701566 140509305742528 spec.py:321] Evaluating on the training split.
I0306 21:15:09.767710 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 21:18:15.856636 140509305742528 spec.py:349] Evaluating on the test split.
I0306 21:24:32.797933 140509305742528 submission_runner.py:469] Time since start: 29598.98s, 	Step: 4429, 	{'train/loss': 0.12210476412525717, 'validation/loss': 0.12469422000874723, 'validation/num_examples': 83274637, 'test/loss': 0.12709205892269737, 'test/num_examples': 95000000, 'score': 4238.617676258087, 'total_duration': 29598.98412656784, 'accumulated_submission_time': 4238.617676258087, 'accumulated_eval_time': 25359.37685751915, 'accumulated_logging_time': 0.7594344615936279}
I0306 21:24:32.807605 140356628764416 logging_writer.py:48] [4429] accumulated_eval_time=25359.4, accumulated_logging_time=0.759434, accumulated_submission_time=4238.62, global_step=4429, preemption_count=0, score=4238.62, test/loss=0.127092, test/num_examples=95000000, total_duration=29599, train/loss=0.122105, validation/loss=0.124694, validation/num_examples=83274637
I0306 21:25:27.767994 140356637157120 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.009948397055268288, loss=0.11795253306627274
I0306 21:26:33.649199 140509305742528 spec.py:321] Evaluating on the training split.
I0306 21:27:31.131631 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 21:30:44.588540 140509305742528 spec.py:349] Evaluating on the test split.
I0306 21:36:48.070264 140509305742528 submission_runner.py:469] Time since start: 30334.26s, 	Step: 4556, 	{'train/loss': 0.12163741908873776, 'validation/loss': 0.12446063164930661, 'validation/num_examples': 83274637, 'test/loss': 0.1268463900596217, 'test/num_examples': 95000000, 'score': 4359.428817510605, 'total_duration': 30334.25648856163, 'accumulated_submission_time': 4359.428817510605, 'accumulated_eval_time': 25973.797860860825, 'accumulated_logging_time': 0.7920169830322266}
I0306 21:36:48.081095 140356628764416 logging_writer.py:48] [4556] accumulated_eval_time=25973.8, accumulated_logging_time=0.792017, accumulated_submission_time=4359.43, global_step=4556, preemption_count=0, score=4359.43, test/loss=0.126846, test/num_examples=95000000, total_duration=30334.3, train/loss=0.121637, validation/loss=0.124461, validation/num_examples=83274637
I0306 21:37:10.881178 140356637157120 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.013989487662911415, loss=0.12038874626159668
I0306 21:38:48.891020 140509305742528 spec.py:321] Evaluating on the training split.
I0306 21:39:46.323455 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 21:42:54.201684 140509305742528 spec.py:349] Evaluating on the test split.
I0306 21:48:58.295788 140509305742528 submission_runner.py:469] Time since start: 31064.48s, 	Step: 4685, 	{'train/loss': 0.12301447802463418, 'validation/loss': 0.1246822144529526, 'validation/num_examples': 83274637, 'test/loss': 0.12710248657483553, 'test/num_examples': 95000000, 'score': 4480.223861455917, 'total_duration': 31064.48199248314, 'accumulated_submission_time': 4480.223861455917, 'accumulated_eval_time': 26583.202547073364, 'accumulated_logging_time': 0.8104231357574463}
I0306 21:48:58.305314 140356628764416 logging_writer.py:48] [4685] accumulated_eval_time=26583.2, accumulated_logging_time=0.810423, accumulated_submission_time=4480.22, global_step=4685, preemption_count=0, score=4480.22, test/loss=0.127102, test/num_examples=95000000, total_duration=31064.5, train/loss=0.123014, validation/loss=0.124682, validation/num_examples=83274637
I0306 21:49:00.001313 140356637157120 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.006509195547550917, loss=0.12331221997737885
I0306 21:50:48.559833 140356628764416 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.011107420548796654, loss=0.12065690010786057
I0306 21:50:59.103171 140509305742528 spec.py:321] Evaluating on the training split.
I0306 21:51:55.610996 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 21:55:01.905308 140509305742528 spec.py:349] Evaluating on the test split.
I0306 22:00:59.503194 140509305742528 submission_runner.py:469] Time since start: 31785.69s, 	Step: 4810, 	{'train/loss': 0.12219414013033768, 'validation/loss': 0.12440907996552195, 'validation/num_examples': 83274637, 'test/loss': 0.12675211577919407, 'test/num_examples': 95000000, 'score': 4601.008006811142, 'total_duration': 31785.689422369003, 'accumulated_submission_time': 4601.008006811142, 'accumulated_eval_time': 27183.60250711441, 'accumulated_logging_time': 0.8267953395843506}
I0306 22:00:59.513183 140356637157120 logging_writer.py:48] [4810] accumulated_eval_time=27183.6, accumulated_logging_time=0.826795, accumulated_submission_time=4601.01, global_step=4810, preemption_count=0, score=4601.01, test/loss=0.126752, test/num_examples=95000000, total_duration=31785.7, train/loss=0.122194, validation/loss=0.124409, validation/num_examples=83274637
I0306 22:02:19.226721 140356628764416 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.008606147952377796, loss=0.12089800089597702
I0306 22:03:01.142689 140509305742528 spec.py:321] Evaluating on the training split.
I0306 22:03:57.638047 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 22:07:07.005117 140509305742528 spec.py:349] Evaluating on the test split.
I0306 22:13:04.536681 140509305742528 submission_runner.py:469] Time since start: 32510.72s, 	Step: 4937, 	{'train/loss': 0.12202023659721485, 'validation/loss': 0.12440742384199015, 'validation/num_examples': 83274637, 'test/loss': 0.12677354612458883, 'test/num_examples': 95000000, 'score': 4722.624469995499, 'total_duration': 32510.72287130356, 'accumulated_submission_time': 4722.624469995499, 'accumulated_eval_time': 27786.996401309967, 'accumulated_logging_time': 0.8433670997619629}
I0306 22:13:04.546812 140356637157120 logging_writer.py:48] [4937] accumulated_eval_time=27787, accumulated_logging_time=0.843367, accumulated_submission_time=4722.62, global_step=4937, preemption_count=0, score=4722.62, test/loss=0.126774, test/num_examples=95000000, total_duration=32510.7, train/loss=0.12202, validation/loss=0.124407, validation/num_examples=83274637
I0306 22:13:48.270457 140356628764416 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.01170666515827179, loss=0.12190550565719604
I0306 22:15:05.435179 140509305742528 spec.py:321] Evaluating on the training split.
I0306 22:16:01.032018 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 22:19:10.904048 140509305742528 spec.py:349] Evaluating on the test split.
I0306 22:25:26.979499 140509305742528 submission_runner.py:469] Time since start: 33253.17s, 	Step: 5067, 	{'train/loss': 0.12393351803598164, 'validation/loss': 0.12451191425098354, 'validation/num_examples': 83274637, 'test/loss': 0.12687136709498356, 'test/num_examples': 95000000, 'score': 4843.497511148453, 'total_duration': 33253.16571331024, 'accumulated_submission_time': 4843.497511148453, 'accumulated_eval_time': 28408.54064488411, 'accumulated_logging_time': 0.8614559173583984}
I0306 22:25:26.990642 140356637157120 logging_writer.py:48] [5067] accumulated_eval_time=28408.5, accumulated_logging_time=0.861456, accumulated_submission_time=4843.5, global_step=5067, preemption_count=0, score=4843.5, test/loss=0.126871, test/num_examples=95000000, total_duration=33253.2, train/loss=0.123934, validation/loss=0.124512, validation/num_examples=83274637
I0306 22:25:37.039300 140356628764416 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.011982287280261517, loss=0.11614276468753815
I0306 22:27:27.499213 140509305742528 spec.py:321] Evaluating on the training split.
I0306 22:28:29.361585 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 22:31:38.660803 140509305742528 spec.py:349] Evaluating on the test split.
I0306 22:37:36.008801 140509305742528 submission_runner.py:469] Time since start: 33982.20s, 	Step: 5194, 	{'train/loss': 0.12352597946593971, 'validation/loss': 0.12450362377090916, 'validation/num_examples': 83274637, 'test/loss': 0.12688801067023026, 'test/num_examples': 95000000, 'score': 4963.992910861969, 'total_duration': 33982.19502043724, 'accumulated_submission_time': 4963.992910861969, 'accumulated_eval_time': 29017.050176143646, 'accumulated_logging_time': 0.8794779777526855}
I0306 22:37:36.018816 140356637157120 logging_writer.py:48] [5194] accumulated_eval_time=29017.1, accumulated_logging_time=0.879478, accumulated_submission_time=4963.99, global_step=5194, preemption_count=0, score=4963.99, test/loss=0.126888, test/num_examples=95000000, total_duration=33982.2, train/loss=0.123526, validation/loss=0.124504, validation/num_examples=83274637
I0306 22:37:36.758261 140356628764416 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.03154521808028221, loss=0.125582754611969
I0306 22:39:14.814199 140356637157120 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.010922376066446304, loss=0.1197047308087349
I0306 22:39:37.196273 140509305742528 spec.py:321] Evaluating on the training split.
I0306 22:40:36.613993 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 22:43:40.940185 140509305742528 spec.py:349] Evaluating on the test split.
I0306 22:49:41.130553 140509305742528 submission_runner.py:469] Time since start: 34707.32s, 	Step: 5318, 	{'train/loss': 0.12354870204983642, 'validation/loss': 0.12464527777818098, 'validation/num_examples': 83274637, 'test/loss': 0.12713911635485198, 'test/num_examples': 95000000, 'score': 5085.157001018524, 'total_duration': 34707.31677412987, 'accumulated_submission_time': 5085.157001018524, 'accumulated_eval_time': 29620.984396219254, 'accumulated_logging_time': 0.8968589305877686}
I0306 22:49:41.142345 140356628764416 logging_writer.py:48] [5318] accumulated_eval_time=29621, accumulated_logging_time=0.896859, accumulated_submission_time=5085.16, global_step=5318, preemption_count=0, score=5085.16, test/loss=0.127139, test/num_examples=95000000, total_duration=34707.3, train/loss=0.123549, validation/loss=0.124645, validation/num_examples=83274637
I0306 22:50:47.158681 140356637157120 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.00730037922039628, loss=0.11999334394931793
I0306 22:51:41.407299 140509305742528 spec.py:321] Evaluating on the training split.
I0306 22:52:43.678337 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 22:55:53.983431 140509305742528 spec.py:349] Evaluating on the test split.
I0306 23:01:41.995172 140509305742528 submission_runner.py:469] Time since start: 35428.18s, 	Step: 5448, 	{'train/loss': 0.12361655376101814, 'validation/loss': 0.124411129647509, 'validation/num_examples': 83274637, 'test/loss': 0.1267885797080592, 'test/num_examples': 95000000, 'score': 5205.378924369812, 'total_duration': 35428.18138861656, 'accumulated_submission_time': 5205.378924369812, 'accumulated_eval_time': 30221.572199821472, 'accumulated_logging_time': 0.9449586868286133}
I0306 23:01:42.004728 140356628764416 logging_writer.py:48] [5448] accumulated_eval_time=30221.6, accumulated_logging_time=0.944959, accumulated_submission_time=5205.38, global_step=5448, preemption_count=0, score=5205.38, test/loss=0.126789, test/num_examples=95000000, total_duration=35428.2, train/loss=0.123617, validation/loss=0.124411, validation/num_examples=83274637
I0306 23:02:16.872586 140356637157120 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.010058185085654259, loss=0.12058462202548981
I0306 23:03:43.081677 140509305742528 spec.py:321] Evaluating on the training split.
I0306 23:04:43.275188 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 23:07:51.538985 140509305742528 spec.py:349] Evaluating on the test split.
I0306 23:13:54.924954 140509305742528 submission_runner.py:469] Time since start: 36161.11s, 	Step: 5575, 	{'train/loss': 0.12186008486779606, 'validation/loss': 0.12440496549715897, 'validation/num_examples': 83274637, 'test/loss': 0.12678455087376644, 'test/num_examples': 95000000, 'score': 5326.442034244537, 'total_duration': 36161.111144542694, 'accumulated_submission_time': 5326.442034244537, 'accumulated_eval_time': 30833.41538333893, 'accumulated_logging_time': 0.9620006084442139}
I0306 23:13:54.934854 140356628764416 logging_writer.py:48] [5575] accumulated_eval_time=30833.4, accumulated_logging_time=0.962001, accumulated_submission_time=5326.44, global_step=5575, preemption_count=0, score=5326.44, test/loss=0.126785, test/num_examples=95000000, total_duration=36161.1, train/loss=0.12186, validation/loss=0.124405, validation/num_examples=83274637
I0306 23:13:57.705225 140356637157120 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.03003094717860222, loss=0.12634262442588806
I0306 23:15:55.579001 140509305742528 spec.py:321] Evaluating on the training split.
I0306 23:16:51.553871 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 23:20:01.750228 140509305742528 spec.py:349] Evaluating on the test split.
I0306 23:26:28.669547 140509305742528 submission_runner.py:469] Time since start: 36914.86s, 	Step: 5700, 	{'train/loss': 0.12373997178514423, 'validation/loss': 0.1244649840938833, 'validation/num_examples': 83274637, 'test/loss': 0.12692333149671053, 'test/num_examples': 95000000, 'score': 5447.07194185257, 'total_duration': 36914.85576796532, 'accumulated_submission_time': 5447.07194185257, 'accumulated_eval_time': 31466.50586438179, 'accumulated_logging_time': 0.9792451858520508}
I0306 23:26:28.679646 140356628764416 logging_writer.py:48] [5700] accumulated_eval_time=31466.5, accumulated_logging_time=0.979245, accumulated_submission_time=5447.07, global_step=5700, preemption_count=0, score=5447.07, test/loss=0.126923, test/num_examples=95000000, total_duration=36914.9, train/loss=0.12374, validation/loss=0.124465, validation/num_examples=83274637
I0306 23:26:28.795854 140356637157120 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.02805670164525509, loss=0.13138175010681152
I0306 23:27:56.330198 140356628764416 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.0069444989785552025, loss=0.12893618643283844
I0306 23:28:29.318338 140509305742528 spec.py:321] Evaluating on the training split.
I0306 23:29:25.481853 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 23:32:35.470558 140509305742528 spec.py:349] Evaluating on the test split.
I0306 23:38:28.718010 140509305742528 submission_runner.py:469] Time since start: 37634.90s, 	Step: 5829, 	{'train/loss': 0.12467125643911602, 'validation/loss': 0.12439533651961836, 'validation/num_examples': 83274637, 'test/loss': 0.1268094626747533, 'test/num_examples': 95000000, 'score': 5567.697677612305, 'total_duration': 37634.904227018356, 'accumulated_submission_time': 5567.697677612305, 'accumulated_eval_time': 32065.905464172363, 'accumulated_logging_time': 0.9956927299499512}
I0306 23:38:28.728605 140356637157120 logging_writer.py:48] [5829] accumulated_eval_time=32065.9, accumulated_logging_time=0.995693, accumulated_submission_time=5567.7, global_step=5829, preemption_count=0, score=5567.7, test/loss=0.126809, test/num_examples=95000000, total_duration=37634.9, train/loss=0.124671, validation/loss=0.124395, validation/num_examples=83274637
I0306 23:39:22.463022 140356628764416 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.008185181766748428, loss=0.12149649858474731
I0306 23:40:29.718807 140509305742528 spec.py:321] Evaluating on the training split.
I0306 23:41:30.705505 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 23:44:37.745075 140509305742528 spec.py:349] Evaluating on the test split.
I0306 23:50:39.057867 140509305742528 submission_runner.py:469] Time since start: 38365.24s, 	Step: 5959, 	{'train/loss': 0.12374095472290456, 'validation/loss': 0.12430862470925946, 'validation/num_examples': 83274637, 'test/loss': 0.12665763365542762, 'test/num_examples': 95000000, 'score': 5688.673250675201, 'total_duration': 38365.244097948074, 'accumulated_submission_time': 5688.673250675201, 'accumulated_eval_time': 32675.244466781616, 'accumulated_logging_time': 1.0134906768798828}
I0306 23:50:39.067646 140356637157120 logging_writer.py:48] [5959] accumulated_eval_time=32675.2, accumulated_logging_time=1.01349, accumulated_submission_time=5688.67, global_step=5959, preemption_count=0, score=5688.67, test/loss=0.126658, test/num_examples=95000000, total_duration=38365.2, train/loss=0.123741, validation/loss=0.124309, validation/num_examples=83274637
I0306 23:50:58.948839 140356628764416 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.020645590499043465, loss=0.11834096908569336
I0306 23:52:40.471301 140509305742528 spec.py:321] Evaluating on the training split.
I0306 23:53:37.087219 140509305742528 spec.py:333] Evaluating on the validation split.
I0306 23:56:47.605256 140509305742528 spec.py:349] Evaluating on the test split.
I0307 00:02:57.533635 140509305742528 submission_runner.py:469] Time since start: 39103.72s, 	Step: 6087, 	{'train/loss': 0.12241206222079085, 'validation/loss': 0.12426193354862282, 'validation/num_examples': 83274637, 'test/loss': 0.12659296302425987, 'test/num_examples': 95000000, 'score': 5810.06338095665, 'total_duration': 39103.71987295151, 'accumulated_submission_time': 5810.06338095665, 'accumulated_eval_time': 33292.30675339699, 'accumulated_logging_time': 1.030564785003662}
I0307 00:02:57.543337 140356637157120 logging_writer.py:48] [6087] accumulated_eval_time=33292.3, accumulated_logging_time=1.03056, accumulated_submission_time=5810.06, global_step=6087, preemption_count=0, score=5810.06, test/loss=0.126593, test/num_examples=95000000, total_duration=39103.7, train/loss=0.122412, validation/loss=0.124262, validation/num_examples=83274637
I0307 00:02:59.036651 140356628764416 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.006966893561184406, loss=0.1260806918144226
I0307 00:04:40.608805 140356637157120 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.007351729087531567, loss=0.12130370736122131
I0307 00:04:57.578153 140509305742528 spec.py:321] Evaluating on the training split.
I0307 00:05:56.487303 140509305742528 spec.py:333] Evaluating on the validation split.
I0307 00:09:05.894716 140509305742528 spec.py:349] Evaluating on the test split.
I0307 00:15:02.790015 140509305742528 submission_runner.py:469] Time since start: 39828.98s, 	Step: 6215, 	{'train/loss': 0.12251727470436936, 'validation/loss': 0.12412731492645421, 'validation/num_examples': 83274637, 'test/loss': 0.12651640030838815, 'test/num_examples': 95000000, 'score': 5930.084972143173, 'total_duration': 39828.976217508316, 'accumulated_submission_time': 5930.084972143173, 'accumulated_eval_time': 33897.51853084564, 'accumulated_logging_time': 1.047086477279663}
I0307 00:15:02.800544 140356628764416 logging_writer.py:48] [6215] accumulated_eval_time=33897.5, accumulated_logging_time=1.04709, accumulated_submission_time=5930.08, global_step=6215, preemption_count=0, score=5930.08, test/loss=0.126516, test/num_examples=95000000, total_duration=39829, train/loss=0.122517, validation/loss=0.124127, validation/num_examples=83274637
I0307 00:16:15.512846 140356637157120 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.008075067773461342, loss=0.11580611765384674
I0307 00:17:02.857689 140509305742528 spec.py:321] Evaluating on the training split.
I0307 00:17:58.621954 140509305742528 spec.py:333] Evaluating on the validation split.
I0307 00:21:09.898002 140509305742528 spec.py:349] Evaluating on the test split.
I0307 00:27:18.518543 140509305742528 submission_runner.py:469] Time since start: 40564.70s, 	Step: 6337, 	{'train/loss': 0.12331262448767447, 'validation/loss': 0.12422000914782583, 'validation/num_examples': 83274637, 'test/loss': 0.12664726968544407, 'test/num_examples': 95000000, 'score': 6050.127838134766, 'total_duration': 40564.704760074615, 'accumulated_submission_time': 6050.127838134766, 'accumulated_eval_time': 34513.17931032181, 'accumulated_logging_time': 1.0652971267700195}
I0307 00:27:18.528299 140356628764416 logging_writer.py:48] [6337] accumulated_eval_time=34513.2, accumulated_logging_time=1.0653, accumulated_submission_time=6050.13, global_step=6337, preemption_count=0, score=6050.13, test/loss=0.126647, test/num_examples=95000000, total_duration=40564.7, train/loss=0.123313, validation/loss=0.12422, validation/num_examples=83274637
I0307 00:28:04.419587 140356637157120 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.013745592907071114, loss=0.11426647752523422
I0307 00:29:19.893100 140509305742528 spec.py:321] Evaluating on the training split.
I0307 00:30:16.765556 140509305742528 spec.py:333] Evaluating on the validation split.
I0307 00:33:27.510703 140509305742528 spec.py:349] Evaluating on the test split.
I0307 00:39:21.599889 140509305742528 submission_runner.py:469] Time since start: 41287.79s, 	Step: 6455, 	{'train/loss': 0.12309476358335723, 'validation/loss': 0.12406390551169935, 'validation/num_examples': 83274637, 'test/loss': 0.12645907514391447, 'test/num_examples': 95000000, 'score': 6171.478994846344, 'total_duration': 41287.78611207008, 'accumulated_submission_time': 6171.478994846344, 'accumulated_eval_time': 35114.88603401184, 'accumulated_logging_time': 1.0821278095245361}
I0307 00:39:21.609852 140356628764416 logging_writer.py:48] [6455] accumulated_eval_time=35114.9, accumulated_logging_time=1.08213, accumulated_submission_time=6171.48, global_step=6455, preemption_count=0, score=6171.48, test/loss=0.126459, test/num_examples=95000000, total_duration=41287.8, train/loss=0.123095, validation/loss=0.124064, validation/num_examples=83274637
I0307 00:39:47.143750 140356637157120 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.02260431833565235, loss=0.12413617968559265
I0307 00:41:22.449660 140509305742528 spec.py:321] Evaluating on the training split.
I0307 00:42:18.252609 140509305742528 spec.py:333] Evaluating on the validation split.
I0307 00:45:26.865802 140509305742528 spec.py:349] Evaluating on the test split.
I0307 00:51:21.572289 140509305742528 submission_runner.py:469] Time since start: 42007.76s, 	Step: 6583, 	{'train/loss': 0.12206921633918705, 'validation/loss': 0.12420100576267748, 'validation/num_examples': 83274637, 'test/loss': 0.1266279203227796, 'test/num_examples': 95000000, 'score': 6292.305370330811, 'total_duration': 42007.75849699974, 'accumulated_submission_time': 6292.305370330811, 'accumulated_eval_time': 35714.00858545303, 'accumulated_logging_time': 1.0986964702606201}
I0307 00:51:21.582412 140356628764416 logging_writer.py:48] [6583] accumulated_eval_time=35714, accumulated_logging_time=1.0987, accumulated_submission_time=6292.31, global_step=6583, preemption_count=0, score=6292.31, test/loss=0.126628, test/num_examples=95000000, total_duration=42007.8, train/loss=0.122069, validation/loss=0.124201, validation/num_examples=83274637
I0307 00:51:23.528396 140356637157120 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.01206649374216795, loss=0.12850701808929443
I0307 00:53:15.734850 140356628764416 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.010127279907464981, loss=0.12167095392942429
I0307 00:53:22.090628 140509305742528 spec.py:321] Evaluating on the training split.
I0307 00:54:18.322158 140509305742528 spec.py:333] Evaluating on the validation split.
I0307 00:57:27.392095 140509305742528 spec.py:349] Evaluating on the test split.
I0307 01:03:30.893545 140509305742528 submission_runner.py:469] Time since start: 42737.08s, 	Step: 6706, 	{'train/loss': 0.12409710525622908, 'validation/loss': 0.12423189405614168, 'validation/num_examples': 83274637, 'test/loss': 0.12674699332853617, 'test/num_examples': 95000000, 'score': 6412.801421403885, 'total_duration': 42737.07977414131, 'accumulated_submission_time': 6412.801421403885, 'accumulated_eval_time': 36322.81144142151, 'accumulated_logging_time': 1.1150517463684082}
I0307 01:03:30.903564 140356637157120 logging_writer.py:48] [6706] accumulated_eval_time=36322.8, accumulated_logging_time=1.11505, accumulated_submission_time=6412.8, global_step=6706, preemption_count=0, score=6412.8, test/loss=0.126747, test/num_examples=95000000, total_duration=42737.1, train/loss=0.124097, validation/loss=0.124232, validation/num_examples=83274637
I0307 01:04:54.328168 140356628764416 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.011583475396037102, loss=0.12264174222946167
I0307 01:05:31.974495 140509305742528 spec.py:321] Evaluating on the training split.
I0307 01:06:32.662690 140509305742528 spec.py:333] Evaluating on the validation split.
I0307 01:09:40.935518 140509305742528 spec.py:349] Evaluating on the test split.
I0307 01:15:39.010474 140509305742528 submission_runner.py:469] Time since start: 43465.20s, 	Step: 6833, 	{'train/loss': 0.12259552231843367, 'validation/loss': 0.12432100161841594, 'validation/num_examples': 83274637, 'test/loss': 0.12675763980263158, 'test/num_examples': 95000000, 'score': 6533.792570352554, 'total_duration': 43465.19669699669, 'accumulated_submission_time': 6533.792570352554, 'accumulated_eval_time': 36929.84735369682, 'accumulated_logging_time': 1.19862961769104}
I0307 01:15:39.021029 140356637157120 logging_writer.py:48] [6833] accumulated_eval_time=36929.8, accumulated_logging_time=1.19863, accumulated_submission_time=6533.79, global_step=6833, preemption_count=0, score=6533.79, test/loss=0.126758, test/num_examples=95000000, total_duration=43465.2, train/loss=0.122596, validation/loss=0.124321, validation/num_examples=83274637
I0307 01:16:27.358731 140356628764416 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.02912282571196556, loss=0.11980347335338593
I0307 01:17:40.090260 140509305742528 spec.py:321] Evaluating on the training split.
I0307 01:18:39.929375 140509305742528 spec.py:333] Evaluating on the validation split.
I0307 01:21:52.967058 140509305742528 spec.py:349] Evaluating on the test split.
I0307 01:28:06.644240 140509305742528 submission_runner.py:469] Time since start: 44212.83s, 	Step: 6959, 	{'train/loss': 0.12503757068899068, 'validation/loss': 0.12420375335421006, 'validation/num_examples': 83274637, 'test/loss': 0.12668076964432565, 'test/num_examples': 95000000, 'score': 6654.848897218704, 'total_duration': 44212.830439567566, 'accumulated_submission_time': 6654.848897218704, 'accumulated_eval_time': 37556.401248693466, 'accumulated_logging_time': 1.2157745361328125}
I0307 01:28:06.654737 140356637157120 logging_writer.py:48] [6959] accumulated_eval_time=37556.4, accumulated_logging_time=1.21577, accumulated_submission_time=6654.85, global_step=6959, preemption_count=0, score=6654.85, test/loss=0.126681, test/num_examples=95000000, total_duration=44212.8, train/loss=0.125038, validation/loss=0.124204, validation/num_examples=83274637
I0307 01:28:25.848103 140356628764416 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.009575705043971539, loss=0.12134060263633728
I0307 01:30:07.988050 140509305742528 spec.py:321] Evaluating on the training split.
I0307 01:31:07.450843 140509305742528 spec.py:333] Evaluating on the validation split.
I0307 01:34:14.300359 140509305742528 spec.py:349] Evaluating on the test split.
I0307 01:40:04.934434 140509305742528 submission_runner.py:469] Time since start: 44931.12s, 	Step: 7088, 	{'train/loss': 0.12217032515777732, 'validation/loss': 0.12397654663424673, 'validation/num_examples': 83274637, 'test/loss': 0.12633424015213815, 'test/num_examples': 95000000, 'score': 6776.16875576973, 'total_duration': 44931.12065386772, 'accumulated_submission_time': 6776.16875576973, 'accumulated_eval_time': 38153.34756731987, 'accumulated_logging_time': 1.2331268787384033}
I0307 01:40:04.944926 140356637157120 logging_writer.py:48] [7088] accumulated_eval_time=38153.3, accumulated_logging_time=1.23313, accumulated_submission_time=6776.17, global_step=7088, preemption_count=0, score=6776.17, test/loss=0.126334, test/num_examples=95000000, total_duration=44931.1, train/loss=0.12217, validation/loss=0.123977, validation/num_examples=83274637
I0307 01:40:06.374862 140356628764416 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.007953447289764881, loss=0.12164382636547089
I0307 01:41:44.759796 140356637157120 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.010467346757650375, loss=0.11340638995170593
I0307 01:42:05.825267 140509305742528 spec.py:321] Evaluating on the training split.
I0307 01:43:02.029450 140509305742528 spec.py:333] Evaluating on the validation split.
I0307 01:46:12.552645 140509305742528 spec.py:349] Evaluating on the test split.
I0307 01:52:05.495921 140509305742528 submission_runner.py:469] Time since start: 45651.68s, 	Step: 7219, 	{'train/loss': 0.1223513736336861, 'validation/loss': 0.12413108544161419, 'validation/num_examples': 83274637, 'test/loss': 0.12652017534950658, 'test/num_examples': 95000000, 'score': 6897.035079240799, 'total_duration': 45651.6821243763, 'accumulated_submission_time': 6897.035079240799, 'accumulated_eval_time': 38753.01813483238, 'accumulated_logging_time': 1.251053810119629}
I0307 01:52:05.506471 140356628764416 logging_writer.py:48] [7219] accumulated_eval_time=38753, accumulated_logging_time=1.25105, accumulated_submission_time=6897.04, global_step=7219, preemption_count=0, score=6897.04, test/loss=0.12652, test/num_examples=95000000, total_duration=45651.7, train/loss=0.122351, validation/loss=0.124131, validation/num_examples=83274637
I0307 01:53:14.565810 140356637157120 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.022414015606045723, loss=0.12491725385189056
I0307 01:54:05.860481 140509305742528 spec.py:321] Evaluating on the training split.
I0307 01:54:59.931645 140509305742528 spec.py:333] Evaluating on the validation split.
I0307 01:58:08.303738 140509305742528 spec.py:349] Evaluating on the test split.
I0307 02:03:59.089145 140509305742528 submission_runner.py:469] Time since start: 46365.28s, 	Step: 7347, 	{'train/loss': 0.12127834854870097, 'validation/loss': 0.12402632768024704, 'validation/num_examples': 83274637, 'test/loss': 0.1264284992393092, 'test/num_examples': 95000000, 'score': 7017.375420808792, 'total_duration': 46365.27537202835, 'accumulated_submission_time': 7017.375420808792, 'accumulated_eval_time': 39346.24674606323, 'accumulated_logging_time': 1.2683088779449463}
I0307 02:03:59.099787 140356628764416 logging_writer.py:48] [7347] accumulated_eval_time=39346.2, accumulated_logging_time=1.26831, accumulated_submission_time=7017.38, global_step=7347, preemption_count=0, score=7017.38, test/loss=0.126428, test/num_examples=95000000, total_duration=46365.3, train/loss=0.121278, validation/loss=0.124026, validation/num_examples=83274637
I0307 02:04:33.433356 140356637157120 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.0065954914316535, loss=0.12296728044748306
I0307 02:05:59.449592 140509305742528 spec.py:321] Evaluating on the training split.
I0307 02:06:56.282595 140509305742528 spec.py:333] Evaluating on the validation split.
I0307 02:10:07.127747 140509305742528 spec.py:349] Evaluating on the test split.
I0307 02:16:11.191086 140509305742528 submission_runner.py:469] Time since start: 47097.38s, 	Step: 7470, 	{'train/loss': 0.12420235880000412, 'validation/loss': 0.12395385588430274, 'validation/num_examples': 83274637, 'test/loss': 0.12625660303248357, 'test/num_examples': 95000000, 'score': 7137.711483240128, 'total_duration': 47097.37731003761, 'accumulated_submission_time': 7137.711483240128, 'accumulated_eval_time': 39957.98818349838, 'accumulated_logging_time': 1.285646677017212}
I0307 02:16:11.201621 140356628764416 logging_writer.py:48] [7470] accumulated_eval_time=39958, accumulated_logging_time=1.28565, accumulated_submission_time=7137.71, global_step=7470, preemption_count=0, score=7137.71, test/loss=0.126257, test/num_examples=95000000, total_duration=47097.4, train/loss=0.124202, validation/loss=0.123954, validation/num_examples=83274637
I0307 02:16:18.106443 140356637157120 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.007722263224422932, loss=0.130680114030838
I0307 02:18:11.426834 140509305742528 spec.py:321] Evaluating on the training split.
I0307 02:19:07.759766 140509305742528 spec.py:333] Evaluating on the validation split.
I0307 02:22:17.998506 140509305742528 spec.py:349] Evaluating on the test split.
I0307 02:28:14.959597 140509305742528 submission_runner.py:469] Time since start: 47821.15s, 	Step: 7593, 	{'train/loss': 0.12151141345219792, 'validation/loss': 0.1237976818509353, 'validation/num_examples': 83274637, 'test/loss': 0.12613208875411183, 'test/num_examples': 95000000, 'score': 7257.9241416454315, 'total_duration': 47821.14582967758, 'accumulated_submission_time': 7257.9241416454315, 'accumulated_eval_time': 40561.520896434784, 'accumulated_logging_time': 1.302649736404419}
I0307 02:28:14.970026 140356628764416 logging_writer.py:48] [7593] accumulated_eval_time=40561.5, accumulated_logging_time=1.30265, accumulated_submission_time=7257.92, global_step=7593, preemption_count=0, score=7257.92, test/loss=0.126132, test/num_examples=95000000, total_duration=47821.1, train/loss=0.121511, validation/loss=0.123798, validation/num_examples=83274637
I0307 02:28:15.885884 140356637157120 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.007003773003816605, loss=0.12187018245458603
I0307 02:29:53.707676 140356628764416 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.007732103578746319, loss=0.12344996631145477
I0307 02:30:15.699051 140509305742528 spec.py:321] Evaluating on the training split.
I0307 02:31:13.526221 140509305742528 spec.py:333] Evaluating on the validation split.
I0307 02:34:24.350327 140509305742528 spec.py:349] Evaluating on the test split.
I0307 02:40:29.218116 140509305742528 submission_runner.py:469] Time since start: 48555.40s, 	Step: 7722, 	{'train/loss': 0.1231841328641716, 'validation/loss': 0.12388422563669506, 'validation/num_examples': 83274637, 'test/loss': 0.12623506155427633, 'test/num_examples': 95000000, 'score': 7378.605705499649, 'total_duration': 48555.40432238579, 'accumulated_submission_time': 7378.605705499649, 'accumulated_eval_time': 41175.03987503052, 'accumulated_logging_time': 1.3543345928192139}
I0307 02:40:29.261675 140356637157120 logging_writer.py:48] [7722] accumulated_eval_time=41175, accumulated_logging_time=1.35433, accumulated_submission_time=7378.61, global_step=7722, preemption_count=0, score=7378.61, test/loss=0.126235, test/num_examples=95000000, total_duration=48555.4, train/loss=0.123184, validation/loss=0.123884, validation/num_examples=83274637
I0307 02:41:33.257474 140356628764416 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.009237650781869888, loss=0.1214287057518959
I0307 02:42:29.335186 140509305742528 spec.py:321] Evaluating on the training split.
I0307 02:43:28.096050 140509305742528 spec.py:333] Evaluating on the validation split.
I0307 02:46:37.030075 140509305742528 spec.py:349] Evaluating on the test split.
I0307 02:52:50.938106 140509305742528 submission_runner.py:469] Time since start: 49297.12s, 	Step: 7850, 	{'train/loss': 0.1254490743502506, 'validation/loss': 0.12390891825760637, 'validation/num_examples': 83274637, 'test/loss': 0.12622211369243422, 'test/num_examples': 95000000, 'score': 7498.665834903717, 'total_duration': 49297.12431430817, 'accumulated_submission_time': 7498.665834903717, 'accumulated_eval_time': 41796.64272117615, 'accumulated_logging_time': 1.4044930934906006}
I0307 02:52:50.948688 140356637157120 logging_writer.py:48] [7850] accumulated_eval_time=41796.6, accumulated_logging_time=1.40449, accumulated_submission_time=7498.67, global_step=7850, preemption_count=0, score=7498.67, test/loss=0.126222, test/num_examples=95000000, total_duration=49297.1, train/loss=0.125449, validation/loss=0.123909, validation/num_examples=83274637
I0307 02:53:20.894028 140356628764416 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.008622318506240845, loss=0.11955440044403076
I0307 02:54:51.528320 140509305742528 spec.py:321] Evaluating on the training split.
I0307 02:55:48.355149 140509305742528 spec.py:333] Evaluating on the validation split.
I0307 02:59:00.669840 140509305742528 spec.py:349] Evaluating on the test split.
I0307 03:04:55.034817 140509305742528 submission_runner.py:469] Time since start: 50021.22s, 	Step: 7974, 	{'train/loss': 0.12153728056769326, 'validation/loss': 0.12372038572725931, 'validation/num_examples': 83274637, 'test/loss': 0.12609796714638158, 'test/num_examples': 95000000, 'score': 7619.232511520386, 'total_duration': 50021.22103476524, 'accumulated_submission_time': 7619.232511520386, 'accumulated_eval_time': 42400.1491522789, 'accumulated_logging_time': 1.4221105575561523}
I0307 03:04:55.075200 140356637157120 logging_writer.py:48] [7974] accumulated_eval_time=42400.1, accumulated_logging_time=1.42211, accumulated_submission_time=7619.23, global_step=7974, preemption_count=0, score=7619.23, test/loss=0.126098, test/num_examples=95000000, total_duration=50021.2, train/loss=0.121537, validation/loss=0.12372, validation/num_examples=83274637
I0307 03:04:58.003437 140356628764416 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.007668066769838333, loss=0.12585681676864624
I0307 03:06:55.000918 140356637157120 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.009070107713341713, loss=0.130984365940094
I0307 03:06:56.038441 140356628764416 logging_writer.py:48] [8102] global_step=8102, preemption_count=0, score=7740.18
I0307 03:07:05.622525 140509305742528 submission_runner.py:646] Tuning trial 3/5
I0307 03:07:05.644122 140509305742528 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.0, learning_rate=0.001308209823469072, one_minus_beta1=0.02686663061, beta2=0.9981232922116359, weight_decay=0.16375311233774334, warmup_factor=0.1)
I0307 03:07:05.645195 140509305742528 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/loss': 0.9870146346167199, 'validation/loss': 0.9862271805163347, 'validation/num_examples': 83274637, 'test/loss': 0.985843563569079, 'test/num_examples': 95000000, 'score': 17.72789716720581, 'total_duration': 1190.4917731285095, 'accumulated_submission_time': 17.72789716720581, 'accumulated_eval_time': 1172.76375746727, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (124, {'train/loss': 0.14307794647303018, 'validation/loss': 0.14277844433636086, 'validation/num_examples': 83274637, 'test/loss': 0.14598290960115132, 'test/num_examples': 95000000, 'score': 138.4297993183136, 'total_duration': 2360.947211265564, 'accumulated_submission_time': 138.4297993183136, 'accumulated_eval_time': 2222.443418979645, 'accumulated_logging_time': 0.06685161590576172, 'global_step': 124, 'preemption_count': 0}), (245, {'train/loss': 0.13053450523729218, 'validation/loss': 0.13068818285337813, 'validation/num_examples': 83274637, 'test/loss': 0.13347282935855262, 'test/num_examples': 95000000, 'score': 259.29946541786194, 'total_duration': 3518.0293073654175, 'accumulated_submission_time': 259.29946541786194, 'accumulated_eval_time': 3258.631545305252, 'accumulated_logging_time': 0.08512091636657715, 'global_step': 245, 'preemption_count': 0}), (369, {'train/loss': 0.12754434197203918, 'validation/loss': 0.1282757396677488, 'validation/num_examples': 83274637, 'test/loss': 0.13091664190995067, 'test/num_examples': 95000000, 'score': 380.1980209350586, 'total_duration': 4648.295297622681, 'accumulated_submission_time': 380.1980209350586, 'accumulated_eval_time': 4267.975531101227, 'accumulated_logging_time': 0.10165786743164062, 'global_step': 369, 'preemption_count': 0}), (494, {'train/loss': 0.12870058463007775, 'validation/loss': 0.12785489244265258, 'validation/num_examples': 83274637, 'test/loss': 0.13028595790501646, 'test/num_examples': 95000000, 'score': 500.134396314621, 'total_duration': 5805.875465869904, 'accumulated_submission_time': 500.134396314621, 'accumulated_eval_time': 5305.530732870102, 'accumulated_logging_time': 0.1841130256652832, 'global_step': 494, 'preemption_count': 0}), (620, {'train/loss': 0.12362088646107125, 'validation/loss': 0.12737766259786992, 'validation/num_examples': 83274637, 'test/loss': 0.1299505213096217, 'test/num_examples': 95000000, 'score': 620.7894442081451, 'total_duration': 6914.787329912186, 'accumulated_submission_time': 620.7894442081451, 'accumulated_eval_time': 6293.76421046257, 'accumulated_logging_time': 0.20059657096862793, 'global_step': 620, 'preemption_count': 0}), (745, {'train/loss': 0.12734343246234664, 'validation/loss': 0.12696358962668197, 'validation/num_examples': 83274637, 'test/loss': 0.1295415900390625, 'test/num_examples': 95000000, 'score': 740.8555519580841, 'total_duration': 8019.275276660919, 'accumulated_submission_time': 740.8555519580841, 'accumulated_eval_time': 7278.1632380485535, 'accumulated_logging_time': 0.2167654037475586, 'global_step': 745, 'preemption_count': 0}), (872, {'train/loss': 0.12576120418244563, 'validation/loss': 0.12676201601037712, 'validation/num_examples': 83274637, 'test/loss': 0.12933615482113486, 'test/num_examples': 95000000, 'score': 861.0649273395538, 'total_duration': 9021.15331864357, 'accumulated_submission_time': 861.0649273395538, 'accumulated_eval_time': 8159.809928417206, 'accumulated_logging_time': 0.2318553924560547, 'global_step': 872, 'preemption_count': 0}), (996, {'train/loss': 0.12408440759253202, 'validation/loss': 0.12664844259824723, 'validation/num_examples': 83274637, 'test/loss': 0.1291295396587171, 'test/num_examples': 95000000, 'score': 982.4999506473541, 'total_duration': 9893.30924987793, 'accumulated_submission_time': 982.4999506473541, 'accumulated_eval_time': 8910.508894443512, 'accumulated_logging_time': 0.24726533889770508, 'global_step': 996, 'preemption_count': 0}), (1126, {'train/loss': 0.12540010775222718, 'validation/loss': 0.12641072524654176, 'validation/num_examples': 83274637, 'test/loss': 0.12866692138157895, 'test/num_examples': 95000000, 'score': 1102.9177012443542, 'total_duration': 10621.201610565186, 'accumulated_submission_time': 1102.9177012443542, 'accumulated_eval_time': 9517.962346792221, 'accumulated_logging_time': 0.2617225646972656, 'global_step': 1126, 'preemption_count': 0}), (1253, {'train/loss': 0.12415934215832806, 'validation/loss': 0.1262083578406577, 'validation/num_examples': 83274637, 'test/loss': 0.1285697015625, 'test/num_examples': 95000000, 'score': 1223.3134772777557, 'total_duration': 11341.136915922165, 'accumulated_submission_time': 1223.3134772777557, 'accumulated_eval_time': 10117.478810071945, 'accumulated_logging_time': 0.2776312828063965, 'global_step': 1253, 'preemption_count': 0}), (1379, {'train/loss': 0.12402049420436598, 'validation/loss': 0.1259793766774953, 'validation/num_examples': 83274637, 'test/loss': 0.1284818775287829, 'test/num_examples': 95000000, 'score': 1343.547863960266, 'total_duration': 12076.516550064087, 'accumulated_submission_time': 1343.547863960266, 'accumulated_eval_time': 10732.60162115097, 'accumulated_logging_time': 0.29361414909362793, 'global_step': 1379, 'preemption_count': 0}), (1506, {'train/loss': 0.12453832281694847, 'validation/loss': 0.12591303304170737, 'validation/num_examples': 83274637, 'test/loss': 0.12836292896792764, 'test/num_examples': 95000000, 'score': 1463.8219027519226, 'total_duration': 12812.291413068771, 'accumulated_submission_time': 1463.8219027519226, 'accumulated_eval_time': 11348.081369161606, 'accumulated_logging_time': 0.30875658988952637, 'global_step': 1506, 'preemption_count': 0}), (1638, {'train/loss': 0.1244377020113873, 'validation/loss': 0.12603723070857922, 'validation/num_examples': 83274637, 'test/loss': 0.12857375151110198, 'test/num_examples': 95000000, 'score': 1585.2758927345276, 'total_duration': 13545.989592790604, 'accumulated_submission_time': 1585.2758927345276, 'accumulated_eval_time': 11960.289261102676, 'accumulated_logging_time': 0.33843469619750977, 'global_step': 1638, 'preemption_count': 0}), (1762, {'train/loss': 0.1251332244525353, 'validation/loss': 0.12573872166874284, 'validation/num_examples': 83274637, 'test/loss': 0.12816010159333882, 'test/num_examples': 95000000, 'score': 1706.8995563983917, 'total_duration': 14273.08050584793, 'accumulated_submission_time': 1706.8995563983917, 'accumulated_eval_time': 12565.73476433754, 'accumulated_logging_time': 0.35353922843933105, 'global_step': 1762, 'preemption_count': 0}), (1889, {'train/loss': 0.12469019265201106, 'validation/loss': 0.12567573237412086, 'validation/num_examples': 83274637, 'test/loss': 0.12812983347039475, 'test/num_examples': 95000000, 'score': 1827.4074356555939, 'total_duration': 15003.204395532608, 'accumulated_submission_time': 1827.4074356555939, 'accumulated_eval_time': 13175.328134536743, 'accumulated_logging_time': 0.36960649490356445, 'global_step': 1889, 'preemption_count': 0}), (2020, {'train/loss': 0.12386352577065148, 'validation/loss': 0.12573673768146573, 'validation/num_examples': 83274637, 'test/loss': 0.12822271802014804, 'test/num_examples': 95000000, 'score': 1947.667148590088, 'total_duration': 15744.426137924194, 'accumulated_submission_time': 1947.667148590088, 'accumulated_eval_time': 13796.267896413803, 'accumulated_logging_time': 0.38542675971984863, 'global_step': 2020, 'preemption_count': 0}), (2146, {'train/loss': 0.12481278964792783, 'validation/loss': 0.12566271305935714, 'validation/num_examples': 83274637, 'test/loss': 0.1280357357319079, 'test/num_examples': 95000000, 'score': 2068.6708986759186, 'total_duration': 16482.5283536911, 'accumulated_submission_time': 2068.6708986759186, 'accumulated_eval_time': 14413.344351291656, 'accumulated_logging_time': 0.40079474449157715, 'global_step': 2146, 'preemption_count': 0}), (2269, {'train/loss': 0.12229088147949872, 'validation/loss': 0.12551327272203391, 'validation/num_examples': 83274637, 'test/loss': 0.1279012245990954, 'test/num_examples': 95000000, 'score': 2189.3716802597046, 'total_duration': 17200.951144456863, 'accumulated_submission_time': 2189.3716802597046, 'accumulated_eval_time': 15011.04449892044, 'accumulated_logging_time': 0.416607141494751, 'global_step': 2269, 'preemption_count': 0}), (2394, {'train/loss': 0.1255097726371678, 'validation/loss': 0.12545194623533942, 'validation/num_examples': 83274637, 'test/loss': 0.12780543392269736, 'test/num_examples': 95000000, 'score': 2310.1929738521576, 'total_duration': 17941.347943782806, 'accumulated_submission_time': 2310.1929738521576, 'accumulated_eval_time': 15630.59628033638, 'accumulated_logging_time': 0.4338719844818115, 'global_step': 2394, 'preemption_count': 0}), (2520, {'train/loss': 0.12342998578722747, 'validation/loss': 0.12537710428754256, 'validation/num_examples': 83274637, 'test/loss': 0.1278700271587171, 'test/num_examples': 95000000, 'score': 2430.4706349372864, 'total_duration': 18676.393878221512, 'accumulated_submission_time': 2430.4706349372864, 'accumulated_eval_time': 16245.342309951782, 'accumulated_logging_time': 0.44905972480773926, 'global_step': 2520, 'preemption_count': 0}), (2646, {'train/loss': 0.12457071734393167, 'validation/loss': 0.12535613442354304, 'validation/num_examples': 83274637, 'test/loss': 0.12776033624588815, 'test/num_examples': 95000000, 'score': 2550.893527507782, 'total_duration': 19390.1120364666, 'accumulated_submission_time': 2550.893527507782, 'accumulated_eval_time': 16838.614748239517, 'accumulated_logging_time': 0.4656243324279785, 'global_step': 2646, 'preemption_count': 0}), (2777, {'train/loss': 0.1248374111692673, 'validation/loss': 0.1253156425004703, 'validation/num_examples': 83274637, 'test/loss': 0.12763420406044407, 'test/num_examples': 95000000, 'score': 2672.1050760746, 'total_duration': 20120.211345672607, 'accumulated_submission_time': 2672.1050760746, 'accumulated_eval_time': 17447.478541135788, 'accumulated_logging_time': 0.4826650619506836, 'global_step': 2777, 'preemption_count': 0}), (2903, {'train/loss': 0.12232806869788365, 'validation/loss': 0.12529738888170566, 'validation/num_examples': 83274637, 'test/loss': 0.12758772689144737, 'test/num_examples': 95000000, 'score': 2792.8801906108856, 'total_duration': 20835.803799152374, 'accumulated_submission_time': 2792.8801906108856, 'accumulated_eval_time': 18042.274082183838, 'accumulated_logging_time': 0.4982187747955322, 'global_step': 2903, 'preemption_count': 0}), (3034, {'train/loss': 0.12495799123678568, 'validation/loss': 0.12498687539427708, 'validation/num_examples': 83274637, 'test/loss': 0.12727283682154605, 'test/num_examples': 95000000, 'score': 2914.4242186546326, 'total_duration': 21561.07530117035, 'accumulated_submission_time': 2914.4242186546326, 'accumulated_eval_time': 18645.97753882408, 'accumulated_logging_time': 0.5151445865631104, 'global_step': 3034, 'preemption_count': 0}), (3158, {'train/loss': 0.12223682494002318, 'validation/loss': 0.1251790931726945, 'validation/num_examples': 83274637, 'test/loss': 0.12739330848067434, 'test/num_examples': 95000000, 'score': 3034.578158378601, 'total_duration': 22297.25963997841, 'accumulated_submission_time': 3034.578158378601, 'accumulated_eval_time': 19261.985355854034, 'accumulated_logging_time': 0.5316812992095947, 'global_step': 3158, 'preemption_count': 0}), (3286, {'train/loss': 0.12176444657943533, 'validation/loss': 0.12488338053806977, 'validation/num_examples': 83274637, 'test/loss': 0.12720145108963815, 'test/num_examples': 95000000, 'score': 3154.7752990722656, 'total_duration': 23014.231615543365, 'accumulated_submission_time': 3154.7752990722656, 'accumulated_eval_time': 19858.737021684647, 'accumulated_logging_time': 0.5480880737304688, 'global_step': 3286, 'preemption_count': 0}), (3421, {'train/loss': 0.12635828938874058, 'validation/loss': 0.12499612892572937, 'validation/num_examples': 83274637, 'test/loss': 0.12740704832442434, 'test/num_examples': 95000000, 'score': 3275.061017513275, 'total_duration': 23753.182981729507, 'accumulated_submission_time': 3275.061017513275, 'accumulated_eval_time': 20477.37991976738, 'accumulated_logging_time': 0.5642910003662109, 'global_step': 3421, 'preemption_count': 0}), (3546, {'train/loss': 0.12344441868645965, 'validation/loss': 0.12503607968247207, 'validation/num_examples': 83274637, 'test/loss': 0.12738980991981907, 'test/num_examples': 95000000, 'score': 3395.2496240139008, 'total_duration': 24487.732225179672, 'accumulated_submission_time': 3395.2496240139008, 'accumulated_eval_time': 21091.718608617783, 'accumulated_logging_time': 0.5803818702697754, 'global_step': 3546, 'preemption_count': 0}), (3672, {'train/loss': 0.12589199657100927, 'validation/loss': 0.12511885724515753, 'validation/num_examples': 83274637, 'test/loss': 0.12739400322779607, 'test/num_examples': 95000000, 'score': 3515.8456337451935, 'total_duration': 25227.13987517357, 'accumulated_submission_time': 3515.8456337451935, 'accumulated_eval_time': 21710.44246172905, 'accumulated_logging_time': 0.6616146564483643, 'global_step': 3672, 'preemption_count': 0}), (3798, {'train/loss': 0.12451382979469479, 'validation/loss': 0.12495096226466439, 'validation/num_examples': 83274637, 'test/loss': 0.12723812987253288, 'test/num_examples': 95000000, 'score': 3635.9283056259155, 'total_duration': 25966.948876142502, 'accumulated_submission_time': 3635.9283056259155, 'accumulated_eval_time': 22330.14664196968, 'accumulated_logging_time': 0.6772773265838623, 'global_step': 3798, 'preemption_count': 0}), (3922, {'train/loss': 0.12472169059065152, 'validation/loss': 0.12493386829473661, 'validation/num_examples': 83274637, 'test/loss': 0.12725148337787828, 'test/num_examples': 95000000, 'score': 3756.9378538131714, 'total_duration': 26683.06137418747, 'accumulated_submission_time': 3756.9378538131714, 'accumulated_eval_time': 22925.226697444916, 'accumulated_logging_time': 0.694007396697998, 'global_step': 3922, 'preemption_count': 0}), (4045, {'train/loss': 0.12494791117526076, 'validation/loss': 0.12502411575169942, 'validation/num_examples': 83274637, 'test/loss': 0.12738166315789473, 'test/num_examples': 95000000, 'score': 3877.821049451828, 'total_duration': 27419.334699630737, 'accumulated_submission_time': 3877.821049451828, 'accumulated_eval_time': 23540.59383225441, 'accumulated_logging_time': 0.7106015682220459, 'global_step': 4045, 'preemption_count': 0}), (4170, {'train/loss': 0.12198711483030573, 'validation/loss': 0.12487012539313516, 'validation/num_examples': 83274637, 'test/loss': 0.1272055441200658, 'test/num_examples': 95000000, 'score': 3998.225067138672, 'total_duration': 28136.597107172012, 'accumulated_submission_time': 3998.225067138672, 'accumulated_eval_time': 24137.429384946823, 'accumulated_logging_time': 0.7264842987060547, 'global_step': 4170, 'preemption_count': 0}), (4298, {'train/loss': 0.12330603847901027, 'validation/loss': 0.12483316138856676, 'validation/num_examples': 83274637, 'test/loss': 0.12727790523231908, 'test/num_examples': 95000000, 'score': 4118.365837574005, 'total_duration': 28857.612138032913, 'accumulated_submission_time': 4118.365837574005, 'accumulated_eval_time': 24738.2805891037, 'accumulated_logging_time': 0.7425436973571777, 'global_step': 4298, 'preemption_count': 0}), (4429, {'train/loss': 0.12210476412525717, 'validation/loss': 0.12469422000874723, 'validation/num_examples': 83274637, 'test/loss': 0.12709205892269737, 'test/num_examples': 95000000, 'score': 4238.617676258087, 'total_duration': 29598.98412656784, 'accumulated_submission_time': 4238.617676258087, 'accumulated_eval_time': 25359.37685751915, 'accumulated_logging_time': 0.7594344615936279, 'global_step': 4429, 'preemption_count': 0}), (4556, {'train/loss': 0.12163741908873776, 'validation/loss': 0.12446063164930661, 'validation/num_examples': 83274637, 'test/loss': 0.1268463900596217, 'test/num_examples': 95000000, 'score': 4359.428817510605, 'total_duration': 30334.25648856163, 'accumulated_submission_time': 4359.428817510605, 'accumulated_eval_time': 25973.797860860825, 'accumulated_logging_time': 0.7920169830322266, 'global_step': 4556, 'preemption_count': 0}), (4685, {'train/loss': 0.12301447802463418, 'validation/loss': 0.1246822144529526, 'validation/num_examples': 83274637, 'test/loss': 0.12710248657483553, 'test/num_examples': 95000000, 'score': 4480.223861455917, 'total_duration': 31064.48199248314, 'accumulated_submission_time': 4480.223861455917, 'accumulated_eval_time': 26583.202547073364, 'accumulated_logging_time': 0.8104231357574463, 'global_step': 4685, 'preemption_count': 0}), (4810, {'train/loss': 0.12219414013033768, 'validation/loss': 0.12440907996552195, 'validation/num_examples': 83274637, 'test/loss': 0.12675211577919407, 'test/num_examples': 95000000, 'score': 4601.008006811142, 'total_duration': 31785.689422369003, 'accumulated_submission_time': 4601.008006811142, 'accumulated_eval_time': 27183.60250711441, 'accumulated_logging_time': 0.8267953395843506, 'global_step': 4810, 'preemption_count': 0}), (4937, {'train/loss': 0.12202023659721485, 'validation/loss': 0.12440742384199015, 'validation/num_examples': 83274637, 'test/loss': 0.12677354612458883, 'test/num_examples': 95000000, 'score': 4722.624469995499, 'total_duration': 32510.72287130356, 'accumulated_submission_time': 4722.624469995499, 'accumulated_eval_time': 27786.996401309967, 'accumulated_logging_time': 0.8433670997619629, 'global_step': 4937, 'preemption_count': 0}), (5067, {'train/loss': 0.12393351803598164, 'validation/loss': 0.12451191425098354, 'validation/num_examples': 83274637, 'test/loss': 0.12687136709498356, 'test/num_examples': 95000000, 'score': 4843.497511148453, 'total_duration': 33253.16571331024, 'accumulated_submission_time': 4843.497511148453, 'accumulated_eval_time': 28408.54064488411, 'accumulated_logging_time': 0.8614559173583984, 'global_step': 5067, 'preemption_count': 0}), (5194, {'train/loss': 0.12352597946593971, 'validation/loss': 0.12450362377090916, 'validation/num_examples': 83274637, 'test/loss': 0.12688801067023026, 'test/num_examples': 95000000, 'score': 4963.992910861969, 'total_duration': 33982.19502043724, 'accumulated_submission_time': 4963.992910861969, 'accumulated_eval_time': 29017.050176143646, 'accumulated_logging_time': 0.8794779777526855, 'global_step': 5194, 'preemption_count': 0}), (5318, {'train/loss': 0.12354870204983642, 'validation/loss': 0.12464527777818098, 'validation/num_examples': 83274637, 'test/loss': 0.12713911635485198, 'test/num_examples': 95000000, 'score': 5085.157001018524, 'total_duration': 34707.31677412987, 'accumulated_submission_time': 5085.157001018524, 'accumulated_eval_time': 29620.984396219254, 'accumulated_logging_time': 0.8968589305877686, 'global_step': 5318, 'preemption_count': 0}), (5448, {'train/loss': 0.12361655376101814, 'validation/loss': 0.124411129647509, 'validation/num_examples': 83274637, 'test/loss': 0.1267885797080592, 'test/num_examples': 95000000, 'score': 5205.378924369812, 'total_duration': 35428.18138861656, 'accumulated_submission_time': 5205.378924369812, 'accumulated_eval_time': 30221.572199821472, 'accumulated_logging_time': 0.9449586868286133, 'global_step': 5448, 'preemption_count': 0}), (5575, {'train/loss': 0.12186008486779606, 'validation/loss': 0.12440496549715897, 'validation/num_examples': 83274637, 'test/loss': 0.12678455087376644, 'test/num_examples': 95000000, 'score': 5326.442034244537, 'total_duration': 36161.111144542694, 'accumulated_submission_time': 5326.442034244537, 'accumulated_eval_time': 30833.41538333893, 'accumulated_logging_time': 0.9620006084442139, 'global_step': 5575, 'preemption_count': 0}), (5700, {'train/loss': 0.12373997178514423, 'validation/loss': 0.1244649840938833, 'validation/num_examples': 83274637, 'test/loss': 0.12692333149671053, 'test/num_examples': 95000000, 'score': 5447.07194185257, 'total_duration': 36914.85576796532, 'accumulated_submission_time': 5447.07194185257, 'accumulated_eval_time': 31466.50586438179, 'accumulated_logging_time': 0.9792451858520508, 'global_step': 5700, 'preemption_count': 0}), (5829, {'train/loss': 0.12467125643911602, 'validation/loss': 0.12439533651961836, 'validation/num_examples': 83274637, 'test/loss': 0.1268094626747533, 'test/num_examples': 95000000, 'score': 5567.697677612305, 'total_duration': 37634.904227018356, 'accumulated_submission_time': 5567.697677612305, 'accumulated_eval_time': 32065.905464172363, 'accumulated_logging_time': 0.9956927299499512, 'global_step': 5829, 'preemption_count': 0}), (5959, {'train/loss': 0.12374095472290456, 'validation/loss': 0.12430862470925946, 'validation/num_examples': 83274637, 'test/loss': 0.12665763365542762, 'test/num_examples': 95000000, 'score': 5688.673250675201, 'total_duration': 38365.244097948074, 'accumulated_submission_time': 5688.673250675201, 'accumulated_eval_time': 32675.244466781616, 'accumulated_logging_time': 1.0134906768798828, 'global_step': 5959, 'preemption_count': 0}), (6087, {'train/loss': 0.12241206222079085, 'validation/loss': 0.12426193354862282, 'validation/num_examples': 83274637, 'test/loss': 0.12659296302425987, 'test/num_examples': 95000000, 'score': 5810.06338095665, 'total_duration': 39103.71987295151, 'accumulated_submission_time': 5810.06338095665, 'accumulated_eval_time': 33292.30675339699, 'accumulated_logging_time': 1.030564785003662, 'global_step': 6087, 'preemption_count': 0}), (6215, {'train/loss': 0.12251727470436936, 'validation/loss': 0.12412731492645421, 'validation/num_examples': 83274637, 'test/loss': 0.12651640030838815, 'test/num_examples': 95000000, 'score': 5930.084972143173, 'total_duration': 39828.976217508316, 'accumulated_submission_time': 5930.084972143173, 'accumulated_eval_time': 33897.51853084564, 'accumulated_logging_time': 1.047086477279663, 'global_step': 6215, 'preemption_count': 0}), (6337, {'train/loss': 0.12331262448767447, 'validation/loss': 0.12422000914782583, 'validation/num_examples': 83274637, 'test/loss': 0.12664726968544407, 'test/num_examples': 95000000, 'score': 6050.127838134766, 'total_duration': 40564.704760074615, 'accumulated_submission_time': 6050.127838134766, 'accumulated_eval_time': 34513.17931032181, 'accumulated_logging_time': 1.0652971267700195, 'global_step': 6337, 'preemption_count': 0}), (6455, {'train/loss': 0.12309476358335723, 'validation/loss': 0.12406390551169935, 'validation/num_examples': 83274637, 'test/loss': 0.12645907514391447, 'test/num_examples': 95000000, 'score': 6171.478994846344, 'total_duration': 41287.78611207008, 'accumulated_submission_time': 6171.478994846344, 'accumulated_eval_time': 35114.88603401184, 'accumulated_logging_time': 1.0821278095245361, 'global_step': 6455, 'preemption_count': 0}), (6583, {'train/loss': 0.12206921633918705, 'validation/loss': 0.12420100576267748, 'validation/num_examples': 83274637, 'test/loss': 0.1266279203227796, 'test/num_examples': 95000000, 'score': 6292.305370330811, 'total_duration': 42007.75849699974, 'accumulated_submission_time': 6292.305370330811, 'accumulated_eval_time': 35714.00858545303, 'accumulated_logging_time': 1.0986964702606201, 'global_step': 6583, 'preemption_count': 0}), (6706, {'train/loss': 0.12409710525622908, 'validation/loss': 0.12423189405614168, 'validation/num_examples': 83274637, 'test/loss': 0.12674699332853617, 'test/num_examples': 95000000, 'score': 6412.801421403885, 'total_duration': 42737.07977414131, 'accumulated_submission_time': 6412.801421403885, 'accumulated_eval_time': 36322.81144142151, 'accumulated_logging_time': 1.1150517463684082, 'global_step': 6706, 'preemption_count': 0}), (6833, {'train/loss': 0.12259552231843367, 'validation/loss': 0.12432100161841594, 'validation/num_examples': 83274637, 'test/loss': 0.12675763980263158, 'test/num_examples': 95000000, 'score': 6533.792570352554, 'total_duration': 43465.19669699669, 'accumulated_submission_time': 6533.792570352554, 'accumulated_eval_time': 36929.84735369682, 'accumulated_logging_time': 1.19862961769104, 'global_step': 6833, 'preemption_count': 0}), (6959, {'train/loss': 0.12503757068899068, 'validation/loss': 0.12420375335421006, 'validation/num_examples': 83274637, 'test/loss': 0.12668076964432565, 'test/num_examples': 95000000, 'score': 6654.848897218704, 'total_duration': 44212.830439567566, 'accumulated_submission_time': 6654.848897218704, 'accumulated_eval_time': 37556.401248693466, 'accumulated_logging_time': 1.2157745361328125, 'global_step': 6959, 'preemption_count': 0}), (7088, {'train/loss': 0.12217032515777732, 'validation/loss': 0.12397654663424673, 'validation/num_examples': 83274637, 'test/loss': 0.12633424015213815, 'test/num_examples': 95000000, 'score': 6776.16875576973, 'total_duration': 44931.12065386772, 'accumulated_submission_time': 6776.16875576973, 'accumulated_eval_time': 38153.34756731987, 'accumulated_logging_time': 1.2331268787384033, 'global_step': 7088, 'preemption_count': 0}), (7219, {'train/loss': 0.1223513736336861, 'validation/loss': 0.12413108544161419, 'validation/num_examples': 83274637, 'test/loss': 0.12652017534950658, 'test/num_examples': 95000000, 'score': 6897.035079240799, 'total_duration': 45651.6821243763, 'accumulated_submission_time': 6897.035079240799, 'accumulated_eval_time': 38753.01813483238, 'accumulated_logging_time': 1.251053810119629, 'global_step': 7219, 'preemption_count': 0}), (7347, {'train/loss': 0.12127834854870097, 'validation/loss': 0.12402632768024704, 'validation/num_examples': 83274637, 'test/loss': 0.1264284992393092, 'test/num_examples': 95000000, 'score': 7017.375420808792, 'total_duration': 46365.27537202835, 'accumulated_submission_time': 7017.375420808792, 'accumulated_eval_time': 39346.24674606323, 'accumulated_logging_time': 1.2683088779449463, 'global_step': 7347, 'preemption_count': 0}), (7470, {'train/loss': 0.12420235880000412, 'validation/loss': 0.12395385588430274, 'validation/num_examples': 83274637, 'test/loss': 0.12625660303248357, 'test/num_examples': 95000000, 'score': 7137.711483240128, 'total_duration': 47097.37731003761, 'accumulated_submission_time': 7137.711483240128, 'accumulated_eval_time': 39957.98818349838, 'accumulated_logging_time': 1.285646677017212, 'global_step': 7470, 'preemption_count': 0}), (7593, {'train/loss': 0.12151141345219792, 'validation/loss': 0.1237976818509353, 'validation/num_examples': 83274637, 'test/loss': 0.12613208875411183, 'test/num_examples': 95000000, 'score': 7257.9241416454315, 'total_duration': 47821.14582967758, 'accumulated_submission_time': 7257.9241416454315, 'accumulated_eval_time': 40561.520896434784, 'accumulated_logging_time': 1.302649736404419, 'global_step': 7593, 'preemption_count': 0}), (7722, {'train/loss': 0.1231841328641716, 'validation/loss': 0.12388422563669506, 'validation/num_examples': 83274637, 'test/loss': 0.12623506155427633, 'test/num_examples': 95000000, 'score': 7378.605705499649, 'total_duration': 48555.40432238579, 'accumulated_submission_time': 7378.605705499649, 'accumulated_eval_time': 41175.03987503052, 'accumulated_logging_time': 1.3543345928192139, 'global_step': 7722, 'preemption_count': 0}), (7850, {'train/loss': 0.1254490743502506, 'validation/loss': 0.12390891825760637, 'validation/num_examples': 83274637, 'test/loss': 0.12622211369243422, 'test/num_examples': 95000000, 'score': 7498.665834903717, 'total_duration': 49297.12431430817, 'accumulated_submission_time': 7498.665834903717, 'accumulated_eval_time': 41796.64272117615, 'accumulated_logging_time': 1.4044930934906006, 'global_step': 7850, 'preemption_count': 0}), (7974, {'train/loss': 0.12153728056769326, 'validation/loss': 0.12372038572725931, 'validation/num_examples': 83274637, 'test/loss': 0.12609796714638158, 'test/num_examples': 95000000, 'score': 7619.232511520386, 'total_duration': 50021.22103476524, 'accumulated_submission_time': 7619.232511520386, 'accumulated_eval_time': 42400.1491522789, 'accumulated_logging_time': 1.4221105575561523, 'global_step': 7974, 'preemption_count': 0})], 'global_step': 8102}
I0307 03:07:05.645307 140509305742528 submission_runner.py:649] Timing: 7740.176728963852
I0307 03:07:05.645349 140509305742528 submission_runner.py:651] Total number of evals: 64
I0307 03:07:05.645382 140509305742528 submission_runner.py:652] ====================
I0307 03:07:05.645559 140509305742528 submission_runner.py:750] Final criteo1tb score: 2
