python submission_runner.py --framework=jax --workload=criteo1tb --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_2 --overwrite=True --save_checkpoints=False --rng_seed=1801420638 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=0 --hparam_end_index=1 2>&1 | tee -a /logs/criteo1tb_jax_03-06-2025-13-06-45.log
2025-03-06 13:07:02.621902: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741266423.206541       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741266423.414571       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0306 13:07:51.713984 139753023288512 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax.
I0306 13:07:54.966195 139753023288512 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0306 13:07:54.969585 139753023288512 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0306 13:07:55.003014 139753023288512 submission_runner.py:606] Using RNG seed 1801420638
I0306 13:07:58.029756 139753023288512 submission_runner.py:615] --- Tuning run 1/5 ---
I0306 13:07:58.029960 139753023288512 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_1.
I0306 13:07:58.030153 139753023288512 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_1/hparams.json.
I0306 13:07:58.270092 139753023288512 submission_runner.py:218] Initializing dataset.
I0306 13:07:58.270291 139753023288512 submission_runner.py:229] Initializing model.
I0306 13:08:08.399034 139753023288512 submission_runner.py:272] Initializing optimizer.
I0306 13:08:08.987315 139753023288512 submission_runner.py:279] Initializing metrics bundle.
I0306 13:08:08.987554 139753023288512 submission_runner.py:301] Initializing checkpoint and logger.
I0306 13:08:08.988355 139753023288512 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_1 with prefix checkpoint_
I0306 13:08:08.988465 139753023288512 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_1/meta_data_0.json.
I0306 13:08:08.988682 139753023288512 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0306 13:08:08.988743 139753023288512 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0306 13:08:09.568416 139753023288512 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_1/flags_0.json.
I0306 13:08:10.179668 139753023288512 submission_runner.py:337] Starting training loop.
I0306 13:08:26.605298 139611569370880 logging_writer.py:48] [0] global_step=0, grad_norm=10.743408203125, loss=1.4543946981430054
I0306 13:08:26.921680 139753023288512 spec.py:321] Evaluating on the training split.
I0306 13:14:52.421548 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 13:20:48.674165 139753023288512 spec.py:349] Evaluating on the test split.
I0306 13:27:29.836904 139753023288512 submission_runner.py:469] Time since start: 1159.66s, 	Step: 1, 	{'train/loss': 1.4535255662675173, 'validation/loss': 1.4525673488713315, 'validation/num_examples': 83274637, 'test/loss': 1.4525160299342106, 'test/num_examples': 95000000, 'score': 16.74186658859253, 'total_duration': 1159.6571462154388, 'accumulated_submission_time': 16.74186658859253, 'accumulated_eval_time': 1142.9151248931885, 'accumulated_logging_time': 0}
I0306 13:27:29.858864 139599389128448 logging_writer.py:48] [1] accumulated_eval_time=1142.92, accumulated_logging_time=0, accumulated_submission_time=16.7419, global_step=1, preemption_count=0, score=16.7419, test/loss=1.45252, test/num_examples=95000000, total_duration=1159.66, train/loss=1.45353, validation/loss=1.45257, validation/num_examples=83274637
I0306 13:28:59.596961 139599380735744 logging_writer.py:48] [100] global_step=100, grad_norm=0.12201033532619476, loss=0.15149056911468506
I0306 13:29:31.561110 139753023288512 spec.py:321] Evaluating on the training split.
I0306 13:35:36.430583 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 13:40:48.948091 139753023288512 spec.py:349] Evaluating on the test split.
I0306 13:46:38.862894 139753023288512 submission_runner.py:469] Time since start: 2308.68s, 	Step: 126, 	{'train/loss': 0.14135270012812046, 'validation/loss': 0.1411168969393106, 'validation/num_examples': 83274637, 'test/loss': 0.14444340982730264, 'test/num_examples': 95000000, 'score': 138.37683272361755, 'total_duration': 2308.683169603348, 'accumulated_submission_time': 138.37683272361755, 'accumulated_eval_time': 2170.2168505191803, 'accumulated_logging_time': 0.08210229873657227}
I0306 13:46:38.949642 139599389128448 logging_writer.py:48] [126] accumulated_eval_time=2170.22, accumulated_logging_time=0.0821023, accumulated_submission_time=138.377, global_step=126, preemption_count=0, score=138.377, test/loss=0.144443, test/num_examples=95000000, total_duration=2308.68, train/loss=0.141353, validation/loss=0.141117, validation/num_examples=83274637
I0306 13:47:42.409475 139599380735744 logging_writer.py:48] [200] global_step=200, grad_norm=0.030330417677760124, loss=0.1403110921382904
I0306 13:48:39.749404 139753023288512 spec.py:321] Evaluating on the training split.
I0306 13:54:27.965234 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 13:59:48.270154 139753023288512 spec.py:349] Evaluating on the test split.
I0306 14:05:33.355751 139753023288512 submission_runner.py:469] Time since start: 3443.18s, 	Step: 250, 	{'train/loss': 0.13066272484431476, 'validation/loss': 0.13006254446638266, 'validation/num_examples': 83274637, 'test/loss': 0.13297558521792763, 'test/num_examples': 95000000, 'score': 259.161328792572, 'total_duration': 3443.1760256290436, 'accumulated_submission_time': 259.161328792572, 'accumulated_eval_time': 3183.823165178299, 'accumulated_logging_time': 0.1751389503479004}
I0306 14:05:33.365779 139599389128448 logging_writer.py:48] [250] accumulated_eval_time=3183.82, accumulated_logging_time=0.175139, accumulated_submission_time=259.161, global_step=250, preemption_count=0, score=259.161, test/loss=0.132976, test/num_examples=95000000, total_duration=3443.18, train/loss=0.130663, validation/loss=0.130063, validation/num_examples=83274637
I0306 14:06:05.248362 139599380735744 logging_writer.py:48] [300] global_step=300, grad_norm=0.016285564750432968, loss=0.1330030858516693
I0306 14:07:34.287028 139753023288512 spec.py:321] Evaluating on the training split.
I0306 14:13:29.583201 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 14:18:36.106840 139753023288512 spec.py:349] Evaluating on the test split.
I0306 14:24:11.843466 139753023288512 submission_runner.py:469] Time since start: 4561.66s, 	Step: 377, 	{'train/loss': 0.12823215873220806, 'validation/loss': 0.12861615784567867, 'validation/num_examples': 83274637, 'test/loss': 0.1312007239925987, 'test/num_examples': 95000000, 'score': 380.0680949687958, 'total_duration': 4561.663745641708, 'accumulated_submission_time': 380.0680949687958, 'accumulated_eval_time': 4181.379553318024, 'accumulated_logging_time': 0.19199275970458984}
I0306 14:24:11.851482 139599389128448 logging_writer.py:48] [377] accumulated_eval_time=4181.38, accumulated_logging_time=0.191993, accumulated_submission_time=380.068, global_step=377, preemption_count=0, score=380.068, test/loss=0.131201, test/num_examples=95000000, total_duration=4561.66, train/loss=0.128232, validation/loss=0.128616, validation/num_examples=83274637
I0306 14:24:14.467464 139599380735744 logging_writer.py:48] [400] global_step=400, grad_norm=0.013518725521862507, loss=0.12433265894651413
I0306 14:26:09.783146 139599389128448 logging_writer.py:48] [500] global_step=500, grad_norm=0.02536945417523384, loss=0.13309639692306519
I0306 14:26:12.053902 139753023288512 spec.py:321] Evaluating on the training split.
I0306 14:31:56.196248 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 14:37:10.554553 139753023288512 spec.py:349] Evaluating on the test split.
I0306 14:43:09.940469 139753023288512 submission_runner.py:469] Time since start: 5699.76s, 	Step: 503, 	{'train/loss': 0.12624866251816164, 'validation/loss': 0.12786776319379026, 'validation/num_examples': 83274637, 'test/loss': 0.1305146603824013, 'test/num_examples': 95000000, 'score': 500.21348810195923, 'total_duration': 5699.760735750198, 'accumulated_submission_time': 500.21348810195923, 'accumulated_eval_time': 5199.266068935394, 'accumulated_logging_time': 0.24968314170837402}
I0306 14:43:09.948672 139599380735744 logging_writer.py:48] [503] accumulated_eval_time=5199.27, accumulated_logging_time=0.249683, accumulated_submission_time=500.213, global_step=503, preemption_count=0, score=500.213, test/loss=0.130515, test/num_examples=95000000, total_duration=5699.76, train/loss=0.126249, validation/loss=0.127868, validation/num_examples=83274637
I0306 14:44:39.466037 139599389128448 logging_writer.py:48] [600] global_step=600, grad_norm=0.026501251384615898, loss=0.1245148628950119
I0306 14:45:10.758978 139753023288512 spec.py:321] Evaluating on the training split.
I0306 14:50:47.288626 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 14:56:02.317986 139753023288512 spec.py:349] Evaluating on the test split.
I0306 15:01:35.791956 139753023288512 submission_runner.py:469] Time since start: 6805.61s, 	Step: 628, 	{'train/loss': 0.12496061418088353, 'validation/loss': 0.1275918102074611, 'validation/num_examples': 83274637, 'test/loss': 0.13010788941200657, 'test/num_examples': 95000000, 'score': 621.0098540782928, 'total_duration': 6805.612234592438, 'accumulated_submission_time': 621.0098540782928, 'accumulated_eval_time': 6184.2989864349365, 'accumulated_logging_time': 0.26456308364868164}
I0306 15:01:35.799822 139599380735744 logging_writer.py:48] [628] accumulated_eval_time=6184.3, accumulated_logging_time=0.264563, accumulated_submission_time=621.01, global_step=628, preemption_count=0, score=621.01, test/loss=0.130108, test/num_examples=95000000, total_duration=6805.61, train/loss=0.124961, validation/loss=0.127592, validation/num_examples=83274637
I0306 15:02:30.599925 139599389128448 logging_writer.py:48] [700] global_step=700, grad_norm=0.042015399783849716, loss=0.12812185287475586
I0306 15:03:37.188239 139753023288512 spec.py:321] Evaluating on the training split.
I0306 15:08:40.082604 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 15:13:17.598882 139753023288512 spec.py:349] Evaluating on the test split.
I0306 15:18:54.397068 139753023288512 submission_runner.py:469] Time since start: 7844.22s, 	Step: 756, 	{'train/loss': 0.1240639752187069, 'validation/loss': 0.1271913906773751, 'validation/num_examples': 83274637, 'test/loss': 0.12965028114720395, 'test/num_examples': 95000000, 'score': 742.3856189250946, 'total_duration': 7844.217311143875, 'accumulated_submission_time': 742.3856189250946, 'accumulated_eval_time': 7101.507717132568, 'accumulated_logging_time': 0.2784700393676758}
I0306 15:18:54.405247 139599380735744 logging_writer.py:48] [756] accumulated_eval_time=7101.51, accumulated_logging_time=0.27847, accumulated_submission_time=742.386, global_step=756, preemption_count=0, score=742.386, test/loss=0.12965, test/num_examples=95000000, total_duration=7844.22, train/loss=0.124064, validation/loss=0.127191, validation/num_examples=83274637
I0306 15:19:18.672148 139599389128448 logging_writer.py:48] [800] global_step=800, grad_norm=0.04386569559574127, loss=0.13839885592460632
I0306 15:20:55.369088 139753023288512 spec.py:321] Evaluating on the training split.
I0306 15:25:37.368007 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 15:29:47.880561 139753023288512 spec.py:349] Evaluating on the test split.
I0306 15:35:14.894750 139753023288512 submission_runner.py:469] Time since start: 8824.72s, 	Step: 885, 	{'train/loss': 0.12473721775290726, 'validation/loss': 0.1266481217648444, 'validation/num_examples': 83274637, 'test/loss': 0.12928262483552633, 'test/num_examples': 95000000, 'score': 863.336697101593, 'total_duration': 8824.71502494812, 'accumulated_submission_time': 863.336697101593, 'accumulated_eval_time': 7961.03332233429, 'accumulated_logging_time': 0.29311108589172363}
I0306 15:35:14.903276 139599380735744 logging_writer.py:48] [885] accumulated_eval_time=7961.03, accumulated_logging_time=0.293111, accumulated_submission_time=863.337, global_step=885, preemption_count=0, score=863.337, test/loss=0.129283, test/num_examples=95000000, total_duration=8824.72, train/loss=0.124737, validation/loss=0.126648, validation/num_examples=83274637
I0306 15:35:16.586931 139599389128448 logging_writer.py:48] [900] global_step=900, grad_norm=0.055498041212558746, loss=0.12035054713487625
I0306 15:37:06.338739 139599380735744 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.03064393810927868, loss=0.12920528650283813
I0306 15:37:15.584575 139753023288512 spec.py:321] Evaluating on the training split.
I0306 15:40:41.474248 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 15:43:43.365909 139753023288512 spec.py:349] Evaluating on the test split.
I0306 15:49:27.649554 139753023288512 submission_runner.py:469] Time since start: 9677.47s, 	Step: 1008, 	{'train/loss': 0.12581013408987402, 'validation/loss': 0.12641956031723306, 'validation/num_examples': 83274637, 'test/loss': 0.12878289254728617, 'test/num_examples': 95000000, 'score': 984.0054798126221, 'total_duration': 9677.469819545746, 'accumulated_submission_time': 984.0054798126221, 'accumulated_eval_time': 8693.098226547241, 'accumulated_logging_time': 0.3082268238067627}
I0306 15:49:27.658244 139599389128448 logging_writer.py:48] [1008] accumulated_eval_time=8693.1, accumulated_logging_time=0.308227, accumulated_submission_time=984.005, global_step=1008, preemption_count=0, score=984.005, test/loss=0.128783, test/num_examples=95000000, total_duration=9677.47, train/loss=0.12581, validation/loss=0.12642, validation/num_examples=83274637
I0306 15:50:46.580667 139599380735744 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.009881118312478065, loss=0.1258665770292282
I0306 15:51:28.392334 139753023288512 spec.py:321] Evaluating on the training split.
I0306 15:52:28.922141 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 15:55:33.019861 139753023288512 spec.py:349] Evaluating on the test split.
I0306 16:01:16.117007 139753023288512 submission_runner.py:469] Time since start: 10385.94s, 	Step: 1137, 	{'train/loss': 0.12520112972355113, 'validation/loss': 0.1263208865990107, 'validation/num_examples': 83274637, 'test/loss': 0.12880092427014803, 'test/num_examples': 95000000, 'score': 1104.726378917694, 'total_duration': 10385.937270402908, 'accumulated_submission_time': 1104.726378917694, 'accumulated_eval_time': 9280.822821855545, 'accumulated_logging_time': 0.32311487197875977}
I0306 16:01:16.126104 139599389128448 logging_writer.py:48] [1137] accumulated_eval_time=9280.82, accumulated_logging_time=0.323115, accumulated_submission_time=1104.73, global_step=1137, preemption_count=0, score=1104.73, test/loss=0.128801, test/num_examples=95000000, total_duration=10385.9, train/loss=0.125201, validation/loss=0.126321, validation/num_examples=83274637
I0306 16:02:00.160613 139599380735744 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.015957722440361977, loss=0.12172748148441315
I0306 16:03:16.824360 139753023288512 spec.py:321] Evaluating on the training split.
I0306 16:04:16.452822 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 16:07:18.377244 139753023288512 spec.py:349] Evaluating on the test split.
I0306 16:13:00.215281 139753023288512 submission_runner.py:469] Time since start: 11090.04s, 	Step: 1265, 	{'train/loss': 0.1262091969450315, 'validation/loss': 0.1261538307505809, 'validation/num_examples': 83274637, 'test/loss': 0.12867430064761512, 'test/num_examples': 95000000, 'score': 1225.4112598896027, 'total_duration': 11090.035559654236, 'accumulated_submission_time': 1225.4112598896027, 'accumulated_eval_time': 9864.213682413101, 'accumulated_logging_time': 0.33901143074035645}
I0306 16:13:00.223294 139599389128448 logging_writer.py:48] [1265] accumulated_eval_time=9864.21, accumulated_logging_time=0.339011, accumulated_submission_time=1225.41, global_step=1265, preemption_count=0, score=1225.41, test/loss=0.128674, test/num_examples=95000000, total_duration=11090, train/loss=0.126209, validation/loss=0.126154, validation/num_examples=83274637
I0306 16:13:12.292498 139599380735744 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.031861186027526855, loss=0.13066644966602325
I0306 16:15:00.912870 139753023288512 spec.py:321] Evaluating on the training split.
I0306 16:15:59.297129 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 16:19:07.640720 139753023288512 spec.py:349] Evaluating on the test split.
I0306 16:24:52.457872 139753023288512 submission_runner.py:469] Time since start: 11802.28s, 	Step: 1396, 	{'train/loss': 0.12545099882584698, 'validation/loss': 0.12596499445549406, 'validation/num_examples': 83274637, 'test/loss': 0.1284266758223684, 'test/num_examples': 95000000, 'score': 1346.087506055832, 'total_duration': 11802.278131961823, 'accumulated_submission_time': 1346.087506055832, 'accumulated_eval_time': 10455.758607625961, 'accumulated_logging_time': 0.35343289375305176}
I0306 16:24:52.466470 139599389128448 logging_writer.py:48] [1396] accumulated_eval_time=10455.8, accumulated_logging_time=0.353433, accumulated_submission_time=1346.09, global_step=1396, preemption_count=0, score=1346.09, test/loss=0.128427, test/num_examples=95000000, total_duration=11802.3, train/loss=0.125451, validation/loss=0.125965, validation/num_examples=83274637
I0306 16:24:53.021378 139599380735744 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.03163810819387436, loss=0.1236206665635109
I0306 16:26:32.297247 139599389128448 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.040037602186203, loss=0.1280139684677124
I0306 16:26:53.559413 139753023288512 spec.py:321] Evaluating on the training split.
I0306 16:27:52.714925 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 16:30:55.935185 139753023288512 spec.py:349] Evaluating on the test split.
I0306 16:36:49.705595 139753023288512 submission_runner.py:469] Time since start: 12519.53s, 	Step: 1520, 	{'train/loss': 0.12617661714928705, 'validation/loss': 0.12573100950030258, 'validation/num_examples': 83274637, 'test/loss': 0.12821313519736843, 'test/num_examples': 95000000, 'score': 1467.166160583496, 'total_duration': 12519.525873422623, 'accumulated_submission_time': 1467.166160583496, 'accumulated_eval_time': 11051.90472149849, 'accumulated_logging_time': 0.36910104751586914}
I0306 16:36:49.713934 139599380735744 logging_writer.py:48] [1520] accumulated_eval_time=11051.9, accumulated_logging_time=0.369101, accumulated_submission_time=1467.17, global_step=1520, preemption_count=0, score=1467.17, test/loss=0.128213, test/num_examples=95000000, total_duration=12519.5, train/loss=0.126177, validation/loss=0.125731, validation/num_examples=83274637
I0306 16:37:59.612657 139599389128448 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.03060653805732727, loss=0.12739697098731995
I0306 16:38:50.883694 139753023288512 spec.py:321] Evaluating on the training split.
I0306 16:39:49.991501 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 16:42:56.701709 139753023288512 spec.py:349] Evaluating on the test split.
I0306 16:48:37.153658 139753023288512 submission_runner.py:469] Time since start: 13226.97s, 	Step: 1643, 	{'train/loss': 0.12401223138162175, 'validation/loss': 0.12576887564029549, 'validation/num_examples': 83274637, 'test/loss': 0.12812032020970396, 'test/num_examples': 95000000, 'score': 1588.3229467868805, 'total_duration': 13226.973920583725, 'accumulated_submission_time': 1588.3229467868805, 'accumulated_eval_time': 11638.174624919891, 'accumulated_logging_time': 0.38399839401245117}
I0306 16:48:37.162404 139599380735744 logging_writer.py:48] [1643] accumulated_eval_time=11638.2, accumulated_logging_time=0.383998, accumulated_submission_time=1588.32, global_step=1643, preemption_count=0, score=1588.32, test/loss=0.12812, test/num_examples=95000000, total_duration=13227, train/loss=0.124012, validation/loss=0.125769, validation/num_examples=83274637
I0306 16:49:15.689870 139599389128448 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.020250987261533737, loss=0.12127521634101868
I0306 16:50:37.332820 139753023288512 spec.py:321] Evaluating on the training split.
I0306 16:51:34.479626 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 16:54:40.016197 139753023288512 spec.py:349] Evaluating on the test split.
I0306 17:00:12.038561 139753023288512 submission_runner.py:469] Time since start: 13921.86s, 	Step: 1772, 	{'train/loss': 0.12570396423011831, 'validation/loss': 0.126050628066964, 'validation/num_examples': 83274637, 'test/loss': 0.12857186626233552, 'test/num_examples': 95000000, 'score': 1708.4802877902985, 'total_duration': 13921.858832836151, 'accumulated_submission_time': 1708.4802877902985, 'accumulated_eval_time': 12212.880302667618, 'accumulated_logging_time': 0.39930057525634766}
I0306 17:00:12.046836 139599380735744 logging_writer.py:48] [1772] accumulated_eval_time=12212.9, accumulated_logging_time=0.399301, accumulated_submission_time=1708.48, global_step=1772, preemption_count=0, score=1708.48, test/loss=0.128572, test/num_examples=95000000, total_duration=13921.9, train/loss=0.125704, validation/loss=0.126051, validation/num_examples=83274637
I0306 17:00:17.565506 139599389128448 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.009744829498231411, loss=0.12300128489732742
I0306 17:02:12.785691 139753023288512 spec.py:321] Evaluating on the training split.
I0306 17:03:13.888310 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 17:06:16.033160 139753023288512 spec.py:349] Evaluating on the test split.
I0306 17:11:44.374738 139753023288512 submission_runner.py:469] Time since start: 14614.20s, 	Step: 1897, 	{'train/loss': 0.12516175014839606, 'validation/loss': 0.12550562229630127, 'validation/num_examples': 83274637, 'test/loss': 0.12801813953536184, 'test/num_examples': 95000000, 'score': 1829.203898191452, 'total_duration': 14614.195018053055, 'accumulated_submission_time': 1829.203898191452, 'accumulated_eval_time': 12784.469294071198, 'accumulated_logging_time': 0.41504669189453125}
I0306 17:11:44.384461 139599380735744 logging_writer.py:48] [1897] accumulated_eval_time=12784.5, accumulated_logging_time=0.415047, accumulated_submission_time=1829.2, global_step=1897, preemption_count=0, score=1829.2, test/loss=0.128018, test/num_examples=95000000, total_duration=14614.2, train/loss=0.125162, validation/loss=0.125506, validation/num_examples=83274637
I0306 17:11:44.827748 139599389128448 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.011740016750991344, loss=0.1255597174167633
I0306 17:13:17.174947 139599380735744 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.020080653950572014, loss=0.1276850402355194
I0306 17:13:45.715631 139753023288512 spec.py:321] Evaluating on the training split.
I0306 17:14:45.263456 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 17:17:50.822733 139753023288512 spec.py:349] Evaluating on the test split.
I0306 17:23:44.476587 139753023288512 submission_runner.py:469] Time since start: 15334.30s, 	Step: 2023, 	{'train/loss': 0.1250973710169395, 'validation/loss': 0.1253122296297975, 'validation/num_examples': 83274637, 'test/loss': 0.12759800679481909, 'test/num_examples': 95000000, 'score': 1950.521973848343, 'total_duration': 15334.296848773956, 'accumulated_submission_time': 1950.521973848343, 'accumulated_eval_time': 13383.23017668724, 'accumulated_logging_time': 0.43174076080322266}
I0306 17:23:44.484861 139599389128448 logging_writer.py:48] [2023] accumulated_eval_time=13383.2, accumulated_logging_time=0.431741, accumulated_submission_time=1950.52, global_step=2023, preemption_count=0, score=1950.52, test/loss=0.127598, test/num_examples=95000000, total_duration=15334.3, train/loss=0.125097, validation/loss=0.125312, validation/num_examples=83274637
I0306 17:24:42.358720 139599380735744 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.015971582382917404, loss=0.1263025403022766
I0306 17:25:44.711484 139753023288512 spec.py:321] Evaluating on the training split.
I0306 17:26:44.040861 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 17:29:44.965148 139753023288512 spec.py:349] Evaluating on the test split.
I0306 17:35:25.521329 139753023288512 submission_runner.py:469] Time since start: 16035.34s, 	Step: 2155, 	{'train/loss': 0.12333777863180863, 'validation/loss': 0.12542732108578006, 'validation/num_examples': 83274637, 'test/loss': 0.12804813585526315, 'test/num_examples': 95000000, 'score': 2070.7354197502136, 'total_duration': 16035.341599225998, 'accumulated_submission_time': 2070.7354197502136, 'accumulated_eval_time': 13964.039947271347, 'accumulated_logging_time': 0.4464583396911621}
I0306 17:35:25.530065 139599389128448 logging_writer.py:48] [2155] accumulated_eval_time=13964, accumulated_logging_time=0.446458, accumulated_submission_time=2070.74, global_step=2155, preemption_count=0, score=2070.74, test/loss=0.128048, test/num_examples=95000000, total_duration=16035.3, train/loss=0.123338, validation/loss=0.125427, validation/num_examples=83274637
I0306 17:35:49.540947 139599380735744 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.014176147989928722, loss=0.1368049532175064
I0306 17:37:26.515002 139753023288512 spec.py:321] Evaluating on the training split.
I0306 17:38:22.676906 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 17:41:29.354434 139753023288512 spec.py:349] Evaluating on the test split.
I0306 17:47:03.893815 139753023288512 submission_runner.py:469] Time since start: 16733.71s, 	Step: 2286, 	{'train/loss': 0.12571451774323886, 'validation/loss': 0.12537535649397366, 'validation/num_examples': 83274637, 'test/loss': 0.12786514505550986, 'test/num_examples': 95000000, 'score': 2191.70552611351, 'total_duration': 16733.714088201523, 'accumulated_submission_time': 2191.70552611351, 'accumulated_eval_time': 14541.418693065643, 'accumulated_logging_time': 0.46265602111816406}
I0306 17:47:03.902640 139599389128448 logging_writer.py:48] [2286] accumulated_eval_time=14541.4, accumulated_logging_time=0.462656, accumulated_submission_time=2191.71, global_step=2286, preemption_count=0, score=2191.71, test/loss=0.127865, test/num_examples=95000000, total_duration=16733.7, train/loss=0.125715, validation/loss=0.125375, validation/num_examples=83274637
I0306 17:47:05.520719 139599380735744 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.006617294624447823, loss=0.12036769837141037
I0306 17:48:47.473510 139599389128448 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.019317196682095528, loss=0.12353178858757019
I0306 17:49:04.467987 139753023288512 spec.py:321] Evaluating on the training split.
I0306 17:50:04.867825 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 17:53:08.218132 139753023288512 spec.py:349] Evaluating on the test split.
I0306 17:58:48.741041 139753023288512 submission_runner.py:469] Time since start: 17438.56s, 	Step: 2416, 	{'train/loss': 0.12519861234105983, 'validation/loss': 0.12518164363318915, 'validation/num_examples': 83274637, 'test/loss': 0.1277588550884046, 'test/num_examples': 95000000, 'score': 2312.2571444511414, 'total_duration': 17438.56133031845, 'accumulated_submission_time': 2312.2571444511414, 'accumulated_eval_time': 15125.691693544388, 'accumulated_logging_time': 0.47822999954223633}
I0306 17:58:48.750237 139599380735744 logging_writer.py:48] [2416] accumulated_eval_time=15125.7, accumulated_logging_time=0.47823, accumulated_submission_time=2312.26, global_step=2416, preemption_count=0, score=2312.26, test/loss=0.127759, test/num_examples=95000000, total_duration=17438.6, train/loss=0.125199, validation/loss=0.125182, validation/num_examples=83274637
I0306 18:00:05.050762 139599389128448 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.02288176119327545, loss=0.13163703680038452
I0306 18:00:48.786797 139753023288512 spec.py:321] Evaluating on the training split.
I0306 18:01:46.186013 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 18:04:52.478403 139753023288512 spec.py:349] Evaluating on the test split.
I0306 18:10:42.644460 139753023288512 submission_runner.py:469] Time since start: 18152.46s, 	Step: 2538, 	{'train/loss': 0.12364050747135526, 'validation/loss': 0.1251560481263247, 'validation/num_examples': 83274637, 'test/loss': 0.127580181589227, 'test/num_examples': 95000000, 'score': 2432.279986858368, 'total_duration': 18152.464739322662, 'accumulated_submission_time': 2432.279986858368, 'accumulated_eval_time': 15719.549294948578, 'accumulated_logging_time': 0.4940774440765381}
I0306 18:10:42.653273 139599380735744 logging_writer.py:48] [2538] accumulated_eval_time=15719.5, accumulated_logging_time=0.494077, accumulated_submission_time=2432.28, global_step=2538, preemption_count=0, score=2432.28, test/loss=0.12758, test/num_examples=95000000, total_duration=18152.5, train/loss=0.123641, validation/loss=0.125156, validation/num_examples=83274637
I0306 18:11:28.264892 139599389128448 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.011763853020966053, loss=0.12553754448890686
I0306 18:12:42.744578 139753023288512 spec.py:321] Evaluating on the training split.
I0306 18:13:41.367127 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 18:16:41.384893 139753023288512 spec.py:349] Evaluating on the test split.
I0306 18:22:12.423892 139753023288512 submission_runner.py:469] Time since start: 18842.24s, 	Step: 2665, 	{'train/loss': 0.12634129585616244, 'validation/loss': 0.1251323669658885, 'validation/num_examples': 83274637, 'test/loss': 0.12756020328947368, 'test/num_examples': 95000000, 'score': 2552.3581342697144, 'total_duration': 18842.24413895607, 'accumulated_submission_time': 2552.3581342697144, 'accumulated_eval_time': 16289.228524684906, 'accumulated_logging_time': 0.5094401836395264}
I0306 18:22:12.432904 139599380735744 logging_writer.py:48] [2665] accumulated_eval_time=16289.2, accumulated_logging_time=0.50944, accumulated_submission_time=2552.36, global_step=2665, preemption_count=0, score=2552.36, test/loss=0.12756, test/num_examples=95000000, total_duration=18842.2, train/loss=0.126341, validation/loss=0.125132, validation/num_examples=83274637
I0306 18:22:25.167066 139599389128448 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.011670217849314213, loss=0.12490645796060562
I0306 18:24:12.647192 139753023288512 spec.py:321] Evaluating on the training split.
I0306 18:25:08.078428 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 18:28:16.267471 139753023288512 spec.py:349] Evaluating on the test split.
I0306 18:33:57.512925 139753023288512 submission_runner.py:469] Time since start: 19547.33s, 	Step: 2798, 	{'train/loss': 0.12314442951677355, 'validation/loss': 0.1252687324200112, 'validation/num_examples': 83274637, 'test/loss': 0.12772373865131578, 'test/num_examples': 95000000, 'score': 2672.4966566562653, 'total_duration': 19547.333203792572, 'accumulated_submission_time': 2672.4966566562653, 'accumulated_eval_time': 16874.094198703766, 'accumulated_logging_time': 0.5867881774902344}
I0306 18:33:57.521623 139599380735744 logging_writer.py:48] [2798] accumulated_eval_time=16874.1, accumulated_logging_time=0.586788, accumulated_submission_time=2672.5, global_step=2798, preemption_count=0, score=2672.5, test/loss=0.127724, test/num_examples=95000000, total_duration=19547.3, train/loss=0.123144, validation/loss=0.125269, validation/num_examples=83274637
I0306 18:33:57.862740 139599389128448 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.018060067668557167, loss=0.1270856261253357
I0306 18:35:26.357983 139599380735744 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.00891875196248293, loss=0.12159170210361481
I0306 18:35:57.696408 139753023288512 spec.py:321] Evaluating on the training split.
I0306 18:36:53.289688 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 18:39:54.872098 139753023288512 spec.py:349] Evaluating on the test split.
I0306 18:45:29.848927 139753023288512 submission_runner.py:469] Time since start: 20239.67s, 	Step: 2928, 	{'train/loss': 0.1255923117505117, 'validation/loss': 0.12549018212209379, 'validation/num_examples': 83274637, 'test/loss': 0.1280555890625, 'test/num_examples': 95000000, 'score': 2792.658517599106, 'total_duration': 20239.669197797775, 'accumulated_submission_time': 2792.658517599106, 'accumulated_eval_time': 17446.246651649475, 'accumulated_logging_time': 0.6019270420074463}
I0306 18:45:29.858250 139599389128448 logging_writer.py:48] [2928] accumulated_eval_time=17446.2, accumulated_logging_time=0.601927, accumulated_submission_time=2792.66, global_step=2928, preemption_count=0, score=2792.66, test/loss=0.128056, test/num_examples=95000000, total_duration=20239.7, train/loss=0.125592, validation/loss=0.12549, validation/num_examples=83274637
I0306 18:46:24.109801 139599380735744 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.022072698920965195, loss=0.12656188011169434
I0306 18:47:31.100663 139753023288512 spec.py:321] Evaluating on the training split.
I0306 18:48:26.155370 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 18:51:32.886983 139753023288512 spec.py:349] Evaluating on the test split.
I0306 18:57:16.296931 139753023288512 submission_runner.py:469] Time since start: 20946.12s, 	Step: 3058, 	{'train/loss': 0.12569680815832046, 'validation/loss': 0.12484359395946691, 'validation/num_examples': 83274637, 'test/loss': 0.12715878844572368, 'test/num_examples': 95000000, 'score': 2913.8876259326935, 'total_duration': 20946.117216348648, 'accumulated_submission_time': 2913.8876259326935, 'accumulated_eval_time': 18031.44285750389, 'accumulated_logging_time': 0.6177117824554443}
I0306 18:57:16.305935 139599389128448 logging_writer.py:48] [3058] accumulated_eval_time=18031.4, accumulated_logging_time=0.617712, accumulated_submission_time=2913.89, global_step=3058, preemption_count=0, score=2913.89, test/loss=0.127159, test/num_examples=95000000, total_duration=20946.1, train/loss=0.125697, validation/loss=0.124844, validation/num_examples=83274637
I0306 18:57:37.125554 139599380735744 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.005419923923909664, loss=0.1168295219540596
I0306 18:59:17.290348 139753023288512 spec.py:321] Evaluating on the training split.
I0306 19:00:14.895653 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 19:03:16.686069 139753023288512 spec.py:349] Evaluating on the test split.
I0306 19:08:59.015854 139753023288512 submission_runner.py:469] Time since start: 21648.84s, 	Step: 3189, 	{'train/loss': 0.122308903297632, 'validation/loss': 0.12514212313457945, 'validation/num_examples': 83274637, 'test/loss': 0.12743598675986842, 'test/num_examples': 95000000, 'score': 3034.8572487831116, 'total_duration': 21648.83614397049, 'accumulated_submission_time': 3034.8572487831116, 'accumulated_eval_time': 18613.168325424194, 'accumulated_logging_time': 0.6341772079467773}
I0306 19:08:59.024872 139599389128448 logging_writer.py:48] [3189] accumulated_eval_time=18613.2, accumulated_logging_time=0.634177, accumulated_submission_time=3034.86, global_step=3189, preemption_count=0, score=3034.86, test/loss=0.127436, test/num_examples=95000000, total_duration=21648.8, train/loss=0.122309, validation/loss=0.125142, validation/num_examples=83274637
I0306 19:09:00.302631 139599380735744 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.009011158719658852, loss=0.1202518418431282
I0306 19:10:44.830608 139599389128448 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.009699367918074131, loss=0.1191067323088646
I0306 19:10:59.238440 139753023288512 spec.py:321] Evaluating on the training split.
I0306 19:11:55.341844 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 19:15:01.172283 139753023288512 spec.py:349] Evaluating on the test split.
I0306 19:20:39.207363 139753023288512 submission_runner.py:469] Time since start: 22349.03s, 	Step: 3315, 	{'train/loss': 0.12277026053916358, 'validation/loss': 0.12549915802244807, 'validation/num_examples': 83274637, 'test/loss': 0.12873279761513157, 'test/num_examples': 95000000, 'score': 3155.054258584976, 'total_duration': 22349.02760076523, 'accumulated_submission_time': 3155.054258584976, 'accumulated_eval_time': 19193.137138843536, 'accumulated_logging_time': 0.6541063785552979}
I0306 19:20:39.216401 139599380735744 logging_writer.py:48] [3315] accumulated_eval_time=19193.1, accumulated_logging_time=0.654106, accumulated_submission_time=3155.05, global_step=3315, preemption_count=0, score=3155.05, test/loss=0.128733, test/num_examples=95000000, total_duration=22349, train/loss=0.12277, validation/loss=0.125499, validation/num_examples=83274637
I0306 19:21:54.465233 139599389128448 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.02084748074412346, loss=0.13100410997867584
I0306 19:22:39.801196 139753023288512 spec.py:321] Evaluating on the training split.
I0306 19:23:36.076649 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 19:26:41.377711 139753023288512 spec.py:349] Evaluating on the test split.
I0306 19:32:29.314385 139753023288512 submission_runner.py:469] Time since start: 23059.13s, 	Step: 3439, 	{'train/loss': 0.12384747657573449, 'validation/loss': 0.12505317682455605, 'validation/num_examples': 83274637, 'test/loss': 0.1273452509971217, 'test/num_examples': 95000000, 'score': 3275.6263575553894, 'total_duration': 23059.134675502777, 'accumulated_submission_time': 3275.6263575553894, 'accumulated_eval_time': 19782.65028476715, 'accumulated_logging_time': 0.6697869300842285}
I0306 19:32:29.323706 139599380735744 logging_writer.py:48] [3439] accumulated_eval_time=19782.7, accumulated_logging_time=0.669787, accumulated_submission_time=3275.63, global_step=3439, preemption_count=0, score=3275.63, test/loss=0.127345, test/num_examples=95000000, total_duration=23059.1, train/loss=0.123847, validation/loss=0.125053, validation/num_examples=83274637
I0306 19:33:13.642127 139599389128448 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.007993964478373528, loss=0.12706705927848816
I0306 19:34:29.931413 139753023288512 spec.py:321] Evaluating on the training split.
I0306 19:35:27.429682 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 19:38:27.622493 139753023288512 spec.py:349] Evaluating on the test split.
I0306 19:44:14.950056 139753023288512 submission_runner.py:469] Time since start: 23764.77s, 	Step: 3569, 	{'train/loss': 0.124004953171847, 'validation/loss': 0.12510223892861844, 'validation/num_examples': 83274637, 'test/loss': 0.12736081428865131, 'test/num_examples': 95000000, 'score': 3396.2200679779053, 'total_duration': 23764.770309448242, 'accumulated_submission_time': 3396.2200679779053, 'accumulated_eval_time': 20367.66886305809, 'accumulated_logging_time': 0.6858391761779785}
I0306 19:44:14.959106 139599380735744 logging_writer.py:48] [3569] accumulated_eval_time=20367.7, accumulated_logging_time=0.685839, accumulated_submission_time=3396.22, global_step=3569, preemption_count=0, score=3396.22, test/loss=0.127361, test/num_examples=95000000, total_duration=23764.8, train/loss=0.124005, validation/loss=0.125102, validation/num_examples=83274637
I0306 19:44:23.358344 139599389128448 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.011468352749943733, loss=0.12093295156955719
I0306 19:46:15.482460 139753023288512 spec.py:321] Evaluating on the training split.
I0306 19:47:09.193152 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 19:50:14.136137 139753023288512 spec.py:349] Evaluating on the test split.
I0306 19:55:49.002096 139753023288512 submission_runner.py:469] Time since start: 24458.82s, 	Step: 3689, 	{'train/loss': 0.12225167269367467, 'validation/loss': 0.12509591033627082, 'validation/num_examples': 83274637, 'test/loss': 0.1273938716488487, 'test/num_examples': 95000000, 'score': 3516.7128055095673, 'total_duration': 24458.822382688522, 'accumulated_submission_time': 3516.7128055095673, 'accumulated_eval_time': 20941.18845152855, 'accumulated_logging_time': 0.7176284790039062}
I0306 19:55:49.011331 139599380735744 logging_writer.py:48] [3689] accumulated_eval_time=20941.2, accumulated_logging_time=0.717628, accumulated_submission_time=3516.71, global_step=3689, preemption_count=0, score=3516.71, test/loss=0.127394, test/num_examples=95000000, total_duration=24458.8, train/loss=0.122252, validation/loss=0.125096, validation/num_examples=83274637
I0306 19:55:50.281504 139599389128448 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.007520570419728756, loss=0.1282297968864441
I0306 19:57:26.667675 139599380735744 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.012001849710941315, loss=0.126005619764328
I0306 19:57:49.929653 139753023288512 spec.py:321] Evaluating on the training split.
I0306 19:58:46.732804 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 20:01:51.534001 139753023288512 spec.py:349] Evaluating on the test split.
I0306 20:07:24.066087 139753023288512 submission_runner.py:469] Time since start: 25153.89s, 	Step: 3822, 	{'train/loss': 0.12240189462665867, 'validation/loss': 0.12501004413128475, 'validation/num_examples': 83274637, 'test/loss': 0.12727674232113487, 'test/num_examples': 95000000, 'score': 3637.6182913780212, 'total_duration': 25153.886372327805, 'accumulated_submission_time': 3637.6182913780212, 'accumulated_eval_time': 21515.324827432632, 'accumulated_logging_time': 0.7330448627471924}
I0306 20:07:24.075300 139599389128448 logging_writer.py:48] [3822] accumulated_eval_time=21515.3, accumulated_logging_time=0.733045, accumulated_submission_time=3637.62, global_step=3822, preemption_count=0, score=3637.62, test/loss=0.127277, test/num_examples=95000000, total_duration=25153.9, train/loss=0.122402, validation/loss=0.12501, validation/num_examples=83274637
I0306 20:08:32.586860 139599380735744 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.014673188328742981, loss=0.12197309732437134
I0306 20:09:24.942290 139753023288512 spec.py:321] Evaluating on the training split.
I0306 20:10:23.295247 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 20:13:28.859650 139753023288512 spec.py:349] Evaluating on the test split.
I0306 20:18:57.185715 139753023288512 submission_runner.py:469] Time since start: 25847.01s, 	Step: 3944, 	{'train/loss': 0.12431841966865947, 'validation/loss': 0.12485957219234674, 'validation/num_examples': 83274637, 'test/loss': 0.12727956658100328, 'test/num_examples': 95000000, 'score': 3758.471675634384, 'total_duration': 25847.005970478058, 'accumulated_submission_time': 3758.471675634384, 'accumulated_eval_time': 22087.568163394928, 'accumulated_logging_time': 0.748812198638916}
I0306 20:18:57.196751 139599389128448 logging_writer.py:48] [3944] accumulated_eval_time=22087.6, accumulated_logging_time=0.748812, accumulated_submission_time=3758.47, global_step=3944, preemption_count=0, score=3758.47, test/loss=0.12728, test/num_examples=95000000, total_duration=25847, train/loss=0.124318, validation/loss=0.12486, validation/num_examples=83274637
I0306 20:19:36.922467 139599380735744 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.02796678990125656, loss=0.1307380497455597
I0306 20:20:57.426268 139753023288512 spec.py:321] Evaluating on the training split.
I0306 20:21:57.398770 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 20:24:58.709937 139753023288512 spec.py:349] Evaluating on the test split.
I0306 20:30:36.750149 139753023288512 submission_runner.py:469] Time since start: 26546.57s, 	Step: 4067, 	{'train/loss': 0.1229356152573659, 'validation/loss': 0.12478421463137465, 'validation/num_examples': 83274637, 'test/loss': 0.12714343662623356, 'test/num_examples': 95000000, 'score': 3878.6869752407074, 'total_duration': 26546.570418834686, 'accumulated_submission_time': 3878.6869752407074, 'accumulated_eval_time': 22666.89198064804, 'accumulated_logging_time': 0.767214298248291}
I0306 20:30:36.759525 139599389128448 logging_writer.py:48] [4067] accumulated_eval_time=22666.9, accumulated_logging_time=0.767214, accumulated_submission_time=3878.69, global_step=4067, preemption_count=0, score=3878.69, test/loss=0.127143, test/num_examples=95000000, total_duration=26546.6, train/loss=0.122936, validation/loss=0.124784, validation/num_examples=83274637
I0306 20:30:47.332458 139599380735744 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.023498298600316048, loss=0.13279472291469574
I0306 20:32:37.296140 139753023288512 spec.py:321] Evaluating on the training split.
I0306 20:33:33.178440 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 20:36:34.873381 139753023288512 spec.py:349] Evaluating on the test split.
I0306 20:42:15.734642 139753023288512 submission_runner.py:469] Time since start: 27245.55s, 	Step: 4197, 	{'train/loss': 0.12411025789736202, 'validation/loss': 0.12476096219869667, 'validation/num_examples': 83274637, 'test/loss': 0.12719483214432567, 'test/num_examples': 95000000, 'score': 3999.2100105285645, 'total_duration': 27245.55492091179, 'accumulated_submission_time': 3999.2100105285645, 'accumulated_eval_time': 23245.33042860031, 'accumulated_logging_time': 0.7833805084228516}
I0306 20:42:15.743595 139599389128448 logging_writer.py:48] [4197] accumulated_eval_time=23245.3, accumulated_logging_time=0.783381, accumulated_submission_time=3999.21, global_step=4197, preemption_count=0, score=3999.21, test/loss=0.127195, test/num_examples=95000000, total_duration=27245.6, train/loss=0.12411, validation/loss=0.124761, validation/num_examples=83274637
I0306 20:42:16.239387 139599380735744 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.016632676124572754, loss=0.12271888554096222
I0306 20:43:52.847221 139599389128448 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.01482265442609787, loss=0.11961165815591812
I0306 20:44:16.417870 139753023288512 spec.py:321] Evaluating on the training split.
I0306 20:45:13.557159 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 20:48:18.041532 139753023288512 spec.py:349] Evaluating on the test split.
I0306 20:53:51.660729 139753023288512 submission_runner.py:469] Time since start: 27941.48s, 	Step: 4321, 	{'train/loss': 0.12410302182554074, 'validation/loss': 0.12447257490536066, 'validation/num_examples': 83274637, 'test/loss': 0.1267452220497533, 'test/num_examples': 95000000, 'score': 4119.870324611664, 'total_duration': 27941.481004476547, 'accumulated_submission_time': 4119.870324611664, 'accumulated_eval_time': 23820.57322382927, 'accumulated_logging_time': 0.7990310192108154}
I0306 20:53:51.670299 139599380735744 logging_writer.py:48] [4321] accumulated_eval_time=23820.6, accumulated_logging_time=0.799031, accumulated_submission_time=4119.87, global_step=4321, preemption_count=0, score=4119.87, test/loss=0.126745, test/num_examples=95000000, total_duration=27941.5, train/loss=0.124103, validation/loss=0.124473, validation/num_examples=83274637
I0306 20:54:57.801784 139599389128448 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.01524441596120596, loss=0.11947228759527206
I0306 20:55:53.363072 139753023288512 spec.py:321] Evaluating on the training split.
I0306 20:56:52.777963 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 20:59:52.657392 139753023288512 spec.py:349] Evaluating on the test split.
I0306 21:05:28.744401 139753023288512 submission_runner.py:469] Time since start: 28638.56s, 	Step: 4443, 	{'train/loss': 0.12346632489290252, 'validation/loss': 0.12459268810742459, 'validation/num_examples': 83274637, 'test/loss': 0.12696713837376644, 'test/num_examples': 95000000, 'score': 4241.549731731415, 'total_duration': 28638.56467795372, 'accumulated_submission_time': 4241.549731731415, 'accumulated_eval_time': 24395.954483270645, 'accumulated_logging_time': 0.8151791095733643}
I0306 21:05:28.753666 139599380735744 logging_writer.py:48] [4443] accumulated_eval_time=24396, accumulated_logging_time=0.815179, accumulated_submission_time=4241.55, global_step=4443, preemption_count=0, score=4241.55, test/loss=0.126967, test/num_examples=95000000, total_duration=28638.6, train/loss=0.123466, validation/loss=0.124593, validation/num_examples=83274637
I0306 21:06:08.233587 139599389128448 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.009805699810385704, loss=0.11718998104333878
I0306 21:07:28.759672 139753023288512 spec.py:321] Evaluating on the training split.
I0306 21:08:21.403325 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 21:11:23.683468 139753023288512 spec.py:349] Evaluating on the test split.
I0306 21:17:06.699095 139753023288512 submission_runner.py:469] Time since start: 29336.52s, 	Step: 4573, 	{'train/loss': 0.12257073582999362, 'validation/loss': 0.12462302319091954, 'validation/num_examples': 83274637, 'test/loss': 0.1269685390625, 'test/num_examples': 95000000, 'score': 4361.517959594727, 'total_duration': 29336.519376277924, 'accumulated_submission_time': 4361.517959594727, 'accumulated_eval_time': 24973.89384508133, 'accumulated_logging_time': 0.8558626174926758}
I0306 21:17:06.709508 139599380735744 logging_writer.py:48] [4573] accumulated_eval_time=24973.9, accumulated_logging_time=0.855863, accumulated_submission_time=4361.52, global_step=4573, preemption_count=0, score=4361.52, test/loss=0.126969, test/num_examples=95000000, total_duration=29336.5, train/loss=0.122571, validation/loss=0.124623, validation/num_examples=83274637
I0306 21:17:10.363667 139599389128448 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.009830662980675697, loss=0.12163989990949631
I0306 21:19:07.080737 139599380735744 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.008756018243730068, loss=0.1250496804714203
I0306 21:19:07.085039 139753023288512 spec.py:321] Evaluating on the training split.
I0306 21:20:05.446445 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 21:23:09.840424 139753023288512 spec.py:349] Evaluating on the test split.
I0306 21:28:45.298790 139753023288512 submission_runner.py:469] Time since start: 30035.12s, 	Step: 4701, 	{'train/loss': 0.12374013442100969, 'validation/loss': 0.12474999356271586, 'validation/num_examples': 83274637, 'test/loss': 0.1270843792763158, 'test/num_examples': 95000000, 'score': 4481.8787753582, 'total_duration': 30035.119029283524, 'accumulated_submission_time': 4481.8787753582, 'accumulated_eval_time': 25552.1074757576, 'accumulated_logging_time': 0.8733360767364502}
I0306 21:28:45.308284 139599389128448 logging_writer.py:48] [4701] accumulated_eval_time=25552.1, accumulated_logging_time=0.873336, accumulated_submission_time=4481.88, global_step=4701, preemption_count=0, score=4481.88, test/loss=0.127084, test/num_examples=95000000, total_duration=30035.1, train/loss=0.12374, validation/loss=0.12475, validation/num_examples=83274637
I0306 21:30:15.950530 139599380735744 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.02633335255086422, loss=0.12114293873310089
I0306 21:30:45.737971 139753023288512 spec.py:321] Evaluating on the training split.
I0306 21:31:42.900784 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 21:34:47.478985 139753023288512 spec.py:349] Evaluating on the test split.
I0306 21:40:14.483521 139753023288512 submission_runner.py:469] Time since start: 30724.30s, 	Step: 4824, 	{'train/loss': 0.12427228536901984, 'validation/loss': 0.12454464513330189, 'validation/num_examples': 83274637, 'test/loss': 0.12680531116365132, 'test/num_examples': 95000000, 'score': 4602.294522285461, 'total_duration': 30724.303805828094, 'accumulated_submission_time': 4602.294522285461, 'accumulated_eval_time': 26120.85296869278, 'accumulated_logging_time': 0.8893985748291016}
I0306 21:40:14.493379 139599389128448 logging_writer.py:48] [4824] accumulated_eval_time=26120.9, accumulated_logging_time=0.889399, accumulated_submission_time=4602.29, global_step=4824, preemption_count=0, score=4602.29, test/loss=0.126805, test/num_examples=95000000, total_duration=30724.3, train/loss=0.124272, validation/loss=0.124545, validation/num_examples=83274637
I0306 21:41:16.531404 139599380735744 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.011039885692298412, loss=0.12471537292003632
I0306 21:42:14.517582 139753023288512 spec.py:321] Evaluating on the training split.
I0306 21:43:11.546892 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 21:46:15.857014 139753023288512 spec.py:349] Evaluating on the test split.
I0306 21:51:49.708304 139753023288512 submission_runner.py:469] Time since start: 31419.53s, 	Step: 4950, 	{'train/loss': 0.12307780603848913, 'validation/loss': 0.12465086069687138, 'validation/num_examples': 83274637, 'test/loss': 0.12704364125205592, 'test/num_examples': 95000000, 'score': 4722.306229352951, 'total_duration': 31419.528578042984, 'accumulated_submission_time': 4722.306229352951, 'accumulated_eval_time': 26696.0436296463, 'accumulated_logging_time': 0.9055886268615723}
I0306 21:51:49.718213 139599389128448 logging_writer.py:48] [4950] accumulated_eval_time=26696, accumulated_logging_time=0.905589, accumulated_submission_time=4722.31, global_step=4950, preemption_count=0, score=4722.31, test/loss=0.127044, test/num_examples=95000000, total_duration=31419.5, train/loss=0.123078, validation/loss=0.124651, validation/num_examples=83274637
I0306 21:52:20.196418 139599380735744 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.02013113535940647, loss=0.13360419869422913
I0306 21:53:51.235505 139753023288512 spec.py:321] Evaluating on the training split.
I0306 21:54:45.607190 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 21:57:48.461300 139753023288512 spec.py:349] Evaluating on the test split.
I0306 22:03:28.380690 139753023288512 submission_runner.py:469] Time since start: 32118.20s, 	Step: 5078, 	{'train/loss': 0.12164880457164357, 'validation/loss': 0.12459953446485378, 'validation/num_examples': 83274637, 'test/loss': 0.1270372720805921, 'test/num_examples': 95000000, 'score': 4843.81013917923, 'total_duration': 32118.20096206665, 'accumulated_submission_time': 4843.81013917923, 'accumulated_eval_time': 27273.188742876053, 'accumulated_logging_time': 0.921811580657959}
I0306 22:03:28.390434 139599389128448 logging_writer.py:48] [5078] accumulated_eval_time=27273.2, accumulated_logging_time=0.921812, accumulated_submission_time=4843.81, global_step=5078, preemption_count=0, score=4843.81, test/loss=0.127037, test/num_examples=95000000, total_duration=32118.2, train/loss=0.121649, validation/loss=0.1246, validation/num_examples=83274637
I0306 22:03:30.840737 139599380735744 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.005747576244175434, loss=0.11959583312273026
I0306 22:05:29.025021 139599389128448 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.01662704162299633, loss=0.12716075778007507
I0306 22:05:29.029881 139753023288512 spec.py:321] Evaluating on the training split.
I0306 22:06:23.659900 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 22:09:27.997097 139753023288512 spec.py:349] Evaluating on the test split.
I0306 22:15:06.009478 139753023288512 submission_runner.py:469] Time since start: 32815.83s, 	Step: 5201, 	{'train/loss': 0.12272108506715898, 'validation/loss': 0.12459640232707311, 'validation/num_examples': 83274637, 'test/loss': 0.1271086693359375, 'test/num_examples': 95000000, 'score': 4964.435671329498, 'total_duration': 32815.829760313034, 'accumulated_submission_time': 4964.435671329498, 'accumulated_eval_time': 27850.16826939583, 'accumulated_logging_time': 0.9381213188171387}
I0306 22:15:06.019079 139599380735744 logging_writer.py:48] [5201] accumulated_eval_time=27850.2, accumulated_logging_time=0.938121, accumulated_submission_time=4964.44, global_step=5201, preemption_count=0, score=4964.44, test/loss=0.127109, test/num_examples=95000000, total_duration=32815.8, train/loss=0.122721, validation/loss=0.124596, validation/num_examples=83274637
I0306 22:16:32.374686 139599389128448 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.007456707768142223, loss=0.12023676931858063
I0306 22:17:06.611291 139753023288512 spec.py:321] Evaluating on the training split.
I0306 22:18:06.651425 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 22:21:10.822316 139753023288512 spec.py:349] Evaluating on the test split.
I0306 22:27:04.497525 139753023288512 submission_runner.py:469] Time since start: 33534.32s, 	Step: 5331, 	{'train/loss': 0.1229783841438076, 'validation/loss': 0.1245105388544804, 'validation/num_examples': 83274637, 'test/loss': 0.1268741672286184, 'test/num_examples': 95000000, 'score': 5085.01491856575, 'total_duration': 33534.31778001785, 'accumulated_submission_time': 5085.01491856575, 'accumulated_eval_time': 28448.054414749146, 'accumulated_logging_time': 0.9540674686431885}
I0306 22:27:04.507277 139599380735744 logging_writer.py:48] [5331] accumulated_eval_time=28448.1, accumulated_logging_time=0.954067, accumulated_submission_time=5085.01, global_step=5331, preemption_count=0, score=5085.01, test/loss=0.126874, test/num_examples=95000000, total_duration=33534.3, train/loss=0.122978, validation/loss=0.124511, validation/num_examples=83274637
I0306 22:27:57.887197 139599389128448 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.013228927738964558, loss=0.11188478022813797
I0306 22:29:04.583749 139753023288512 spec.py:321] Evaluating on the training split.
I0306 22:30:00.595600 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 22:33:09.275277 139753023288512 spec.py:349] Evaluating on the test split.
I0306 22:38:44.076567 139753023288512 submission_runner.py:469] Time since start: 34233.90s, 	Step: 5460, 	{'train/loss': 0.12334799505301616, 'validation/loss': 0.1243474591250132, 'validation/num_examples': 83274637, 'test/loss': 0.12666098969983552, 'test/num_examples': 95000000, 'score': 5205.063037872314, 'total_duration': 34233.896834135056, 'accumulated_submission_time': 5205.063037872314, 'accumulated_eval_time': 29027.54716014862, 'accumulated_logging_time': 0.9855246543884277}
I0306 22:38:44.087632 139599380735744 logging_writer.py:48] [5460] accumulated_eval_time=29027.5, accumulated_logging_time=0.985525, accumulated_submission_time=5205.06, global_step=5460, preemption_count=0, score=5205.06, test/loss=0.126661, test/num_examples=95000000, total_duration=34233.9, train/loss=0.123348, validation/loss=0.124347, validation/num_examples=83274637
I0306 22:39:02.439392 139599389128448 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.00883758720010519, loss=0.13256999850273132
I0306 22:40:44.189645 139753023288512 spec.py:321] Evaluating on the training split.
I0306 22:41:40.783832 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 22:44:46.977572 139753023288512 spec.py:349] Evaluating on the test split.
I0306 22:50:17.909169 139753023288512 submission_runner.py:469] Time since start: 34927.73s, 	Step: 5583, 	{'train/loss': 0.12263608259974786, 'validation/loss': 0.12443128880571741, 'validation/num_examples': 83274637, 'test/loss': 0.1267839951171875, 'test/num_examples': 95000000, 'score': 5325.151326179504, 'total_duration': 34927.729440927505, 'accumulated_submission_time': 5325.151326179504, 'accumulated_eval_time': 29601.26662015915, 'accumulated_logging_time': 1.003469467163086}
I0306 22:50:17.918777 139599380735744 logging_writer.py:48] [5583] accumulated_eval_time=29601.3, accumulated_logging_time=1.00347, accumulated_submission_time=5325.15, global_step=5583, preemption_count=0, score=5325.15, test/loss=0.126784, test/num_examples=95000000, total_duration=34927.7, train/loss=0.122636, validation/loss=0.124431, validation/num_examples=83274637
I0306 22:50:19.830692 139599389128448 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.01517168153077364, loss=0.120903380215168
I0306 22:52:12.428402 139599380735744 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.009548269212245941, loss=0.12196861207485199
I0306 22:52:19.414354 139753023288512 spec.py:321] Evaluating on the training split.
I0306 22:53:18.265644 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 22:56:24.300669 139753023288512 spec.py:349] Evaluating on the test split.
I0306 23:02:06.132196 139753023288512 submission_runner.py:469] Time since start: 35635.95s, 	Step: 5706, 	{'train/loss': 0.12517706657402544, 'validation/loss': 0.12445623078390565, 'validation/num_examples': 83274637, 'test/loss': 0.12687287839226974, 'test/num_examples': 95000000, 'score': 5446.633773088455, 'total_duration': 35635.952486515045, 'accumulated_submission_time': 5446.633773088455, 'accumulated_eval_time': 30187.98440861702, 'accumulated_logging_time': 1.0195517539978027}
I0306 23:02:06.141871 139599389128448 logging_writer.py:48] [5706] accumulated_eval_time=30188, accumulated_logging_time=1.01955, accumulated_submission_time=5446.63, global_step=5706, preemption_count=0, score=5446.63, test/loss=0.126873, test/num_examples=95000000, total_duration=35636, train/loss=0.125177, validation/loss=0.124456, validation/num_examples=83274637
I0306 23:03:28.153281 139599380735744 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.011350119486451149, loss=0.12486372143030167
I0306 23:04:06.420801 139753023288512 spec.py:321] Evaluating on the training split.
I0306 23:04:59.689286 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 23:08:02.998891 139753023288512 spec.py:349] Evaluating on the test split.
I0306 23:13:37.738099 139753023288512 submission_runner.py:469] Time since start: 36327.56s, 	Step: 5833, 	{'train/loss': 0.12204878446909617, 'validation/loss': 0.12447199169769985, 'validation/num_examples': 83274637, 'test/loss': 0.12678201587171053, 'test/num_examples': 95000000, 'score': 5566.899983167648, 'total_duration': 36327.55837678909, 'accumulated_submission_time': 5566.899983167648, 'accumulated_eval_time': 30759.301645994186, 'accumulated_logging_time': 1.0355281829833984}
I0306 23:13:37.747780 139599389128448 logging_writer.py:48] [5833] accumulated_eval_time=30759.3, accumulated_logging_time=1.03553, accumulated_submission_time=5566.9, global_step=5833, preemption_count=0, score=5566.9, test/loss=0.126782, test/num_examples=95000000, total_duration=36327.6, train/loss=0.122049, validation/loss=0.124472, validation/num_examples=83274637
I0306 23:14:31.412029 139599380735744 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.0174926295876503, loss=0.12777799367904663
I0306 23:15:38.110095 139753023288512 spec.py:321] Evaluating on the training split.
I0306 23:16:37.781540 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 23:19:43.886975 139753023288512 spec.py:349] Evaluating on the test split.
I0306 23:25:21.726485 139753023288512 submission_runner.py:469] Time since start: 37031.55s, 	Step: 5957, 	{'train/loss': 0.12230550385308715, 'validation/loss': 0.12437048485113406, 'validation/num_examples': 83274637, 'test/loss': 0.12676275071957238, 'test/num_examples': 95000000, 'score': 5687.248443365097, 'total_duration': 37031.546755075455, 'accumulated_submission_time': 5687.248443365097, 'accumulated_eval_time': 31342.917960882187, 'accumulated_logging_time': 1.052626609802246}
I0306 23:25:21.736392 139599389128448 logging_writer.py:48] [5957] accumulated_eval_time=31342.9, accumulated_logging_time=1.05263, accumulated_submission_time=5687.25, global_step=5957, preemption_count=0, score=5687.25, test/loss=0.126763, test/num_examples=95000000, total_duration=37031.5, train/loss=0.122306, validation/loss=0.12437, validation/num_examples=83274637
I0306 23:25:43.670339 139599380735744 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.005793750751763582, loss=0.11728915572166443
I0306 23:27:21.837972 139753023288512 spec.py:321] Evaluating on the training split.
I0306 23:28:17.086360 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 23:31:20.450463 139753023288512 spec.py:349] Evaluating on the test split.
I0306 23:37:00.617612 139753023288512 submission_runner.py:469] Time since start: 37730.44s, 	Step: 6086, 	{'train/loss': 0.12360108162294019, 'validation/loss': 0.12437905553638513, 'validation/num_examples': 83274637, 'test/loss': 0.12674325740131578, 'test/num_examples': 95000000, 'score': 5807.33627986908, 'total_duration': 37730.43787646294, 'accumulated_submission_time': 5807.33627986908, 'accumulated_eval_time': 31921.69752550125, 'accumulated_logging_time': 1.0693538188934326}
I0306 23:37:00.627644 139599389128448 logging_writer.py:48] [6086] accumulated_eval_time=31921.7, accumulated_logging_time=1.06935, accumulated_submission_time=5807.34, global_step=6086, preemption_count=0, score=5807.34, test/loss=0.126743, test/num_examples=95000000, total_duration=37730.4, train/loss=0.123601, validation/loss=0.124379, validation/num_examples=83274637
I0306 23:37:02.208210 139599380735744 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.0152961490675807, loss=0.11669303476810455
I0306 23:38:51.641952 139599389128448 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.012113220989704132, loss=0.12982404232025146
I0306 23:39:00.824589 139753023288512 spec.py:321] Evaluating on the training split.
I0306 23:39:55.159951 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 23:43:01.139180 139753023288512 spec.py:349] Evaluating on the test split.
I0306 23:48:45.117253 139753023288512 submission_runner.py:469] Time since start: 38434.94s, 	Step: 6209, 	{'train/loss': 0.12387262581138865, 'validation/loss': 0.12440165120959563, 'validation/num_examples': 83274637, 'test/loss': 0.1268471511307566, 'test/num_examples': 95000000, 'score': 5927.519634008408, 'total_duration': 38434.93751883507, 'accumulated_submission_time': 5927.519634008408, 'accumulated_eval_time': 32505.99011039734, 'accumulated_logging_time': 1.0858027935028076}
I0306 23:48:45.126922 139599380735744 logging_writer.py:48] [6209] accumulated_eval_time=32506, accumulated_logging_time=1.0858, accumulated_submission_time=5927.52, global_step=6209, preemption_count=0, score=5927.52, test/loss=0.126847, test/num_examples=95000000, total_duration=38434.9, train/loss=0.123873, validation/loss=0.124402, validation/num_examples=83274637
I0306 23:50:02.801218 139599389128448 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.008212795481085777, loss=0.1202511191368103
I0306 23:50:46.526172 139753023288512 spec.py:321] Evaluating on the training split.
I0306 23:51:42.967703 139753023288512 spec.py:333] Evaluating on the validation split.
I0306 23:54:50.061639 139753023288512 spec.py:349] Evaluating on the test split.
I0307 00:00:17.363054 139753023288512 submission_runner.py:469] Time since start: 39127.18s, 	Step: 6340, 	{'train/loss': 0.12234312158851128, 'validation/loss': 0.12423494649716245, 'validation/num_examples': 83274637, 'test/loss': 0.12663241683799342, 'test/num_examples': 95000000, 'score': 6048.844500303268, 'total_duration': 39127.183329343796, 'accumulated_submission_time': 6048.844500303268, 'accumulated_eval_time': 33076.826924562454, 'accumulated_logging_time': 1.161954402923584}
I0307 00:00:17.373495 139599380735744 logging_writer.py:48] [6340] accumulated_eval_time=33076.8, accumulated_logging_time=1.16195, accumulated_submission_time=6048.84, global_step=6340, preemption_count=0, score=6048.84, test/loss=0.126632, test/num_examples=95000000, total_duration=39127.2, train/loss=0.122343, validation/loss=0.124235, validation/num_examples=83274637
I0307 00:01:02.842645 139599389128448 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.006438232958316803, loss=0.11667025834321976
I0307 00:02:18.313938 139753023288512 spec.py:321] Evaluating on the training split.
I0307 00:03:12.283103 139753023288512 spec.py:333] Evaluating on the validation split.
I0307 00:06:15.822526 139753023288512 spec.py:349] Evaluating on the test split.
I0307 00:12:01.121923 139753023288512 submission_runner.py:469] Time since start: 39830.94s, 	Step: 6464, 	{'train/loss': 0.12559325805625077, 'validation/loss': 0.12431065022774243, 'validation/num_examples': 83274637, 'test/loss': 0.12671306304481908, 'test/num_examples': 95000000, 'score': 6169.7713878154755, 'total_duration': 39830.94220995903, 'accumulated_submission_time': 6169.7713878154755, 'accumulated_eval_time': 33659.63486289978, 'accumulated_logging_time': 1.1789536476135254}
I0307 00:12:01.132159 139599380735744 logging_writer.py:48] [6464] accumulated_eval_time=33659.6, accumulated_logging_time=1.17895, accumulated_submission_time=6169.77, global_step=6464, preemption_count=0, score=6169.77, test/loss=0.126713, test/num_examples=95000000, total_duration=39830.9, train/loss=0.125593, validation/loss=0.124311, validation/num_examples=83274637
I0307 00:12:15.096703 139599389128448 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.009351260028779507, loss=0.11910790950059891
I0307 00:14:02.114363 139753023288512 spec.py:321] Evaluating on the training split.
I0307 00:15:01.589501 139753023288512 spec.py:333] Evaluating on the validation split.
I0307 00:18:08.385601 139753023288512 spec.py:349] Evaluating on the test split.
I0307 00:23:52.149639 139753023288512 submission_runner.py:469] Time since start: 40541.97s, 	Step: 6588, 	{'train/loss': 0.11996863952269719, 'validation/loss': 0.12432182410398859, 'validation/num_examples': 83274637, 'test/loss': 0.12667677528782895, 'test/num_examples': 95000000, 'score': 6290.740315437317, 'total_duration': 40541.96988940239, 'accumulated_submission_time': 6290.740315437317, 'accumulated_eval_time': 34249.67004823685, 'accumulated_logging_time': 1.195768117904663}
I0307 00:23:52.179090 139599380735744 logging_writer.py:48] [6588] accumulated_eval_time=34249.7, accumulated_logging_time=1.19577, accumulated_submission_time=6290.74, global_step=6588, preemption_count=0, score=6290.74, test/loss=0.126677, test/num_examples=95000000, total_duration=40542, train/loss=0.119969, validation/loss=0.124322, validation/num_examples=83274637
I0307 00:23:53.558136 139599389128448 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.0058677527122199535, loss=0.1256456971168518
I0307 00:25:38.682340 139599380735744 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.01232672668993473, loss=0.11660540103912354
I0307 00:25:53.988426 139753023288512 spec.py:321] Evaluating on the training split.
I0307 00:26:52.077591 139753023288512 spec.py:333] Evaluating on the validation split.
I0307 00:29:58.961658 139753023288512 spec.py:349] Evaluating on the test split.
I0307 00:35:50.015329 139753023288512 submission_runner.py:469] Time since start: 41259.84s, 	Step: 6712, 	{'train/loss': 0.12280562264645624, 'validation/loss': 0.12431128359182497, 'validation/num_examples': 83274637, 'test/loss': 0.12684299226973683, 'test/num_examples': 95000000, 'score': 6412.536952257156, 'total_duration': 41259.83560585976, 'accumulated_submission_time': 6412.536952257156, 'accumulated_eval_time': 34845.696894168854, 'accumulated_logging_time': 1.231266736984253}
I0307 00:35:50.025530 139599389128448 logging_writer.py:48] [6712] accumulated_eval_time=34845.7, accumulated_logging_time=1.23127, accumulated_submission_time=6412.54, global_step=6712, preemption_count=0, score=6412.54, test/loss=0.126843, test/num_examples=95000000, total_duration=41259.8, train/loss=0.122806, validation/loss=0.124311, validation/num_examples=83274637
I0307 00:37:09.745067 139599380735744 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.00884243194013834, loss=0.12199626863002777
I0307 00:37:50.330569 139753023288512 spec.py:321] Evaluating on the training split.
I0307 00:38:50.099773 139753023288512 spec.py:333] Evaluating on the validation split.
I0307 00:41:53.638343 139753023288512 spec.py:349] Evaluating on the test split.
I0307 00:47:35.582239 139753023288512 submission_runner.py:469] Time since start: 41965.40s, 	Step: 6833, 	{'train/loss': 0.12369571075593151, 'validation/loss': 0.12405964489547437, 'validation/num_examples': 83274637, 'test/loss': 0.12637062740542762, 'test/num_examples': 95000000, 'score': 6532.760256528854, 'total_duration': 41965.40253376961, 'accumulated_submission_time': 6532.760256528854, 'accumulated_eval_time': 35430.948519706726, 'accumulated_logging_time': 1.315375804901123}
I0307 00:47:35.592234 139599389128448 logging_writer.py:48] [6833] accumulated_eval_time=35430.9, accumulated_logging_time=1.31538, accumulated_submission_time=6532.76, global_step=6833, preemption_count=0, score=6532.76, test/loss=0.126371, test/num_examples=95000000, total_duration=41965.4, train/loss=0.123696, validation/loss=0.12406, validation/num_examples=83274637
I0307 00:48:26.370965 139599380735744 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.007390716578811407, loss=0.12890544533729553
I0307 00:49:36.975110 139753023288512 spec.py:321] Evaluating on the training split.
I0307 00:50:35.251847 139753023288512 spec.py:333] Evaluating on the validation split.
I0307 00:53:40.176309 139753023288512 spec.py:349] Evaluating on the test split.
I0307 00:59:13.103330 139753023288512 submission_runner.py:469] Time since start: 42662.92s, 	Step: 6961, 	{'train/loss': 0.12298316031741272, 'validation/loss': 0.1240582803875, 'validation/num_examples': 83274637, 'test/loss': 0.1264679142783717, 'test/num_examples': 95000000, 'score': 6654.1306483745575, 'total_duration': 42662.923614263535, 'accumulated_submission_time': 6654.1306483745575, 'accumulated_eval_time': 36007.076681137085, 'accumulated_logging_time': 1.3315908908843994}
I0307 00:59:13.114823 139599389128448 logging_writer.py:48] [6961] accumulated_eval_time=36007.1, accumulated_logging_time=1.33159, accumulated_submission_time=6654.13, global_step=6961, preemption_count=0, score=6654.13, test/loss=0.126468, test/num_examples=95000000, total_duration=42662.9, train/loss=0.122983, validation/loss=0.124058, validation/num_examples=83274637
I0307 00:59:32.300919 139599380735744 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.021724620833992958, loss=0.12197539210319519
I0307 01:01:13.136301 139753023288512 spec.py:321] Evaluating on the training split.
I0307 01:02:11.659671 139753023288512 spec.py:333] Evaluating on the validation split.
I0307 01:05:17.240178 139753023288512 spec.py:349] Evaluating on the test split.
I0307 01:11:06.111847 139753023288512 submission_runner.py:469] Time since start: 43375.93s, 	Step: 7088, 	{'train/loss': 0.12429668513015381, 'validation/loss': 0.12408114839119998, 'validation/num_examples': 83274637, 'test/loss': 0.12646262034333883, 'test/num_examples': 95000000, 'score': 6774.138768911362, 'total_duration': 43375.932131528854, 'accumulated_submission_time': 6774.138768911362, 'accumulated_eval_time': 36600.05218958855, 'accumulated_logging_time': 1.349961280822754}
I0307 01:11:06.123566 139599389128448 logging_writer.py:48] [7088] accumulated_eval_time=36600.1, accumulated_logging_time=1.34996, accumulated_submission_time=6774.14, global_step=7088, preemption_count=0, score=6774.14, test/loss=0.126463, test/num_examples=95000000, total_duration=43375.9, train/loss=0.124297, validation/loss=0.124081, validation/num_examples=83274637
I0307 01:11:07.511961 139599380735744 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.006545839365571737, loss=0.11581263691186905
I0307 01:12:52.936775 139599389128448 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.008010661229491234, loss=0.11917094886302948
I0307 01:13:06.613867 139753023288512 spec.py:321] Evaluating on the training split.
I0307 01:14:02.460532 139753023288512 spec.py:333] Evaluating on the validation split.
I0307 01:17:07.183981 139753023288512 spec.py:349] Evaluating on the test split.
I0307 01:22:53.989905 139753023288512 submission_runner.py:469] Time since start: 44083.81s, 	Step: 7213, 	{'train/loss': 0.12213393607698146, 'validation/loss': 0.12414768436754225, 'validation/num_examples': 83274637, 'test/loss': 0.12655958035567436, 'test/num_examples': 95000000, 'score': 6894.61526966095, 'total_duration': 44083.810190439224, 'accumulated_submission_time': 6894.61526966095, 'accumulated_eval_time': 37187.4281771183, 'accumulated_logging_time': 1.3690671920776367}
I0307 01:22:54.000131 139599380735744 logging_writer.py:48] [7213] accumulated_eval_time=37187.4, accumulated_logging_time=1.36907, accumulated_submission_time=6894.62, global_step=7213, preemption_count=0, score=6894.62, test/loss=0.12656, test/num_examples=95000000, total_duration=44083.8, train/loss=0.122134, validation/loss=0.124148, validation/num_examples=83274637
I0307 01:24:09.383391 139599389128448 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.015271699987351894, loss=0.12709829211235046
I0307 01:24:54.331969 139753023288512 spec.py:321] Evaluating on the training split.
I0307 01:25:53.001761 139753023288512 spec.py:333] Evaluating on the validation split.
I0307 01:28:58.810425 139753023288512 spec.py:349] Evaluating on the test split.
I0307 01:34:43.204849 139753023288512 submission_runner.py:469] Time since start: 44793.03s, 	Step: 7338, 	{'train/loss': 0.1235097642261652, 'validation/loss': 0.12410270606571175, 'validation/num_examples': 83274637, 'test/loss': 0.12651335892269736, 'test/num_examples': 95000000, 'score': 7014.933057069778, 'total_duration': 44793.02511024475, 'accumulated_submission_time': 7014.933057069778, 'accumulated_eval_time': 37776.300975084305, 'accumulated_logging_time': 1.385474443435669}
I0307 01:34:43.219920 139599380735744 logging_writer.py:48] [7338] accumulated_eval_time=37776.3, accumulated_logging_time=1.38547, accumulated_submission_time=7014.93, global_step=7338, preemption_count=0, score=7014.93, test/loss=0.126513, test/num_examples=95000000, total_duration=44793, train/loss=0.12351, validation/loss=0.124103, validation/num_examples=83274637
I0307 01:35:30.052637 139599389128448 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.015780486166477203, loss=0.1269257515668869
I0307 01:36:44.933389 139753023288512 spec.py:321] Evaluating on the training split.
I0307 01:37:42.827942 139753023288512 spec.py:333] Evaluating on the validation split.
I0307 01:40:42.149644 139753023288512 spec.py:349] Evaluating on the test split.
I0307 01:46:18.386526 139753023288512 submission_runner.py:469] Time since start: 45488.21s, 	Step: 7465, 	{'train/loss': 0.12133449195362862, 'validation/loss': 0.12405050438894438, 'validation/num_examples': 83274637, 'test/loss': 0.1263840394736842, 'test/num_examples': 95000000, 'score': 7136.63315653801, 'total_duration': 45488.2067899704, 'accumulated_submission_time': 7136.63315653801, 'accumulated_eval_time': 38349.75403761864, 'accumulated_logging_time': 1.4077308177947998}
I0307 01:46:18.396790 139599380735744 logging_writer.py:48] [7465] accumulated_eval_time=38349.8, accumulated_logging_time=1.40773, accumulated_submission_time=7136.63, global_step=7465, preemption_count=0, score=7136.63, test/loss=0.126384, test/num_examples=95000000, total_duration=45488.2, train/loss=0.121334, validation/loss=0.124051, validation/num_examples=83274637
I0307 01:46:31.945354 139599389128448 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.009735559113323689, loss=0.11641966551542282
I0307 01:48:19.042433 139753023288512 spec.py:321] Evaluating on the training split.
I0307 01:49:20.174165 139753023288512 spec.py:333] Evaluating on the validation split.
I0307 01:52:26.215953 139753023288512 spec.py:349] Evaluating on the test split.
I0307 01:58:06.086626 139753023288512 submission_runner.py:469] Time since start: 46195.91s, 	Step: 7587, 	{'train/loss': 0.12244779918834849, 'validation/loss': 0.12397980760495915, 'validation/num_examples': 83274637, 'test/loss': 0.12636739111842105, 'test/num_examples': 95000000, 'score': 7257.265156507492, 'total_duration': 46195.90688920021, 'accumulated_submission_time': 7257.265156507492, 'accumulated_eval_time': 38936.798154354095, 'accumulated_logging_time': 1.4252865314483643}
I0307 01:58:06.096915 139599380735744 logging_writer.py:48] [7587] accumulated_eval_time=38936.8, accumulated_logging_time=1.42529, accumulated_submission_time=7257.27, global_step=7587, preemption_count=0, score=7257.27, test/loss=0.126367, test/num_examples=95000000, total_duration=46195.9, train/loss=0.122448, validation/loss=0.12398, validation/num_examples=83274637
I0307 01:58:07.629855 139599389128448 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.011817285791039467, loss=0.12954463064670563
I0307 01:59:55.291137 139599380735744 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.012001074850559235, loss=0.1212480217218399
I0307 02:00:07.046707 139753023288512 spec.py:321] Evaluating on the training split.
I0307 02:01:03.100593 139753023288512 spec.py:333] Evaluating on the validation split.
I0307 02:04:06.258108 139753023288512 spec.py:349] Evaluating on the test split.
I0307 02:09:31.706672 139753023288512 submission_runner.py:469] Time since start: 46881.53s, 	Step: 7711, 	{'train/loss': 0.12295537896501194, 'validation/loss': 0.1238808358271874, 'validation/num_examples': 83274637, 'test/loss': 0.12623757565789473, 'test/num_examples': 95000000, 'score': 7378.154509067535, 'total_duration': 46881.526947021484, 'accumulated_submission_time': 7378.154509067535, 'accumulated_eval_time': 39501.458052396774, 'accumulated_logging_time': 1.4887006282806396}
I0307 02:09:31.749009 139599389128448 logging_writer.py:48] [7711] accumulated_eval_time=39501.5, accumulated_logging_time=1.4887, accumulated_submission_time=7378.15, global_step=7711, preemption_count=0, score=7378.15, test/loss=0.126238, test/num_examples=95000000, total_duration=46881.5, train/loss=0.122955, validation/loss=0.123881, validation/num_examples=83274637
I0307 02:10:51.822256 139599380735744 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.010797721333801746, loss=0.1357974112033844
I0307 02:11:33.044123 139753023288512 spec.py:321] Evaluating on the training split.
I0307 02:12:30.507042 139753023288512 spec.py:333] Evaluating on the validation split.
I0307 02:15:35.287439 139753023288512 spec.py:349] Evaluating on the test split.
I0307 02:21:08.326703 139753023288512 submission_runner.py:469] Time since start: 47578.15s, 	Step: 7837, 	{'train/loss': 0.12246245826424668, 'validation/loss': 0.12386608992715235, 'validation/num_examples': 83274637, 'test/loss': 0.1262916603515625, 'test/num_examples': 95000000, 'score': 7499.4356808662415, 'total_duration': 47578.146976709366, 'accumulated_submission_time': 7499.4356808662415, 'accumulated_eval_time': 40076.740567445755, 'accumulated_logging_time': 1.5378289222717285}
I0307 02:21:08.337298 139599389128448 logging_writer.py:48] [7837] accumulated_eval_time=40076.7, accumulated_logging_time=1.53783, accumulated_submission_time=7499.44, global_step=7837, preemption_count=0, score=7499.44, test/loss=0.126292, test/num_examples=95000000, total_duration=47578.1, train/loss=0.122462, validation/loss=0.123866, validation/num_examples=83274637
I0307 02:21:56.220319 139599380735744 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.00826063472777605, loss=0.12605538964271545
I0307 02:23:09.300737 139753023288512 spec.py:321] Evaluating on the training split.
I0307 02:24:08.554808 139753023288512 spec.py:333] Evaluating on the validation split.
I0307 02:27:13.197423 139753023288512 spec.py:349] Evaluating on the test split.
I0307 02:32:59.617670 139753023288512 submission_runner.py:469] Time since start: 48289.44s, 	Step: 7963, 	{'train/loss': 0.12176896098696585, 'validation/loss': 0.12380759475111476, 'validation/num_examples': 83274637, 'test/loss': 0.12612920148026316, 'test/num_examples': 95000000, 'score': 7620.3857316970825, 'total_duration': 48289.43793439865, 'accumulated_submission_time': 7620.3857316970825, 'accumulated_eval_time': 40667.057428598404, 'accumulated_logging_time': 1.5544493198394775}
I0307 02:32:59.628084 139599389128448 logging_writer.py:48] [7963] accumulated_eval_time=40667.1, accumulated_logging_time=1.55445, accumulated_submission_time=7620.39, global_step=7963, preemption_count=0, score=7620.39, test/loss=0.126129, test/num_examples=95000000, total_duration=48289.4, train/loss=0.121769, validation/loss=0.123808, validation/num_examples=83274637
I0307 02:33:15.044175 139599380735744 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.010158848948776722, loss=0.1278596669435501
I0307 02:35:00.502516 139599389128448 logging_writer.py:48] [8085] global_step=8085, preemption_count=0, score=7741.24
I0307 02:35:11.442774 139753023288512 submission_runner.py:646] Tuning trial 1/5
I0307 02:35:11.481047 139753023288512 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.1, learning_rate=0.001308209823469072, one_minus_beta1=0.02686663061, beta2=0.9981232922116359, weight_decay=0.16375311233774334, warmup_factor=0.1)
I0307 02:35:11.482144 139753023288512 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/loss': 1.4535255662675173, 'validation/loss': 1.4525673488713315, 'validation/num_examples': 83274637, 'test/loss': 1.4525160299342106, 'test/num_examples': 95000000, 'score': 16.74186658859253, 'total_duration': 1159.6571462154388, 'accumulated_submission_time': 16.74186658859253, 'accumulated_eval_time': 1142.9151248931885, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (126, {'train/loss': 0.14135270012812046, 'validation/loss': 0.1411168969393106, 'validation/num_examples': 83274637, 'test/loss': 0.14444340982730264, 'test/num_examples': 95000000, 'score': 138.37683272361755, 'total_duration': 2308.683169603348, 'accumulated_submission_time': 138.37683272361755, 'accumulated_eval_time': 2170.2168505191803, 'accumulated_logging_time': 0.08210229873657227, 'global_step': 126, 'preemption_count': 0}), (250, {'train/loss': 0.13066272484431476, 'validation/loss': 0.13006254446638266, 'validation/num_examples': 83274637, 'test/loss': 0.13297558521792763, 'test/num_examples': 95000000, 'score': 259.161328792572, 'total_duration': 3443.1760256290436, 'accumulated_submission_time': 259.161328792572, 'accumulated_eval_time': 3183.823165178299, 'accumulated_logging_time': 0.1751389503479004, 'global_step': 250, 'preemption_count': 0}), (377, {'train/loss': 0.12823215873220806, 'validation/loss': 0.12861615784567867, 'validation/num_examples': 83274637, 'test/loss': 0.1312007239925987, 'test/num_examples': 95000000, 'score': 380.0680949687958, 'total_duration': 4561.663745641708, 'accumulated_submission_time': 380.0680949687958, 'accumulated_eval_time': 4181.379553318024, 'accumulated_logging_time': 0.19199275970458984, 'global_step': 377, 'preemption_count': 0}), (503, {'train/loss': 0.12624866251816164, 'validation/loss': 0.12786776319379026, 'validation/num_examples': 83274637, 'test/loss': 0.1305146603824013, 'test/num_examples': 95000000, 'score': 500.21348810195923, 'total_duration': 5699.760735750198, 'accumulated_submission_time': 500.21348810195923, 'accumulated_eval_time': 5199.266068935394, 'accumulated_logging_time': 0.24968314170837402, 'global_step': 503, 'preemption_count': 0}), (628, {'train/loss': 0.12496061418088353, 'validation/loss': 0.1275918102074611, 'validation/num_examples': 83274637, 'test/loss': 0.13010788941200657, 'test/num_examples': 95000000, 'score': 621.0098540782928, 'total_duration': 6805.612234592438, 'accumulated_submission_time': 621.0098540782928, 'accumulated_eval_time': 6184.2989864349365, 'accumulated_logging_time': 0.26456308364868164, 'global_step': 628, 'preemption_count': 0}), (756, {'train/loss': 0.1240639752187069, 'validation/loss': 0.1271913906773751, 'validation/num_examples': 83274637, 'test/loss': 0.12965028114720395, 'test/num_examples': 95000000, 'score': 742.3856189250946, 'total_duration': 7844.217311143875, 'accumulated_submission_time': 742.3856189250946, 'accumulated_eval_time': 7101.507717132568, 'accumulated_logging_time': 0.2784700393676758, 'global_step': 756, 'preemption_count': 0}), (885, {'train/loss': 0.12473721775290726, 'validation/loss': 0.1266481217648444, 'validation/num_examples': 83274637, 'test/loss': 0.12928262483552633, 'test/num_examples': 95000000, 'score': 863.336697101593, 'total_duration': 8824.71502494812, 'accumulated_submission_time': 863.336697101593, 'accumulated_eval_time': 7961.03332233429, 'accumulated_logging_time': 0.29311108589172363, 'global_step': 885, 'preemption_count': 0}), (1008, {'train/loss': 0.12581013408987402, 'validation/loss': 0.12641956031723306, 'validation/num_examples': 83274637, 'test/loss': 0.12878289254728617, 'test/num_examples': 95000000, 'score': 984.0054798126221, 'total_duration': 9677.469819545746, 'accumulated_submission_time': 984.0054798126221, 'accumulated_eval_time': 8693.098226547241, 'accumulated_logging_time': 0.3082268238067627, 'global_step': 1008, 'preemption_count': 0}), (1137, {'train/loss': 0.12520112972355113, 'validation/loss': 0.1263208865990107, 'validation/num_examples': 83274637, 'test/loss': 0.12880092427014803, 'test/num_examples': 95000000, 'score': 1104.726378917694, 'total_duration': 10385.937270402908, 'accumulated_submission_time': 1104.726378917694, 'accumulated_eval_time': 9280.822821855545, 'accumulated_logging_time': 0.32311487197875977, 'global_step': 1137, 'preemption_count': 0}), (1265, {'train/loss': 0.1262091969450315, 'validation/loss': 0.1261538307505809, 'validation/num_examples': 83274637, 'test/loss': 0.12867430064761512, 'test/num_examples': 95000000, 'score': 1225.4112598896027, 'total_duration': 11090.035559654236, 'accumulated_submission_time': 1225.4112598896027, 'accumulated_eval_time': 9864.213682413101, 'accumulated_logging_time': 0.33901143074035645, 'global_step': 1265, 'preemption_count': 0}), (1396, {'train/loss': 0.12545099882584698, 'validation/loss': 0.12596499445549406, 'validation/num_examples': 83274637, 'test/loss': 0.1284266758223684, 'test/num_examples': 95000000, 'score': 1346.087506055832, 'total_duration': 11802.278131961823, 'accumulated_submission_time': 1346.087506055832, 'accumulated_eval_time': 10455.758607625961, 'accumulated_logging_time': 0.35343289375305176, 'global_step': 1396, 'preemption_count': 0}), (1520, {'train/loss': 0.12617661714928705, 'validation/loss': 0.12573100950030258, 'validation/num_examples': 83274637, 'test/loss': 0.12821313519736843, 'test/num_examples': 95000000, 'score': 1467.166160583496, 'total_duration': 12519.525873422623, 'accumulated_submission_time': 1467.166160583496, 'accumulated_eval_time': 11051.90472149849, 'accumulated_logging_time': 0.36910104751586914, 'global_step': 1520, 'preemption_count': 0}), (1643, {'train/loss': 0.12401223138162175, 'validation/loss': 0.12576887564029549, 'validation/num_examples': 83274637, 'test/loss': 0.12812032020970396, 'test/num_examples': 95000000, 'score': 1588.3229467868805, 'total_duration': 13226.973920583725, 'accumulated_submission_time': 1588.3229467868805, 'accumulated_eval_time': 11638.174624919891, 'accumulated_logging_time': 0.38399839401245117, 'global_step': 1643, 'preemption_count': 0}), (1772, {'train/loss': 0.12570396423011831, 'validation/loss': 0.126050628066964, 'validation/num_examples': 83274637, 'test/loss': 0.12857186626233552, 'test/num_examples': 95000000, 'score': 1708.4802877902985, 'total_duration': 13921.858832836151, 'accumulated_submission_time': 1708.4802877902985, 'accumulated_eval_time': 12212.880302667618, 'accumulated_logging_time': 0.39930057525634766, 'global_step': 1772, 'preemption_count': 0}), (1897, {'train/loss': 0.12516175014839606, 'validation/loss': 0.12550562229630127, 'validation/num_examples': 83274637, 'test/loss': 0.12801813953536184, 'test/num_examples': 95000000, 'score': 1829.203898191452, 'total_duration': 14614.195018053055, 'accumulated_submission_time': 1829.203898191452, 'accumulated_eval_time': 12784.469294071198, 'accumulated_logging_time': 0.41504669189453125, 'global_step': 1897, 'preemption_count': 0}), (2023, {'train/loss': 0.1250973710169395, 'validation/loss': 0.1253122296297975, 'validation/num_examples': 83274637, 'test/loss': 0.12759800679481909, 'test/num_examples': 95000000, 'score': 1950.521973848343, 'total_duration': 15334.296848773956, 'accumulated_submission_time': 1950.521973848343, 'accumulated_eval_time': 13383.23017668724, 'accumulated_logging_time': 0.43174076080322266, 'global_step': 2023, 'preemption_count': 0}), (2155, {'train/loss': 0.12333777863180863, 'validation/loss': 0.12542732108578006, 'validation/num_examples': 83274637, 'test/loss': 0.12804813585526315, 'test/num_examples': 95000000, 'score': 2070.7354197502136, 'total_duration': 16035.341599225998, 'accumulated_submission_time': 2070.7354197502136, 'accumulated_eval_time': 13964.039947271347, 'accumulated_logging_time': 0.4464583396911621, 'global_step': 2155, 'preemption_count': 0}), (2286, {'train/loss': 0.12571451774323886, 'validation/loss': 0.12537535649397366, 'validation/num_examples': 83274637, 'test/loss': 0.12786514505550986, 'test/num_examples': 95000000, 'score': 2191.70552611351, 'total_duration': 16733.714088201523, 'accumulated_submission_time': 2191.70552611351, 'accumulated_eval_time': 14541.418693065643, 'accumulated_logging_time': 0.46265602111816406, 'global_step': 2286, 'preemption_count': 0}), (2416, {'train/loss': 0.12519861234105983, 'validation/loss': 0.12518164363318915, 'validation/num_examples': 83274637, 'test/loss': 0.1277588550884046, 'test/num_examples': 95000000, 'score': 2312.2571444511414, 'total_duration': 17438.56133031845, 'accumulated_submission_time': 2312.2571444511414, 'accumulated_eval_time': 15125.691693544388, 'accumulated_logging_time': 0.47822999954223633, 'global_step': 2416, 'preemption_count': 0}), (2538, {'train/loss': 0.12364050747135526, 'validation/loss': 0.1251560481263247, 'validation/num_examples': 83274637, 'test/loss': 0.127580181589227, 'test/num_examples': 95000000, 'score': 2432.279986858368, 'total_duration': 18152.464739322662, 'accumulated_submission_time': 2432.279986858368, 'accumulated_eval_time': 15719.549294948578, 'accumulated_logging_time': 0.4940774440765381, 'global_step': 2538, 'preemption_count': 0}), (2665, {'train/loss': 0.12634129585616244, 'validation/loss': 0.1251323669658885, 'validation/num_examples': 83274637, 'test/loss': 0.12756020328947368, 'test/num_examples': 95000000, 'score': 2552.3581342697144, 'total_duration': 18842.24413895607, 'accumulated_submission_time': 2552.3581342697144, 'accumulated_eval_time': 16289.228524684906, 'accumulated_logging_time': 0.5094401836395264, 'global_step': 2665, 'preemption_count': 0}), (2798, {'train/loss': 0.12314442951677355, 'validation/loss': 0.1252687324200112, 'validation/num_examples': 83274637, 'test/loss': 0.12772373865131578, 'test/num_examples': 95000000, 'score': 2672.4966566562653, 'total_duration': 19547.333203792572, 'accumulated_submission_time': 2672.4966566562653, 'accumulated_eval_time': 16874.094198703766, 'accumulated_logging_time': 0.5867881774902344, 'global_step': 2798, 'preemption_count': 0}), (2928, {'train/loss': 0.1255923117505117, 'validation/loss': 0.12549018212209379, 'validation/num_examples': 83274637, 'test/loss': 0.1280555890625, 'test/num_examples': 95000000, 'score': 2792.658517599106, 'total_duration': 20239.669197797775, 'accumulated_submission_time': 2792.658517599106, 'accumulated_eval_time': 17446.246651649475, 'accumulated_logging_time': 0.6019270420074463, 'global_step': 2928, 'preemption_count': 0}), (3058, {'train/loss': 0.12569680815832046, 'validation/loss': 0.12484359395946691, 'validation/num_examples': 83274637, 'test/loss': 0.12715878844572368, 'test/num_examples': 95000000, 'score': 2913.8876259326935, 'total_duration': 20946.117216348648, 'accumulated_submission_time': 2913.8876259326935, 'accumulated_eval_time': 18031.44285750389, 'accumulated_logging_time': 0.6177117824554443, 'global_step': 3058, 'preemption_count': 0}), (3189, {'train/loss': 0.122308903297632, 'validation/loss': 0.12514212313457945, 'validation/num_examples': 83274637, 'test/loss': 0.12743598675986842, 'test/num_examples': 95000000, 'score': 3034.8572487831116, 'total_duration': 21648.83614397049, 'accumulated_submission_time': 3034.8572487831116, 'accumulated_eval_time': 18613.168325424194, 'accumulated_logging_time': 0.6341772079467773, 'global_step': 3189, 'preemption_count': 0}), (3315, {'train/loss': 0.12277026053916358, 'validation/loss': 0.12549915802244807, 'validation/num_examples': 83274637, 'test/loss': 0.12873279761513157, 'test/num_examples': 95000000, 'score': 3155.054258584976, 'total_duration': 22349.02760076523, 'accumulated_submission_time': 3155.054258584976, 'accumulated_eval_time': 19193.137138843536, 'accumulated_logging_time': 0.6541063785552979, 'global_step': 3315, 'preemption_count': 0}), (3439, {'train/loss': 0.12384747657573449, 'validation/loss': 0.12505317682455605, 'validation/num_examples': 83274637, 'test/loss': 0.1273452509971217, 'test/num_examples': 95000000, 'score': 3275.6263575553894, 'total_duration': 23059.134675502777, 'accumulated_submission_time': 3275.6263575553894, 'accumulated_eval_time': 19782.65028476715, 'accumulated_logging_time': 0.6697869300842285, 'global_step': 3439, 'preemption_count': 0}), (3569, {'train/loss': 0.124004953171847, 'validation/loss': 0.12510223892861844, 'validation/num_examples': 83274637, 'test/loss': 0.12736081428865131, 'test/num_examples': 95000000, 'score': 3396.2200679779053, 'total_duration': 23764.770309448242, 'accumulated_submission_time': 3396.2200679779053, 'accumulated_eval_time': 20367.66886305809, 'accumulated_logging_time': 0.6858391761779785, 'global_step': 3569, 'preemption_count': 0}), (3689, {'train/loss': 0.12225167269367467, 'validation/loss': 0.12509591033627082, 'validation/num_examples': 83274637, 'test/loss': 0.1273938716488487, 'test/num_examples': 95000000, 'score': 3516.7128055095673, 'total_duration': 24458.822382688522, 'accumulated_submission_time': 3516.7128055095673, 'accumulated_eval_time': 20941.18845152855, 'accumulated_logging_time': 0.7176284790039062, 'global_step': 3689, 'preemption_count': 0}), (3822, {'train/loss': 0.12240189462665867, 'validation/loss': 0.12501004413128475, 'validation/num_examples': 83274637, 'test/loss': 0.12727674232113487, 'test/num_examples': 95000000, 'score': 3637.6182913780212, 'total_duration': 25153.886372327805, 'accumulated_submission_time': 3637.6182913780212, 'accumulated_eval_time': 21515.324827432632, 'accumulated_logging_time': 0.7330448627471924, 'global_step': 3822, 'preemption_count': 0}), (3944, {'train/loss': 0.12431841966865947, 'validation/loss': 0.12485957219234674, 'validation/num_examples': 83274637, 'test/loss': 0.12727956658100328, 'test/num_examples': 95000000, 'score': 3758.471675634384, 'total_duration': 25847.005970478058, 'accumulated_submission_time': 3758.471675634384, 'accumulated_eval_time': 22087.568163394928, 'accumulated_logging_time': 0.748812198638916, 'global_step': 3944, 'preemption_count': 0}), (4067, {'train/loss': 0.1229356152573659, 'validation/loss': 0.12478421463137465, 'validation/num_examples': 83274637, 'test/loss': 0.12714343662623356, 'test/num_examples': 95000000, 'score': 3878.6869752407074, 'total_duration': 26546.570418834686, 'accumulated_submission_time': 3878.6869752407074, 'accumulated_eval_time': 22666.89198064804, 'accumulated_logging_time': 0.767214298248291, 'global_step': 4067, 'preemption_count': 0}), (4197, {'train/loss': 0.12411025789736202, 'validation/loss': 0.12476096219869667, 'validation/num_examples': 83274637, 'test/loss': 0.12719483214432567, 'test/num_examples': 95000000, 'score': 3999.2100105285645, 'total_duration': 27245.55492091179, 'accumulated_submission_time': 3999.2100105285645, 'accumulated_eval_time': 23245.33042860031, 'accumulated_logging_time': 0.7833805084228516, 'global_step': 4197, 'preemption_count': 0}), (4321, {'train/loss': 0.12410302182554074, 'validation/loss': 0.12447257490536066, 'validation/num_examples': 83274637, 'test/loss': 0.1267452220497533, 'test/num_examples': 95000000, 'score': 4119.870324611664, 'total_duration': 27941.481004476547, 'accumulated_submission_time': 4119.870324611664, 'accumulated_eval_time': 23820.57322382927, 'accumulated_logging_time': 0.7990310192108154, 'global_step': 4321, 'preemption_count': 0}), (4443, {'train/loss': 0.12346632489290252, 'validation/loss': 0.12459268810742459, 'validation/num_examples': 83274637, 'test/loss': 0.12696713837376644, 'test/num_examples': 95000000, 'score': 4241.549731731415, 'total_duration': 28638.56467795372, 'accumulated_submission_time': 4241.549731731415, 'accumulated_eval_time': 24395.954483270645, 'accumulated_logging_time': 0.8151791095733643, 'global_step': 4443, 'preemption_count': 0}), (4573, {'train/loss': 0.12257073582999362, 'validation/loss': 0.12462302319091954, 'validation/num_examples': 83274637, 'test/loss': 0.1269685390625, 'test/num_examples': 95000000, 'score': 4361.517959594727, 'total_duration': 29336.519376277924, 'accumulated_submission_time': 4361.517959594727, 'accumulated_eval_time': 24973.89384508133, 'accumulated_logging_time': 0.8558626174926758, 'global_step': 4573, 'preemption_count': 0}), (4701, {'train/loss': 0.12374013442100969, 'validation/loss': 0.12474999356271586, 'validation/num_examples': 83274637, 'test/loss': 0.1270843792763158, 'test/num_examples': 95000000, 'score': 4481.8787753582, 'total_duration': 30035.119029283524, 'accumulated_submission_time': 4481.8787753582, 'accumulated_eval_time': 25552.1074757576, 'accumulated_logging_time': 0.8733360767364502, 'global_step': 4701, 'preemption_count': 0}), (4824, {'train/loss': 0.12427228536901984, 'validation/loss': 0.12454464513330189, 'validation/num_examples': 83274637, 'test/loss': 0.12680531116365132, 'test/num_examples': 95000000, 'score': 4602.294522285461, 'total_duration': 30724.303805828094, 'accumulated_submission_time': 4602.294522285461, 'accumulated_eval_time': 26120.85296869278, 'accumulated_logging_time': 0.8893985748291016, 'global_step': 4824, 'preemption_count': 0}), (4950, {'train/loss': 0.12307780603848913, 'validation/loss': 0.12465086069687138, 'validation/num_examples': 83274637, 'test/loss': 0.12704364125205592, 'test/num_examples': 95000000, 'score': 4722.306229352951, 'total_duration': 31419.528578042984, 'accumulated_submission_time': 4722.306229352951, 'accumulated_eval_time': 26696.0436296463, 'accumulated_logging_time': 0.9055886268615723, 'global_step': 4950, 'preemption_count': 0}), (5078, {'train/loss': 0.12164880457164357, 'validation/loss': 0.12459953446485378, 'validation/num_examples': 83274637, 'test/loss': 0.1270372720805921, 'test/num_examples': 95000000, 'score': 4843.81013917923, 'total_duration': 32118.20096206665, 'accumulated_submission_time': 4843.81013917923, 'accumulated_eval_time': 27273.188742876053, 'accumulated_logging_time': 0.921811580657959, 'global_step': 5078, 'preemption_count': 0}), (5201, {'train/loss': 0.12272108506715898, 'validation/loss': 0.12459640232707311, 'validation/num_examples': 83274637, 'test/loss': 0.1271086693359375, 'test/num_examples': 95000000, 'score': 4964.435671329498, 'total_duration': 32815.829760313034, 'accumulated_submission_time': 4964.435671329498, 'accumulated_eval_time': 27850.16826939583, 'accumulated_logging_time': 0.9381213188171387, 'global_step': 5201, 'preemption_count': 0}), (5331, {'train/loss': 0.1229783841438076, 'validation/loss': 0.1245105388544804, 'validation/num_examples': 83274637, 'test/loss': 0.1268741672286184, 'test/num_examples': 95000000, 'score': 5085.01491856575, 'total_duration': 33534.31778001785, 'accumulated_submission_time': 5085.01491856575, 'accumulated_eval_time': 28448.054414749146, 'accumulated_logging_time': 0.9540674686431885, 'global_step': 5331, 'preemption_count': 0}), (5460, {'train/loss': 0.12334799505301616, 'validation/loss': 0.1243474591250132, 'validation/num_examples': 83274637, 'test/loss': 0.12666098969983552, 'test/num_examples': 95000000, 'score': 5205.063037872314, 'total_duration': 34233.896834135056, 'accumulated_submission_time': 5205.063037872314, 'accumulated_eval_time': 29027.54716014862, 'accumulated_logging_time': 0.9855246543884277, 'global_step': 5460, 'preemption_count': 0}), (5583, {'train/loss': 0.12263608259974786, 'validation/loss': 0.12443128880571741, 'validation/num_examples': 83274637, 'test/loss': 0.1267839951171875, 'test/num_examples': 95000000, 'score': 5325.151326179504, 'total_duration': 34927.729440927505, 'accumulated_submission_time': 5325.151326179504, 'accumulated_eval_time': 29601.26662015915, 'accumulated_logging_time': 1.003469467163086, 'global_step': 5583, 'preemption_count': 0}), (5706, {'train/loss': 0.12517706657402544, 'validation/loss': 0.12445623078390565, 'validation/num_examples': 83274637, 'test/loss': 0.12687287839226974, 'test/num_examples': 95000000, 'score': 5446.633773088455, 'total_duration': 35635.952486515045, 'accumulated_submission_time': 5446.633773088455, 'accumulated_eval_time': 30187.98440861702, 'accumulated_logging_time': 1.0195517539978027, 'global_step': 5706, 'preemption_count': 0}), (5833, {'train/loss': 0.12204878446909617, 'validation/loss': 0.12447199169769985, 'validation/num_examples': 83274637, 'test/loss': 0.12678201587171053, 'test/num_examples': 95000000, 'score': 5566.899983167648, 'total_duration': 36327.55837678909, 'accumulated_submission_time': 5566.899983167648, 'accumulated_eval_time': 30759.301645994186, 'accumulated_logging_time': 1.0355281829833984, 'global_step': 5833, 'preemption_count': 0}), (5957, {'train/loss': 0.12230550385308715, 'validation/loss': 0.12437048485113406, 'validation/num_examples': 83274637, 'test/loss': 0.12676275071957238, 'test/num_examples': 95000000, 'score': 5687.248443365097, 'total_duration': 37031.546755075455, 'accumulated_submission_time': 5687.248443365097, 'accumulated_eval_time': 31342.917960882187, 'accumulated_logging_time': 1.052626609802246, 'global_step': 5957, 'preemption_count': 0}), (6086, {'train/loss': 0.12360108162294019, 'validation/loss': 0.12437905553638513, 'validation/num_examples': 83274637, 'test/loss': 0.12674325740131578, 'test/num_examples': 95000000, 'score': 5807.33627986908, 'total_duration': 37730.43787646294, 'accumulated_submission_time': 5807.33627986908, 'accumulated_eval_time': 31921.69752550125, 'accumulated_logging_time': 1.0693538188934326, 'global_step': 6086, 'preemption_count': 0}), (6209, {'train/loss': 0.12387262581138865, 'validation/loss': 0.12440165120959563, 'validation/num_examples': 83274637, 'test/loss': 0.1268471511307566, 'test/num_examples': 95000000, 'score': 5927.519634008408, 'total_duration': 38434.93751883507, 'accumulated_submission_time': 5927.519634008408, 'accumulated_eval_time': 32505.99011039734, 'accumulated_logging_time': 1.0858027935028076, 'global_step': 6209, 'preemption_count': 0}), (6340, {'train/loss': 0.12234312158851128, 'validation/loss': 0.12423494649716245, 'validation/num_examples': 83274637, 'test/loss': 0.12663241683799342, 'test/num_examples': 95000000, 'score': 6048.844500303268, 'total_duration': 39127.183329343796, 'accumulated_submission_time': 6048.844500303268, 'accumulated_eval_time': 33076.826924562454, 'accumulated_logging_time': 1.161954402923584, 'global_step': 6340, 'preemption_count': 0}), (6464, {'train/loss': 0.12559325805625077, 'validation/loss': 0.12431065022774243, 'validation/num_examples': 83274637, 'test/loss': 0.12671306304481908, 'test/num_examples': 95000000, 'score': 6169.7713878154755, 'total_duration': 39830.94220995903, 'accumulated_submission_time': 6169.7713878154755, 'accumulated_eval_time': 33659.63486289978, 'accumulated_logging_time': 1.1789536476135254, 'global_step': 6464, 'preemption_count': 0}), (6588, {'train/loss': 0.11996863952269719, 'validation/loss': 0.12432182410398859, 'validation/num_examples': 83274637, 'test/loss': 0.12667677528782895, 'test/num_examples': 95000000, 'score': 6290.740315437317, 'total_duration': 40541.96988940239, 'accumulated_submission_time': 6290.740315437317, 'accumulated_eval_time': 34249.67004823685, 'accumulated_logging_time': 1.195768117904663, 'global_step': 6588, 'preemption_count': 0}), (6712, {'train/loss': 0.12280562264645624, 'validation/loss': 0.12431128359182497, 'validation/num_examples': 83274637, 'test/loss': 0.12684299226973683, 'test/num_examples': 95000000, 'score': 6412.536952257156, 'total_duration': 41259.83560585976, 'accumulated_submission_time': 6412.536952257156, 'accumulated_eval_time': 34845.696894168854, 'accumulated_logging_time': 1.231266736984253, 'global_step': 6712, 'preemption_count': 0}), (6833, {'train/loss': 0.12369571075593151, 'validation/loss': 0.12405964489547437, 'validation/num_examples': 83274637, 'test/loss': 0.12637062740542762, 'test/num_examples': 95000000, 'score': 6532.760256528854, 'total_duration': 41965.40253376961, 'accumulated_submission_time': 6532.760256528854, 'accumulated_eval_time': 35430.948519706726, 'accumulated_logging_time': 1.315375804901123, 'global_step': 6833, 'preemption_count': 0}), (6961, {'train/loss': 0.12298316031741272, 'validation/loss': 0.1240582803875, 'validation/num_examples': 83274637, 'test/loss': 0.1264679142783717, 'test/num_examples': 95000000, 'score': 6654.1306483745575, 'total_duration': 42662.923614263535, 'accumulated_submission_time': 6654.1306483745575, 'accumulated_eval_time': 36007.076681137085, 'accumulated_logging_time': 1.3315908908843994, 'global_step': 6961, 'preemption_count': 0}), (7088, {'train/loss': 0.12429668513015381, 'validation/loss': 0.12408114839119998, 'validation/num_examples': 83274637, 'test/loss': 0.12646262034333883, 'test/num_examples': 95000000, 'score': 6774.138768911362, 'total_duration': 43375.932131528854, 'accumulated_submission_time': 6774.138768911362, 'accumulated_eval_time': 36600.05218958855, 'accumulated_logging_time': 1.349961280822754, 'global_step': 7088, 'preemption_count': 0}), (7213, {'train/loss': 0.12213393607698146, 'validation/loss': 0.12414768436754225, 'validation/num_examples': 83274637, 'test/loss': 0.12655958035567436, 'test/num_examples': 95000000, 'score': 6894.61526966095, 'total_duration': 44083.810190439224, 'accumulated_submission_time': 6894.61526966095, 'accumulated_eval_time': 37187.4281771183, 'accumulated_logging_time': 1.3690671920776367, 'global_step': 7213, 'preemption_count': 0}), (7338, {'train/loss': 0.1235097642261652, 'validation/loss': 0.12410270606571175, 'validation/num_examples': 83274637, 'test/loss': 0.12651335892269736, 'test/num_examples': 95000000, 'score': 7014.933057069778, 'total_duration': 44793.02511024475, 'accumulated_submission_time': 7014.933057069778, 'accumulated_eval_time': 37776.300975084305, 'accumulated_logging_time': 1.385474443435669, 'global_step': 7338, 'preemption_count': 0}), (7465, {'train/loss': 0.12133449195362862, 'validation/loss': 0.12405050438894438, 'validation/num_examples': 83274637, 'test/loss': 0.1263840394736842, 'test/num_examples': 95000000, 'score': 7136.63315653801, 'total_duration': 45488.2067899704, 'accumulated_submission_time': 7136.63315653801, 'accumulated_eval_time': 38349.75403761864, 'accumulated_logging_time': 1.4077308177947998, 'global_step': 7465, 'preemption_count': 0}), (7587, {'train/loss': 0.12244779918834849, 'validation/loss': 0.12397980760495915, 'validation/num_examples': 83274637, 'test/loss': 0.12636739111842105, 'test/num_examples': 95000000, 'score': 7257.265156507492, 'total_duration': 46195.90688920021, 'accumulated_submission_time': 7257.265156507492, 'accumulated_eval_time': 38936.798154354095, 'accumulated_logging_time': 1.4252865314483643, 'global_step': 7587, 'preemption_count': 0}), (7711, {'train/loss': 0.12295537896501194, 'validation/loss': 0.1238808358271874, 'validation/num_examples': 83274637, 'test/loss': 0.12623757565789473, 'test/num_examples': 95000000, 'score': 7378.154509067535, 'total_duration': 46881.526947021484, 'accumulated_submission_time': 7378.154509067535, 'accumulated_eval_time': 39501.458052396774, 'accumulated_logging_time': 1.4887006282806396, 'global_step': 7711, 'preemption_count': 0}), (7837, {'train/loss': 0.12246245826424668, 'validation/loss': 0.12386608992715235, 'validation/num_examples': 83274637, 'test/loss': 0.1262916603515625, 'test/num_examples': 95000000, 'score': 7499.4356808662415, 'total_duration': 47578.146976709366, 'accumulated_submission_time': 7499.4356808662415, 'accumulated_eval_time': 40076.740567445755, 'accumulated_logging_time': 1.5378289222717285, 'global_step': 7837, 'preemption_count': 0}), (7963, {'train/loss': 0.12176896098696585, 'validation/loss': 0.12380759475111476, 'validation/num_examples': 83274637, 'test/loss': 0.12612920148026316, 'test/num_examples': 95000000, 'score': 7620.3857316970825, 'total_duration': 48289.43793439865, 'accumulated_submission_time': 7620.3857316970825, 'accumulated_eval_time': 40667.057428598404, 'accumulated_logging_time': 1.5544493198394775, 'global_step': 7963, 'preemption_count': 0})], 'global_step': 8085}
I0307 02:35:11.482246 139753023288512 submission_runner.py:649] Timing: 7741.241304397583
I0307 02:35:11.482283 139753023288512 submission_runner.py:651] Total number of evals: 64
I0307 02:35:11.482312 139753023288512 submission_runner.py:652] ====================
I0307 02:35:11.482455 139753023288512 submission_runner.py:750] Final criteo1tb score: 0
