python submission_runner.py --framework=jax --workload=criteo1tb --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_2 --overwrite=True --save_checkpoints=False --rng_seed=935442281 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=1 --hparam_end_index=2 2>&1 | tee -a /logs/criteo1tb_jax_03-06-2025-13-07-16.log
2025-03-06 13:07:33.254261: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741266453.746916       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741266453.892311       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0306 13:08:21.454846 140404200342720 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax.
I0306 13:08:24.656433 140404200342720 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0306 13:08:24.660324 140404200342720 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0306 13:08:24.662697 140404200342720 submission_runner.py:606] Using RNG seed 935442281
I0306 13:08:28.146891 140404200342720 submission_runner.py:615] --- Tuning run 2/5 ---
I0306 13:08:28.147089 140404200342720 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_2.
I0306 13:08:28.147306 140404200342720 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_2/hparams.json.
I0306 13:08:28.403965 140404200342720 submission_runner.py:218] Initializing dataset.
I0306 13:08:28.404189 140404200342720 submission_runner.py:229] Initializing model.
I0306 13:08:38.600386 140404200342720 submission_runner.py:272] Initializing optimizer.
I0306 13:08:39.204162 140404200342720 submission_runner.py:279] Initializing metrics bundle.
I0306 13:08:39.204416 140404200342720 submission_runner.py:301] Initializing checkpoint and logger.
I0306 13:08:39.205274 140404200342720 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_2 with prefix checkpoint_
I0306 13:08:39.205429 140404200342720 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_2/meta_data_0.json.
I0306 13:08:39.205626 140404200342720 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0306 13:08:39.205684 140404200342720 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0306 13:08:39.780953 140404200342720 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_2/criteo1tb_jax/trial_2/flags_0.json.
I0306 13:08:40.263807 140404200342720 submission_runner.py:337] Starting training loop.
I0306 13:08:57.235991 140262256932608 logging_writer.py:48] [0] global_step=0, grad_norm=1.3141638040542603, loss=0.22132423520088196
I0306 13:08:57.608655 140404200342720 spec.py:321] Evaluating on the training split.
I0306 13:15:07.013227 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 13:21:17.318135 140404200342720 spec.py:349] Evaluating on the test split.
I0306 13:28:26.195785 140404200342720 submission_runner.py:469] Time since start: 1185.93s, 	Step: 1, 	{'train/loss': 0.2209187685131277, 'validation/loss': 0.22167475255138308, 'validation/num_examples': 83274637, 'test/loss': 0.22238874467516448, 'test/num_examples': 95000000, 'score': 17.344715118408203, 'total_duration': 1185.931919336319, 'accumulated_submission_time': 17.344715118408203, 'accumulated_eval_time': 1168.5870623588562, 'accumulated_logging_time': 0}
I0306 13:28:26.235641 140252249302784 logging_writer.py:48] [1] accumulated_eval_time=1168.59, accumulated_logging_time=0, accumulated_submission_time=17.3447, global_step=1, preemption_count=0, score=17.3447, test/loss=0.222389, test/num_examples=95000000, total_duration=1185.93, train/loss=0.220919, validation/loss=0.221675, validation/num_examples=83274637
I0306 13:29:54.967983 140252240910080 logging_writer.py:48] [100] global_step=100, grad_norm=0.038432568311691284, loss=0.12638285756111145
I0306 13:30:27.223424 140404200342720 spec.py:321] Evaluating on the training split.
I0306 13:36:26.943290 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 13:41:51.372285 140404200342720 spec.py:349] Evaluating on the test split.
I0306 13:48:05.983099 140404200342720 submission_runner.py:469] Time since start: 2365.72s, 	Step: 128, 	{'train/loss': 0.13093109610461215, 'validation/loss': 0.13073758040856126, 'validation/num_examples': 83274637, 'test/loss': 0.13399970381373355, 'test/num_examples': 95000000, 'score': 138.2899205684662, 'total_duration': 2365.7192277908325, 'accumulated_submission_time': 138.2899205684662, 'accumulated_eval_time': 2227.3466699123383, 'accumulated_logging_time': 0.07489347457885742}
I0306 13:48:05.991581 140252249302784 logging_writer.py:48] [128] accumulated_eval_time=2227.35, accumulated_logging_time=0.0748935, accumulated_submission_time=138.29, global_step=128, preemption_count=0, score=138.29, test/loss=0.134, test/num_examples=95000000, total_duration=2365.72, train/loss=0.130931, validation/loss=0.130738, validation/num_examples=83274637
I0306 13:49:02.330942 140252240910080 logging_writer.py:48] [200] global_step=200, grad_norm=0.008416851051151752, loss=0.12442059814929962
I0306 13:50:06.626036 140404200342720 spec.py:321] Evaluating on the training split.
I0306 13:56:05.988641 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 14:01:20.887495 140404200342720 spec.py:349] Evaluating on the test split.
I0306 14:07:13.540621 140404200342720 submission_runner.py:469] Time since start: 3513.28s, 	Step: 255, 	{'train/loss': 0.12782747463657046, 'validation/loss': 0.12869227925717347, 'validation/num_examples': 83274637, 'test/loss': 0.13144199499383225, 'test/num_examples': 95000000, 'score': 258.91094613075256, 'total_duration': 3513.276751756668, 'accumulated_submission_time': 258.91094613075256, 'accumulated_eval_time': 3254.261204957962, 'accumulated_logging_time': 0.08986425399780273}
I0306 14:07:13.549222 140252249302784 logging_writer.py:48] [255] accumulated_eval_time=3254.26, accumulated_logging_time=0.0898643, accumulated_submission_time=258.911, global_step=255, preemption_count=0, score=258.911, test/loss=0.131442, test/num_examples=95000000, total_duration=3513.28, train/loss=0.127827, validation/loss=0.128692, validation/num_examples=83274637
I0306 14:07:38.560289 140252240910080 logging_writer.py:48] [300] global_step=300, grad_norm=0.014145324937999249, loss=0.12791484594345093
I0306 14:09:14.357606 140404200342720 spec.py:321] Evaluating on the training split.
I0306 14:15:04.833949 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 14:20:21.866676 140404200342720 spec.py:349] Evaluating on the test split.
I0306 14:26:26.754587 140404200342720 submission_runner.py:469] Time since start: 4666.49s, 	Step: 375, 	{'train/loss': 0.1279561566716095, 'validation/loss': 0.12830987090751106, 'validation/num_examples': 83274637, 'test/loss': 0.13047055153166118, 'test/num_examples': 95000000, 'score': 379.7065842151642, 'total_duration': 4666.490714073181, 'accumulated_submission_time': 379.7065842151642, 'accumulated_eval_time': 4286.658121585846, 'accumulated_logging_time': 0.10478901863098145}
I0306 14:26:26.762228 140252249302784 logging_writer.py:48] [375] accumulated_eval_time=4286.66, accumulated_logging_time=0.104789, accumulated_submission_time=379.707, global_step=375, preemption_count=0, score=379.707, test/loss=0.130471, test/num_examples=95000000, total_duration=4666.49, train/loss=0.127956, validation/loss=0.12831, validation/num_examples=83274637
I0306 14:26:29.597155 140252240910080 logging_writer.py:48] [400] global_step=400, grad_norm=0.009948034770786762, loss=0.12334393709897995
I0306 14:28:26.973181 140404200342720 spec.py:321] Evaluating on the training split.
I0306 14:34:13.217624 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 14:39:37.405465 140404200342720 spec.py:349] Evaluating on the test split.
I0306 14:45:39.668891 140404200342720 submission_runner.py:469] Time since start: 5819.41s, 	Step: 498, 	{'train/loss': 0.12974432848815648, 'validation/loss': 0.12695870359728723, 'validation/num_examples': 83274637, 'test/loss': 0.12931911977796054, 'test/num_examples': 95000000, 'score': 499.86661553382874, 'total_duration': 5819.405024051666, 'accumulated_submission_time': 499.86661553382874, 'accumulated_eval_time': 5319.353770971298, 'accumulated_logging_time': 0.15645360946655273}
I0306 14:45:39.677645 140252249302784 logging_writer.py:48] [498] accumulated_eval_time=5319.35, accumulated_logging_time=0.156454, accumulated_submission_time=499.867, global_step=498, preemption_count=0, score=499.867, test/loss=0.129319, test/num_examples=95000000, total_duration=5819.41, train/loss=0.129744, validation/loss=0.126959, validation/num_examples=83274637
I0306 14:45:40.027281 140252240910080 logging_writer.py:48] [500] global_step=500, grad_norm=0.05969751626253128, loss=0.12444305419921875
I0306 14:47:12.379252 140252249302784 logging_writer.py:48] [600] global_step=600, grad_norm=0.0759844034910202, loss=0.12122996151447296
I0306 14:47:40.172936 140404200342720 spec.py:321] Evaluating on the training split.
I0306 14:53:24.679943 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 14:58:23.287100 140404200342720 spec.py:349] Evaluating on the test split.
I0306 15:04:21.247410 140404200342720 submission_runner.py:469] Time since start: 6940.98s, 	Step: 625, 	{'train/loss': 0.12674199482836063, 'validation/loss': 0.1268780185260388, 'validation/num_examples': 83274637, 'test/loss': 0.12922596109169407, 'test/num_examples': 95000000, 'score': 620.3479719161987, 'total_duration': 6940.983546495438, 'accumulated_submission_time': 620.3479719161987, 'accumulated_eval_time': 6320.428179264069, 'accumulated_logging_time': 0.17185664176940918}
I0306 15:04:21.255319 140252240910080 logging_writer.py:48] [625] accumulated_eval_time=6320.43, accumulated_logging_time=0.171857, accumulated_submission_time=620.348, global_step=625, preemption_count=0, score=620.348, test/loss=0.129226, test/num_examples=95000000, total_duration=6940.98, train/loss=0.126742, validation/loss=0.126878, validation/num_examples=83274637
I0306 15:05:23.157778 140252249302784 logging_writer.py:48] [700] global_step=700, grad_norm=0.04153991490602493, loss=0.12822960317134857
I0306 15:06:21.563015 140404200342720 spec.py:321] Evaluating on the training split.
I0306 15:11:36.632563 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 15:16:14.963622 140404200342720 spec.py:349] Evaluating on the test split.
I0306 15:22:17.516916 140404200342720 submission_runner.py:469] Time since start: 8017.25s, 	Step: 749, 	{'train/loss': 0.12405250099657467, 'validation/loss': 0.12651037993501327, 'validation/num_examples': 83274637, 'test/loss': 0.12883419776932567, 'test/num_examples': 95000000, 'score': 740.6417620182037, 'total_duration': 8017.253054618835, 'accumulated_submission_time': 740.6417620182037, 'accumulated_eval_time': 7276.3820123672485, 'accumulated_logging_time': 0.1863255500793457}
I0306 15:22:17.525050 140252240910080 logging_writer.py:48] [749] accumulated_eval_time=7276.38, accumulated_logging_time=0.186326, accumulated_submission_time=740.642, global_step=749, preemption_count=0, score=740.642, test/loss=0.128834, test/num_examples=95000000, total_duration=8017.25, train/loss=0.124053, validation/loss=0.12651, validation/num_examples=83274637
I0306 15:22:49.261868 140252249302784 logging_writer.py:48] [800] global_step=800, grad_norm=0.07750990986824036, loss=0.13239802420139313
I0306 15:24:17.732010 140404200342720 spec.py:321] Evaluating on the training split.
I0306 15:28:52.699956 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 15:33:05.393125 140404200342720 spec.py:349] Evaluating on the test split.
I0306 15:39:07.280796 140404200342720 submission_runner.py:469] Time since start: 9027.02s, 	Step: 874, 	{'train/loss': 0.12402263984271565, 'validation/loss': 0.12617973242622219, 'validation/num_examples': 83274637, 'test/loss': 0.1285111533203125, 'test/num_examples': 95000000, 'score': 860.8349533081055, 'total_duration': 9027.016941785812, 'accumulated_submission_time': 860.8349533081055, 'accumulated_eval_time': 8165.930740594864, 'accumulated_logging_time': 0.20085692405700684}
I0306 15:39:07.288804 140252240910080 logging_writer.py:48] [874] accumulated_eval_time=8165.93, accumulated_logging_time=0.200857, accumulated_submission_time=860.835, global_step=874, preemption_count=0, score=860.835, test/loss=0.128511, test/num_examples=95000000, total_duration=9027.02, train/loss=0.124023, validation/loss=0.12618, validation/num_examples=83274637
I0306 15:39:10.146334 140252249302784 logging_writer.py:48] [900] global_step=900, grad_norm=0.040420662611722946, loss=0.13530978560447693
I0306 15:41:02.793091 140252240910080 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.021709803491830826, loss=0.1277068704366684
I0306 15:41:08.156919 140404200342720 spec.py:321] Evaluating on the training split.
I0306 15:44:29.828437 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 15:47:34.607632 140404200342720 spec.py:349] Evaluating on the test split.
I0306 15:53:38.954373 140404200342720 submission_runner.py:469] Time since start: 9898.69s, 	Step: 1006, 	{'train/loss': 0.12438687286193266, 'validation/loss': 0.126139806360699, 'validation/num_examples': 83274637, 'test/loss': 0.128481746875, 'test/num_examples': 95000000, 'score': 981.6895778179169, 'total_duration': 9898.690483808517, 'accumulated_submission_time': 981.6895778179169, 'accumulated_eval_time': 8916.728100538254, 'accumulated_logging_time': 0.21520709991455078}
I0306 15:53:38.962983 140252249302784 logging_writer.py:48] [1006] accumulated_eval_time=8916.73, accumulated_logging_time=0.215207, accumulated_submission_time=981.69, global_step=1006, preemption_count=0, score=981.69, test/loss=0.128482, test/num_examples=95000000, total_duration=9898.69, train/loss=0.124387, validation/loss=0.12614, validation/num_examples=83274637
I0306 15:55:01.974099 140252240910080 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.007039058953523636, loss=0.13213181495666504
I0306 15:55:39.182405 140404200342720 spec.py:321] Evaluating on the training split.
I0306 15:56:32.309283 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 15:59:42.081979 140404200342720 spec.py:349] Evaluating on the test split.
I0306 16:05:48.540462 140404200342720 submission_runner.py:469] Time since start: 10628.28s, 	Step: 1129, 	{'train/loss': 0.12596395004938984, 'validation/loss': 0.125858556928943, 'validation/num_examples': 83274637, 'test/loss': 0.1282085619140625, 'test/num_examples': 95000000, 'score': 1101.8951392173767, 'total_duration': 10628.276590824127, 'accumulated_submission_time': 1101.8951392173767, 'accumulated_eval_time': 9526.086087942123, 'accumulated_logging_time': 0.23058176040649414}
I0306 16:05:48.548241 140252249302784 logging_writer.py:48] [1129] accumulated_eval_time=9526.09, accumulated_logging_time=0.230582, accumulated_submission_time=1101.9, global_step=1129, preemption_count=0, score=1101.9, test/loss=0.128209, test/num_examples=95000000, total_duration=10628.3, train/loss=0.125964, validation/loss=0.125859, validation/num_examples=83274637
I0306 16:06:45.127043 140252240910080 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.005513998679816723, loss=0.12299267202615738
I0306 16:07:49.790444 140404200342720 spec.py:321] Evaluating on the training split.
I0306 16:08:45.420512 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 16:11:50.460536 140404200342720 spec.py:349] Evaluating on the test split.
I0306 16:17:51.264148 140404200342720 submission_runner.py:469] Time since start: 11351.00s, 	Step: 1255, 	{'train/loss': 0.12510174620638853, 'validation/loss': 0.12584953439027, 'validation/num_examples': 83274637, 'test/loss': 0.1282173911698191, 'test/num_examples': 95000000, 'score': 1223.1237287521362, 'total_duration': 11351.000273942947, 'accumulated_submission_time': 1223.1237287521362, 'accumulated_eval_time': 10127.559713840485, 'accumulated_logging_time': 0.24488615989685059}
I0306 16:17:51.272359 140252249302784 logging_writer.py:48] [1255] accumulated_eval_time=10127.6, accumulated_logging_time=0.244886, accumulated_submission_time=1223.12, global_step=1255, preemption_count=0, score=1223.12, test/loss=0.128217, test/num_examples=95000000, total_duration=11351, train/loss=0.125102, validation/loss=0.12585, validation/num_examples=83274637
I0306 16:18:16.142515 140252240910080 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.008732717484235764, loss=0.1187950074672699
I0306 16:19:52.536851 140404200342720 spec.py:321] Evaluating on the training split.
I0306 16:20:48.689534 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 16:23:58.463356 140404200342720 spec.py:349] Evaluating on the test split.
I0306 16:30:02.796820 140404200342720 submission_runner.py:469] Time since start: 12082.53s, 	Step: 1374, 	{'train/loss': 0.12470472183476829, 'validation/loss': 0.1259988057765603, 'validation/num_examples': 83274637, 'test/loss': 0.1282124005550987, 'test/num_examples': 95000000, 'score': 1344.374713420868, 'total_duration': 12082.53295326233, 'accumulated_submission_time': 1344.374713420868, 'accumulated_eval_time': 10737.819620132446, 'accumulated_logging_time': 0.2598905563354492}
I0306 16:30:02.805100 140252249302784 logging_writer.py:48] [1374] accumulated_eval_time=10737.8, accumulated_logging_time=0.259891, accumulated_submission_time=1344.37, global_step=1374, preemption_count=0, score=1344.37, test/loss=0.128212, test/num_examples=95000000, total_duration=12082.5, train/loss=0.124705, validation/loss=0.125999, validation/num_examples=83274637
I0306 16:30:05.655280 140252240910080 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.020138487219810486, loss=0.12450508773326874
I0306 16:32:02.571943 140252249302784 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.015103555284440517, loss=0.12269146740436554
I0306 16:32:03.684754 140404200342720 spec.py:321] Evaluating on the training split.
I0306 16:32:57.420222 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 16:36:01.780539 140404200342720 spec.py:349] Evaluating on the test split.
I0306 16:42:02.179938 140404200342720 submission_runner.py:469] Time since start: 12801.92s, 	Step: 1502, 	{'train/loss': 0.125160771873106, 'validation/loss': 0.1257132817089389, 'validation/num_examples': 83274637, 'test/loss': 0.12810703275082236, 'test/num_examples': 95000000, 'score': 1465.2403779029846, 'total_duration': 12801.91608953476, 'accumulated_submission_time': 1465.2403779029846, 'accumulated_eval_time': 11336.314753293991, 'accumulated_logging_time': 0.27492213249206543}
I0306 16:42:02.189172 140252240910080 logging_writer.py:48] [1502] accumulated_eval_time=11336.3, accumulated_logging_time=0.274922, accumulated_submission_time=1465.24, global_step=1502, preemption_count=0, score=1465.24, test/loss=0.128107, test/num_examples=95000000, total_duration=12801.9, train/loss=0.125161, validation/loss=0.125713, validation/num_examples=83274637
I0306 16:43:27.194962 140252249302784 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.01198473758995533, loss=0.12228885293006897
I0306 16:44:03.185905 140404200342720 spec.py:321] Evaluating on the training split.
I0306 16:45:00.939087 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 16:48:09.123225 140404200342720 spec.py:349] Evaluating on the test split.
I0306 16:54:05.281963 140404200342720 submission_runner.py:469] Time since start: 13525.02s, 	Step: 1632, 	{'train/loss': 0.12469422821916125, 'validation/loss': 0.12562484800997617, 'validation/num_examples': 83274637, 'test/loss': 0.12792691001233553, 'test/num_examples': 95000000, 'score': 1586.222808122635, 'total_duration': 13525.018112897873, 'accumulated_submission_time': 1586.222808122635, 'accumulated_eval_time': 11938.41075849533, 'accumulated_logging_time': 0.2911524772644043}
I0306 16:54:05.290105 140252240910080 logging_writer.py:48] [1632] accumulated_eval_time=11938.4, accumulated_logging_time=0.291152, accumulated_submission_time=1586.22, global_step=1632, preemption_count=0, score=1586.22, test/loss=0.127927, test/num_examples=95000000, total_duration=13525, train/loss=0.124694, validation/loss=0.125625, validation/num_examples=83274637
I0306 16:54:54.649724 140252249302784 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.02108413353562355, loss=0.12668153643608093
I0306 16:56:05.876885 140404200342720 spec.py:321] Evaluating on the training split.
I0306 16:56:58.402982 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 17:00:09.052431 140404200342720 spec.py:349] Evaluating on the test split.
I0306 17:05:59.718299 140404200342720 submission_runner.py:469] Time since start: 14239.45s, 	Step: 1763, 	{'train/loss': 0.12555807759786178, 'validation/loss': 0.12547037126194557, 'validation/num_examples': 83274637, 'test/loss': 0.1278964861533717, 'test/num_examples': 95000000, 'score': 1706.7953004837036, 'total_duration': 14239.45443534851, 'accumulated_submission_time': 1706.7953004837036, 'accumulated_eval_time': 12532.252103805542, 'accumulated_logging_time': 0.30565738677978516}
I0306 17:05:59.727908 140252240910080 logging_writer.py:48] [1763] accumulated_eval_time=12532.3, accumulated_logging_time=0.305657, accumulated_submission_time=1706.8, global_step=1763, preemption_count=0, score=1706.8, test/loss=0.127896, test/num_examples=95000000, total_duration=14239.5, train/loss=0.125558, validation/loss=0.12547, validation/num_examples=83274637
I0306 17:06:13.966909 140252249302784 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.043958086520433426, loss=0.12893369793891907
I0306 17:07:59.822248 140404200342720 spec.py:321] Evaluating on the training split.
I0306 17:08:53.030590 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 17:11:57.028624 140404200342720 spec.py:349] Evaluating on the test split.
I0306 17:17:50.980458 140404200342720 submission_runner.py:469] Time since start: 14950.72s, 	Step: 1894, 	{'train/loss': 0.1250567229804378, 'validation/loss': 0.12519719548371275, 'validation/num_examples': 83274637, 'test/loss': 0.12745882200863487, 'test/num_examples': 95000000, 'score': 1826.8758404254913, 'total_duration': 14950.716592788696, 'accumulated_submission_time': 1826.8758404254913, 'accumulated_eval_time': 13123.410247325897, 'accumulated_logging_time': 0.3221569061279297}
I0306 17:17:50.988718 140252240910080 logging_writer.py:48] [1894] accumulated_eval_time=13123.4, accumulated_logging_time=0.322157, accumulated_submission_time=1826.88, global_step=1894, preemption_count=0, score=1826.88, test/loss=0.127459, test/num_examples=95000000, total_duration=14950.7, train/loss=0.125057, validation/loss=0.125197, validation/num_examples=83274637
I0306 17:17:51.749541 140252249302784 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.02073930948972702, loss=0.12867285311222076
I0306 17:19:27.821061 140252240910080 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.009200211614370346, loss=0.12347270548343658
I0306 17:19:51.495073 140404200342720 spec.py:321] Evaluating on the training split.
I0306 17:20:48.509877 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 17:23:53.320965 140404200342720 spec.py:349] Evaluating on the test split.
I0306 17:29:43.377049 140404200342720 submission_runner.py:469] Time since start: 15663.11s, 	Step: 2022, 	{'train/loss': 0.12519821647624924, 'validation/loss': 0.1252331535453642, 'validation/num_examples': 83274637, 'test/loss': 0.12765986363075657, 'test/num_examples': 95000000, 'score': 1947.3675935268402, 'total_duration': 15663.11318731308, 'accumulated_submission_time': 1947.3675935268402, 'accumulated_eval_time': 13715.292154550552, 'accumulated_logging_time': 0.33677101135253906}
I0306 17:29:43.385502 140252249302784 logging_writer.py:48] [2022] accumulated_eval_time=13715.3, accumulated_logging_time=0.336771, accumulated_submission_time=1947.37, global_step=2022, preemption_count=0, score=1947.37, test/loss=0.12766, test/num_examples=95000000, total_duration=15663.1, train/loss=0.125198, validation/loss=0.125233, validation/num_examples=83274637
I0306 17:30:44.500801 140252240910080 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.010007091797888279, loss=0.12581847608089447
I0306 17:31:43.465859 140404200342720 spec.py:321] Evaluating on the training split.
I0306 17:32:38.776209 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 17:35:46.385368 140404200342720 spec.py:349] Evaluating on the test split.
I0306 17:41:50.297479 140404200342720 submission_runner.py:469] Time since start: 16390.03s, 	Step: 2150, 	{'train/loss': 0.12429834533271925, 'validation/loss': 0.12530517327680044, 'validation/num_examples': 83274637, 'test/loss': 0.12761825399876645, 'test/num_examples': 95000000, 'score': 2067.435028076172, 'total_duration': 16390.033614873886, 'accumulated_submission_time': 2067.435028076172, 'accumulated_eval_time': 14322.123769044876, 'accumulated_logging_time': 0.35189366340637207}
I0306 17:41:50.305949 140252249302784 logging_writer.py:48] [2150] accumulated_eval_time=14322.1, accumulated_logging_time=0.351894, accumulated_submission_time=2067.44, global_step=2150, preemption_count=0, score=2067.44, test/loss=0.127618, test/num_examples=95000000, total_duration=16390, train/loss=0.124298, validation/loss=0.125305, validation/num_examples=83274637
I0306 17:42:21.528494 140252240910080 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.008985849097371101, loss=0.12275844812393188
I0306 17:43:50.358062 140404200342720 spec.py:321] Evaluating on the training split.
I0306 17:44:48.223529 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 17:47:52.942980 140404200342720 spec.py:349] Evaluating on the test split.
I0306 17:53:49.989289 140404200342720 submission_runner.py:469] Time since start: 17109.73s, 	Step: 2277, 	{'train/loss': 0.12439608504796552, 'validation/loss': 0.1252450385826772, 'validation/num_examples': 83274637, 'test/loss': 0.12761947515419408, 'test/num_examples': 95000000, 'score': 2187.4741320610046, 'total_duration': 17109.725430488586, 'accumulated_submission_time': 2187.4741320610046, 'accumulated_eval_time': 14921.754938364029, 'accumulated_logging_time': 0.3667290210723877}
I0306 17:53:49.998167 140252249302784 logging_writer.py:48] [2277] accumulated_eval_time=14921.8, accumulated_logging_time=0.366729, accumulated_submission_time=2187.47, global_step=2277, preemption_count=0, score=2187.47, test/loss=0.127619, test/num_examples=95000000, total_duration=17109.7, train/loss=0.124396, validation/loss=0.125245, validation/num_examples=83274637
I0306 17:53:52.575096 140252240910080 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.009528813883662224, loss=0.12443853914737701
I0306 17:55:49.160075 140252249302784 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.006536995992064476, loss=0.1231008991599083
I0306 17:55:50.206717 140404200342720 spec.py:321] Evaluating on the training split.
I0306 17:56:47.271365 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 17:59:52.390935 140404200342720 spec.py:349] Evaluating on the test split.
I0306 18:05:44.202630 140404200342720 submission_runner.py:469] Time since start: 17823.94s, 	Step: 2402, 	{'train/loss': 0.12399703336867897, 'validation/loss': 0.12494347646856149, 'validation/num_examples': 83274637, 'test/loss': 0.1273400443153783, 'test/num_examples': 95000000, 'score': 2307.669291496277, 'total_duration': 17823.93878364563, 'accumulated_submission_time': 2307.669291496277, 'accumulated_eval_time': 15515.750794410706, 'accumulated_logging_time': 0.3827962875366211}
I0306 18:05:44.211044 140252240910080 logging_writer.py:48] [2402] accumulated_eval_time=15515.8, accumulated_logging_time=0.382796, accumulated_submission_time=2307.67, global_step=2402, preemption_count=0, score=2307.67, test/loss=0.12734, test/num_examples=95000000, total_duration=17823.9, train/loss=0.123997, validation/loss=0.124943, validation/num_examples=83274637
I0306 18:07:09.898197 140252249302784 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.01637096144258976, loss=0.12039823085069656
I0306 18:07:44.748807 140404200342720 spec.py:321] Evaluating on the training split.
I0306 18:08:41.495557 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 18:11:50.292511 140404200342720 spec.py:349] Evaluating on the test split.
I0306 18:18:12.862643 140404200342720 submission_runner.py:469] Time since start: 18572.60s, 	Step: 2529, 	{'train/loss': 0.12288207895819496, 'validation/loss': 0.12501768723936316, 'validation/num_examples': 83274637, 'test/loss': 0.12742921579975328, 'test/num_examples': 95000000, 'score': 2428.193514585495, 'total_duration': 18572.59878063202, 'accumulated_submission_time': 2428.193514585495, 'accumulated_eval_time': 16143.864559173584, 'accumulated_logging_time': 0.39778780937194824}
I0306 18:18:12.872274 140252240910080 logging_writer.py:48] [2529] accumulated_eval_time=16143.9, accumulated_logging_time=0.397788, accumulated_submission_time=2428.19, global_step=2529, preemption_count=0, score=2428.19, test/loss=0.127429, test/num_examples=95000000, total_duration=18572.6, train/loss=0.122882, validation/loss=0.125018, validation/num_examples=83274637
I0306 18:19:09.461827 140252249302784 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.00870843417942524, loss=0.12891362607479095
I0306 18:20:14.142920 140404200342720 spec.py:321] Evaluating on the training split.
I0306 18:21:10.012436 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 18:24:17.334443 140404200342720 spec.py:349] Evaluating on the test split.
I0306 18:30:08.350402 140404200342720 submission_runner.py:469] Time since start: 19288.09s, 	Step: 2656, 	{'train/loss': 0.12505408825130207, 'validation/loss': 0.12503498558762105, 'validation/num_examples': 83274637, 'test/loss': 0.12741361648848684, 'test/num_examples': 95000000, 'score': 2549.449943304062, 'total_duration': 19288.086532354355, 'accumulated_submission_time': 2549.449943304062, 'accumulated_eval_time': 16738.071964025497, 'accumulated_logging_time': 0.4148406982421875}
I0306 18:30:08.359169 140252240910080 logging_writer.py:48] [2656] accumulated_eval_time=16738.1, accumulated_logging_time=0.414841, accumulated_submission_time=2549.45, global_step=2656, preemption_count=0, score=2549.45, test/loss=0.127414, test/num_examples=95000000, total_duration=19288.1, train/loss=0.125054, validation/loss=0.125035, validation/num_examples=83274637
I0306 18:30:30.398209 140252249302784 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.013448808342218399, loss=0.1307728886604309
I0306 18:32:09.910220 140404200342720 spec.py:321] Evaluating on the training split.
I0306 18:33:05.825852 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 18:36:12.881315 140404200342720 spec.py:349] Evaluating on the test split.
I0306 18:42:20.831564 140404200342720 submission_runner.py:469] Time since start: 20020.57s, 	Step: 2782, 	{'train/loss': 0.12211666103897605, 'validation/loss': 0.12514805176552435, 'validation/num_examples': 83274637, 'test/loss': 0.12761840310444078, 'test/num_examples': 95000000, 'score': 2670.957683801651, 'total_duration': 20020.56770658493, 'accumulated_submission_time': 2670.957683801651, 'accumulated_eval_time': 17348.9932448864, 'accumulated_logging_time': 0.4603312015533447}
I0306 18:42:20.841030 140252240910080 logging_writer.py:48] [2782] accumulated_eval_time=17349, accumulated_logging_time=0.460331, accumulated_submission_time=2670.96, global_step=2782, preemption_count=0, score=2670.96, test/loss=0.127618, test/num_examples=95000000, total_duration=20020.6, train/loss=0.122117, validation/loss=0.125148, validation/num_examples=83274637
I0306 18:42:22.859334 140252249302784 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.005034441594034433, loss=0.12153521925210953
I0306 18:44:14.238950 140252240910080 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.006847552489489317, loss=0.12520211935043335
I0306 18:44:21.292800 140404200342720 spec.py:321] Evaluating on the training split.
I0306 18:45:15.925228 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 18:48:26.244812 140404200342720 spec.py:349] Evaluating on the test split.
I0306 18:54:27.546283 140404200342720 submission_runner.py:469] Time since start: 20747.28s, 	Step: 2908, 	{'train/loss': 0.12297361437817039, 'validation/loss': 0.12494412196423586, 'validation/num_examples': 83274637, 'test/loss': 0.12724154489103617, 'test/num_examples': 95000000, 'score': 2791.395147562027, 'total_duration': 20747.282421827316, 'accumulated_submission_time': 2791.395147562027, 'accumulated_eval_time': 17955.24665594101, 'accumulated_logging_time': 0.4762110710144043}
I0306 18:54:27.554855 140252249302784 logging_writer.py:48] [2908] accumulated_eval_time=17955.2, accumulated_logging_time=0.476211, accumulated_submission_time=2791.4, global_step=2908, preemption_count=0, score=2791.4, test/loss=0.127242, test/num_examples=95000000, total_duration=20747.3, train/loss=0.122974, validation/loss=0.124944, validation/num_examples=83274637
I0306 18:55:50.626581 140252240910080 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.00528729846701026, loss=0.11563630402088165
I0306 18:56:28.880906 140404200342720 spec.py:321] Evaluating on the training split.
I0306 18:57:24.788454 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 19:00:31.013677 140404200342720 spec.py:349] Evaluating on the test split.
I0306 19:06:20.079638 140404200342720 submission_runner.py:469] Time since start: 21459.82s, 	Step: 3034, 	{'train/loss': 0.12301442732319892, 'validation/loss': 0.12469653533682808, 'validation/num_examples': 83274637, 'test/loss': 0.1268287025596217, 'test/num_examples': 95000000, 'score': 2912.707358121872, 'total_duration': 21459.81579041481, 'accumulated_submission_time': 2912.707358121872, 'accumulated_eval_time': 18546.445335626602, 'accumulated_logging_time': 0.4913210868835449}
I0306 19:06:20.089218 140252249302784 logging_writer.py:48] [3034] accumulated_eval_time=18546.4, accumulated_logging_time=0.491321, accumulated_submission_time=2912.71, global_step=3034, preemption_count=0, score=2912.71, test/loss=0.126829, test/num_examples=95000000, total_duration=21459.8, train/loss=0.123014, validation/loss=0.124697, validation/num_examples=83274637
I0306 19:07:11.474648 140252240910080 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.016526654362678528, loss=0.12086351215839386
I0306 19:08:20.749981 140404200342720 spec.py:321] Evaluating on the training split.
I0306 19:09:17.910428 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 19:12:27.329443 140404200342720 spec.py:349] Evaluating on the test split.
I0306 19:18:18.477090 140404200342720 submission_runner.py:469] Time since start: 22178.21s, 	Step: 3159, 	{'train/loss': 0.12343464671112832, 'validation/loss': 0.12470855579178891, 'validation/num_examples': 83274637, 'test/loss': 0.12705982408511513, 'test/num_examples': 95000000, 'score': 3033.3538892269135, 'total_duration': 22178.21322798729, 'accumulated_submission_time': 3033.3538892269135, 'accumulated_eval_time': 19144.172388076782, 'accumulated_logging_time': 0.5078270435333252}
I0306 19:18:18.485926 140252249302784 logging_writer.py:48] [3159] accumulated_eval_time=19144.2, accumulated_logging_time=0.507827, accumulated_submission_time=3033.35, global_step=3159, preemption_count=0, score=3033.35, test/loss=0.12706, test/num_examples=95000000, total_duration=22178.2, train/loss=0.123435, validation/loss=0.124709, validation/num_examples=83274637
I0306 19:18:38.314013 140252240910080 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.03823651373386383, loss=0.1227359026670456
I0306 19:20:19.490355 140404200342720 spec.py:321] Evaluating on the training split.
I0306 19:21:14.581551 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 19:24:21.103715 140404200342720 spec.py:349] Evaluating on the test split.
I0306 19:30:17.391662 140404200342720 submission_runner.py:469] Time since start: 22897.13s, 	Step: 3285, 	{'train/loss': 0.12627397763466686, 'validation/loss': 0.12474967585456122, 'validation/num_examples': 83274637, 'test/loss': 0.1271163505653783, 'test/num_examples': 95000000, 'score': 3154.3454473018646, 'total_duration': 22897.127810001373, 'accumulated_submission_time': 3154.3454473018646, 'accumulated_eval_time': 19742.07364296913, 'accumulated_logging_time': 0.5230464935302734}
I0306 19:30:17.400508 140252249302784 logging_writer.py:48] [3285] accumulated_eval_time=19742.1, accumulated_logging_time=0.523046, accumulated_submission_time=3154.35, global_step=3285, preemption_count=0, score=3154.35, test/loss=0.127116, test/num_examples=95000000, total_duration=22897.1, train/loss=0.126274, validation/loss=0.12475, validation/num_examples=83274637
I0306 19:30:19.076090 140252240910080 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.007264309097081423, loss=0.1227903813123703
I0306 19:32:05.325037 140252249302784 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.011166534386575222, loss=0.12376011908054352
I0306 19:32:17.626806 140404200342720 spec.py:321] Evaluating on the training split.
I0306 19:33:12.347937 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 19:36:26.051476 140404200342720 spec.py:349] Evaluating on the test split.
I0306 19:42:23.010970 140404200342720 submission_runner.py:469] Time since start: 23622.75s, 	Step: 3411, 	{'train/loss': 0.1227719017521203, 'validation/loss': 0.12496288930812714, 'validation/num_examples': 83274637, 'test/loss': 0.12725739363692434, 'test/num_examples': 95000000, 'score': 3274.5585658550262, 'total_duration': 23622.747117996216, 'accumulated_submission_time': 3274.5585658550262, 'accumulated_eval_time': 20347.457743883133, 'accumulated_logging_time': 0.5382003784179688}
I0306 19:42:23.020966 140252240910080 logging_writer.py:48] [3411] accumulated_eval_time=20347.5, accumulated_logging_time=0.5382, accumulated_submission_time=3274.56, global_step=3411, preemption_count=0, score=3274.56, test/loss=0.127257, test/num_examples=95000000, total_duration=23622.7, train/loss=0.122772, validation/loss=0.124963, validation/num_examples=83274637
I0306 19:43:42.303101 140252249302784 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.008127273060381413, loss=0.12050126492977142
I0306 19:44:23.826452 140404200342720 spec.py:321] Evaluating on the training split.
I0306 19:45:19.547831 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 19:48:28.428121 140404200342720 spec.py:349] Evaluating on the test split.
I0306 19:54:30.182672 140404200342720 submission_runner.py:469] Time since start: 24349.92s, 	Step: 3534, 	{'train/loss': 0.12335698639259399, 'validation/loss': 0.12463293572756169, 'validation/num_examples': 83274637, 'test/loss': 0.1270975515727796, 'test/num_examples': 95000000, 'score': 3395.350783586502, 'total_duration': 24349.918817281723, 'accumulated_submission_time': 3395.350783586502, 'accumulated_eval_time': 20953.813903570175, 'accumulated_logging_time': 0.5552661418914795}
I0306 19:54:30.191977 140252240910080 logging_writer.py:48] [3534] accumulated_eval_time=20953.8, accumulated_logging_time=0.555266, accumulated_submission_time=3395.35, global_step=3534, preemption_count=0, score=3395.35, test/loss=0.127098, test/num_examples=95000000, total_duration=24349.9, train/loss=0.123357, validation/loss=0.124633, validation/num_examples=83274637
I0306 19:55:20.049286 140252249302784 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.021281970664858818, loss=0.11976313591003418
I0306 19:56:30.276662 140404200342720 spec.py:321] Evaluating on the training split.
I0306 19:57:25.354454 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 20:00:37.386036 140404200342720 spec.py:349] Evaluating on the test split.
I0306 20:06:38.152344 140404200342720 submission_runner.py:469] Time since start: 25077.89s, 	Step: 3657, 	{'train/loss': 0.12315784600920647, 'validation/loss': 0.12463135991645782, 'validation/num_examples': 83274637, 'test/loss': 0.12699423969983553, 'test/num_examples': 95000000, 'score': 3515.399905204773, 'total_duration': 25077.888488054276, 'accumulated_submission_time': 3515.399905204773, 'accumulated_eval_time': 21561.689523220062, 'accumulated_logging_time': 0.5936183929443359}
I0306 20:06:38.161440 140252240910080 logging_writer.py:48] [3657] accumulated_eval_time=21561.7, accumulated_logging_time=0.593618, accumulated_submission_time=3515.4, global_step=3657, preemption_count=0, score=3515.4, test/loss=0.126994, test/num_examples=95000000, total_duration=25077.9, train/loss=0.123158, validation/loss=0.124631, validation/num_examples=83274637
I0306 20:07:00.430316 140252249302784 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.012537871487438679, loss=0.12397320568561554
I0306 20:08:38.681152 140404200342720 spec.py:321] Evaluating on the training split.
I0306 20:09:37.305001 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 20:12:47.371492 140404200342720 spec.py:349] Evaluating on the test split.
I0306 20:18:39.301560 140404200342720 submission_runner.py:469] Time since start: 25799.04s, 	Step: 3784, 	{'train/loss': 0.12292983580919557, 'validation/loss': 0.12471398084147083, 'validation/num_examples': 83274637, 'test/loss': 0.1270961740439967, 'test/num_examples': 95000000, 'score': 3635.9060020446777, 'total_duration': 25799.037702083588, 'accumulated_submission_time': 3635.9060020446777, 'accumulated_eval_time': 22162.309873104095, 'accumulated_logging_time': 0.609560489654541}
I0306 20:18:39.310969 140252240910080 logging_writer.py:48] [3784] accumulated_eval_time=22162.3, accumulated_logging_time=0.60956, accumulated_submission_time=3635.91, global_step=3784, preemption_count=0, score=3635.91, test/loss=0.127096, test/num_examples=95000000, total_duration=25799, train/loss=0.12293, validation/loss=0.124714, validation/num_examples=83274637
I0306 20:18:41.106840 140252249302784 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.015988102182745934, loss=0.1222771406173706
I0306 20:20:29.929711 140252240910080 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.026270704343914986, loss=0.11941880732774734
I0306 20:20:39.674948 140404200342720 spec.py:321] Evaluating on the training split.
I0306 20:21:33.812678 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 20:24:39.435509 140404200342720 spec.py:349] Evaluating on the test split.
I0306 20:30:37.556566 140404200342720 submission_runner.py:469] Time since start: 26517.29s, 	Step: 3909, 	{'train/loss': 0.12349289894666311, 'validation/loss': 0.12470760371689237, 'validation/num_examples': 83274637, 'test/loss': 0.1270296873355263, 'test/num_examples': 95000000, 'score': 3756.2560908794403, 'total_duration': 26517.292717456818, 'accumulated_submission_time': 3756.2560908794403, 'accumulated_eval_time': 22760.191435098648, 'accumulated_logging_time': 0.6255919933319092}
I0306 20:30:37.565328 140252249302784 logging_writer.py:48] [3909] accumulated_eval_time=22760.2, accumulated_logging_time=0.625592, accumulated_submission_time=3756.26, global_step=3909, preemption_count=0, score=3756.26, test/loss=0.12703, test/num_examples=95000000, total_duration=26517.3, train/loss=0.123493, validation/loss=0.124708, validation/num_examples=83274637
I0306 20:31:50.945547 140252240910080 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.00536717614158988, loss=0.1300898939371109
I0306 20:32:39.048543 140404200342720 spec.py:321] Evaluating on the training split.
I0306 20:33:38.555338 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 20:36:49.751524 140404200342720 spec.py:349] Evaluating on the test split.
I0306 20:42:38.553219 140404200342720 submission_runner.py:469] Time since start: 27238.29s, 	Step: 4041, 	{'train/loss': 0.1267893070811933, 'validation/loss': 0.12468139107612719, 'validation/num_examples': 83274637, 'test/loss': 0.12706084602179277, 'test/num_examples': 95000000, 'score': 3877.725663661957, 'total_duration': 27238.289368629456, 'accumulated_submission_time': 3877.725663661957, 'accumulated_eval_time': 23359.69605588913, 'accumulated_logging_time': 0.6407222747802734}
I0306 20:42:38.563598 140252249302784 logging_writer.py:48] [4041] accumulated_eval_time=23359.7, accumulated_logging_time=0.640722, accumulated_submission_time=3877.73, global_step=4041, preemption_count=0, score=3877.73, test/loss=0.127061, test/num_examples=95000000, total_duration=27238.3, train/loss=0.126789, validation/loss=0.124681, validation/num_examples=83274637
I0306 20:43:24.258882 140252240910080 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.01592934876680374, loss=0.1318688988685608
I0306 20:44:39.185817 140404200342720 spec.py:321] Evaluating on the training split.
I0306 20:45:38.195987 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 20:48:45.214024 140404200342720 spec.py:349] Evaluating on the test split.
I0306 20:54:45.328867 140404200342720 submission_runner.py:469] Time since start: 27965.07s, 	Step: 4169, 	{'train/loss': 0.1228753166191233, 'validation/loss': 0.12450269412978272, 'validation/num_examples': 83274637, 'test/loss': 0.1269277083984375, 'test/num_examples': 95000000, 'score': 3998.3350121974945, 'total_duration': 27965.065019845963, 'accumulated_submission_time': 3998.3350121974945, 'accumulated_eval_time': 23965.839072227478, 'accumulated_logging_time': 0.6575424671173096}
I0306 20:54:45.338175 140252249302784 logging_writer.py:48] [4169] accumulated_eval_time=23965.8, accumulated_logging_time=0.657542, accumulated_submission_time=3998.34, global_step=4169, preemption_count=0, score=3998.34, test/loss=0.126928, test/num_examples=95000000, total_duration=27965.1, train/loss=0.122875, validation/loss=0.124503, validation/num_examples=83274637
I0306 20:54:53.001518 140252240910080 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.008349025622010231, loss=0.12179112434387207
I0306 20:56:45.580852 140404200342720 spec.py:321] Evaluating on the training split.
I0306 20:57:48.066800 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 21:00:58.844031 140404200342720 spec.py:349] Evaluating on the test split.
I0306 21:06:59.097096 140404200342720 submission_runner.py:469] Time since start: 28698.83s, 	Step: 4296, 	{'train/loss': 0.12310909620433483, 'validation/loss': 0.1247721765389908, 'validation/num_examples': 83274637, 'test/loss': 0.12717749186883223, 'test/num_examples': 95000000, 'score': 4118.564800262451, 'total_duration': 28698.833248376846, 'accumulated_submission_time': 4118.564800262451, 'accumulated_eval_time': 24579.355286836624, 'accumulated_logging_time': 0.6733770370483398}
I0306 21:06:59.106272 140252249302784 logging_writer.py:48] [4296] accumulated_eval_time=24579.4, accumulated_logging_time=0.673377, accumulated_submission_time=4118.56, global_step=4296, preemption_count=0, score=4118.56, test/loss=0.127177, test/num_examples=95000000, total_duration=28698.8, train/loss=0.123109, validation/loss=0.124772, validation/num_examples=83274637
I0306 21:06:59.655273 140252240910080 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.0072759403847157955, loss=0.13190779089927673
I0306 21:08:35.461671 140252249302784 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.008525279350578785, loss=0.11413522064685822
I0306 21:09:00.003012 140404200342720 spec.py:321] Evaluating on the training split.
I0306 21:09:55.846747 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 21:13:02.457794 140404200342720 spec.py:349] Evaluating on the test split.
I0306 21:18:57.012026 140404200342720 submission_runner.py:469] Time since start: 29416.75s, 	Step: 4423, 	{'train/loss': 0.1249580193404694, 'validation/loss': 0.12460516651971604, 'validation/num_examples': 83274637, 'test/loss': 0.1269663798725329, 'test/num_examples': 95000000, 'score': 4239.448970794678, 'total_duration': 29416.748157978058, 'accumulated_submission_time': 4239.448970794678, 'accumulated_eval_time': 25176.364231348038, 'accumulated_logging_time': 0.6889345645904541}
I0306 21:18:57.022961 140252240910080 logging_writer.py:48] [4423] accumulated_eval_time=25176.4, accumulated_logging_time=0.688935, accumulated_submission_time=4239.45, global_step=4423, preemption_count=0, score=4239.45, test/loss=0.126966, test/num_examples=95000000, total_duration=29416.7, train/loss=0.124958, validation/loss=0.124605, validation/num_examples=83274637
I0306 21:19:58.169950 140252249302784 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.00623825890943408, loss=0.12189614027738571
I0306 21:20:57.330984 140404200342720 spec.py:321] Evaluating on the training split.
I0306 21:21:54.237731 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 21:25:03.433907 140404200342720 spec.py:349] Evaluating on the test split.
I0306 21:30:46.324816 140404200342720 submission_runner.py:469] Time since start: 30126.06s, 	Step: 4551, 	{'train/loss': 0.12223237256209056, 'validation/loss': 0.12450075345035352, 'validation/num_examples': 83274637, 'test/loss': 0.12698479748149671, 'test/num_examples': 95000000, 'score': 4359.743313074112, 'total_duration': 30126.060968399048, 'accumulated_submission_time': 4359.743313074112, 'accumulated_eval_time': 25765.358011484146, 'accumulated_logging_time': 0.7068400382995605}
I0306 21:30:46.334019 140252240910080 logging_writer.py:48] [4551] accumulated_eval_time=25765.4, accumulated_logging_time=0.70684, accumulated_submission_time=4359.74, global_step=4551, preemption_count=0, score=4359.74, test/loss=0.126985, test/num_examples=95000000, total_duration=30126.1, train/loss=0.122232, validation/loss=0.124501, validation/num_examples=83274637
I0306 21:31:15.045213 140252249302784 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.007926573045551777, loss=0.12052467465400696
I0306 21:32:46.555466 140404200342720 spec.py:321] Evaluating on the training split.
I0306 21:33:41.924950 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 21:36:50.081917 140404200342720 spec.py:349] Evaluating on the test split.
I0306 21:42:56.296430 140404200342720 submission_runner.py:469] Time since start: 30856.03s, 	Step: 4676, 	{'train/loss': 0.12266166057179934, 'validation/loss': 0.12440604673920704, 'validation/num_examples': 83274637, 'test/loss': 0.1268265031352796, 'test/num_examples': 95000000, 'score': 4479.951153039932, 'total_duration': 30856.03257751465, 'accumulated_submission_time': 4479.951153039932, 'accumulated_eval_time': 26375.09892129898, 'accumulated_logging_time': 0.722822904586792}
I0306 21:42:56.305912 140252240910080 logging_writer.py:48] [4676] accumulated_eval_time=26375.1, accumulated_logging_time=0.722823, accumulated_submission_time=4479.95, global_step=4676, preemption_count=0, score=4479.95, test/loss=0.126827, test/num_examples=95000000, total_duration=30856, train/loss=0.122662, validation/loss=0.124406, validation/num_examples=83274637
I0306 21:42:58.956276 140252249302784 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.018026502802968025, loss=0.1302066296339035
I0306 21:44:57.297634 140404200342720 spec.py:321] Evaluating on the training split.
I0306 21:45:57.074931 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 21:49:07.820969 140404200342720 spec.py:349] Evaluating on the test split.
I0306 21:55:02.152945 140404200342720 submission_runner.py:469] Time since start: 31581.89s, 	Step: 4797, 	{'train/loss': 0.12298685980011832, 'validation/loss': 0.12448154241503928, 'validation/num_examples': 83274637, 'test/loss': 0.12699948564967106, 'test/num_examples': 95000000, 'score': 4600.926641702652, 'total_duration': 31581.889095067978, 'accumulated_submission_time': 4600.926641702652, 'accumulated_eval_time': 26979.95418357849, 'accumulated_logging_time': 0.739922046661377}
I0306 21:55:02.163406 140252240910080 logging_writer.py:48] [4797] accumulated_eval_time=26980, accumulated_logging_time=0.739922, accumulated_submission_time=4600.93, global_step=4797, preemption_count=0, score=4600.93, test/loss=0.126999, test/num_examples=95000000, total_duration=31581.9, train/loss=0.122987, validation/loss=0.124482, validation/num_examples=83274637
I0306 21:55:02.609230 140252249302784 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.005776716861873865, loss=0.12131179124116898
I0306 21:56:40.497375 140252240910080 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.03856180980801582, loss=0.1286853551864624
I0306 21:57:02.530509 140404200342720 spec.py:321] Evaluating on the training split.
I0306 21:57:56.360796 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 22:01:08.919575 140404200342720 spec.py:349] Evaluating on the test split.
I0306 22:07:26.093365 140404200342720 submission_runner.py:469] Time since start: 32325.83s, 	Step: 4918, 	{'train/loss': 0.12089453847293959, 'validation/loss': 0.12440475500319316, 'validation/num_examples': 83274637, 'test/loss': 0.12676948932976972, 'test/num_examples': 95000000, 'score': 4721.280546426773, 'total_duration': 32325.82950425148, 'accumulated_submission_time': 4721.280546426773, 'accumulated_eval_time': 27603.51697063446, 'accumulated_logging_time': 0.757615327835083}
I0306 22:07:26.102668 140252249302784 logging_writer.py:48] [4918] accumulated_eval_time=27603.5, accumulated_logging_time=0.757615, accumulated_submission_time=4721.28, global_step=4918, preemption_count=0, score=4721.28, test/loss=0.126769, test/num_examples=95000000, total_duration=32325.8, train/loss=0.120895, validation/loss=0.124405, validation/num_examples=83274637
I0306 22:08:34.847923 140252240910080 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.006130625493824482, loss=0.12105187028646469
I0306 22:09:27.422897 140404200342720 spec.py:321] Evaluating on the training split.
I0306 22:10:23.711980 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 22:13:34.346737 140404200342720 spec.py:349] Evaluating on the test split.
I0306 22:19:28.012647 140404200342720 submission_runner.py:469] Time since start: 33047.75s, 	Step: 5048, 	{'train/loss': 0.12291765526967978, 'validation/loss': 0.12439396162151313, 'validation/num_examples': 83274637, 'test/loss': 0.12684296127672698, 'test/num_examples': 95000000, 'score': 4842.586594581604, 'total_duration': 33047.7487847805, 'accumulated_submission_time': 4842.586594581604, 'accumulated_eval_time': 28204.106652975082, 'accumulated_logging_time': 0.7742297649383545}
I0306 22:19:28.022615 140252249302784 logging_writer.py:48] [5048] accumulated_eval_time=28204.1, accumulated_logging_time=0.77423, accumulated_submission_time=4842.59, global_step=5048, preemption_count=0, score=4842.59, test/loss=0.126843, test/num_examples=95000000, total_duration=33047.7, train/loss=0.122918, validation/loss=0.124394, validation/num_examples=83274637
I0306 22:20:00.000822 140252240910080 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.005671895574778318, loss=0.12582236528396606
I0306 22:21:28.561877 140404200342720 spec.py:321] Evaluating on the training split.
I0306 22:22:24.287391 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 22:25:30.485894 140404200342720 spec.py:349] Evaluating on the test split.
I0306 22:31:27.543223 140404200342720 submission_runner.py:469] Time since start: 33767.28s, 	Step: 5171, 	{'train/loss': 0.12309326662582422, 'validation/loss': 0.12466336567670395, 'validation/num_examples': 83274637, 'test/loss': 0.12729101167763157, 'test/num_examples': 95000000, 'score': 4963.108927965164, 'total_duration': 33767.27935433388, 'accumulated_submission_time': 4963.108927965164, 'accumulated_eval_time': 28803.08793282509, 'accumulated_logging_time': 0.7946240901947021}
I0306 22:31:27.553156 140252249302784 logging_writer.py:48] [5171] accumulated_eval_time=28803.1, accumulated_logging_time=0.794624, accumulated_submission_time=4963.11, global_step=5171, preemption_count=0, score=4963.11, test/loss=0.127291, test/num_examples=95000000, total_duration=33767.3, train/loss=0.123093, validation/loss=0.124663, validation/num_examples=83274637
I0306 22:31:33.097404 140252240910080 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.007426864001899958, loss=0.11989055573940277
I0306 22:33:27.823348 140252249302784 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.005855189636349678, loss=0.12147582322359085
I0306 22:33:27.827763 140404200342720 spec.py:321] Evaluating on the training split.
I0306 22:34:23.950422 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 22:37:37.725456 140404200342720 spec.py:349] Evaluating on the test split.
I0306 22:43:44.178814 140404200342720 submission_runner.py:469] Time since start: 34503.91s, 	Step: 5301, 	{'train/loss': 0.12297805308499052, 'validation/loss': 0.12428412710852428, 'validation/num_examples': 83274637, 'test/loss': 0.1266606758120888, 'test/num_examples': 95000000, 'score': 5083.369934558868, 'total_duration': 34503.914956092834, 'accumulated_submission_time': 5083.369934558868, 'accumulated_eval_time': 29419.43890118599, 'accumulated_logging_time': 0.8110606670379639}
I0306 22:43:44.188219 140252240910080 logging_writer.py:48] [5301] accumulated_eval_time=29419.4, accumulated_logging_time=0.811061, accumulated_submission_time=5083.37, global_step=5301, preemption_count=0, score=5083.37, test/loss=0.126661, test/num_examples=95000000, total_duration=34503.9, train/loss=0.122978, validation/loss=0.124284, validation/num_examples=83274637
I0306 22:45:12.590947 140252249302784 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.013829832896590233, loss=0.12150844931602478
I0306 22:45:45.109809 140404200342720 spec.py:321] Evaluating on the training split.
I0306 22:46:40.779422 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 22:49:53.670812 140404200342720 spec.py:349] Evaluating on the test split.
I0306 22:55:47.335562 140404200342720 submission_runner.py:469] Time since start: 35227.07s, 	Step: 5428, 	{'train/loss': 0.12283640415788447, 'validation/loss': 0.12436963690035921, 'validation/num_examples': 83274637, 'test/loss': 0.12680228038651314, 'test/num_examples': 95000000, 'score': 5204.270402908325, 'total_duration': 35227.07170009613, 'accumulated_submission_time': 5204.270402908325, 'accumulated_eval_time': 30021.664585590363, 'accumulated_logging_time': 0.8350987434387207}
I0306 22:55:47.344994 140252240910080 logging_writer.py:48] [5428] accumulated_eval_time=30021.7, accumulated_logging_time=0.835099, accumulated_submission_time=5204.27, global_step=5428, preemption_count=0, score=5204.27, test/loss=0.126802, test/num_examples=95000000, total_duration=35227.1, train/loss=0.122836, validation/loss=0.12437, validation/num_examples=83274637
I0306 22:56:43.072257 140252249302784 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.009648485109210014, loss=0.1307332068681717
I0306 22:57:47.979688 140404200342720 spec.py:321] Evaluating on the training split.
I0306 22:58:43.189561 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 23:01:56.569978 140404200342720 spec.py:349] Evaluating on the test split.
I0306 23:08:06.629799 140404200342720 submission_runner.py:469] Time since start: 35966.37s, 	Step: 5553, 	{'train/loss': 0.1241072101647374, 'validation/loss': 0.12413229118346382, 'validation/num_examples': 83274637, 'test/loss': 0.12649329131373355, 'test/num_examples': 95000000, 'score': 5324.891401767731, 'total_duration': 35966.365944862366, 'accumulated_submission_time': 5324.891401767731, 'accumulated_eval_time': 30640.31463623047, 'accumulated_logging_time': 0.8517365455627441}
I0306 23:08:06.668905 140252240910080 logging_writer.py:48] [5553] accumulated_eval_time=30640.3, accumulated_logging_time=0.851737, accumulated_submission_time=5324.89, global_step=5553, preemption_count=0, score=5324.89, test/loss=0.126493, test/num_examples=95000000, total_duration=35966.4, train/loss=0.124107, validation/loss=0.124132, validation/num_examples=83274637
I0306 23:08:35.783586 140252249302784 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.0070322598330676556, loss=0.12388761341571808
I0306 23:10:07.736103 140404200342720 spec.py:321] Evaluating on the training split.
I0306 23:11:04.521033 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 23:14:13.538998 140404200342720 spec.py:349] Evaluating on the test split.
I0306 23:20:04.874619 140404200342720 submission_runner.py:469] Time since start: 36684.61s, 	Step: 5679, 	{'train/loss': 0.12214450497156794, 'validation/loss': 0.12417404887895031, 'validation/num_examples': 83274637, 'test/loss': 0.1266518058388158, 'test/num_examples': 95000000, 'score': 5445.944703102112, 'total_duration': 36684.610759973526, 'accumulated_submission_time': 5445.944703102112, 'accumulated_eval_time': 31237.45308828354, 'accumulated_logging_time': 0.8978672027587891}
I0306 23:20:04.884384 140252240910080 logging_writer.py:48] [5679] accumulated_eval_time=31237.5, accumulated_logging_time=0.897867, accumulated_submission_time=5445.94, global_step=5679, preemption_count=0, score=5445.94, test/loss=0.126652, test/num_examples=95000000, total_duration=36684.6, train/loss=0.122145, validation/loss=0.124174, validation/num_examples=83274637
I0306 23:20:07.204359 140252249302784 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.005412692669779062, loss=0.11464300006628036
I0306 23:21:57.068552 140252240910080 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.019494639709591866, loss=0.12385846674442291
I0306 23:22:05.072055 140404200342720 spec.py:321] Evaluating on the training split.
I0306 23:22:56.640101 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 23:26:07.028607 140404200342720 spec.py:349] Evaluating on the test split.
I0306 23:32:01.337833 140404200342720 submission_runner.py:469] Time since start: 37401.07s, 	Step: 5807, 	{'train/loss': 0.1236418171803344, 'validation/loss': 0.12424107713171793, 'validation/num_examples': 83274637, 'test/loss': 0.12665060270353617, 'test/num_examples': 95000000, 'score': 5566.119457483292, 'total_duration': 37401.07398414612, 'accumulated_submission_time': 5566.119457483292, 'accumulated_eval_time': 31833.71880364418, 'accumulated_logging_time': 0.9144628047943115}
I0306 23:32:01.348770 140252249302784 logging_writer.py:48] [5807] accumulated_eval_time=31833.7, accumulated_logging_time=0.914463, accumulated_submission_time=5566.12, global_step=5807, preemption_count=0, score=5566.12, test/loss=0.126651, test/num_examples=95000000, total_duration=37401.1, train/loss=0.123642, validation/loss=0.124241, validation/num_examples=83274637
I0306 23:33:25.945794 140252240910080 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.006423040758818388, loss=0.11924699693918228
I0306 23:34:02.620974 140404200342720 spec.py:321] Evaluating on the training split.
I0306 23:35:03.662464 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 23:38:10.542840 140404200342720 spec.py:349] Evaluating on the test split.
I0306 23:43:54.834667 140404200342720 submission_runner.py:469] Time since start: 38114.57s, 	Step: 5929, 	{'train/loss': 0.12422188618601118, 'validation/loss': 0.1241272719469626, 'validation/num_examples': 83274637, 'test/loss': 0.12652331935649672, 'test/num_examples': 95000000, 'score': 5687.377359390259, 'total_duration': 38114.5708053112, 'accumulated_submission_time': 5687.377359390259, 'accumulated_eval_time': 32425.932426929474, 'accumulated_logging_time': 0.9324440956115723}
I0306 23:43:54.865958 140252249302784 logging_writer.py:48] [5929] accumulated_eval_time=32425.9, accumulated_logging_time=0.932444, accumulated_submission_time=5687.38, global_step=5929, preemption_count=0, score=5687.38, test/loss=0.126523, test/num_examples=95000000, total_duration=38114.6, train/loss=0.124222, validation/loss=0.124127, validation/num_examples=83274637
I0306 23:44:47.318752 140252240910080 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.01020455826073885, loss=0.12206107378005981
I0306 23:45:55.137844 140404200342720 spec.py:321] Evaluating on the training split.
I0306 23:46:56.530747 140404200342720 spec.py:333] Evaluating on the validation split.
I0306 23:50:05.709313 140404200342720 spec.py:349] Evaluating on the test split.
I0306 23:56:12.198235 140404200342720 submission_runner.py:469] Time since start: 38851.93s, 	Step: 6058, 	{'train/loss': 0.12284806678833077, 'validation/loss': 0.12408280768102448, 'validation/num_examples': 83274637, 'test/loss': 0.12644319987664474, 'test/num_examples': 95000000, 'score': 5807.635162115097, 'total_duration': 38851.934390068054, 'accumulated_submission_time': 5807.635162115097, 'accumulated_eval_time': 33042.992782354355, 'accumulated_logging_time': 0.9701330661773682}
I0306 23:56:12.208085 140252249302784 logging_writer.py:48] [6058] accumulated_eval_time=33043, accumulated_logging_time=0.970133, accumulated_submission_time=5807.64, global_step=6058, preemption_count=0, score=5807.64, test/loss=0.126443, test/num_examples=95000000, total_duration=38851.9, train/loss=0.122848, validation/loss=0.124083, validation/num_examples=83274637
I0306 23:56:32.719956 140252240910080 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.005333057139068842, loss=0.11989980936050415
I0306 23:58:12.715047 140404200342720 spec.py:321] Evaluating on the training split.
I0306 23:59:06.603004 140404200342720 spec.py:333] Evaluating on the validation split.
I0307 00:02:15.610626 140404200342720 spec.py:349] Evaluating on the test split.
I0307 00:08:20.532421 140404200342720 submission_runner.py:469] Time since start: 39580.27s, 	Step: 6185, 	{'train/loss': 0.12140100446980705, 'validation/loss': 0.12419052285358693, 'validation/num_examples': 83274637, 'test/loss': 0.1265128461143092, 'test/num_examples': 95000000, 'score': 5928.128986597061, 'total_duration': 39580.26856923103, 'accumulated_submission_time': 5928.128986597061, 'accumulated_eval_time': 33650.81011915207, 'accumulated_logging_time': 0.986473560333252}
I0307 00:08:20.542672 140252249302784 logging_writer.py:48] [6185] accumulated_eval_time=33650.8, accumulated_logging_time=0.986474, accumulated_submission_time=5928.13, global_step=6185, preemption_count=0, score=5928.13, test/loss=0.126513, test/num_examples=95000000, total_duration=39580.3, train/loss=0.121401, validation/loss=0.124191, validation/num_examples=83274637
I0307 00:08:22.293752 140252240910080 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.012084227986633778, loss=0.13258719444274902
I0307 00:10:02.646469 140252249302784 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.012612724676728249, loss=0.12673227488994598
I0307 00:10:21.361908 140404200342720 spec.py:321] Evaluating on the training split.
I0307 00:11:15.715468 140404200342720 spec.py:333] Evaluating on the validation split.
I0307 00:14:24.079648 140404200342720 spec.py:349] Evaluating on the test split.
I0307 00:20:13.378699 140404200342720 submission_runner.py:469] Time since start: 40293.11s, 	Step: 6318, 	{'train/loss': 0.12312161799449965, 'validation/loss': 0.12391587621512613, 'validation/num_examples': 83274637, 'test/loss': 0.12609078934004933, 'test/num_examples': 95000000, 'score': 6048.927755355835, 'total_duration': 40293.11482334137, 'accumulated_submission_time': 6048.927755355835, 'accumulated_eval_time': 34242.82682609558, 'accumulated_logging_time': 1.0097787380218506}
I0307 00:20:13.388648 140252240910080 logging_writer.py:48] [6318] accumulated_eval_time=34242.8, accumulated_logging_time=1.00978, accumulated_submission_time=6048.93, global_step=6318, preemption_count=0, score=6048.93, test/loss=0.126091, test/num_examples=95000000, total_duration=40293.1, train/loss=0.123122, validation/loss=0.123916, validation/num_examples=83274637
I0307 00:21:21.537624 140252249302784 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.006326995324343443, loss=0.12362125515937805
I0307 00:22:13.709309 140404200342720 spec.py:321] Evaluating on the training split.
I0307 00:23:11.356225 140404200342720 spec.py:333] Evaluating on the validation split.
I0307 00:26:20.202201 140404200342720 spec.py:349] Evaluating on the test split.
I0307 00:32:21.797445 140404200342720 submission_runner.py:469] Time since start: 41021.53s, 	Step: 6441, 	{'train/loss': 0.12237790389771357, 'validation/loss': 0.12397073234164924, 'validation/num_examples': 83274637, 'test/loss': 0.12617568190789474, 'test/num_examples': 95000000, 'score': 6169.235493183136, 'total_duration': 41021.533591747284, 'accumulated_submission_time': 6169.235493183136, 'accumulated_eval_time': 34850.91489958763, 'accumulated_logging_time': 1.0262317657470703}
I0307 00:32:21.807112 140252240910080 logging_writer.py:48] [6441] accumulated_eval_time=34850.9, accumulated_logging_time=1.02623, accumulated_submission_time=6169.24, global_step=6441, preemption_count=0, score=6169.24, test/loss=0.126176, test/num_examples=95000000, total_duration=41021.5, train/loss=0.122378, validation/loss=0.123971, validation/num_examples=83274637
I0307 00:33:06.835352 140252249302784 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.006365789566189051, loss=0.1196734607219696
I0307 00:34:21.938625 140404200342720 spec.py:321] Evaluating on the training split.
I0307 00:35:16.950334 140404200342720 spec.py:333] Evaluating on the validation split.
I0307 00:38:27.321464 140404200342720 spec.py:349] Evaluating on the test split.
I0307 00:44:32.437952 140404200342720 submission_runner.py:469] Time since start: 41752.17s, 	Step: 6558, 	{'train/loss': 0.12242173281668117, 'validation/loss': 0.12399387147382018, 'validation/num_examples': 83274637, 'test/loss': 0.12627139088199013, 'test/num_examples': 95000000, 'score': 6289.35422539711, 'total_duration': 41752.17410182953, 'accumulated_submission_time': 6289.35422539711, 'accumulated_eval_time': 35461.414174079895, 'accumulated_logging_time': 1.0421249866485596}
I0307 00:44:32.449199 140252240910080 logging_writer.py:48] [6558] accumulated_eval_time=35461.4, accumulated_logging_time=1.04212, accumulated_submission_time=6289.35, global_step=6558, preemption_count=0, score=6289.35, test/loss=0.126271, test/num_examples=95000000, total_duration=41752.2, train/loss=0.122422, validation/loss=0.123994, validation/num_examples=83274637
I0307 00:44:53.571458 140252249302784 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.007369139697402716, loss=0.12296091020107269
I0307 00:46:32.472552 140404200342720 spec.py:321] Evaluating on the training split.
I0307 00:47:31.248264 140404200342720 spec.py:333] Evaluating on the validation split.
I0307 00:50:39.400903 140404200342720 spec.py:349] Evaluating on the test split.
I0307 00:56:33.227911 140404200342720 submission_runner.py:469] Time since start: 42472.96s, 	Step: 6688, 	{'train/loss': 0.12221682260293255, 'validation/loss': 0.12400939112783786, 'validation/num_examples': 83274637, 'test/loss': 0.12629944808799343, 'test/num_examples': 95000000, 'score': 6409.363773345947, 'total_duration': 42472.96404719353, 'accumulated_submission_time': 6409.363773345947, 'accumulated_eval_time': 36062.16946744919, 'accumulated_logging_time': 1.0602271556854248}
I0307 00:56:33.289293 140252240910080 logging_writer.py:48] [6688] accumulated_eval_time=36062.2, accumulated_logging_time=1.06023, accumulated_submission_time=6409.36, global_step=6688, preemption_count=0, score=6409.36, test/loss=0.126299, test/num_examples=95000000, total_duration=42473, train/loss=0.122217, validation/loss=0.124009, validation/num_examples=83274637
I0307 00:56:34.706670 140252249302784 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.009935934096574783, loss=0.12463589012622833
I0307 00:58:25.368746 140252240910080 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.008620674721896648, loss=0.11879497021436691
I0307 00:58:34.174618 140404200342720 spec.py:321] Evaluating on the training split.
I0307 00:59:29.902590 140404200342720 spec.py:333] Evaluating on the validation split.
I0307 01:02:39.609372 140404200342720 spec.py:349] Evaluating on the test split.
I0307 01:08:45.313748 140404200342720 submission_runner.py:469] Time since start: 43205.05s, 	Step: 6809, 	{'train/loss': 0.12248969560711638, 'validation/loss': 0.12410983696731133, 'validation/num_examples': 83274637, 'test/loss': 0.12642227137129936, 'test/num_examples': 95000000, 'score': 6530.226616859436, 'total_duration': 43205.04988527298, 'accumulated_submission_time': 6530.226616859436, 'accumulated_eval_time': 36673.3085269928, 'accumulated_logging_time': 1.136946678161621}
I0307 01:08:45.324101 140252249302784 logging_writer.py:48] [6809] accumulated_eval_time=36673.3, accumulated_logging_time=1.13695, accumulated_submission_time=6530.23, global_step=6809, preemption_count=0, score=6530.23, test/loss=0.126422, test/num_examples=95000000, total_duration=43205, train/loss=0.12249, validation/loss=0.12411, validation/num_examples=83274637
I0307 01:10:07.749658 140252240910080 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.006389016751199961, loss=0.13626667857170105
I0307 01:10:46.279849 140404200342720 spec.py:321] Evaluating on the training split.
I0307 01:11:42.862291 140404200342720 spec.py:333] Evaluating on the validation split.
I0307 01:14:49.162979 140404200342720 spec.py:349] Evaluating on the test split.
I0307 01:20:59.536075 140404200342720 submission_runner.py:469] Time since start: 43939.27s, 	Step: 6931, 	{'train/loss': 0.12301362640921425, 'validation/loss': 0.12409963940569135, 'validation/num_examples': 83274637, 'test/loss': 0.1264707748149671, 'test/num_examples': 95000000, 'score': 6651.166893482208, 'total_duration': 43939.2722094059, 'accumulated_submission_time': 6651.166893482208, 'accumulated_eval_time': 37286.56468296051, 'accumulated_logging_time': 1.1540663242340088}
I0307 01:20:59.546266 140252249302784 logging_writer.py:48] [6931] accumulated_eval_time=37286.6, accumulated_logging_time=1.15407, accumulated_submission_time=6651.17, global_step=6931, preemption_count=0, score=6651.17, test/loss=0.126471, test/num_examples=95000000, total_duration=43939.3, train/loss=0.123014, validation/loss=0.1241, validation/num_examples=83274637
I0307 01:21:52.361958 140252240910080 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.008452066220343113, loss=0.12693873047828674
I0307 01:23:00.334059 140404200342720 spec.py:321] Evaluating on the training split.
I0307 01:23:55.084818 140404200342720 spec.py:333] Evaluating on the validation split.
I0307 01:27:02.819346 140404200342720 spec.py:349] Evaluating on the test split.
I0307 01:33:10.389680 140404200342720 submission_runner.py:469] Time since start: 44670.13s, 	Step: 7059, 	{'train/loss': 0.12388650652419471, 'validation/loss': 0.12406451953794241, 'validation/num_examples': 83274637, 'test/loss': 0.12642387001439145, 'test/num_examples': 95000000, 'score': 6771.9419021606445, 'total_duration': 44670.12581658363, 'accumulated_submission_time': 6771.9419021606445, 'accumulated_eval_time': 37896.6202352047, 'accumulated_logging_time': 1.170367956161499}
I0307 01:33:10.399940 140252249302784 logging_writer.py:48] [7059] accumulated_eval_time=37896.6, accumulated_logging_time=1.17037, accumulated_submission_time=6771.94, global_step=7059, preemption_count=0, score=6771.94, test/loss=0.126424, test/num_examples=95000000, total_duration=44670.1, train/loss=0.123887, validation/loss=0.124065, validation/num_examples=83274637
I0307 01:33:31.500604 140252240910080 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.007921013049781322, loss=0.11829668283462524
I0307 01:35:11.586352 140404200342720 spec.py:321] Evaluating on the training split.
I0307 01:36:08.765827 140404200342720 spec.py:333] Evaluating on the validation split.
I0307 01:39:17.056217 140404200342720 spec.py:349] Evaluating on the test split.
I0307 01:45:09.742616 140404200342720 submission_runner.py:469] Time since start: 45389.48s, 	Step: 7181, 	{'train/loss': 0.12124679995548425, 'validation/loss': 0.12393589103143209, 'validation/num_examples': 83274637, 'test/loss': 0.12620605325863488, 'test/num_examples': 95000000, 'score': 6893.114670991898, 'total_duration': 45389.47875785828, 'accumulated_submission_time': 6893.114670991898, 'accumulated_eval_time': 38494.776440143585, 'accumulated_logging_time': 1.1873807907104492}
I0307 01:45:09.753652 140252249302784 logging_writer.py:48] [7181] accumulated_eval_time=38494.8, accumulated_logging_time=1.18738, accumulated_submission_time=6893.11, global_step=7181, preemption_count=0, score=6893.11, test/loss=0.126206, test/num_examples=95000000, total_duration=45389.5, train/loss=0.121247, validation/loss=0.123936, validation/num_examples=83274637
I0307 01:45:11.859568 140252240910080 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.005821534898132086, loss=0.11871347576379776
I0307 01:47:02.018664 140252249302784 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.013518878258764744, loss=0.13454030454158783
I0307 01:47:11.281643 140404200342720 spec.py:321] Evaluating on the training split.
I0307 01:48:13.175379 140404200342720 spec.py:333] Evaluating on the validation split.
I0307 01:51:21.934619 140404200342720 spec.py:349] Evaluating on the test split.
I0307 01:57:23.514395 140404200342720 submission_runner.py:469] Time since start: 46123.25s, 	Step: 7308, 	{'train/loss': 0.12531035807007138, 'validation/loss': 0.12397034187912462, 'validation/num_examples': 83274637, 'test/loss': 0.1262839890419408, 'test/num_examples': 95000000, 'score': 7014.628491640091, 'total_duration': 46123.25054335594, 'accumulated_submission_time': 7014.628491640091, 'accumulated_eval_time': 39107.00913167, 'accumulated_logging_time': 1.205528974533081}
I0307 01:57:23.525900 140252240910080 logging_writer.py:48] [7308] accumulated_eval_time=39107, accumulated_logging_time=1.20553, accumulated_submission_time=7014.63, global_step=7308, preemption_count=0, score=7014.63, test/loss=0.126284, test/num_examples=95000000, total_duration=46123.3, train/loss=0.12531, validation/loss=0.12397, validation/num_examples=83274637
I0307 01:58:46.901699 140252249302784 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.00935988500714302, loss=0.11606574058532715
I0307 01:59:24.526605 140404200342720 spec.py:321] Evaluating on the training split.
I0307 02:00:20.720626 140404200342720 spec.py:333] Evaluating on the validation split.
I0307 02:03:30.254697 140404200342720 spec.py:349] Evaluating on the test split.
I0307 02:09:36.540241 140404200342720 submission_runner.py:469] Time since start: 46856.28s, 	Step: 7433, 	{'train/loss': 0.12331362865256064, 'validation/loss': 0.12397352013923557, 'validation/num_examples': 83274637, 'test/loss': 0.126281008203125, 'test/num_examples': 95000000, 'score': 7135.615629911423, 'total_duration': 46856.276341199875, 'accumulated_submission_time': 7135.615629911423, 'accumulated_eval_time': 39719.02266025543, 'accumulated_logging_time': 1.2237024307250977}
I0307 02:09:36.564915 140252240910080 logging_writer.py:48] [7433] accumulated_eval_time=39719, accumulated_logging_time=1.2237, accumulated_submission_time=7135.62, global_step=7433, preemption_count=0, score=7135.62, test/loss=0.126281, test/num_examples=95000000, total_duration=46856.3, train/loss=0.123314, validation/loss=0.123974, validation/num_examples=83274637
I0307 02:10:26.952817 140252249302784 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.005909352097660303, loss=0.12999515235424042
I0307 02:11:36.917025 140404200342720 spec.py:321] Evaluating on the training split.
I0307 02:12:35.374802 140404200342720 spec.py:333] Evaluating on the validation split.
I0307 02:15:44.370349 140404200342720 spec.py:349] Evaluating on the test split.
I0307 02:21:49.397107 140404200342720 submission_runner.py:469] Time since start: 47589.13s, 	Step: 7563, 	{'train/loss': 0.12293878967329017, 'validation/loss': 0.12380228310161945, 'validation/num_examples': 83274637, 'test/loss': 0.1261419839740954, 'test/num_examples': 95000000, 'score': 7255.953263998032, 'total_duration': 47589.13324427605, 'accumulated_submission_time': 7255.953263998032, 'accumulated_eval_time': 40331.50267910957, 'accumulated_logging_time': 1.255857229232788}
I0307 02:21:49.407480 140252240910080 logging_writer.py:48] [7563] accumulated_eval_time=40331.5, accumulated_logging_time=1.25586, accumulated_submission_time=7255.95, global_step=7563, preemption_count=0, score=7255.95, test/loss=0.126142, test/num_examples=95000000, total_duration=47589.1, train/loss=0.122939, validation/loss=0.123802, validation/num_examples=83274637
I0307 02:22:04.475420 140252249302784 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.008174179121851921, loss=0.12934769690036774
I0307 02:23:49.575967 140404200342720 spec.py:321] Evaluating on the training split.
I0307 02:24:45.875826 140404200342720 spec.py:333] Evaluating on the validation split.
I0307 02:27:55.913982 140404200342720 spec.py:349] Evaluating on the test split.
I0307 02:33:54.710261 140404200342720 submission_runner.py:469] Time since start: 48314.45s, 	Step: 7691, 	{'train/loss': 0.12167247027486751, 'validation/loss': 0.12381949674568418, 'validation/num_examples': 83274637, 'test/loss': 0.12616694294819078, 'test/num_examples': 95000000, 'score': 7376.079919576645, 'total_duration': 48314.44637775421, 'accumulated_submission_time': 7376.079919576645, 'accumulated_eval_time': 40936.63688874245, 'accumulated_logging_time': 1.3009600639343262}
I0307 02:33:54.720521 140252240910080 logging_writer.py:48] [7691] accumulated_eval_time=40936.6, accumulated_logging_time=1.30096, accumulated_submission_time=7376.08, global_step=7691, preemption_count=0, score=7376.08, test/loss=0.126167, test/num_examples=95000000, total_duration=48314.4, train/loss=0.121672, validation/loss=0.123819, validation/num_examples=83274637
I0307 02:33:55.802013 140252249302784 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.00701485387980938, loss=0.12027149647474289
I0307 02:35:32.047342 140252240910080 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.007489171344786882, loss=0.12670862674713135
I0307 02:35:54.939281 140404200342720 spec.py:321] Evaluating on the training split.
I0307 02:36:53.496620 140404200342720 spec.py:333] Evaluating on the validation split.
I0307 02:40:03.390850 140404200342720 spec.py:349] Evaluating on the test split.
I0307 02:46:20.931548 140404200342720 submission_runner.py:469] Time since start: 49060.67s, 	Step: 7820, 	{'train/loss': 0.1225201178154668, 'validation/loss': 0.12377129714561605, 'validation/num_examples': 83274637, 'test/loss': 0.12610260268297696, 'test/num_examples': 95000000, 'score': 7496.2853837013245, 'total_duration': 49060.66769242287, 'accumulated_submission_time': 7496.2853837013245, 'accumulated_eval_time': 41562.62910246849, 'accumulated_logging_time': 1.3174386024475098}
I0307 02:46:20.942946 140252249302784 logging_writer.py:48] [7820] accumulated_eval_time=41562.6, accumulated_logging_time=1.31744, accumulated_submission_time=7496.29, global_step=7820, preemption_count=0, score=7496.29, test/loss=0.126103, test/num_examples=95000000, total_duration=49060.7, train/loss=0.12252, validation/loss=0.123771, validation/num_examples=83274637
I0307 02:47:25.045969 140252240910080 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.011216671206057072, loss=0.1217586025595665
I0307 02:48:21.587078 140404200342720 spec.py:321] Evaluating on the training split.
I0307 02:49:20.144237 140404200342720 spec.py:333] Evaluating on the validation split.
I0307 02:52:30.925408 140404200342720 spec.py:349] Evaluating on the test split.
I0307 02:58:30.849456 140404200342720 submission_runner.py:469] Time since start: 49790.59s, 	Step: 7949, 	{'train/loss': 0.12438195752881982, 'validation/loss': 0.12382280584404559, 'validation/num_examples': 83274637, 'test/loss': 0.12615920402960526, 'test/num_examples': 95000000, 'score': 7616.91669178009, 'total_duration': 49790.58560466766, 'accumulated_submission_time': 7616.91669178009, 'accumulated_eval_time': 42171.891421079636, 'accumulated_logging_time': 1.3354179859161377}
I0307 02:58:30.860121 140252249302784 logging_writer.py:48] [7949] accumulated_eval_time=42171.9, accumulated_logging_time=1.33542, accumulated_submission_time=7616.92, global_step=7949, preemption_count=0, score=7616.92, test/loss=0.126159, test/num_examples=95000000, total_duration=49790.6, train/loss=0.124382, validation/loss=0.123823, validation/num_examples=83274637
I0307 02:59:02.024677 140252240910080 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.00949303712695837, loss=0.1280411183834076
I0307 03:00:31.420541 140252249302784 logging_writer.py:48] [8080] global_step=8080, preemption_count=0, score=7737.46
I0307 03:00:33.924841 140404200342720 submission_runner.py:646] Tuning trial 2/5
I0307 03:00:33.944346 140404200342720 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.2, learning_rate=0.0008445074561975979, one_minus_beta1=0.11042418465, beta2=0.9978504782314613, weight_decay=0.08135402759553023, warmup_factor=0.05)
I0307 03:00:33.945398 140404200342720 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/loss': 0.2209187685131277, 'validation/loss': 0.22167475255138308, 'validation/num_examples': 83274637, 'test/loss': 0.22238874467516448, 'test/num_examples': 95000000, 'score': 17.344715118408203, 'total_duration': 1185.931919336319, 'accumulated_submission_time': 17.344715118408203, 'accumulated_eval_time': 1168.5870623588562, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (128, {'train/loss': 0.13093109610461215, 'validation/loss': 0.13073758040856126, 'validation/num_examples': 83274637, 'test/loss': 0.13399970381373355, 'test/num_examples': 95000000, 'score': 138.2899205684662, 'total_duration': 2365.7192277908325, 'accumulated_submission_time': 138.2899205684662, 'accumulated_eval_time': 2227.3466699123383, 'accumulated_logging_time': 0.07489347457885742, 'global_step': 128, 'preemption_count': 0}), (255, {'train/loss': 0.12782747463657046, 'validation/loss': 0.12869227925717347, 'validation/num_examples': 83274637, 'test/loss': 0.13144199499383225, 'test/num_examples': 95000000, 'score': 258.91094613075256, 'total_duration': 3513.276751756668, 'accumulated_submission_time': 258.91094613075256, 'accumulated_eval_time': 3254.261204957962, 'accumulated_logging_time': 0.08986425399780273, 'global_step': 255, 'preemption_count': 0}), (375, {'train/loss': 0.1279561566716095, 'validation/loss': 0.12830987090751106, 'validation/num_examples': 83274637, 'test/loss': 0.13047055153166118, 'test/num_examples': 95000000, 'score': 379.7065842151642, 'total_duration': 4666.490714073181, 'accumulated_submission_time': 379.7065842151642, 'accumulated_eval_time': 4286.658121585846, 'accumulated_logging_time': 0.10478901863098145, 'global_step': 375, 'preemption_count': 0}), (498, {'train/loss': 0.12974432848815648, 'validation/loss': 0.12695870359728723, 'validation/num_examples': 83274637, 'test/loss': 0.12931911977796054, 'test/num_examples': 95000000, 'score': 499.86661553382874, 'total_duration': 5819.405024051666, 'accumulated_submission_time': 499.86661553382874, 'accumulated_eval_time': 5319.353770971298, 'accumulated_logging_time': 0.15645360946655273, 'global_step': 498, 'preemption_count': 0}), (625, {'train/loss': 0.12674199482836063, 'validation/loss': 0.1268780185260388, 'validation/num_examples': 83274637, 'test/loss': 0.12922596109169407, 'test/num_examples': 95000000, 'score': 620.3479719161987, 'total_duration': 6940.983546495438, 'accumulated_submission_time': 620.3479719161987, 'accumulated_eval_time': 6320.428179264069, 'accumulated_logging_time': 0.17185664176940918, 'global_step': 625, 'preemption_count': 0}), (749, {'train/loss': 0.12405250099657467, 'validation/loss': 0.12651037993501327, 'validation/num_examples': 83274637, 'test/loss': 0.12883419776932567, 'test/num_examples': 95000000, 'score': 740.6417620182037, 'total_duration': 8017.253054618835, 'accumulated_submission_time': 740.6417620182037, 'accumulated_eval_time': 7276.3820123672485, 'accumulated_logging_time': 0.1863255500793457, 'global_step': 749, 'preemption_count': 0}), (874, {'train/loss': 0.12402263984271565, 'validation/loss': 0.12617973242622219, 'validation/num_examples': 83274637, 'test/loss': 0.1285111533203125, 'test/num_examples': 95000000, 'score': 860.8349533081055, 'total_duration': 9027.016941785812, 'accumulated_submission_time': 860.8349533081055, 'accumulated_eval_time': 8165.930740594864, 'accumulated_logging_time': 0.20085692405700684, 'global_step': 874, 'preemption_count': 0}), (1006, {'train/loss': 0.12438687286193266, 'validation/loss': 0.126139806360699, 'validation/num_examples': 83274637, 'test/loss': 0.128481746875, 'test/num_examples': 95000000, 'score': 981.6895778179169, 'total_duration': 9898.690483808517, 'accumulated_submission_time': 981.6895778179169, 'accumulated_eval_time': 8916.728100538254, 'accumulated_logging_time': 0.21520709991455078, 'global_step': 1006, 'preemption_count': 0}), (1129, {'train/loss': 0.12596395004938984, 'validation/loss': 0.125858556928943, 'validation/num_examples': 83274637, 'test/loss': 0.1282085619140625, 'test/num_examples': 95000000, 'score': 1101.8951392173767, 'total_duration': 10628.276590824127, 'accumulated_submission_time': 1101.8951392173767, 'accumulated_eval_time': 9526.086087942123, 'accumulated_logging_time': 0.23058176040649414, 'global_step': 1129, 'preemption_count': 0}), (1255, {'train/loss': 0.12510174620638853, 'validation/loss': 0.12584953439027, 'validation/num_examples': 83274637, 'test/loss': 0.1282173911698191, 'test/num_examples': 95000000, 'score': 1223.1237287521362, 'total_duration': 11351.000273942947, 'accumulated_submission_time': 1223.1237287521362, 'accumulated_eval_time': 10127.559713840485, 'accumulated_logging_time': 0.24488615989685059, 'global_step': 1255, 'preemption_count': 0}), (1374, {'train/loss': 0.12470472183476829, 'validation/loss': 0.1259988057765603, 'validation/num_examples': 83274637, 'test/loss': 0.1282124005550987, 'test/num_examples': 95000000, 'score': 1344.374713420868, 'total_duration': 12082.53295326233, 'accumulated_submission_time': 1344.374713420868, 'accumulated_eval_time': 10737.819620132446, 'accumulated_logging_time': 0.2598905563354492, 'global_step': 1374, 'preemption_count': 0}), (1502, {'train/loss': 0.125160771873106, 'validation/loss': 0.1257132817089389, 'validation/num_examples': 83274637, 'test/loss': 0.12810703275082236, 'test/num_examples': 95000000, 'score': 1465.2403779029846, 'total_duration': 12801.91608953476, 'accumulated_submission_time': 1465.2403779029846, 'accumulated_eval_time': 11336.314753293991, 'accumulated_logging_time': 0.27492213249206543, 'global_step': 1502, 'preemption_count': 0}), (1632, {'train/loss': 0.12469422821916125, 'validation/loss': 0.12562484800997617, 'validation/num_examples': 83274637, 'test/loss': 0.12792691001233553, 'test/num_examples': 95000000, 'score': 1586.222808122635, 'total_duration': 13525.018112897873, 'accumulated_submission_time': 1586.222808122635, 'accumulated_eval_time': 11938.41075849533, 'accumulated_logging_time': 0.2911524772644043, 'global_step': 1632, 'preemption_count': 0}), (1763, {'train/loss': 0.12555807759786178, 'validation/loss': 0.12547037126194557, 'validation/num_examples': 83274637, 'test/loss': 0.1278964861533717, 'test/num_examples': 95000000, 'score': 1706.7953004837036, 'total_duration': 14239.45443534851, 'accumulated_submission_time': 1706.7953004837036, 'accumulated_eval_time': 12532.252103805542, 'accumulated_logging_time': 0.30565738677978516, 'global_step': 1763, 'preemption_count': 0}), (1894, {'train/loss': 0.1250567229804378, 'validation/loss': 0.12519719548371275, 'validation/num_examples': 83274637, 'test/loss': 0.12745882200863487, 'test/num_examples': 95000000, 'score': 1826.8758404254913, 'total_duration': 14950.716592788696, 'accumulated_submission_time': 1826.8758404254913, 'accumulated_eval_time': 13123.410247325897, 'accumulated_logging_time': 0.3221569061279297, 'global_step': 1894, 'preemption_count': 0}), (2022, {'train/loss': 0.12519821647624924, 'validation/loss': 0.1252331535453642, 'validation/num_examples': 83274637, 'test/loss': 0.12765986363075657, 'test/num_examples': 95000000, 'score': 1947.3675935268402, 'total_duration': 15663.11318731308, 'accumulated_submission_time': 1947.3675935268402, 'accumulated_eval_time': 13715.292154550552, 'accumulated_logging_time': 0.33677101135253906, 'global_step': 2022, 'preemption_count': 0}), (2150, {'train/loss': 0.12429834533271925, 'validation/loss': 0.12530517327680044, 'validation/num_examples': 83274637, 'test/loss': 0.12761825399876645, 'test/num_examples': 95000000, 'score': 2067.435028076172, 'total_duration': 16390.033614873886, 'accumulated_submission_time': 2067.435028076172, 'accumulated_eval_time': 14322.123769044876, 'accumulated_logging_time': 0.35189366340637207, 'global_step': 2150, 'preemption_count': 0}), (2277, {'train/loss': 0.12439608504796552, 'validation/loss': 0.1252450385826772, 'validation/num_examples': 83274637, 'test/loss': 0.12761947515419408, 'test/num_examples': 95000000, 'score': 2187.4741320610046, 'total_duration': 17109.725430488586, 'accumulated_submission_time': 2187.4741320610046, 'accumulated_eval_time': 14921.754938364029, 'accumulated_logging_time': 0.3667290210723877, 'global_step': 2277, 'preemption_count': 0}), (2402, {'train/loss': 0.12399703336867897, 'validation/loss': 0.12494347646856149, 'validation/num_examples': 83274637, 'test/loss': 0.1273400443153783, 'test/num_examples': 95000000, 'score': 2307.669291496277, 'total_duration': 17823.93878364563, 'accumulated_submission_time': 2307.669291496277, 'accumulated_eval_time': 15515.750794410706, 'accumulated_logging_time': 0.3827962875366211, 'global_step': 2402, 'preemption_count': 0}), (2529, {'train/loss': 0.12288207895819496, 'validation/loss': 0.12501768723936316, 'validation/num_examples': 83274637, 'test/loss': 0.12742921579975328, 'test/num_examples': 95000000, 'score': 2428.193514585495, 'total_duration': 18572.59878063202, 'accumulated_submission_time': 2428.193514585495, 'accumulated_eval_time': 16143.864559173584, 'accumulated_logging_time': 0.39778780937194824, 'global_step': 2529, 'preemption_count': 0}), (2656, {'train/loss': 0.12505408825130207, 'validation/loss': 0.12503498558762105, 'validation/num_examples': 83274637, 'test/loss': 0.12741361648848684, 'test/num_examples': 95000000, 'score': 2549.449943304062, 'total_duration': 19288.086532354355, 'accumulated_submission_time': 2549.449943304062, 'accumulated_eval_time': 16738.071964025497, 'accumulated_logging_time': 0.4148406982421875, 'global_step': 2656, 'preemption_count': 0}), (2782, {'train/loss': 0.12211666103897605, 'validation/loss': 0.12514805176552435, 'validation/num_examples': 83274637, 'test/loss': 0.12761840310444078, 'test/num_examples': 95000000, 'score': 2670.957683801651, 'total_duration': 20020.56770658493, 'accumulated_submission_time': 2670.957683801651, 'accumulated_eval_time': 17348.9932448864, 'accumulated_logging_time': 0.4603312015533447, 'global_step': 2782, 'preemption_count': 0}), (2908, {'train/loss': 0.12297361437817039, 'validation/loss': 0.12494412196423586, 'validation/num_examples': 83274637, 'test/loss': 0.12724154489103617, 'test/num_examples': 95000000, 'score': 2791.395147562027, 'total_duration': 20747.282421827316, 'accumulated_submission_time': 2791.395147562027, 'accumulated_eval_time': 17955.24665594101, 'accumulated_logging_time': 0.4762110710144043, 'global_step': 2908, 'preemption_count': 0}), (3034, {'train/loss': 0.12301442732319892, 'validation/loss': 0.12469653533682808, 'validation/num_examples': 83274637, 'test/loss': 0.1268287025596217, 'test/num_examples': 95000000, 'score': 2912.707358121872, 'total_duration': 21459.81579041481, 'accumulated_submission_time': 2912.707358121872, 'accumulated_eval_time': 18546.445335626602, 'accumulated_logging_time': 0.4913210868835449, 'global_step': 3034, 'preemption_count': 0}), (3159, {'train/loss': 0.12343464671112832, 'validation/loss': 0.12470855579178891, 'validation/num_examples': 83274637, 'test/loss': 0.12705982408511513, 'test/num_examples': 95000000, 'score': 3033.3538892269135, 'total_duration': 22178.21322798729, 'accumulated_submission_time': 3033.3538892269135, 'accumulated_eval_time': 19144.172388076782, 'accumulated_logging_time': 0.5078270435333252, 'global_step': 3159, 'preemption_count': 0}), (3285, {'train/loss': 0.12627397763466686, 'validation/loss': 0.12474967585456122, 'validation/num_examples': 83274637, 'test/loss': 0.1271163505653783, 'test/num_examples': 95000000, 'score': 3154.3454473018646, 'total_duration': 22897.127810001373, 'accumulated_submission_time': 3154.3454473018646, 'accumulated_eval_time': 19742.07364296913, 'accumulated_logging_time': 0.5230464935302734, 'global_step': 3285, 'preemption_count': 0}), (3411, {'train/loss': 0.1227719017521203, 'validation/loss': 0.12496288930812714, 'validation/num_examples': 83274637, 'test/loss': 0.12725739363692434, 'test/num_examples': 95000000, 'score': 3274.5585658550262, 'total_duration': 23622.747117996216, 'accumulated_submission_time': 3274.5585658550262, 'accumulated_eval_time': 20347.457743883133, 'accumulated_logging_time': 0.5382003784179688, 'global_step': 3411, 'preemption_count': 0}), (3534, {'train/loss': 0.12335698639259399, 'validation/loss': 0.12463293572756169, 'validation/num_examples': 83274637, 'test/loss': 0.1270975515727796, 'test/num_examples': 95000000, 'score': 3395.350783586502, 'total_duration': 24349.918817281723, 'accumulated_submission_time': 3395.350783586502, 'accumulated_eval_time': 20953.813903570175, 'accumulated_logging_time': 0.5552661418914795, 'global_step': 3534, 'preemption_count': 0}), (3657, {'train/loss': 0.12315784600920647, 'validation/loss': 0.12463135991645782, 'validation/num_examples': 83274637, 'test/loss': 0.12699423969983553, 'test/num_examples': 95000000, 'score': 3515.399905204773, 'total_duration': 25077.888488054276, 'accumulated_submission_time': 3515.399905204773, 'accumulated_eval_time': 21561.689523220062, 'accumulated_logging_time': 0.5936183929443359, 'global_step': 3657, 'preemption_count': 0}), (3784, {'train/loss': 0.12292983580919557, 'validation/loss': 0.12471398084147083, 'validation/num_examples': 83274637, 'test/loss': 0.1270961740439967, 'test/num_examples': 95000000, 'score': 3635.9060020446777, 'total_duration': 25799.037702083588, 'accumulated_submission_time': 3635.9060020446777, 'accumulated_eval_time': 22162.309873104095, 'accumulated_logging_time': 0.609560489654541, 'global_step': 3784, 'preemption_count': 0}), (3909, {'train/loss': 0.12349289894666311, 'validation/loss': 0.12470760371689237, 'validation/num_examples': 83274637, 'test/loss': 0.1270296873355263, 'test/num_examples': 95000000, 'score': 3756.2560908794403, 'total_duration': 26517.292717456818, 'accumulated_submission_time': 3756.2560908794403, 'accumulated_eval_time': 22760.191435098648, 'accumulated_logging_time': 0.6255919933319092, 'global_step': 3909, 'preemption_count': 0}), (4041, {'train/loss': 0.1267893070811933, 'validation/loss': 0.12468139107612719, 'validation/num_examples': 83274637, 'test/loss': 0.12706084602179277, 'test/num_examples': 95000000, 'score': 3877.725663661957, 'total_duration': 27238.289368629456, 'accumulated_submission_time': 3877.725663661957, 'accumulated_eval_time': 23359.69605588913, 'accumulated_logging_time': 0.6407222747802734, 'global_step': 4041, 'preemption_count': 0}), (4169, {'train/loss': 0.1228753166191233, 'validation/loss': 0.12450269412978272, 'validation/num_examples': 83274637, 'test/loss': 0.1269277083984375, 'test/num_examples': 95000000, 'score': 3998.3350121974945, 'total_duration': 27965.065019845963, 'accumulated_submission_time': 3998.3350121974945, 'accumulated_eval_time': 23965.839072227478, 'accumulated_logging_time': 0.6575424671173096, 'global_step': 4169, 'preemption_count': 0}), (4296, {'train/loss': 0.12310909620433483, 'validation/loss': 0.1247721765389908, 'validation/num_examples': 83274637, 'test/loss': 0.12717749186883223, 'test/num_examples': 95000000, 'score': 4118.564800262451, 'total_duration': 28698.833248376846, 'accumulated_submission_time': 4118.564800262451, 'accumulated_eval_time': 24579.355286836624, 'accumulated_logging_time': 0.6733770370483398, 'global_step': 4296, 'preemption_count': 0}), (4423, {'train/loss': 0.1249580193404694, 'validation/loss': 0.12460516651971604, 'validation/num_examples': 83274637, 'test/loss': 0.1269663798725329, 'test/num_examples': 95000000, 'score': 4239.448970794678, 'total_duration': 29416.748157978058, 'accumulated_submission_time': 4239.448970794678, 'accumulated_eval_time': 25176.364231348038, 'accumulated_logging_time': 0.6889345645904541, 'global_step': 4423, 'preemption_count': 0}), (4551, {'train/loss': 0.12223237256209056, 'validation/loss': 0.12450075345035352, 'validation/num_examples': 83274637, 'test/loss': 0.12698479748149671, 'test/num_examples': 95000000, 'score': 4359.743313074112, 'total_duration': 30126.060968399048, 'accumulated_submission_time': 4359.743313074112, 'accumulated_eval_time': 25765.358011484146, 'accumulated_logging_time': 0.7068400382995605, 'global_step': 4551, 'preemption_count': 0}), (4676, {'train/loss': 0.12266166057179934, 'validation/loss': 0.12440604673920704, 'validation/num_examples': 83274637, 'test/loss': 0.1268265031352796, 'test/num_examples': 95000000, 'score': 4479.951153039932, 'total_duration': 30856.03257751465, 'accumulated_submission_time': 4479.951153039932, 'accumulated_eval_time': 26375.09892129898, 'accumulated_logging_time': 0.722822904586792, 'global_step': 4676, 'preemption_count': 0}), (4797, {'train/loss': 0.12298685980011832, 'validation/loss': 0.12448154241503928, 'validation/num_examples': 83274637, 'test/loss': 0.12699948564967106, 'test/num_examples': 95000000, 'score': 4600.926641702652, 'total_duration': 31581.889095067978, 'accumulated_submission_time': 4600.926641702652, 'accumulated_eval_time': 26979.95418357849, 'accumulated_logging_time': 0.739922046661377, 'global_step': 4797, 'preemption_count': 0}), (4918, {'train/loss': 0.12089453847293959, 'validation/loss': 0.12440475500319316, 'validation/num_examples': 83274637, 'test/loss': 0.12676948932976972, 'test/num_examples': 95000000, 'score': 4721.280546426773, 'total_duration': 32325.82950425148, 'accumulated_submission_time': 4721.280546426773, 'accumulated_eval_time': 27603.51697063446, 'accumulated_logging_time': 0.757615327835083, 'global_step': 4918, 'preemption_count': 0}), (5048, {'train/loss': 0.12291765526967978, 'validation/loss': 0.12439396162151313, 'validation/num_examples': 83274637, 'test/loss': 0.12684296127672698, 'test/num_examples': 95000000, 'score': 4842.586594581604, 'total_duration': 33047.7487847805, 'accumulated_submission_time': 4842.586594581604, 'accumulated_eval_time': 28204.106652975082, 'accumulated_logging_time': 0.7742297649383545, 'global_step': 5048, 'preemption_count': 0}), (5171, {'train/loss': 0.12309326662582422, 'validation/loss': 0.12466336567670395, 'validation/num_examples': 83274637, 'test/loss': 0.12729101167763157, 'test/num_examples': 95000000, 'score': 4963.108927965164, 'total_duration': 33767.27935433388, 'accumulated_submission_time': 4963.108927965164, 'accumulated_eval_time': 28803.08793282509, 'accumulated_logging_time': 0.7946240901947021, 'global_step': 5171, 'preemption_count': 0}), (5301, {'train/loss': 0.12297805308499052, 'validation/loss': 0.12428412710852428, 'validation/num_examples': 83274637, 'test/loss': 0.1266606758120888, 'test/num_examples': 95000000, 'score': 5083.369934558868, 'total_duration': 34503.914956092834, 'accumulated_submission_time': 5083.369934558868, 'accumulated_eval_time': 29419.43890118599, 'accumulated_logging_time': 0.8110606670379639, 'global_step': 5301, 'preemption_count': 0}), (5428, {'train/loss': 0.12283640415788447, 'validation/loss': 0.12436963690035921, 'validation/num_examples': 83274637, 'test/loss': 0.12680228038651314, 'test/num_examples': 95000000, 'score': 5204.270402908325, 'total_duration': 35227.07170009613, 'accumulated_submission_time': 5204.270402908325, 'accumulated_eval_time': 30021.664585590363, 'accumulated_logging_time': 0.8350987434387207, 'global_step': 5428, 'preemption_count': 0}), (5553, {'train/loss': 0.1241072101647374, 'validation/loss': 0.12413229118346382, 'validation/num_examples': 83274637, 'test/loss': 0.12649329131373355, 'test/num_examples': 95000000, 'score': 5324.891401767731, 'total_duration': 35966.365944862366, 'accumulated_submission_time': 5324.891401767731, 'accumulated_eval_time': 30640.31463623047, 'accumulated_logging_time': 0.8517365455627441, 'global_step': 5553, 'preemption_count': 0}), (5679, {'train/loss': 0.12214450497156794, 'validation/loss': 0.12417404887895031, 'validation/num_examples': 83274637, 'test/loss': 0.1266518058388158, 'test/num_examples': 95000000, 'score': 5445.944703102112, 'total_duration': 36684.610759973526, 'accumulated_submission_time': 5445.944703102112, 'accumulated_eval_time': 31237.45308828354, 'accumulated_logging_time': 0.8978672027587891, 'global_step': 5679, 'preemption_count': 0}), (5807, {'train/loss': 0.1236418171803344, 'validation/loss': 0.12424107713171793, 'validation/num_examples': 83274637, 'test/loss': 0.12665060270353617, 'test/num_examples': 95000000, 'score': 5566.119457483292, 'total_duration': 37401.07398414612, 'accumulated_submission_time': 5566.119457483292, 'accumulated_eval_time': 31833.71880364418, 'accumulated_logging_time': 0.9144628047943115, 'global_step': 5807, 'preemption_count': 0}), (5929, {'train/loss': 0.12422188618601118, 'validation/loss': 0.1241272719469626, 'validation/num_examples': 83274637, 'test/loss': 0.12652331935649672, 'test/num_examples': 95000000, 'score': 5687.377359390259, 'total_duration': 38114.5708053112, 'accumulated_submission_time': 5687.377359390259, 'accumulated_eval_time': 32425.932426929474, 'accumulated_logging_time': 0.9324440956115723, 'global_step': 5929, 'preemption_count': 0}), (6058, {'train/loss': 0.12284806678833077, 'validation/loss': 0.12408280768102448, 'validation/num_examples': 83274637, 'test/loss': 0.12644319987664474, 'test/num_examples': 95000000, 'score': 5807.635162115097, 'total_duration': 38851.934390068054, 'accumulated_submission_time': 5807.635162115097, 'accumulated_eval_time': 33042.992782354355, 'accumulated_logging_time': 0.9701330661773682, 'global_step': 6058, 'preemption_count': 0}), (6185, {'train/loss': 0.12140100446980705, 'validation/loss': 0.12419052285358693, 'validation/num_examples': 83274637, 'test/loss': 0.1265128461143092, 'test/num_examples': 95000000, 'score': 5928.128986597061, 'total_duration': 39580.26856923103, 'accumulated_submission_time': 5928.128986597061, 'accumulated_eval_time': 33650.81011915207, 'accumulated_logging_time': 0.986473560333252, 'global_step': 6185, 'preemption_count': 0}), (6318, {'train/loss': 0.12312161799449965, 'validation/loss': 0.12391587621512613, 'validation/num_examples': 83274637, 'test/loss': 0.12609078934004933, 'test/num_examples': 95000000, 'score': 6048.927755355835, 'total_duration': 40293.11482334137, 'accumulated_submission_time': 6048.927755355835, 'accumulated_eval_time': 34242.82682609558, 'accumulated_logging_time': 1.0097787380218506, 'global_step': 6318, 'preemption_count': 0}), (6441, {'train/loss': 0.12237790389771357, 'validation/loss': 0.12397073234164924, 'validation/num_examples': 83274637, 'test/loss': 0.12617568190789474, 'test/num_examples': 95000000, 'score': 6169.235493183136, 'total_duration': 41021.533591747284, 'accumulated_submission_time': 6169.235493183136, 'accumulated_eval_time': 34850.91489958763, 'accumulated_logging_time': 1.0262317657470703, 'global_step': 6441, 'preemption_count': 0}), (6558, {'train/loss': 0.12242173281668117, 'validation/loss': 0.12399387147382018, 'validation/num_examples': 83274637, 'test/loss': 0.12627139088199013, 'test/num_examples': 95000000, 'score': 6289.35422539711, 'total_duration': 41752.17410182953, 'accumulated_submission_time': 6289.35422539711, 'accumulated_eval_time': 35461.414174079895, 'accumulated_logging_time': 1.0421249866485596, 'global_step': 6558, 'preemption_count': 0}), (6688, {'train/loss': 0.12221682260293255, 'validation/loss': 0.12400939112783786, 'validation/num_examples': 83274637, 'test/loss': 0.12629944808799343, 'test/num_examples': 95000000, 'score': 6409.363773345947, 'total_duration': 42472.96404719353, 'accumulated_submission_time': 6409.363773345947, 'accumulated_eval_time': 36062.16946744919, 'accumulated_logging_time': 1.0602271556854248, 'global_step': 6688, 'preemption_count': 0}), (6809, {'train/loss': 0.12248969560711638, 'validation/loss': 0.12410983696731133, 'validation/num_examples': 83274637, 'test/loss': 0.12642227137129936, 'test/num_examples': 95000000, 'score': 6530.226616859436, 'total_duration': 43205.04988527298, 'accumulated_submission_time': 6530.226616859436, 'accumulated_eval_time': 36673.3085269928, 'accumulated_logging_time': 1.136946678161621, 'global_step': 6809, 'preemption_count': 0}), (6931, {'train/loss': 0.12301362640921425, 'validation/loss': 0.12409963940569135, 'validation/num_examples': 83274637, 'test/loss': 0.1264707748149671, 'test/num_examples': 95000000, 'score': 6651.166893482208, 'total_duration': 43939.2722094059, 'accumulated_submission_time': 6651.166893482208, 'accumulated_eval_time': 37286.56468296051, 'accumulated_logging_time': 1.1540663242340088, 'global_step': 6931, 'preemption_count': 0}), (7059, {'train/loss': 0.12388650652419471, 'validation/loss': 0.12406451953794241, 'validation/num_examples': 83274637, 'test/loss': 0.12642387001439145, 'test/num_examples': 95000000, 'score': 6771.9419021606445, 'total_duration': 44670.12581658363, 'accumulated_submission_time': 6771.9419021606445, 'accumulated_eval_time': 37896.6202352047, 'accumulated_logging_time': 1.170367956161499, 'global_step': 7059, 'preemption_count': 0}), (7181, {'train/loss': 0.12124679995548425, 'validation/loss': 0.12393589103143209, 'validation/num_examples': 83274637, 'test/loss': 0.12620605325863488, 'test/num_examples': 95000000, 'score': 6893.114670991898, 'total_duration': 45389.47875785828, 'accumulated_submission_time': 6893.114670991898, 'accumulated_eval_time': 38494.776440143585, 'accumulated_logging_time': 1.1873807907104492, 'global_step': 7181, 'preemption_count': 0}), (7308, {'train/loss': 0.12531035807007138, 'validation/loss': 0.12397034187912462, 'validation/num_examples': 83274637, 'test/loss': 0.1262839890419408, 'test/num_examples': 95000000, 'score': 7014.628491640091, 'total_duration': 46123.25054335594, 'accumulated_submission_time': 7014.628491640091, 'accumulated_eval_time': 39107.00913167, 'accumulated_logging_time': 1.205528974533081, 'global_step': 7308, 'preemption_count': 0}), (7433, {'train/loss': 0.12331362865256064, 'validation/loss': 0.12397352013923557, 'validation/num_examples': 83274637, 'test/loss': 0.126281008203125, 'test/num_examples': 95000000, 'score': 7135.615629911423, 'total_duration': 46856.276341199875, 'accumulated_submission_time': 7135.615629911423, 'accumulated_eval_time': 39719.02266025543, 'accumulated_logging_time': 1.2237024307250977, 'global_step': 7433, 'preemption_count': 0}), (7563, {'train/loss': 0.12293878967329017, 'validation/loss': 0.12380228310161945, 'validation/num_examples': 83274637, 'test/loss': 0.1261419839740954, 'test/num_examples': 95000000, 'score': 7255.953263998032, 'total_duration': 47589.13324427605, 'accumulated_submission_time': 7255.953263998032, 'accumulated_eval_time': 40331.50267910957, 'accumulated_logging_time': 1.255857229232788, 'global_step': 7563, 'preemption_count': 0}), (7691, {'train/loss': 0.12167247027486751, 'validation/loss': 0.12381949674568418, 'validation/num_examples': 83274637, 'test/loss': 0.12616694294819078, 'test/num_examples': 95000000, 'score': 7376.079919576645, 'total_duration': 48314.44637775421, 'accumulated_submission_time': 7376.079919576645, 'accumulated_eval_time': 40936.63688874245, 'accumulated_logging_time': 1.3009600639343262, 'global_step': 7691, 'preemption_count': 0}), (7820, {'train/loss': 0.1225201178154668, 'validation/loss': 0.12377129714561605, 'validation/num_examples': 83274637, 'test/loss': 0.12610260268297696, 'test/num_examples': 95000000, 'score': 7496.2853837013245, 'total_duration': 49060.66769242287, 'accumulated_submission_time': 7496.2853837013245, 'accumulated_eval_time': 41562.62910246849, 'accumulated_logging_time': 1.3174386024475098, 'global_step': 7820, 'preemption_count': 0}), (7949, {'train/loss': 0.12438195752881982, 'validation/loss': 0.12382280584404559, 'validation/num_examples': 83274637, 'test/loss': 0.12615920402960526, 'test/num_examples': 95000000, 'score': 7616.91669178009, 'total_duration': 49790.58560466766, 'accumulated_submission_time': 7616.91669178009, 'accumulated_eval_time': 42171.891421079636, 'accumulated_logging_time': 1.3354179859161377, 'global_step': 7949, 'preemption_count': 0})], 'global_step': 8080}
I0307 03:00:33.945498 140404200342720 submission_runner.py:649] Timing: 7737.457255363464
I0307 03:00:33.945535 140404200342720 submission_runner.py:651] Total number of evals: 64
I0307 03:00:33.945563 140404200342720 submission_runner.py:652] ====================
I0307 03:00:33.945690 140404200342720 submission_runner.py:750] Final criteo1tb score: 1
