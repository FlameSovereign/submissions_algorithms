python submission_runner.py --framework=jax --workload=fastmri --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_0 --overwrite=True --save_checkpoints=False --rng_seed=1173376629 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=3 --hparam_end_index=4 2>&1 | tee -a /logs/fastmri_jax_03-07-2025-14-57-19.log
2025-03-07 14:57:27.878093: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741359447.900595       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741359447.907382       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0307 14:57:33.715070 140109165544640 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax.
I0307 14:57:34.582814 140109165544640 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0307 14:57:34.585882 140109165544640 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0307 14:57:34.587637 140109165544640 submission_runner.py:606] Using RNG seed 1173376629
I0307 14:57:35.175239 140109165544640 submission_runner.py:615] --- Tuning run 4/5 ---
I0307 14:57:35.175465 140109165544640 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_4.
I0307 14:57:35.175712 140109165544640 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_4/hparams.json.
I0307 14:57:35.422227 140109165544640 submission_runner.py:218] Initializing dataset.
I0307 14:57:40.501974 140109165544640 submission_runner.py:229] Initializing model.
I0307 14:57:50.905831 140109165544640 submission_runner.py:272] Initializing optimizer.
I0307 14:57:51.380018 140109165544640 submission_runner.py:279] Initializing metrics bundle.
I0307 14:57:51.380223 140109165544640 submission_runner.py:301] Initializing checkpoint and logger.
I0307 14:57:51.381047 140109165544640 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_4 with prefix checkpoint_
I0307 14:57:51.381173 140109165544640 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_4/meta_data_0.json.
I0307 14:57:51.381356 140109165544640 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0307 14:57:51.381407 140109165544640 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0307 14:57:51.536728 140109165544640 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_4/flags_0.json.
I0307 14:57:51.567493 140109165544640 submission_runner.py:337] Starting training loop.
E0307 15:01:30.621429       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:01:30.830140       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:01:31.233377       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:01:31.441539       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:01:33.954535       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:01:34.163503       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
I0307 15:01:46.205606 139971591640832 logging_writer.py:48] [0] global_step=0, grad_norm=5.177431106567383, loss=1.1675852537155151
I0307 15:01:46.257978 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:08:25.393725 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:12:17.411031 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:15:59.424446 140109165544640 submission_runner.py:469] Time since start: 1087.86s, 	Step: 1, 	{'train/ssim': 0.20671616281781877, 'train/loss': 1.1657427379063197, 'validation/ssim': 0.2001037082446715, 'validation/loss': 1.168095835018641, 'validation/num_examples': 3554, 'test/ssim': 0.22316559783841805, 'test/loss': 1.162183142147794, 'test/num_examples': 3581, 'score': 234.6903417110443, 'total_duration': 1087.8568575382233, 'accumulated_submission_time': 234.6903417110443, 'accumulated_eval_time': 853.16637134552, 'accumulated_logging_time': 0}
I0307 15:15:59.432039 139952272680704 logging_writer.py:48] [1] accumulated_eval_time=853.166, accumulated_logging_time=0, accumulated_submission_time=234.69, global_step=1, preemption_count=0, score=234.69, test/loss=1.16218, test/num_examples=3581, test/ssim=0.223166, total_duration=1087.86, train/loss=1.16574, train/ssim=0.206716, validation/loss=1.1681, validation/num_examples=3554, validation/ssim=0.200104
I0307 15:16:11.798591 139952264288000 logging_writer.py:48] [100] global_step=100, grad_norm=0.28735435009002686, loss=0.3344610929489136
I0307 15:16:27.883984 139952272680704 logging_writer.py:48] [200] global_step=200, grad_norm=0.27273204922676086, loss=0.24644646048545837
I0307 15:17:20.565093 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:17:22.418382 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:17:23.719827 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:17:25.019538 140109165544640 submission_runner.py:469] Time since start: 1173.45s, 	Step: 251, 	{'train/ssim': 0.705282483782087, 'train/loss': 0.3029660837990897, 'validation/ssim': 0.6860172956527856, 'validation/loss': 0.3175792103747538, 'validation/num_examples': 3554, 'test/ssim': 0.7041785339508866, 'test/loss': 0.3194918575249581, 'test/num_examples': 3581, 'score': 315.7797758579254, 'total_duration': 1173.451992034912, 'accumulated_submission_time': 315.7797758579254, 'accumulated_eval_time': 857.6207811832428, 'accumulated_logging_time': 0.015702486038208008}
I0307 15:17:25.028111 139952264288000 logging_writer.py:48] [251] accumulated_eval_time=857.621, accumulated_logging_time=0.0157025, accumulated_submission_time=315.78, global_step=251, preemption_count=0, score=315.78, test/loss=0.319492, test/num_examples=3581, test/ssim=0.704179, total_duration=1173.45, train/loss=0.302966, train/ssim=0.705282, validation/loss=0.317579, validation/num_examples=3554, validation/ssim=0.686017
I0307 15:18:43.271429 139952272680704 logging_writer.py:48] [300] global_step=300, grad_norm=0.24599255621433258, loss=0.28669607639312744
I0307 15:18:46.348293 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:18:47.646833 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:18:48.949220 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:18:50.253605 140109165544640 submission_runner.py:469] Time since start: 1258.69s, 	Step: 303, 	{'train/ssim': 0.7072178976876395, 'train/loss': 0.2995407921927316, 'validation/ssim': 0.691677731077659, 'validation/loss': 0.3136507720174451, 'validation/num_examples': 3554, 'test/ssim': 0.7074550361281765, 'test/loss': 0.31570116696628037, 'test/num_examples': 3581, 'score': 397.0884356498718, 'total_duration': 1258.6860280036926, 'accumulated_submission_time': 397.0884356498718, 'accumulated_eval_time': 861.5260148048401, 'accumulated_logging_time': 0.031862497329711914}
I0307 15:18:50.266910 139952264288000 logging_writer.py:48] [303] accumulated_eval_time=861.526, accumulated_logging_time=0.0318625, accumulated_submission_time=397.088, global_step=303, preemption_count=0, score=397.088, test/loss=0.315701, test/num_examples=3581, test/ssim=0.707455, total_duration=1258.69, train/loss=0.299541, train/ssim=0.707218, validation/loss=0.313651, validation/num_examples=3554, validation/ssim=0.691678
I0307 15:20:10.291923 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:20:11.590123 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:20:12.891771 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:20:14.196968 140109165544640 submission_runner.py:469] Time since start: 1342.63s, 	Step: 353, 	{'train/ssim': 0.7151392527988979, 'train/loss': 0.29306534358433317, 'validation/ssim': 0.6993550400956668, 'validation/loss': 0.3070184796729917, 'validation/num_examples': 3554, 'test/ssim': 0.7155369021179488, 'test/loss': 0.3093186042655683, 'test/num_examples': 3581, 'score': 477.1009681224823, 'total_duration': 1342.629417181015, 'accumulated_submission_time': 477.1009681224823, 'accumulated_eval_time': 865.4310169219971, 'accumulated_logging_time': 0.053195953369140625}
I0307 15:20:14.212460 139952272680704 logging_writer.py:48] [353] accumulated_eval_time=865.431, accumulated_logging_time=0.053196, accumulated_submission_time=477.101, global_step=353, preemption_count=0, score=477.101, test/loss=0.309319, test/num_examples=3581, test/ssim=0.715537, total_duration=1342.63, train/loss=0.293065, train/ssim=0.715139, validation/loss=0.307018, validation/num_examples=3554, validation/ssim=0.699355
I0307 15:21:20.228150 139952264288000 logging_writer.py:48] [400] global_step=400, grad_norm=0.15813671052455902, loss=0.31339171528816223
I0307 15:21:35.429039 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:21:36.736189 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:21:38.039607 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:21:39.341377 140109165544640 submission_runner.py:469] Time since start: 1427.77s, 	Step: 415, 	{'train/ssim': 0.7228619030543736, 'train/loss': 0.2984508105686733, 'validation/ssim': 0.7049966531988604, 'validation/loss': 0.3135324455608997, 'validation/num_examples': 3554, 'test/ssim': 0.7219814374040072, 'test/loss': 0.31550209111456295, 'test/num_examples': 3581, 'score': 558.3022339344025, 'total_duration': 1427.7738292217255, 'accumulated_submission_time': 558.3022339344025, 'accumulated_eval_time': 869.343314409256, 'accumulated_logging_time': 0.0801093578338623}
I0307 15:21:39.349771 139952272680704 logging_writer.py:48] [415] accumulated_eval_time=869.343, accumulated_logging_time=0.0801094, accumulated_submission_time=558.302, global_step=415, preemption_count=0, score=558.302, test/loss=0.315502, test/num_examples=3581, test/ssim=0.721981, total_duration=1427.77, train/loss=0.298451, train/ssim=0.722862, validation/loss=0.313532, validation/num_examples=3554, validation/ssim=0.704997
I0307 15:22:59.826941 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:23:01.122555 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:23:02.423674 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:23:03.729252 140109165544640 submission_runner.py:469] Time since start: 1512.16s, 	Step: 472, 	{'train/ssim': 0.711263792855399, 'train/loss': 0.2929296152932303, 'validation/ssim': 0.6940774397026238, 'validation/loss': 0.3069745151260024, 'validation/num_examples': 3554, 'test/ssim': 0.7114199180571069, 'test/loss': 0.3088820350133517, 'test/num_examples': 3581, 'score': 638.768340587616, 'total_duration': 1512.1616942882538, 'accumulated_submission_time': 638.768340587616, 'accumulated_eval_time': 873.2455675601959, 'accumulated_logging_time': 0.09580659866333008}
I0307 15:23:03.738498 139952264288000 logging_writer.py:48] [472] accumulated_eval_time=873.246, accumulated_logging_time=0.0958066, accumulated_submission_time=638.768, global_step=472, preemption_count=0, score=638.768, test/loss=0.308882, test/num_examples=3581, test/ssim=0.71142, total_duration=1512.16, train/loss=0.29293, train/ssim=0.711264, validation/loss=0.306975, validation/num_examples=3554, validation/ssim=0.694077
I0307 15:23:48.599142 139952272680704 logging_writer.py:48] [500] global_step=500, grad_norm=0.26549091935157776, loss=0.3905327320098877
I0307 15:24:24.892110 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:24:26.187961 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:24:27.501069 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:24:28.809445 140109165544640 submission_runner.py:469] Time since start: 1597.24s, 	Step: 524, 	{'train/ssim': 0.7222776412963867, 'train/loss': 0.28827299390520367, 'validation/ssim': 0.7032111430342571, 'validation/loss': 0.30332188560644696, 'validation/num_examples': 3554, 'test/ssim': 0.7204899365793423, 'test/loss': 0.3051686227005376, 'test/num_examples': 3581, 'score': 719.9098932743073, 'total_duration': 1597.2418990135193, 'accumulated_submission_time': 719.9098932743073, 'accumulated_eval_time': 877.1628525257111, 'accumulated_logging_time': 0.1129617691040039}
I0307 15:24:28.819618 139952264288000 logging_writer.py:48] [524] accumulated_eval_time=877.163, accumulated_logging_time=0.112962, accumulated_submission_time=719.91, global_step=524, preemption_count=0, score=719.91, test/loss=0.305169, test/num_examples=3581, test/ssim=0.72049, total_duration=1597.24, train/loss=0.288273, train/ssim=0.722278, validation/loss=0.303322, validation/num_examples=3554, validation/ssim=0.703211
I0307 15:25:50.810500 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:25:52.112975 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:25:53.412910 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:25:54.718364 140109165544640 submission_runner.py:469] Time since start: 1683.15s, 	Step: 582, 	{'train/ssim': 0.7233101981026786, 'train/loss': 0.2878648212977818, 'validation/ssim': 0.7056848357484524, 'validation/loss': 0.30216077505099886, 'validation/num_examples': 3554, 'test/ssim': 0.7225816647322675, 'test/loss': 0.3040022904631213, 'test/num_examples': 3581, 'score': 801.8866031169891, 'total_duration': 1683.1508169174194, 'accumulated_submission_time': 801.8866031169891, 'accumulated_eval_time': 881.0706655979156, 'accumulated_logging_time': 0.13306879997253418}
I0307 15:25:54.733213 139952272680704 logging_writer.py:48] [582] accumulated_eval_time=881.071, accumulated_logging_time=0.133069, accumulated_submission_time=801.887, global_step=582, preemption_count=0, score=801.887, test/loss=0.304002, test/num_examples=3581, test/ssim=0.722582, total_duration=1683.15, train/loss=0.287865, train/ssim=0.72331, validation/loss=0.302161, validation/num_examples=3554, validation/ssim=0.705685
I0307 15:26:26.894200 139952264288000 logging_writer.py:48] [600] global_step=600, grad_norm=0.39537176489830017, loss=0.302417516708374
I0307 15:27:15.094495 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:27:16.390535 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:27:17.690562 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:27:18.999450 140109165544640 submission_runner.py:469] Time since start: 1767.43s, 	Step: 634, 	{'train/ssim': 0.7266605240958077, 'train/loss': 0.28808750425066265, 'validation/ssim': 0.7101684639007104, 'validation/loss': 0.3027997035690419, 'validation/num_examples': 3554, 'test/ssim': 0.7266017015803895, 'test/loss': 0.3046693650080285, 'test/num_examples': 3581, 'score': 882.2309019565582, 'total_duration': 1767.4319069385529, 'accumulated_submission_time': 882.2309019565582, 'accumulated_eval_time': 884.9755778312683, 'accumulated_logging_time': 0.16155719757080078}
I0307 15:27:19.007653 139952272680704 logging_writer.py:48] [634] accumulated_eval_time=884.976, accumulated_logging_time=0.161557, accumulated_submission_time=882.231, global_step=634, preemption_count=0, score=882.231, test/loss=0.304669, test/num_examples=3581, test/ssim=0.726602, total_duration=1767.43, train/loss=0.288088, train/ssim=0.726661, validation/loss=0.3028, validation/num_examples=3554, validation/ssim=0.710168
I0307 15:28:39.539735 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:28:40.838544 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:28:42.138596 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:28:43.446507 140109165544640 submission_runner.py:469] Time since start: 1851.88s, 	Step: 689, 	{'train/ssim': 0.7293769291469029, 'train/loss': 0.28445868832724436, 'validation/ssim': 0.710915792504924, 'validation/loss': 0.299088546246307, 'validation/num_examples': 3554, 'test/ssim': 0.7281276997957973, 'test/loss': 0.3009009341293459, 'test/num_examples': 3581, 'score': 962.7514953613281, 'total_duration': 1851.878939628601, 'accumulated_submission_time': 962.7514953613281, 'accumulated_eval_time': 888.882283449173, 'accumulated_logging_time': 0.17729854583740234}
I0307 15:28:43.458291 139952264288000 logging_writer.py:48] [689] accumulated_eval_time=888.882, accumulated_logging_time=0.177299, accumulated_submission_time=962.751, global_step=689, preemption_count=0, score=962.751, test/loss=0.300901, test/num_examples=3581, test/ssim=0.728128, total_duration=1851.88, train/loss=0.284459, train/ssim=0.729377, validation/loss=0.299089, validation/num_examples=3554, validation/ssim=0.710916
I0307 15:29:02.942538 139952272680704 logging_writer.py:48] [700] global_step=700, grad_norm=0.061372820287942886, loss=0.2757606506347656
I0307 15:30:06.170951 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:30:07.469194 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:30:08.772980 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:30:10.081009 140109165544640 submission_runner.py:469] Time since start: 1938.51s, 	Step: 740, 	{'train/ssim': 0.7318135670253209, 'train/loss': 0.28533901487077984, 'validation/ssim': 0.7142448017418753, 'validation/loss': 0.2990193707794035, 'validation/num_examples': 3554, 'test/ssim': 0.7310040049698059, 'test/loss': 0.30121706930893954, 'test/num_examples': 3581, 'score': 1045.4500977993011, 'total_duration': 1938.5134534835815, 'accumulated_submission_time': 1045.4500977993011, 'accumulated_eval_time': 892.7922830581665, 'accumulated_logging_time': 0.20007634162902832}
I0307 15:30:10.092109 139952264288000 logging_writer.py:48] [740] accumulated_eval_time=892.792, accumulated_logging_time=0.200076, accumulated_submission_time=1045.45, global_step=740, preemption_count=0, score=1045.45, test/loss=0.301217, test/num_examples=3581, test/ssim=0.731004, total_duration=1938.51, train/loss=0.285339, train/ssim=0.731814, validation/loss=0.299019, validation/num_examples=3554, validation/ssim=0.714245
I0307 15:31:30.675269 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:31:31.974079 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:31:33.276617 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:31:34.583835 140109165544640 submission_runner.py:469] Time since start: 2023.02s, 	Step: 795, 	{'train/ssim': 0.7219310488019671, 'train/loss': 0.284042273248945, 'validation/ssim': 0.7051036793929375, 'validation/loss': 0.29820334757051914, 'validation/num_examples': 3554, 'test/ssim': 0.7220443644626152, 'test/loss': 0.29985217254476754, 'test/num_examples': 3581, 'score': 1126.0184872150421, 'total_duration': 2023.0162734985352, 'accumulated_submission_time': 1126.0184872150421, 'accumulated_eval_time': 896.700784444809, 'accumulated_logging_time': 0.2222738265991211}
I0307 15:31:34.594924 139952272680704 logging_writer.py:48] [795] accumulated_eval_time=896.701, accumulated_logging_time=0.222274, accumulated_submission_time=1126.02, global_step=795, preemption_count=0, score=1126.02, test/loss=0.299852, test/num_examples=3581, test/ssim=0.722044, total_duration=2023.02, train/loss=0.284042, train/ssim=0.721931, validation/loss=0.298203, validation/num_examples=3554, validation/ssim=0.705104
I0307 15:31:35.482374 139952264288000 logging_writer.py:48] [800] global_step=800, grad_norm=0.24862942099571228, loss=0.27607929706573486
I0307 15:32:55.103359 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:32:56.401302 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:32:57.702414 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:32:59.018119 140109165544640 submission_runner.py:469] Time since start: 2107.45s, 	Step: 846, 	{'train/ssim': 0.7320085934230259, 'train/loss': 0.2813753741128104, 'validation/ssim': 0.7137809070765335, 'validation/loss': 0.2962357967035383, 'validation/num_examples': 3554, 'test/ssim': 0.7308770600260053, 'test/loss': 0.2980636260057421, 'test/num_examples': 3581, 'score': 1206.514904975891, 'total_duration': 2107.4505593776703, 'accumulated_submission_time': 1206.514904975891, 'accumulated_eval_time': 900.6154789924622, 'accumulated_logging_time': 0.24252939224243164}
I0307 15:32:59.027262 139952272680704 logging_writer.py:48] [846] accumulated_eval_time=900.615, accumulated_logging_time=0.242529, accumulated_submission_time=1206.51, global_step=846, preemption_count=0, score=1206.51, test/loss=0.298064, test/num_examples=3581, test/ssim=0.730877, total_duration=2107.45, train/loss=0.281375, train/ssim=0.732009, validation/loss=0.296236, validation/num_examples=3554, validation/ssim=0.713781
I0307 15:34:20.090913 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:34:21.388350 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:34:22.968072 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:34:24.279578 140109165544640 submission_runner.py:469] Time since start: 2192.71s, 	Step: 893, 	{'train/ssim': 0.7241850580487933, 'train/loss': 0.2827650138310024, 'validation/ssim': 0.7082522279034187, 'validation/loss': 0.2969078016737303, 'validation/num_examples': 3554, 'test/ssim': 0.7248704234370636, 'test/loss': 0.2985970061173555, 'test/num_examples': 3581, 'score': 1287.567913532257, 'total_duration': 2192.7120316028595, 'accumulated_submission_time': 1287.567913532257, 'accumulated_eval_time': 904.8040964603424, 'accumulated_logging_time': 0.2594764232635498}
I0307 15:34:24.297561 139952264288000 logging_writer.py:48] [893] accumulated_eval_time=904.804, accumulated_logging_time=0.259476, accumulated_submission_time=1287.57, global_step=893, preemption_count=0, score=1287.57, test/loss=0.298597, test/num_examples=3581, test/ssim=0.72487, total_duration=2192.71, train/loss=0.282765, train/ssim=0.724185, validation/loss=0.296908, validation/num_examples=3554, validation/ssim=0.708252
I0307 15:34:33.157581 139952272680704 logging_writer.py:48] [900] global_step=900, grad_norm=0.07907341420650482, loss=0.24176833033561707
I0307 15:35:44.281199 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:35:45.583511 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:35:46.882675 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:35:48.198839 140109165544640 submission_runner.py:469] Time since start: 2276.63s, 	Step: 942, 	{'train/ssim': 0.7333933966500419, 'train/loss': 0.2822187287466867, 'validation/ssim': 0.7155687528576955, 'validation/loss': 0.29635477575882807, 'validation/num_examples': 3554, 'test/ssim': 0.7323925590355348, 'test/loss': 0.2982508391183503, 'test/num_examples': 3581, 'score': 1367.5126893520355, 'total_duration': 2276.631281852722, 'accumulated_submission_time': 1367.5126893520355, 'accumulated_eval_time': 908.7216784954071, 'accumulated_logging_time': 0.3132045269012451}
I0307 15:35:48.209481 139952264288000 logging_writer.py:48] [942] accumulated_eval_time=908.722, accumulated_logging_time=0.313205, accumulated_submission_time=1367.51, global_step=942, preemption_count=0, score=1367.51, test/loss=0.298251, test/num_examples=3581, test/ssim=0.732393, total_duration=2276.63, train/loss=0.282219, train/ssim=0.733393, validation/loss=0.296355, validation/num_examples=3554, validation/ssim=0.715569
I0307 15:36:20.256880 139952272680704 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.33535969257354736, loss=0.2962837219238281
I0307 15:36:46.240421 139952264288000 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.19375264644622803, loss=0.3514839708805084
I0307 15:36:54.435350 139952272680704 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.16178128123283386, loss=0.3528509736061096
I0307 15:37:02.625588 139952264288000 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.2733759880065918, loss=0.2035963237285614
I0307 15:37:08.277935 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:37:09.580461 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:37:10.885147 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:37:12.197070 140109165544640 submission_runner.py:469] Time since start: 2360.63s, 	Step: 1370, 	{'train/ssim': 0.7322026661464146, 'train/loss': 0.2798666102545602, 'validation/ssim': 0.7137093959930711, 'validation/loss': 0.2942538543168789, 'validation/num_examples': 3554, 'test/ssim': 0.7310141632923765, 'test/loss': 0.29592979876431164, 'test/num_examples': 3581, 'score': 1447.5413138866425, 'total_duration': 2360.6295263767242, 'accumulated_submission_time': 1447.5413138866425, 'accumulated_eval_time': 912.6407668590546, 'accumulated_logging_time': 0.3380317687988281}
I0307 15:37:12.205840 139952272680704 logging_writer.py:48] [1370] accumulated_eval_time=912.641, accumulated_logging_time=0.338032, accumulated_submission_time=1447.54, global_step=1370, preemption_count=0, score=1447.54, test/loss=0.29593, test/num_examples=3581, test/ssim=0.731014, total_duration=2360.63, train/loss=0.279867, train/ssim=0.732203, validation/loss=0.294254, validation/num_examples=3554, validation/ssim=0.713709
I0307 15:37:14.766334 139952264288000 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.3747260868549347, loss=0.24157683551311493
I0307 15:37:22.951939 139952272680704 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.16449466347694397, loss=0.24597638845443726
I0307 15:37:31.127754 139952264288000 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.3283257782459259, loss=0.28432849049568176
I0307 15:37:39.330892 139952272680704 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.08235783129930496, loss=0.29164624214172363
I0307 15:37:47.496643 139952264288000 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.11229514330625534, loss=0.28002387285232544
I0307 15:37:55.682430 139952272680704 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.22408685088157654, loss=0.33442583680152893
I0307 15:38:03.854671 139952264288000 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.10730164498090744, loss=0.2533276677131653
I0307 15:38:12.036959 139952272680704 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.0591052807867527, loss=0.3499566912651062
I0307 15:38:20.246795 139952264288000 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.11075009405612946, loss=0.27905741333961487
I0307 15:38:28.445204 139952272680704 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.20729008316993713, loss=0.3630138635635376
I0307 15:38:32.266117 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:38:33.572352 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:38:34.880297 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:38:36.195986 140109165544640 submission_runner.py:469] Time since start: 2444.63s, 	Step: 2347, 	{'train/ssim': 0.7364521026611328, 'train/loss': 0.27657132489340647, 'validation/ssim': 0.7167752361995287, 'validation/loss': 0.2917878897457091, 'validation/num_examples': 3554, 'test/ssim': 0.7343070960450991, 'test/loss': 0.29335623205590267, 'test/num_examples': 3581, 'score': 1527.5437803268433, 'total_duration': 2444.6282966136932, 'accumulated_submission_time': 1527.5437803268433, 'accumulated_eval_time': 916.5704438686371, 'accumulated_logging_time': 0.3541278839111328}
I0307 15:38:36.218357 139952264288000 logging_writer.py:48] [2347] accumulated_eval_time=916.57, accumulated_logging_time=0.354128, accumulated_submission_time=1527.54, global_step=2347, preemption_count=0, score=1527.54, test/loss=0.293356, test/num_examples=3581, test/ssim=0.734307, total_duration=2444.63, train/loss=0.276571, train/ssim=0.736452, validation/loss=0.291788, validation/num_examples=3554, validation/ssim=0.716775
I0307 15:38:40.660524 139952272680704 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.23847109079360962, loss=0.31463301181793213
I0307 15:38:48.834377 139952264288000 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.11880380660295486, loss=0.3285404145717621
I0307 15:38:57.037597 139952272680704 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.17103475332260132, loss=0.25273722410202026
I0307 15:39:05.253860 139952264288000 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.11504491418600082, loss=0.306845098733902
I0307 15:39:13.462068 139952272680704 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.27552586793899536, loss=0.2901327311992645
I0307 15:39:21.669679 139952264288000 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.20684410631656647, loss=0.22078509628772736
I0307 15:39:29.868919 139952272680704 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.2622477412223816, loss=0.3233160674571991
I0307 15:39:38.078537 139952264288000 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.23147276043891907, loss=0.2767890989780426
I0307 15:39:46.249876 139952272680704 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.19574101269245148, loss=0.3634258806705475
I0307 15:39:54.421630 139952264288000 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.2100651115179062, loss=0.25605669617652893
I0307 15:39:56.227438 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:39:57.535019 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:39:58.844660 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:40:00.156188 140109165544640 submission_runner.py:469] Time since start: 2528.59s, 	Step: 3323, 	{'train/ssim': 0.7392417362758091, 'train/loss': 0.27632990905216764, 'validation/ssim': 0.7198116064205824, 'validation/loss': 0.291975597752972, 'validation/num_examples': 3554, 'test/ssim': 0.7370551609187378, 'test/loss': 0.2934399189079517, 'test/num_examples': 3581, 'score': 1607.4873449802399, 'total_duration': 2528.588622570038, 'accumulated_submission_time': 1607.4873449802399, 'accumulated_eval_time': 920.4991307258606, 'accumulated_logging_time': 0.3931305408477783}
I0307 15:40:00.167707 139952272680704 logging_writer.py:48] [3323] accumulated_eval_time=920.499, accumulated_logging_time=0.393131, accumulated_submission_time=1607.49, global_step=3323, preemption_count=0, score=1607.49, test/loss=0.29344, test/num_examples=3581, test/ssim=0.737055, total_duration=2528.59, train/loss=0.27633, train/ssim=0.739242, validation/loss=0.291976, validation/num_examples=3554, validation/ssim=0.719812
I0307 15:40:06.583242 139952264288000 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.3110843300819397, loss=0.22501324117183685
I0307 15:40:14.775863 139952272680704 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.22843843698501587, loss=0.2210627943277359
I0307 15:40:22.960197 139952264288000 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.35703223943710327, loss=0.2588947117328644
I0307 15:40:31.166114 139952272680704 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.3076801598072052, loss=0.2991707921028137
I0307 15:40:39.370510 139952264288000 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.16238121688365936, loss=0.2890506982803345
I0307 15:40:47.589536 139952272680704 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.1385602504014969, loss=0.2862640619277954
I0307 15:40:55.778099 139952264288000 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.21122483909130096, loss=0.27945131063461304
I0307 15:41:03.981816 139952272680704 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.19188499450683594, loss=0.31240084767341614
I0307 15:41:12.180267 139952264288000 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.19956821203231812, loss=0.2841286361217499
I0307 15:41:20.225507 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:41:21.533631 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:41:22.842017 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:41:24.154983 140109165544640 submission_runner.py:469] Time since start: 2612.59s, 	Step: 4299, 	{'train/ssim': 0.731006213596889, 'train/loss': 0.27738252707890104, 'validation/ssim': 0.7119475167724747, 'validation/loss': 0.292336381816703, 'validation/num_examples': 3554, 'test/ssim': 0.7297006035543493, 'test/loss': 0.2937341693791888, 'test/num_examples': 3581, 'score': 1687.4880573749542, 'total_duration': 2612.5874392986298, 'accumulated_submission_time': 1687.4880573749542, 'accumulated_eval_time': 924.428567647934, 'accumulated_logging_time': 0.41267895698547363}
I0307 15:41:24.164528 139952272680704 logging_writer.py:48] [4299] accumulated_eval_time=924.429, accumulated_logging_time=0.412679, accumulated_submission_time=1687.49, global_step=4299, preemption_count=0, score=1687.49, test/loss=0.293734, test/num_examples=3581, test/ssim=0.729701, total_duration=2612.59, train/loss=0.277383, train/ssim=0.731006, validation/loss=0.292336, validation/num_examples=3554, validation/ssim=0.711948
I0307 15:41:24.342330 139952264288000 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.21632885932922363, loss=0.30914270877838135
I0307 15:41:32.526145 139952272680704 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.12067677825689316, loss=0.26933592557907104
I0307 15:41:40.694845 139952264288000 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.12351939082145691, loss=0.3150908052921295
I0307 15:41:48.892947 139952272680704 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.19933107495307922, loss=0.330387145280838
I0307 15:41:57.082859 139952264288000 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.08087042719125748, loss=0.3907173275947571
I0307 15:42:05.282979 139952272680704 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.31446799635887146, loss=0.2969483435153961
I0307 15:42:13.463218 139952264288000 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.23127613961696625, loss=0.3326972424983978
I0307 15:42:21.643908 139952272680704 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.13601785898208618, loss=0.2894396483898163
I0307 15:42:29.828345 139952264288000 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.3282325267791748, loss=0.21305644512176514
I0307 15:42:38.013269 139952272680704 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.16279804706573486, loss=0.2935260832309723
I0307 15:42:44.231960 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:42:45.541121 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:42:46.853784 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:42:48.168956 140109165544640 submission_runner.py:469] Time since start: 2696.60s, 	Step: 5277, 	{'train/ssim': 0.7407995632716587, 'train/loss': 0.27575646127973286, 'validation/ssim': 0.7220635529509004, 'validation/loss': 0.2906025643421145, 'validation/num_examples': 3554, 'test/ssim': 0.7392231787559341, 'test/loss': 0.2921881954019478, 'test/num_examples': 3581, 'score': 1767.4991495609283, 'total_duration': 2696.601394176483, 'accumulated_submission_time': 1767.4991495609283, 'accumulated_eval_time': 928.3655023574829, 'accumulated_logging_time': 0.4297447204589844}
I0307 15:42:48.180614 139952264288000 logging_writer.py:48] [5277] accumulated_eval_time=928.366, accumulated_logging_time=0.429745, accumulated_submission_time=1767.5, global_step=5277, preemption_count=0, score=1767.5, test/loss=0.292188, test/num_examples=3581, test/ssim=0.739223, total_duration=2696.6, train/loss=0.275756, train/ssim=0.7408, validation/loss=0.290603, validation/num_examples=3554, validation/ssim=0.722064
I0307 15:42:50.176070 139952272680704 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.26194053888320923, loss=0.2674747705459595
I0307 15:43:02.125957 139952264288000 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.30362093448638916, loss=0.259733110666275
I0307 15:43:10.513986 139952272680704 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.272947758436203, loss=0.25356462597846985
I0307 15:43:18.709360 139952264288000 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.13503992557525635, loss=0.2585901618003845
I0307 15:43:26.909061 139952272680704 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.32215937972068787, loss=0.3580924868583679
I0307 15:43:35.120319 139952264288000 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.13213445246219635, loss=0.32266777753829956
I0307 15:43:43.362525 139952272680704 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.1477729082107544, loss=0.3100566565990448
I0307 15:43:51.575606 139952264288000 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.3163819909095764, loss=0.31875696778297424
I0307 15:43:59.756515 139952272680704 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.10497862845659256, loss=0.3276349902153015
I0307 15:44:07.956417 139952264288000 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.16004535555839539, loss=0.2808748185634613
I0307 15:44:08.205988 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:44:09.511000 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:44:10.820791 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:44:12.136047 140109165544640 submission_runner.py:469] Time since start: 2780.57s, 	Step: 6204, 	{'train/ssim': 0.7345397812979562, 'train/loss': 0.27634971482413156, 'validation/ssim': 0.7145186184360931, 'validation/loss': 0.29171878297341025, 'validation/num_examples': 3554, 'test/ssim': 0.7320955133211743, 'test/loss': 0.2930724126138823, 'test/num_examples': 3581, 'score': 1847.4643604755402, 'total_duration': 2780.568505525589, 'accumulated_submission_time': 1847.4643604755402, 'accumulated_eval_time': 932.2955176830292, 'accumulated_logging_time': 0.44945812225341797}
I0307 15:44:12.146220 139952272680704 logging_writer.py:48] [6204] accumulated_eval_time=932.296, accumulated_logging_time=0.449458, accumulated_submission_time=1847.46, global_step=6204, preemption_count=0, score=1847.46, test/loss=0.293072, test/num_examples=3581, test/ssim=0.732096, total_duration=2780.57, train/loss=0.27635, train/ssim=0.73454, validation/loss=0.291719, validation/num_examples=3554, validation/ssim=0.714519
I0307 15:44:20.093672 139952264288000 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.227402463555336, loss=0.2749853730201721
I0307 15:44:28.276616 139952272680704 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.16768726706504822, loss=0.2509649097919464
I0307 15:44:36.489070 139952264288000 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.12740550935268402, loss=0.2145681381225586
I0307 15:44:44.671509 139952272680704 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.122297503054142, loss=0.2166510969400406
I0307 15:44:52.885961 139952264288000 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.16473080217838287, loss=0.28690940141677856
I0307 15:45:01.083640 139952272680704 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.17901521921157837, loss=0.2564176917076111
I0307 15:45:09.289264 139952264288000 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.16928409039974213, loss=0.30316197872161865
I0307 15:45:17.504465 139952272680704 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.2118312567472458, loss=0.2340770661830902
I0307 15:45:25.705287 139952264288000 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.15223167836666107, loss=0.2642068862915039
I0307 15:45:32.201468 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:45:33.510123 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:45:34.824534 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:45:36.135847 140109165544640 submission_runner.py:469] Time since start: 2864.57s, 	Step: 7180, 	{'train/ssim': 0.7371964454650879, 'train/loss': 0.27438037736075266, 'validation/ssim': 0.7181911006963985, 'validation/loss': 0.2895794269001477, 'validation/num_examples': 3554, 'test/ssim': 0.7355382983759774, 'test/loss': 0.29099336532000486, 'test/num_examples': 3581, 'score': 1927.4638183116913, 'total_duration': 2864.568295955658, 'accumulated_submission_time': 1927.4638183116913, 'accumulated_eval_time': 936.2298450469971, 'accumulated_logging_time': 0.46725916862487793}
I0307 15:45:36.146717 139952272680704 logging_writer.py:48] [7180] accumulated_eval_time=936.23, accumulated_logging_time=0.467259, accumulated_submission_time=1927.46, global_step=7180, preemption_count=0, score=1927.46, test/loss=0.290993, test/num_examples=3581, test/ssim=0.735538, total_duration=2864.57, train/loss=0.27438, train/ssim=0.737196, validation/loss=0.289579, validation/num_examples=3554, validation/ssim=0.718191
I0307 15:45:37.901314 139952264288000 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.10644658654928207, loss=0.29557204246520996
I0307 15:45:46.091426 139952272680704 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.2553426921367645, loss=0.26973745226860046
I0307 15:45:54.281747 139952264288000 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.15184557437896729, loss=0.27037692070007324
I0307 15:46:02.481292 139952272680704 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.15505093336105347, loss=0.2648376226425171
I0307 15:46:10.669964 139952264288000 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.14275991916656494, loss=0.24466630816459656
I0307 15:46:18.884766 139952272680704 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.22631216049194336, loss=0.34423691034317017
I0307 15:46:27.093582 139952264288000 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.18594901263713837, loss=0.29180821776390076
I0307 15:46:35.295931 139952272680704 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.0991818755865097, loss=0.413116455078125
I0307 15:46:43.511722 139952264288000 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.041067399084568024, loss=0.2674618065357208
I0307 15:46:51.715462 139952272680704 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.08433669805526733, loss=0.3281624913215637
I0307 15:46:56.155064 140109165544640 spec.py:321] Evaluating on the training split.
I0307 15:46:57.462898 140109165544640 spec.py:333] Evaluating on the validation split.
I0307 15:46:58.778366 140109165544640 spec.py:349] Evaluating on the test split.
I0307 15:47:00.089895 140109165544640 submission_runner.py:469] Time since start: 2948.52s, 	Step: 8155, 	{'train/ssim': 0.7426966939653669, 'train/loss': 0.2730290378843035, 'validation/ssim': 0.7236905159679234, 'validation/loss': 0.28820316484287073, 'validation/num_examples': 3554, 'test/ssim': 0.7409528206593828, 'test/loss': 0.28962546878272477, 'test/num_examples': 3581, 'score': 2007.4167020320892, 'total_duration': 2948.5223524570465, 'accumulated_submission_time': 2007.4167020320892, 'accumulated_eval_time': 940.1646292209625, 'accumulated_logging_time': 0.48647284507751465}
I0307 15:47:00.100126 139952264288000 logging_writer.py:48] [8155] accumulated_eval_time=940.165, accumulated_logging_time=0.486473, accumulated_submission_time=2007.42, global_step=8155, preemption_count=0, score=2007.42, test/loss=0.289625, test/num_examples=3581, test/ssim=0.740953, total_duration=2948.52, train/loss=0.273029, train/ssim=0.742697, validation/loss=0.288203, validation/num_examples=3554, validation/ssim=0.723691
I0307 15:47:00.112323 139952272680704 logging_writer.py:48] [8155] global_step=8155, preemption_count=0, score=2007.42
I0307 15:47:00.669472 140109165544640 submission_runner.py:646] Tuning trial 4/5
I0307 15:47:00.669639 140109165544640 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.0, learning_rate=0.004958460849689891, one_minus_beta1=0.13625575743, beta2=0.6291854735396584, weight_decay=0.1147386261512052, warmup_factor=0.02)
I0307 15:47:00.670375 140109165544640 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/ssim': 0.20671616281781877, 'train/loss': 1.1657427379063197, 'validation/ssim': 0.2001037082446715, 'validation/loss': 1.168095835018641, 'validation/num_examples': 3554, 'test/ssim': 0.22316559783841805, 'test/loss': 1.162183142147794, 'test/num_examples': 3581, 'score': 234.6903417110443, 'total_duration': 1087.8568575382233, 'accumulated_submission_time': 234.6903417110443, 'accumulated_eval_time': 853.16637134552, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (251, {'train/ssim': 0.705282483782087, 'train/loss': 0.3029660837990897, 'validation/ssim': 0.6860172956527856, 'validation/loss': 0.3175792103747538, 'validation/num_examples': 3554, 'test/ssim': 0.7041785339508866, 'test/loss': 0.3194918575249581, 'test/num_examples': 3581, 'score': 315.7797758579254, 'total_duration': 1173.451992034912, 'accumulated_submission_time': 315.7797758579254, 'accumulated_eval_time': 857.6207811832428, 'accumulated_logging_time': 0.015702486038208008, 'global_step': 251, 'preemption_count': 0}), (303, {'train/ssim': 0.7072178976876395, 'train/loss': 0.2995407921927316, 'validation/ssim': 0.691677731077659, 'validation/loss': 0.3136507720174451, 'validation/num_examples': 3554, 'test/ssim': 0.7074550361281765, 'test/loss': 0.31570116696628037, 'test/num_examples': 3581, 'score': 397.0884356498718, 'total_duration': 1258.6860280036926, 'accumulated_submission_time': 397.0884356498718, 'accumulated_eval_time': 861.5260148048401, 'accumulated_logging_time': 0.031862497329711914, 'global_step': 303, 'preemption_count': 0}), (353, {'train/ssim': 0.7151392527988979, 'train/loss': 0.29306534358433317, 'validation/ssim': 0.6993550400956668, 'validation/loss': 0.3070184796729917, 'validation/num_examples': 3554, 'test/ssim': 0.7155369021179488, 'test/loss': 0.3093186042655683, 'test/num_examples': 3581, 'score': 477.1009681224823, 'total_duration': 1342.629417181015, 'accumulated_submission_time': 477.1009681224823, 'accumulated_eval_time': 865.4310169219971, 'accumulated_logging_time': 0.053195953369140625, 'global_step': 353, 'preemption_count': 0}), (415, {'train/ssim': 0.7228619030543736, 'train/loss': 0.2984508105686733, 'validation/ssim': 0.7049966531988604, 'validation/loss': 0.3135324455608997, 'validation/num_examples': 3554, 'test/ssim': 0.7219814374040072, 'test/loss': 0.31550209111456295, 'test/num_examples': 3581, 'score': 558.3022339344025, 'total_duration': 1427.7738292217255, 'accumulated_submission_time': 558.3022339344025, 'accumulated_eval_time': 869.343314409256, 'accumulated_logging_time': 0.0801093578338623, 'global_step': 415, 'preemption_count': 0}), (472, {'train/ssim': 0.711263792855399, 'train/loss': 0.2929296152932303, 'validation/ssim': 0.6940774397026238, 'validation/loss': 0.3069745151260024, 'validation/num_examples': 3554, 'test/ssim': 0.7114199180571069, 'test/loss': 0.3088820350133517, 'test/num_examples': 3581, 'score': 638.768340587616, 'total_duration': 1512.1616942882538, 'accumulated_submission_time': 638.768340587616, 'accumulated_eval_time': 873.2455675601959, 'accumulated_logging_time': 0.09580659866333008, 'global_step': 472, 'preemption_count': 0}), (524, {'train/ssim': 0.7222776412963867, 'train/loss': 0.28827299390520367, 'validation/ssim': 0.7032111430342571, 'validation/loss': 0.30332188560644696, 'validation/num_examples': 3554, 'test/ssim': 0.7204899365793423, 'test/loss': 0.3051686227005376, 'test/num_examples': 3581, 'score': 719.9098932743073, 'total_duration': 1597.2418990135193, 'accumulated_submission_time': 719.9098932743073, 'accumulated_eval_time': 877.1628525257111, 'accumulated_logging_time': 0.1129617691040039, 'global_step': 524, 'preemption_count': 0}), (582, {'train/ssim': 0.7233101981026786, 'train/loss': 0.2878648212977818, 'validation/ssim': 0.7056848357484524, 'validation/loss': 0.30216077505099886, 'validation/num_examples': 3554, 'test/ssim': 0.7225816647322675, 'test/loss': 0.3040022904631213, 'test/num_examples': 3581, 'score': 801.8866031169891, 'total_duration': 1683.1508169174194, 'accumulated_submission_time': 801.8866031169891, 'accumulated_eval_time': 881.0706655979156, 'accumulated_logging_time': 0.13306879997253418, 'global_step': 582, 'preemption_count': 0}), (634, {'train/ssim': 0.7266605240958077, 'train/loss': 0.28808750425066265, 'validation/ssim': 0.7101684639007104, 'validation/loss': 0.3027997035690419, 'validation/num_examples': 3554, 'test/ssim': 0.7266017015803895, 'test/loss': 0.3046693650080285, 'test/num_examples': 3581, 'score': 882.2309019565582, 'total_duration': 1767.4319069385529, 'accumulated_submission_time': 882.2309019565582, 'accumulated_eval_time': 884.9755778312683, 'accumulated_logging_time': 0.16155719757080078, 'global_step': 634, 'preemption_count': 0}), (689, {'train/ssim': 0.7293769291469029, 'train/loss': 0.28445868832724436, 'validation/ssim': 0.710915792504924, 'validation/loss': 0.299088546246307, 'validation/num_examples': 3554, 'test/ssim': 0.7281276997957973, 'test/loss': 0.3009009341293459, 'test/num_examples': 3581, 'score': 962.7514953613281, 'total_duration': 1851.878939628601, 'accumulated_submission_time': 962.7514953613281, 'accumulated_eval_time': 888.882283449173, 'accumulated_logging_time': 0.17729854583740234, 'global_step': 689, 'preemption_count': 0}), (740, {'train/ssim': 0.7318135670253209, 'train/loss': 0.28533901487077984, 'validation/ssim': 0.7142448017418753, 'validation/loss': 0.2990193707794035, 'validation/num_examples': 3554, 'test/ssim': 0.7310040049698059, 'test/loss': 0.30121706930893954, 'test/num_examples': 3581, 'score': 1045.4500977993011, 'total_duration': 1938.5134534835815, 'accumulated_submission_time': 1045.4500977993011, 'accumulated_eval_time': 892.7922830581665, 'accumulated_logging_time': 0.20007634162902832, 'global_step': 740, 'preemption_count': 0}), (795, {'train/ssim': 0.7219310488019671, 'train/loss': 0.284042273248945, 'validation/ssim': 0.7051036793929375, 'validation/loss': 0.29820334757051914, 'validation/num_examples': 3554, 'test/ssim': 0.7220443644626152, 'test/loss': 0.29985217254476754, 'test/num_examples': 3581, 'score': 1126.0184872150421, 'total_duration': 2023.0162734985352, 'accumulated_submission_time': 1126.0184872150421, 'accumulated_eval_time': 896.700784444809, 'accumulated_logging_time': 0.2222738265991211, 'global_step': 795, 'preemption_count': 0}), (846, {'train/ssim': 0.7320085934230259, 'train/loss': 0.2813753741128104, 'validation/ssim': 0.7137809070765335, 'validation/loss': 0.2962357967035383, 'validation/num_examples': 3554, 'test/ssim': 0.7308770600260053, 'test/loss': 0.2980636260057421, 'test/num_examples': 3581, 'score': 1206.514904975891, 'total_duration': 2107.4505593776703, 'accumulated_submission_time': 1206.514904975891, 'accumulated_eval_time': 900.6154789924622, 'accumulated_logging_time': 0.24252939224243164, 'global_step': 846, 'preemption_count': 0}), (893, {'train/ssim': 0.7241850580487933, 'train/loss': 0.2827650138310024, 'validation/ssim': 0.7082522279034187, 'validation/loss': 0.2969078016737303, 'validation/num_examples': 3554, 'test/ssim': 0.7248704234370636, 'test/loss': 0.2985970061173555, 'test/num_examples': 3581, 'score': 1287.567913532257, 'total_duration': 2192.7120316028595, 'accumulated_submission_time': 1287.567913532257, 'accumulated_eval_time': 904.8040964603424, 'accumulated_logging_time': 0.2594764232635498, 'global_step': 893, 'preemption_count': 0}), (942, {'train/ssim': 0.7333933966500419, 'train/loss': 0.2822187287466867, 'validation/ssim': 0.7155687528576955, 'validation/loss': 0.29635477575882807, 'validation/num_examples': 3554, 'test/ssim': 0.7323925590355348, 'test/loss': 0.2982508391183503, 'test/num_examples': 3581, 'score': 1367.5126893520355, 'total_duration': 2276.631281852722, 'accumulated_submission_time': 1367.5126893520355, 'accumulated_eval_time': 908.7216784954071, 'accumulated_logging_time': 0.3132045269012451, 'global_step': 942, 'preemption_count': 0}), (1370, {'train/ssim': 0.7322026661464146, 'train/loss': 0.2798666102545602, 'validation/ssim': 0.7137093959930711, 'validation/loss': 0.2942538543168789, 'validation/num_examples': 3554, 'test/ssim': 0.7310141632923765, 'test/loss': 0.29592979876431164, 'test/num_examples': 3581, 'score': 1447.5413138866425, 'total_duration': 2360.6295263767242, 'accumulated_submission_time': 1447.5413138866425, 'accumulated_eval_time': 912.6407668590546, 'accumulated_logging_time': 0.3380317687988281, 'global_step': 1370, 'preemption_count': 0}), (2347, {'train/ssim': 0.7364521026611328, 'train/loss': 0.27657132489340647, 'validation/ssim': 0.7167752361995287, 'validation/loss': 0.2917878897457091, 'validation/num_examples': 3554, 'test/ssim': 0.7343070960450991, 'test/loss': 0.29335623205590267, 'test/num_examples': 3581, 'score': 1527.5437803268433, 'total_duration': 2444.6282966136932, 'accumulated_submission_time': 1527.5437803268433, 'accumulated_eval_time': 916.5704438686371, 'accumulated_logging_time': 0.3541278839111328, 'global_step': 2347, 'preemption_count': 0}), (3323, {'train/ssim': 0.7392417362758091, 'train/loss': 0.27632990905216764, 'validation/ssim': 0.7198116064205824, 'validation/loss': 0.291975597752972, 'validation/num_examples': 3554, 'test/ssim': 0.7370551609187378, 'test/loss': 0.2934399189079517, 'test/num_examples': 3581, 'score': 1607.4873449802399, 'total_duration': 2528.588622570038, 'accumulated_submission_time': 1607.4873449802399, 'accumulated_eval_time': 920.4991307258606, 'accumulated_logging_time': 0.3931305408477783, 'global_step': 3323, 'preemption_count': 0}), (4299, {'train/ssim': 0.731006213596889, 'train/loss': 0.27738252707890104, 'validation/ssim': 0.7119475167724747, 'validation/loss': 0.292336381816703, 'validation/num_examples': 3554, 'test/ssim': 0.7297006035543493, 'test/loss': 0.2937341693791888, 'test/num_examples': 3581, 'score': 1687.4880573749542, 'total_duration': 2612.5874392986298, 'accumulated_submission_time': 1687.4880573749542, 'accumulated_eval_time': 924.428567647934, 'accumulated_logging_time': 0.41267895698547363, 'global_step': 4299, 'preemption_count': 0}), (5277, {'train/ssim': 0.7407995632716587, 'train/loss': 0.27575646127973286, 'validation/ssim': 0.7220635529509004, 'validation/loss': 0.2906025643421145, 'validation/num_examples': 3554, 'test/ssim': 0.7392231787559341, 'test/loss': 0.2921881954019478, 'test/num_examples': 3581, 'score': 1767.4991495609283, 'total_duration': 2696.601394176483, 'accumulated_submission_time': 1767.4991495609283, 'accumulated_eval_time': 928.3655023574829, 'accumulated_logging_time': 0.4297447204589844, 'global_step': 5277, 'preemption_count': 0}), (6204, {'train/ssim': 0.7345397812979562, 'train/loss': 0.27634971482413156, 'validation/ssim': 0.7145186184360931, 'validation/loss': 0.29171878297341025, 'validation/num_examples': 3554, 'test/ssim': 0.7320955133211743, 'test/loss': 0.2930724126138823, 'test/num_examples': 3581, 'score': 1847.4643604755402, 'total_duration': 2780.568505525589, 'accumulated_submission_time': 1847.4643604755402, 'accumulated_eval_time': 932.2955176830292, 'accumulated_logging_time': 0.44945812225341797, 'global_step': 6204, 'preemption_count': 0}), (7180, {'train/ssim': 0.7371964454650879, 'train/loss': 0.27438037736075266, 'validation/ssim': 0.7181911006963985, 'validation/loss': 0.2895794269001477, 'validation/num_examples': 3554, 'test/ssim': 0.7355382983759774, 'test/loss': 0.29099336532000486, 'test/num_examples': 3581, 'score': 1927.4638183116913, 'total_duration': 2864.568295955658, 'accumulated_submission_time': 1927.4638183116913, 'accumulated_eval_time': 936.2298450469971, 'accumulated_logging_time': 0.46725916862487793, 'global_step': 7180, 'preemption_count': 0}), (8155, {'train/ssim': 0.7426966939653669, 'train/loss': 0.2730290378843035, 'validation/ssim': 0.7236905159679234, 'validation/loss': 0.28820316484287073, 'validation/num_examples': 3554, 'test/ssim': 0.7409528206593828, 'test/loss': 0.28962546878272477, 'test/num_examples': 3581, 'score': 2007.4167020320892, 'total_duration': 2948.5223524570465, 'accumulated_submission_time': 2007.4167020320892, 'accumulated_eval_time': 940.1646292209625, 'accumulated_logging_time': 0.48647284507751465, 'global_step': 8155, 'preemption_count': 0})], 'global_step': 8155}
I0307 15:47:00.670468 140109165544640 submission_runner.py:649] Timing: 2007.4167020320892
I0307 15:47:00.670502 140109165544640 submission_runner.py:651] Total number of evals: 23
I0307 15:47:00.670534 140109165544640 submission_runner.py:652] ====================
I0307 15:47:00.670650 140109165544640 submission_runner.py:750] Final fastmri score: 3
