python submission_runner.py --framework=jax --workload=fastmri --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_0 --overwrite=True --save_checkpoints=False --rng_seed=-823545107 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=1 --hparam_end_index=2 2>&1 | tee -a /logs/fastmri_jax_03-07-2025-14-55-24.log
2025-03-07 14:55:25.159149: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741359325.180913       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741359325.187505       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0307 14:55:31.008323 140623735375040 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax.
I0307 14:55:31.881050 140623735375040 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0307 14:55:31.884014 140623735375040 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0307 14:55:31.885766 140623735375040 submission_runner.py:606] Using RNG seed -823545107
I0307 14:55:32.473238 140623735375040 submission_runner.py:615] --- Tuning run 2/5 ---
I0307 14:55:32.473457 140623735375040 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_2.
I0307 14:55:32.473659 140623735375040 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_2/hparams.json.
I0307 14:55:32.711152 140623735375040 submission_runner.py:218] Initializing dataset.
I0307 14:55:37.887961 140623735375040 submission_runner.py:229] Initializing model.
I0307 14:55:48.402396 140623735375040 submission_runner.py:272] Initializing optimizer.
I0307 14:55:48.870154 140623735375040 submission_runner.py:279] Initializing metrics bundle.
I0307 14:55:48.870368 140623735375040 submission_runner.py:301] Initializing checkpoint and logger.
I0307 14:55:48.871204 140623735375040 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_2 with prefix checkpoint_
I0307 14:55:48.871312 140623735375040 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_2/meta_data_0.json.
I0307 14:55:48.871495 140623735375040 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0307 14:55:48.871547 140623735375040 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0307 14:55:49.030397 140623735375040 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_2/flags_0.json.
I0307 14:55:49.061457 140623735375040 submission_runner.py:337] Starting training loop.
E0307 14:59:44.202610       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 14:59:44.409761       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 14:59:44.812413       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 14:59:45.019172       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 14:59:47.499021       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 14:59:47.706352       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
I0307 14:59:59.819069 140487029679872 logging_writer.py:48] [0] global_step=0, grad_norm=4.074281692504883, loss=1.1107511520385742
I0307 14:59:59.869325 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:06:53.635386 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:10:50.407840 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:14:45.127159 140623735375040 submission_runner.py:469] Time since start: 1136.07s, 	Step: 1, 	{'train/ssim': 0.17906481879098074, 'train/loss': 1.1395844050816126, 'validation/ssim': 0.1789098942487778, 'validation/loss': 1.1338836549706317, 'validation/num_examples': 3554, 'test/ssim': 0.19996194378752444, 'test/loss': 1.1312351647584473, 'test/num_examples': 3581, 'score': 250.8077085018158, 'total_duration': 1136.0656123161316, 'accumulated_submission_time': 250.8077085018158, 'accumulated_eval_time': 885.257749080658, 'accumulated_logging_time': 0}
I0307 15:14:45.134493 140465546450688 logging_writer.py:48] [1] accumulated_eval_time=885.258, accumulated_logging_time=0, accumulated_submission_time=250.808, global_step=1, preemption_count=0, score=250.808, test/loss=1.13124, test/num_examples=3581, test/ssim=0.199962, total_duration=1136.07, train/loss=1.13958, train/ssim=0.179065, validation/loss=1.13388, validation/num_examples=3554, validation/ssim=0.17891
I0307 15:14:57.313649 140465538057984 logging_writer.py:48] [100] global_step=100, grad_norm=0.591237485408783, loss=0.3663922846317291
I0307 15:15:14.287139 140465546450688 logging_writer.py:48] [200] global_step=200, grad_norm=0.30989310145378113, loss=0.2837057411670685
I0307 15:16:05.304775 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:16:07.148525 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:16:08.434839 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:16:09.723287 140623735375040 submission_runner.py:469] Time since start: 1220.66s, 	Step: 251, 	{'train/ssim': 0.6924285207475934, 'train/loss': 0.31238923754010883, 'validation/ssim': 0.6732763699352842, 'validation/loss': 0.328164018535453, 'validation/num_examples': 3554, 'test/ssim': 0.6923177719648841, 'test/loss': 0.3293103194376571, 'test/num_examples': 3581, 'score': 330.92598128318787, 'total_duration': 1220.661774635315, 'accumulated_submission_time': 330.92598128318787, 'accumulated_eval_time': 889.6762204170227, 'accumulated_logging_time': 0.015365123748779297}
I0307 15:16:09.732924 140465538057984 logging_writer.py:48] [251] accumulated_eval_time=889.676, accumulated_logging_time=0.0153651, accumulated_submission_time=330.926, global_step=251, preemption_count=0, score=330.926, test/loss=0.32931, test/num_examples=3581, test/ssim=0.692318, total_duration=1220.66, train/loss=0.312389, train/ssim=0.692429, validation/loss=0.328164, validation/num_examples=3554, validation/ssim=0.673276
I0307 15:17:29.797942 140465546450688 logging_writer.py:48] [300] global_step=300, grad_norm=0.12724104523658752, loss=0.32878392934799194
I0307 15:17:29.805159 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:17:31.091097 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:17:32.380407 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:17:33.672617 140623735375040 submission_runner.py:469] Time since start: 1304.61s, 	Step: 301, 	{'train/ssim': 0.6996287618364606, 'train/loss': 0.30705574580601286, 'validation/ssim': 0.6811961022131753, 'validation/loss': 0.32210433006823297, 'validation/num_examples': 3554, 'test/ssim': 0.699741051404112, 'test/loss': 0.3233556675531451, 'test/num_examples': 3581, 'score': 410.9870569705963, 'total_duration': 1304.6111092567444, 'accumulated_submission_time': 410.9870569705963, 'accumulated_eval_time': 893.5436208248138, 'accumulated_logging_time': 0.03296637535095215}
I0307 15:17:33.681481 140465538057984 logging_writer.py:48] [301] accumulated_eval_time=893.544, accumulated_logging_time=0.0329664, accumulated_submission_time=410.987, global_step=301, preemption_count=0, score=410.987, test/loss=0.323356, test/num_examples=3581, test/ssim=0.699741, total_duration=1304.61, train/loss=0.307056, train/ssim=0.699629, validation/loss=0.322104, validation/num_examples=3554, validation/ssim=0.681196
I0307 15:18:53.951377 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:18:55.244932 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:18:56.536297 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:18:57.826460 140623735375040 submission_runner.py:469] Time since start: 1388.76s, 	Step: 350, 	{'train/ssim': 0.7018409456525531, 'train/loss': 0.30473388944353375, 'validation/ssim': 0.6844619124138295, 'validation/loss': 0.3190767527565771, 'validation/num_examples': 3554, 'test/ssim': 0.7025477482066811, 'test/loss': 0.3206780291708845, 'test/num_examples': 3581, 'score': 491.2459542751312, 'total_duration': 1388.7649295330048, 'accumulated_submission_time': 491.2459542751312, 'accumulated_eval_time': 897.4186515808105, 'accumulated_logging_time': 0.049484968185424805}
I0307 15:18:57.835591 140465546450688 logging_writer.py:48] [350] accumulated_eval_time=897.419, accumulated_logging_time=0.049485, accumulated_submission_time=491.246, global_step=350, preemption_count=0, score=491.246, test/loss=0.320678, test/num_examples=3581, test/ssim=0.702548, total_duration=1388.76, train/loss=0.304734, train/ssim=0.701841, validation/loss=0.319077, validation/num_examples=3554, validation/ssim=0.684462
I0307 15:20:14.367383 140465538057984 logging_writer.py:48] [400] global_step=400, grad_norm=0.19108282029628754, loss=0.31958502531051636
I0307 15:20:18.922132 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:20:20.214591 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:20:21.532648 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:20:22.830387 140623735375040 submission_runner.py:469] Time since start: 1473.77s, 	Step: 404, 	{'train/ssim': 0.709798880985805, 'train/loss': 0.2986880711146763, 'validation/ssim': 0.6921411448807682, 'validation/loss': 0.313466017878183, 'validation/num_examples': 3554, 'test/ssim': 0.7098529456681094, 'test/loss': 0.31518241074856884, 'test/num_examples': 3581, 'score': 572.3216826915741, 'total_duration': 1473.768880367279, 'accumulated_submission_time': 572.3216826915741, 'accumulated_eval_time': 901.3268578052521, 'accumulated_logging_time': 0.06607556343078613}
I0307 15:20:22.838290 140465546450688 logging_writer.py:48] [404] accumulated_eval_time=901.327, accumulated_logging_time=0.0660756, accumulated_submission_time=572.322, global_step=404, preemption_count=0, score=572.322, test/loss=0.315182, test/num_examples=3581, test/ssim=0.709853, total_duration=1473.77, train/loss=0.298688, train/ssim=0.709799, validation/loss=0.313466, validation/num_examples=3554, validation/ssim=0.692141
I0307 15:21:44.084603 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:21:45.369134 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:21:46.655797 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:21:47.957157 140623735375040 submission_runner.py:469] Time since start: 1558.90s, 	Step: 454, 	{'train/ssim': 0.7116919245038714, 'train/loss': 0.29752087593078613, 'validation/ssim': 0.6948462697180994, 'validation/loss': 0.31156802029843134, 'validation/num_examples': 3554, 'test/ssim': 0.7122706946165527, 'test/loss': 0.3135348876339535, 'test/num_examples': 3581, 'score': 653.5565819740295, 'total_duration': 1558.8956327438354, 'accumulated_submission_time': 653.5565819740295, 'accumulated_eval_time': 905.1993541717529, 'accumulated_logging_time': 0.08144307136535645}
I0307 15:21:47.966649 140465538057984 logging_writer.py:48] [454] accumulated_eval_time=905.199, accumulated_logging_time=0.0814431, accumulated_submission_time=653.557, global_step=454, preemption_count=0, score=653.557, test/loss=0.313535, test/num_examples=3581, test/ssim=0.712271, total_duration=1558.9, train/loss=0.297521, train/ssim=0.711692, validation/loss=0.311568, validation/num_examples=3554, validation/ssim=0.694846
I0307 15:22:55.571782 140465546450688 logging_writer.py:48] [500] global_step=500, grad_norm=0.2824036180973053, loss=0.36635079979896545
I0307 15:23:09.589847 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:23:10.881489 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:23:12.172262 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:23:13.471595 140623735375040 submission_runner.py:469] Time since start: 1644.41s, 	Step: 511, 	{'train/ssim': 0.7140427998134068, 'train/loss': 0.29519735063825336, 'validation/ssim': 0.6971081082714898, 'validation/loss': 0.3092242290816685, 'validation/num_examples': 3554, 'test/ssim': 0.7144494161896119, 'test/loss': 0.3111541586127304, 'test/num_examples': 3581, 'score': 735.1677482128143, 'total_duration': 1644.4100835323334, 'accumulated_submission_time': 735.1677482128143, 'accumulated_eval_time': 909.0810461044312, 'accumulated_logging_time': 0.0994408130645752}
I0307 15:23:13.496345 140465538057984 logging_writer.py:48] [511] accumulated_eval_time=909.081, accumulated_logging_time=0.0994408, accumulated_submission_time=735.168, global_step=511, preemption_count=0, score=735.168, test/loss=0.311154, test/num_examples=3581, test/ssim=0.714449, total_duration=1644.41, train/loss=0.295197, train/ssim=0.714043, validation/loss=0.309224, validation/num_examples=3554, validation/ssim=0.697108
I0307 15:24:33.631665 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:24:34.918611 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:24:36.205759 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:24:37.505364 140623735375040 submission_runner.py:469] Time since start: 1728.44s, 	Step: 562, 	{'train/ssim': 0.7124046598161969, 'train/loss': 0.3007247107369559, 'validation/ssim': 0.6950257687201041, 'validation/loss': 0.3154120673339019, 'validation/num_examples': 3554, 'test/ssim': 0.7124596803223611, 'test/loss': 0.3174884522370672, 'test/num_examples': 3581, 'score': 815.287659406662, 'total_duration': 1728.4437811374664, 'accumulated_submission_time': 815.287659406662, 'accumulated_eval_time': 912.9546277523041, 'accumulated_logging_time': 0.13651657104492188}
I0307 15:24:37.524519 140465546450688 logging_writer.py:48] [562] accumulated_eval_time=912.955, accumulated_logging_time=0.136517, accumulated_submission_time=815.288, global_step=562, preemption_count=0, score=815.288, test/loss=0.317488, test/num_examples=3581, test/ssim=0.71246, total_duration=1728.44, train/loss=0.300725, train/ssim=0.712405, validation/loss=0.315412, validation/num_examples=3554, validation/ssim=0.695026
I0307 15:25:37.948127 140465538057984 logging_writer.py:48] [600] global_step=600, grad_norm=0.3592064380645752, loss=0.34132441878318787
I0307 15:25:59.216216 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:26:00.511542 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:26:01.799354 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:26:03.096265 140623735375040 submission_runner.py:469] Time since start: 1814.03s, 	Step: 619, 	{'train/ssim': 0.7162919044494629, 'train/loss': 0.29481448446001324, 'validation/ssim': 0.6989487115090391, 'validation/loss': 0.3093231836596968, 'validation/num_examples': 3554, 'test/ssim': 0.7164238804846761, 'test/loss': 0.3113341449992146, 'test/num_examples': 3581, 'score': 896.9630463123322, 'total_duration': 1814.0347595214844, 'accumulated_submission_time': 896.9630463123322, 'accumulated_eval_time': 916.8346300125122, 'accumulated_logging_time': 0.1676318645477295}
I0307 15:26:03.104660 140465546450688 logging_writer.py:48] [619] accumulated_eval_time=916.835, accumulated_logging_time=0.167632, accumulated_submission_time=896.963, global_step=619, preemption_count=0, score=896.963, test/loss=0.311334, test/num_examples=3581, test/ssim=0.716424, total_duration=1814.03, train/loss=0.294814, train/ssim=0.716292, validation/loss=0.309323, validation/num_examples=3554, validation/ssim=0.698949
I0307 15:27:24.549548 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:27:25.831960 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:27:27.120512 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:27:28.420979 140623735375040 submission_runner.py:469] Time since start: 1899.36s, 	Step: 667, 	{'train/ssim': 0.7168348857334682, 'train/loss': 0.2931731769016811, 'validation/ssim': 0.7001612399760833, 'validation/loss': 0.3072727184048783, 'validation/num_examples': 3554, 'test/ssim': 0.7174219186330634, 'test/loss': 0.3093600556757889, 'test/num_examples': 3581, 'score': 978.3921360969543, 'total_duration': 1899.3594720363617, 'accumulated_submission_time': 978.3921360969543, 'accumulated_eval_time': 920.7060179710388, 'accumulated_logging_time': 0.18357396125793457}
I0307 15:27:28.429023 140465538057984 logging_writer.py:48] [667] accumulated_eval_time=920.706, accumulated_logging_time=0.183574, accumulated_submission_time=978.392, global_step=667, preemption_count=0, score=978.392, test/loss=0.30936, test/num_examples=3581, test/ssim=0.717422, total_duration=1899.36, train/loss=0.293173, train/ssim=0.716835, validation/loss=0.307273, validation/num_examples=3554, validation/ssim=0.700161
I0307 15:28:21.451872 140465546450688 logging_writer.py:48] [700] global_step=700, grad_norm=0.3030471205711365, loss=0.2648918628692627
I0307 15:28:48.454870 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:28:49.741333 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:28:51.031028 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:28:52.328282 140623735375040 submission_runner.py:469] Time since start: 1983.27s, 	Step: 719, 	{'train/ssim': 0.716047831944057, 'train/loss': 0.2948411192212786, 'validation/ssim': 0.6996615554217079, 'validation/loss': 0.30818515449141815, 'validation/num_examples': 3554, 'test/ssim': 0.7168266682010961, 'test/loss': 0.31048115269826865, 'test/num_examples': 3581, 'score': 1058.4057312011719, 'total_duration': 1983.266755104065, 'accumulated_submission_time': 1058.4057312011719, 'accumulated_eval_time': 924.5793662071228, 'accumulated_logging_time': 0.20059847831726074}
I0307 15:28:52.338016 140465538057984 logging_writer.py:48] [719] accumulated_eval_time=924.579, accumulated_logging_time=0.200598, accumulated_submission_time=1058.41, global_step=719, preemption_count=0, score=1058.41, test/loss=0.310481, test/num_examples=3581, test/ssim=0.716827, total_duration=1983.27, train/loss=0.294841, train/ssim=0.716048, validation/loss=0.308185, validation/num_examples=3554, validation/ssim=0.699662
I0307 15:30:13.380648 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:30:14.678724 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:30:15.968251 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:30:17.264629 140623735375040 submission_runner.py:469] Time since start: 2068.20s, 	Step: 771, 	{'train/ssim': 0.7196765627179827, 'train/loss': 0.2906554767063686, 'validation/ssim': 0.702253196772123, 'validation/loss': 0.30507947141425157, 'validation/num_examples': 3554, 'test/ssim': 0.7196376601333426, 'test/loss': 0.3068244633678616, 'test/num_examples': 3581, 'score': 1139.4371428489685, 'total_duration': 2068.2031099796295, 'accumulated_submission_time': 1139.4371428489685, 'accumulated_eval_time': 928.4632980823517, 'accumulated_logging_time': 0.21805620193481445}
I0307 15:30:17.273818 140465546450688 logging_writer.py:48] [771] accumulated_eval_time=928.463, accumulated_logging_time=0.218056, accumulated_submission_time=1139.44, global_step=771, preemption_count=0, score=1139.44, test/loss=0.306824, test/num_examples=3581, test/ssim=0.719638, total_duration=2068.2, train/loss=0.290655, train/ssim=0.719677, validation/loss=0.305079, validation/num_examples=3554, validation/ssim=0.702253
I0307 15:31:00.435247 140465538057984 logging_writer.py:48] [800] global_step=800, grad_norm=0.5305121541023254, loss=0.19838671386241913
I0307 15:31:39.361848 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:31:40.647454 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:31:41.934036 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:31:43.228213 140623735375040 submission_runner.py:469] Time since start: 2154.17s, 	Step: 821, 	{'train/ssim': 0.7168703760419574, 'train/loss': 0.2906712463923863, 'validation/ssim': 0.6997936551464898, 'validation/loss': 0.3054154223783941, 'validation/num_examples': 3554, 'test/ssim': 0.7171724602284627, 'test/loss': 0.3069323188464291, 'test/num_examples': 3581, 'score': 1221.5134983062744, 'total_duration': 2154.1666975021362, 'accumulated_submission_time': 1221.5134983062744, 'accumulated_eval_time': 932.3296048641205, 'accumulated_logging_time': 0.23600363731384277}
I0307 15:31:43.240394 140465546450688 logging_writer.py:48] [821] accumulated_eval_time=932.33, accumulated_logging_time=0.236004, accumulated_submission_time=1221.51, global_step=821, preemption_count=0, score=1221.51, test/loss=0.306932, test/num_examples=3581, test/ssim=0.717172, total_duration=2154.17, train/loss=0.290671, train/ssim=0.71687, validation/loss=0.305415, validation/num_examples=3554, validation/ssim=0.699794
I0307 15:33:04.709100 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:33:06.006678 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:33:07.296579 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:33:08.595218 140623735375040 submission_runner.py:469] Time since start: 2239.53s, 	Step: 874, 	{'train/ssim': 0.7226708275931222, 'train/loss': 0.28791260719299316, 'validation/ssim': 0.7047189209121765, 'validation/loss': 0.3030704290060495, 'validation/num_examples': 3554, 'test/ssim': 0.7221570604841525, 'test/loss': 0.3045435108908126, 'test/num_examples': 3581, 'score': 1302.9680111408234, 'total_duration': 2239.533702611923, 'accumulated_submission_time': 1302.9680111408234, 'accumulated_eval_time': 936.2156701087952, 'accumulated_logging_time': 0.2590818405151367}
I0307 15:33:08.603871 140465538057984 logging_writer.py:48] [874] accumulated_eval_time=936.216, accumulated_logging_time=0.259082, accumulated_submission_time=1302.97, global_step=874, preemption_count=0, score=1302.97, test/loss=0.304544, test/num_examples=3581, test/ssim=0.722157, total_duration=2239.53, train/loss=0.287913, train/ssim=0.722671, validation/loss=0.30307, validation/num_examples=3554, validation/ssim=0.704719
I0307 15:33:51.797707 140465546450688 logging_writer.py:48] [900] global_step=900, grad_norm=0.46448150277137756, loss=0.27097287774086
I0307 15:34:30.198069 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:34:31.487368 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:34:32.850009 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:34:34.151272 140623735375040 submission_runner.py:469] Time since start: 2325.09s, 	Step: 925, 	{'train/ssim': 0.7242587634495327, 'train/loss': 0.2865838663918631, 'validation/ssim': 0.7066541166203574, 'validation/loss': 0.3011712292707161, 'validation/num_examples': 3554, 'test/ssim': 0.7238684310423066, 'test/loss': 0.3028802389673799, 'test/num_examples': 3581, 'score': 1384.5517058372498, 'total_duration': 2325.0897550582886, 'accumulated_submission_time': 1384.5517058372498, 'accumulated_eval_time': 940.1688132286072, 'accumulated_logging_time': 0.27503418922424316}
I0307 15:34:34.159819 140465538057984 logging_writer.py:48] [925] accumulated_eval_time=940.169, accumulated_logging_time=0.275034, accumulated_submission_time=1384.55, global_step=925, preemption_count=0, score=1384.55, test/loss=0.30288, test/num_examples=3581, test/ssim=0.723868, total_duration=2325.09, train/loss=0.286584, train/ssim=0.724259, validation/loss=0.301171, validation/num_examples=3554, validation/ssim=0.706654
I0307 15:35:45.901668 140465546450688 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.1909288763999939, loss=0.2725052237510681
I0307 15:35:58.732240 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:36:00.029317 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:36:01.316276 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:36:02.618066 140623735375040 submission_runner.py:469] Time since start: 2413.56s, 	Step: 1042, 	{'train/ssim': 0.7244524274553571, 'train/loss': 0.28546881675720215, 'validation/ssim': 0.7069051954004291, 'validation/loss': 0.30002694889341236, 'validation/num_examples': 3554, 'test/ssim': 0.7241503415378037, 'test/loss': 0.3017451998176138, 'test/num_examples': 3581, 'score': 1469.1055796146393, 'total_duration': 2413.556563138962, 'accumulated_submission_time': 1469.1055796146393, 'accumulated_eval_time': 944.0546050071716, 'accumulated_logging_time': 0.29069089889526367}
I0307 15:36:02.626781 140465538057984 logging_writer.py:48] [1042] accumulated_eval_time=944.055, accumulated_logging_time=0.290691, accumulated_submission_time=1469.11, global_step=1042, preemption_count=0, score=1469.11, test/loss=0.301745, test/num_examples=3581, test/ssim=0.72415, total_duration=2413.56, train/loss=0.285469, train/ssim=0.724452, validation/loss=0.300027, validation/num_examples=3554, validation/ssim=0.706905
I0307 15:36:09.957396 140465546450688 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.20680169761180878, loss=0.33843955397605896
I0307 15:36:18.168977 140465538057984 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.08043576776981354, loss=0.3019065856933594
I0307 15:36:26.385506 140465546450688 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.4731966555118561, loss=0.22180132567882538
I0307 15:36:34.611800 140465538057984 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.13493409752845764, loss=0.30733320116996765
I0307 15:36:42.847029 140465546450688 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.18578530848026276, loss=0.29197850823402405
I0307 15:36:51.075561 140465538057984 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.23462148010730743, loss=0.2910623252391815
I0307 15:36:59.302996 140465546450688 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.21730896830558777, loss=0.24488866329193115
I0307 15:37:07.501776 140465538057984 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.13720007240772247, loss=0.2521388828754425
I0307 15:37:15.741989 140465546450688 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.3050534427165985, loss=0.2347370982170105
I0307 15:37:22.666999 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:37:23.957813 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:37:25.249471 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:37:26.548706 140623735375040 submission_runner.py:469] Time since start: 2497.49s, 	Step: 1985, 	{'train/ssim': 0.7296934127807617, 'train/loss': 0.28225294181278776, 'validation/ssim': 0.7117914426306626, 'validation/loss': 0.2975085359915764, 'validation/num_examples': 3554, 'test/ssim': 0.7288630532672438, 'test/loss': 0.29915452076715654, 'test/num_examples': 3581, 'score': 1549.088383436203, 'total_duration': 2497.4871985912323, 'accumulated_submission_time': 1549.088383436203, 'accumulated_eval_time': 947.9362678527832, 'accumulated_logging_time': 0.3070566654205322}
I0307 15:37:26.558244 140465538057984 logging_writer.py:48] [1985] accumulated_eval_time=947.936, accumulated_logging_time=0.307057, accumulated_submission_time=1549.09, global_step=1985, preemption_count=0, score=1549.09, test/loss=0.299155, test/num_examples=3581, test/ssim=0.728863, total_duration=2497.49, train/loss=0.282253, train/ssim=0.729693, validation/loss=0.297509, validation/num_examples=3554, validation/ssim=0.711791
I0307 15:37:27.897606 140465546450688 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.2761295437812805, loss=0.3401084840297699
I0307 15:37:36.111471 140465538057984 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.14248333871364594, loss=0.29075929522514343
I0307 15:37:44.315381 140465546450688 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.23774035274982452, loss=0.2697194218635559
I0307 15:37:52.521491 140465538057984 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.1445111632347107, loss=0.24677351117134094
I0307 15:38:00.728842 140465546450688 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.21216902136802673, loss=0.27956509590148926
I0307 15:38:08.936064 140465538057984 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.11673197150230408, loss=0.3145667016506195
I0307 15:38:17.177357 140465546450688 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.14778465032577515, loss=0.24517670273780823
I0307 15:38:25.424741 140465538057984 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.07109422981739044, loss=0.2683130204677582
I0307 15:38:33.639352 140465546450688 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.09991834312677383, loss=0.28780561685562134
I0307 15:38:41.831353 140465538057984 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.14216504991054535, loss=0.23185700178146362
I0307 15:38:46.612213 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:38:47.899443 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:38:49.193109 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:38:50.491540 140623735375040 submission_runner.py:469] Time since start: 2581.43s, 	Step: 2959, 	{'train/ssim': 0.732860633305141, 'train/loss': 0.2771135228020804, 'validation/ssim': 0.7151523948587859, 'validation/loss': 0.29223907590918685, 'validation/num_examples': 3554, 'test/ssim': 0.7322617961986875, 'test/loss': 0.2937847564620567, 'test/num_examples': 3581, 'score': 1629.0843486785889, 'total_duration': 2581.430034160614, 'accumulated_submission_time': 1629.0843486785889, 'accumulated_eval_time': 951.8155510425568, 'accumulated_logging_time': 0.324265718460083}
I0307 15:38:50.500592 140465546450688 logging_writer.py:48] [2959] accumulated_eval_time=951.816, accumulated_logging_time=0.324266, accumulated_submission_time=1629.08, global_step=2959, preemption_count=0, score=1629.08, test/loss=0.293785, test/num_examples=3581, test/ssim=0.732262, total_duration=2581.43, train/loss=0.277114, train/ssim=0.732861, validation/loss=0.292239, validation/num_examples=3554, validation/ssim=0.715152
I0307 15:38:53.966655 140465538057984 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.11052205413579941, loss=0.26510089635849
I0307 15:39:02.170346 140465546450688 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.2223995327949524, loss=0.2730160057544708
I0307 15:39:10.383574 140465538057984 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.13284966349601746, loss=0.34611600637435913
I0307 15:39:18.579012 140465546450688 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.16252686083316803, loss=0.27896931767463684
I0307 15:39:26.792523 140465538057984 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.08426827937364578, loss=0.2808097004890442
I0307 15:39:35.014028 140465546450688 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.16391301155090332, loss=0.2465365082025528
I0307 15:39:43.235390 140465538057984 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.11443594843149185, loss=0.24967056512832642
I0307 15:39:51.470193 140465546450688 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.17268460988998413, loss=0.23494543135166168
I0307 15:39:59.670871 140465538057984 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.1270473152399063, loss=0.30134129524230957
I0307 15:40:07.884695 140465546450688 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.14277979731559753, loss=0.2795547544956207
I0307 15:40:10.508987 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:40:11.800275 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:40:13.091085 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:40:14.388793 140623735375040 submission_runner.py:469] Time since start: 2665.33s, 	Step: 3933, 	{'train/ssim': 0.7367858205522809, 'train/loss': 0.275369541985648, 'validation/ssim': 0.7182082743475662, 'validation/loss': 0.2909572689333322, 'validation/num_examples': 3554, 'test/ssim': 0.7353945137967747, 'test/loss': 0.29253811211733804, 'test/num_examples': 3581, 'score': 1709.0345633029938, 'total_duration': 2665.327283859253, 'accumulated_submission_time': 1709.0345633029938, 'accumulated_eval_time': 955.6953058242798, 'accumulated_logging_time': 0.3417844772338867}
I0307 15:40:14.398307 140465538057984 logging_writer.py:48] [3933] accumulated_eval_time=955.695, accumulated_logging_time=0.341784, accumulated_submission_time=1709.03, global_step=3933, preemption_count=0, score=1709.03, test/loss=0.292538, test/num_examples=3581, test/ssim=0.735395, total_duration=2665.33, train/loss=0.27537, train/ssim=0.736786, validation/loss=0.290957, validation/num_examples=3554, validation/ssim=0.718208
I0307 15:40:19.991522 140465546450688 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.14639179408550262, loss=0.20600149035453796
I0307 15:40:28.186417 140465538057984 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.1878463327884674, loss=0.22962257266044617
I0307 15:40:36.378293 140465546450688 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.13583320379257202, loss=0.2931380867958069
I0307 15:40:44.601671 140465538057984 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.2228201925754547, loss=0.2702886462211609
I0307 15:40:52.811711 140465546450688 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.041393768042325974, loss=0.26978522539138794
I0307 15:41:01.009293 140465538057984 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.26528745889663696, loss=0.2678631842136383
I0307 15:41:09.224857 140465546450688 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.13751249015331268, loss=0.2893259823322296
I0307 15:41:17.434695 140465538057984 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.09141778945922852, loss=0.2945822477340698
I0307 15:41:25.652915 140465546450688 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.1691305786371231, loss=0.3110894560813904
I0307 15:41:33.843230 140465538057984 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.07709579169750214, loss=0.2475913166999817
I0307 15:41:34.417673 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:41:35.709775 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:41:37.003730 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:41:38.299032 140623735375040 submission_runner.py:469] Time since start: 2749.24s, 	Step: 4908, 	{'train/ssim': 0.7360732214791434, 'train/loss': 0.2768406016486032, 'validation/ssim': 0.7177403267005487, 'validation/loss': 0.29224968922560846, 'validation/num_examples': 3554, 'test/ssim': 0.7349819086410919, 'test/loss': 0.2939701288048031, 'test/num_examples': 3581, 'score': 1788.9964122772217, 'total_duration': 2749.2374958992004, 'accumulated_submission_time': 1788.9964122772217, 'accumulated_eval_time': 959.5765860080719, 'accumulated_logging_time': 0.35947442054748535}
I0307 15:41:38.311003 140465546450688 logging_writer.py:48] [4908] accumulated_eval_time=959.577, accumulated_logging_time=0.359474, accumulated_submission_time=1789, global_step=4908, preemption_count=0, score=1789, test/loss=0.29397, test/num_examples=3581, test/ssim=0.734982, total_duration=2749.24, train/loss=0.276841, train/ssim=0.736073, validation/loss=0.29225, validation/num_examples=3554, validation/ssim=0.71774
I0307 15:41:45.966093 140465538057984 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.11655347049236298, loss=0.3160921037197113
I0307 15:41:54.174277 140465546450688 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.17461127042770386, loss=0.26844727993011475
I0307 15:42:02.373699 140465538057984 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.12002096325159073, loss=0.2214924842119217
I0307 15:42:10.563837 140465546450688 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.06402844935655594, loss=0.24240249395370483
I0307 15:42:21.385597 140465538057984 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.2641109526157379, loss=0.21112701296806335
I0307 15:42:29.789370 140465546450688 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.1326693743467331, loss=0.2601798176765442
I0307 15:42:38.174514 140465538057984 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.22779783606529236, loss=0.3056420087814331
I0307 15:42:46.362032 140465546450688 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.06402061879634857, loss=0.3186800479888916
I0307 15:42:54.564848 140465538057984 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.1619536131620407, loss=0.2751871645450592
I0307 15:42:58.360149 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:42:59.652745 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:43:00.944303 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:43:02.238312 140623735375040 submission_runner.py:469] Time since start: 2833.18s, 	Step: 5847, 	{'train/ssim': 0.738384314945766, 'train/loss': 0.2753558499472482, 'validation/ssim': 0.7201313798053249, 'validation/loss': 0.290738820090479, 'validation/num_examples': 3554, 'test/ssim': 0.737227170635821, 'test/loss': 0.2923655910752932, 'test/num_examples': 3581, 'score': 1868.9860956668854, 'total_duration': 2833.1768052577972, 'accumulated_submission_time': 1868.9860956668854, 'accumulated_eval_time': 963.4547030925751, 'accumulated_logging_time': 0.37937378883361816}
I0307 15:43:02.248684 140465546450688 logging_writer.py:48] [5847] accumulated_eval_time=963.455, accumulated_logging_time=0.379374, accumulated_submission_time=1868.99, global_step=5847, preemption_count=0, score=1868.99, test/loss=0.292366, test/num_examples=3581, test/ssim=0.737227, total_duration=2833.18, train/loss=0.275356, train/ssim=0.738384, validation/loss=0.290739, validation/num_examples=3554, validation/ssim=0.720131
I0307 15:43:06.688461 140465538057984 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.16384513676166534, loss=0.23876041173934937
I0307 15:43:14.886140 140465546450688 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.08072233945131302, loss=0.28953981399536133
I0307 15:43:23.116211 140465538057984 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.1585427224636078, loss=0.31220152974128723
I0307 15:43:31.324397 140465546450688 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.31286248564720154, loss=0.18977713584899902
I0307 15:43:39.533065 140465538057984 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.08840063959360123, loss=0.32101529836654663
I0307 15:43:47.740813 140465546450688 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.13538600504398346, loss=0.35266342759132385
I0307 15:43:55.960388 140465538057984 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.22838424146175385, loss=0.2047128826379776
I0307 15:44:04.167963 140465546450688 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.07066775858402252, loss=0.24515867233276367
I0307 15:44:12.372113 140465538057984 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.08985602855682373, loss=0.2940267026424408
I0307 15:44:20.595245 140465546450688 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.07625981420278549, loss=0.26726508140563965
I0307 15:44:22.312632 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:44:23.602851 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:44:24.897047 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:44:26.191085 140623735375040 submission_runner.py:469] Time since start: 2917.13s, 	Step: 6822, 	{'train/ssim': 0.7388275010245187, 'train/loss': 0.2733966282435826, 'validation/ssim': 0.7199950210150534, 'validation/loss': 0.2893448004778946, 'validation/num_examples': 3554, 'test/ssim': 0.7372138080101578, 'test/loss': 0.29082496896598364, 'test/num_examples': 3581, 'score': 1948.9933586120605, 'total_duration': 2917.129576921463, 'accumulated_submission_time': 1948.9933586120605, 'accumulated_eval_time': 967.3331134319305, 'accumulated_logging_time': 0.39739108085632324}
I0307 15:44:26.201860 140465538057984 logging_writer.py:48] [6822] accumulated_eval_time=967.333, accumulated_logging_time=0.397391, accumulated_submission_time=1948.99, global_step=6822, preemption_count=0, score=1948.99, test/loss=0.290825, test/num_examples=3581, test/ssim=0.737214, total_duration=2917.13, train/loss=0.273397, train/ssim=0.738828, validation/loss=0.289345, validation/num_examples=3554, validation/ssim=0.719995
I0307 15:44:32.700731 140465546450688 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.20573922991752625, loss=0.33740249276161194
I0307 15:44:40.909472 140465538057984 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.16441836953163147, loss=0.27184703946113586
I0307 15:44:49.125007 140465546450688 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.07881182432174683, loss=0.30089718103408813
I0307 15:44:57.332112 140465538057984 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.23755478858947754, loss=0.24341854453086853
I0307 15:45:05.531295 140465546450688 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.05228234827518463, loss=0.2689332067966461
I0307 15:45:13.729649 140465538057984 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.14815811812877655, loss=0.24121356010437012
I0307 15:45:21.944355 140465546450688 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.07792040705680847, loss=0.2695951759815216
I0307 15:45:30.151656 140465538057984 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.08205369859933853, loss=0.3178434371948242
I0307 15:45:38.342788 140465546450688 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.10028814524412155, loss=0.2101643830537796
I0307 15:45:46.211499 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:45:47.502773 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:45:48.794316 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:45:50.086565 140623735375040 submission_runner.py:469] Time since start: 3001.03s, 	Step: 7797, 	{'train/ssim': 0.7402552877153669, 'train/loss': 0.27263457434517996, 'validation/ssim': 0.720736098410242, 'validation/loss': 0.2891081132175014, 'validation/num_examples': 3554, 'test/ssim': 0.7378831664732267, 'test/loss': 0.2906445394311994, 'test/num_examples': 3581, 'score': 2028.9461615085602, 'total_duration': 3001.0250585079193, 'accumulated_submission_time': 2028.9461615085602, 'accumulated_eval_time': 971.2081315517426, 'accumulated_logging_time': 0.415452241897583}
I0307 15:45:50.097279 140465538057984 logging_writer.py:48] [7797] accumulated_eval_time=971.208, accumulated_logging_time=0.415452, accumulated_submission_time=2028.95, global_step=7797, preemption_count=0, score=2028.95, test/loss=0.290645, test/num_examples=3581, test/ssim=0.737883, total_duration=3001.03, train/loss=0.272635, train/ssim=0.740255, validation/loss=0.289108, validation/num_examples=3554, validation/ssim=0.720736
I0307 15:45:50.446499 140465546450688 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.19248370826244354, loss=0.19075235724449158
I0307 15:45:58.643997 140465538057984 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.04260462149977684, loss=0.26079681515693665
I0307 15:46:06.880261 140465546450688 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.08110111206769943, loss=0.2998753488063812
I0307 15:46:15.070017 140465538057984 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.10733750462532043, loss=0.3635371923446655
I0307 15:46:23.266710 140465546450688 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.09965506941080093, loss=0.24475841224193573
I0307 15:46:31.471385 140465538057984 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.12057525664567947, loss=0.23412910103797913
I0307 15:46:39.675585 140465546450688 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.10607240349054337, loss=0.31163883209228516
I0307 15:46:47.870377 140465538057984 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.11105336993932724, loss=0.25969940423965454
I0307 15:46:56.088487 140465546450688 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.07248321920633316, loss=0.24290584027767181
I0307 15:47:04.285331 140465538057984 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.09476669877767563, loss=0.29036882519721985
I0307 15:47:10.116487 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:47:11.404808 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:47:12.699702 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:47:13.995066 140623735375040 submission_runner.py:469] Time since start: 3084.93s, 	Step: 8772, 	{'train/ssim': 0.7415261268615723, 'train/loss': 0.272073711667742, 'validation/ssim': 0.722594699634215, 'validation/loss': 0.2882488467549768, 'validation/num_examples': 3554, 'test/ssim': 0.7397861816269896, 'test/loss': 0.28965826175692894, 'test/num_examples': 3581, 'score': 2108.9076297283173, 'total_duration': 3084.9335582256317, 'accumulated_submission_time': 2108.9076297283173, 'accumulated_eval_time': 975.0866611003876, 'accumulated_logging_time': 0.43488478660583496}
I0307 15:47:14.006127 140465546450688 logging_writer.py:48] [8772] accumulated_eval_time=975.087, accumulated_logging_time=0.434885, accumulated_submission_time=2108.91, global_step=8772, preemption_count=0, score=2108.91, test/loss=0.289658, test/num_examples=3581, test/ssim=0.739786, total_duration=3084.93, train/loss=0.272074, train/ssim=0.741526, validation/loss=0.288249, validation/num_examples=3554, validation/ssim=0.722595
I0307 15:47:16.403338 140465538057984 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.03987981379032135, loss=0.30403566360473633
I0307 15:47:24.604394 140465546450688 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.21702799201011658, loss=0.17369253933429718
I0307 15:47:32.810479 140465538057984 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.06498154252767563, loss=0.24016834795475006
I0307 15:47:41.010508 140465546450688 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.25518086552619934, loss=0.2459840178489685
I0307 15:47:49.202318 140465538057984 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.04183250293135643, loss=0.2864830195903778
I0307 15:47:57.410383 140465546450688 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.03436524048447609, loss=0.25066903233528137
I0307 15:48:05.622126 140465538057984 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.19246803224086761, loss=0.26521310210227966
I0307 15:48:13.835589 140465546450688 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.09031014144420624, loss=0.19030225276947021
I0307 15:48:22.065226 140465538057984 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.07908367365598679, loss=0.24410802125930786
I0307 15:48:30.279303 140465546450688 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.04873882979154587, loss=0.30282965302467346
I0307 15:48:34.064796 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:48:35.353606 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:48:36.648659 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:48:37.943738 140623735375040 submission_runner.py:469] Time since start: 3168.88s, 	Step: 9747, 	{'train/ssim': 0.7413732664925712, 'train/loss': 0.27183447565351215, 'validation/ssim': 0.7225546506796919, 'validation/loss': 0.28767826936858115, 'validation/num_examples': 3554, 'test/ssim': 0.7396875299977311, 'test/loss': 0.2891334378163397, 'test/num_examples': 3581, 'score': 2188.909674167633, 'total_duration': 3168.8822083473206, 'accumulated_submission_time': 2188.909674167633, 'accumulated_eval_time': 978.9655377864838, 'accumulated_logging_time': 0.4535958766937256}
I0307 15:48:37.957057 140465538057984 logging_writer.py:48] [9747] accumulated_eval_time=978.966, accumulated_logging_time=0.453596, accumulated_submission_time=2188.91, global_step=9747, preemption_count=0, score=2188.91, test/loss=0.289133, test/num_examples=3581, test/ssim=0.739688, total_duration=3168.88, train/loss=0.271834, train/ssim=0.741373, validation/loss=0.287678, validation/num_examples=3554, validation/ssim=0.722555
I0307 15:48:42.409297 140465546450688 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.07375341653823853, loss=0.27482840418815613
I0307 15:48:50.632495 140465538057984 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.0339755043387413, loss=0.35249823331832886
I0307 15:48:58.843712 140465546450688 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.14314718544483185, loss=0.23830372095108032
I0307 15:49:07.047306 140465538057984 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.025307293981313705, loss=0.29663941264152527
I0307 15:49:15.252153 140465546450688 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.04614141210913658, loss=0.21860677003860474
I0307 15:49:23.476691 140465538057984 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.06061244010925293, loss=0.3157396614551544
I0307 15:49:31.680065 140465546450688 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.10337353497743607, loss=0.2940284311771393
I0307 15:49:39.876393 140465538057984 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.08851377665996552, loss=0.24071402847766876
I0307 15:49:48.081622 140465546450688 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.10554146766662598, loss=0.24029108881950378
I0307 15:49:56.266248 140465538057984 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.0900309756398201, loss=0.2479487657546997
I0307 15:49:57.992742 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:49:59.280890 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:50:00.574811 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:50:01.871922 140623735375040 submission_runner.py:469] Time since start: 3252.81s, 	Step: 10722, 	{'train/ssim': 0.7422718320574079, 'train/loss': 0.2709884984152658, 'validation/ssim': 0.7230590064671849, 'validation/loss': 0.28717144057532007, 'validation/num_examples': 3554, 'test/ssim': 0.7402164445380132, 'test/loss': 0.2885682532921146, 'test/num_examples': 3581, 'score': 2268.889263153076, 'total_duration': 3252.8103988170624, 'accumulated_submission_time': 2268.889263153076, 'accumulated_eval_time': 982.8446590900421, 'accumulated_logging_time': 0.4746363162994385}
I0307 15:50:01.885611 140465546450688 logging_writer.py:48] [10722] accumulated_eval_time=982.845, accumulated_logging_time=0.474636, accumulated_submission_time=2268.89, global_step=10722, preemption_count=0, score=2268.89, test/loss=0.288568, test/num_examples=3581, test/ssim=0.740216, total_duration=3252.81, train/loss=0.270988, train/ssim=0.742272, validation/loss=0.287171, validation/num_examples=3554, validation/ssim=0.723059
I0307 15:50:08.376535 140465538057984 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.06538035720586777, loss=0.29034796357154846
I0307 15:50:16.574926 140465546450688 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.05935564637184143, loss=0.23844152688980103
I0307 15:50:24.765329 140465538057984 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.04921475797891617, loss=0.26305216550827026
I0307 15:50:32.960163 140465546450688 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.07845112681388855, loss=0.2290155291557312
I0307 15:50:41.184275 140465538057984 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.03797847032546997, loss=0.28755271434783936
I0307 15:50:49.424016 140465546450688 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.04934431612491608, loss=0.27881693840026855
I0307 15:50:57.644297 140465538057984 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.11301451176404953, loss=0.22877006232738495
I0307 15:51:05.847899 140465546450688 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.06866659224033356, loss=0.2501141428947449
I0307 15:51:14.052780 140465538057984 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.05917662754654884, loss=0.24790805578231812
I0307 15:51:21.935592 140623735375040 spec.py:321] Evaluating on the training split.
I0307 15:51:23.226645 140623735375040 spec.py:333] Evaluating on the validation split.
I0307 15:51:24.518671 140623735375040 spec.py:349] Evaluating on the test split.
I0307 15:51:25.816253 140623735375040 submission_runner.py:469] Time since start: 3336.75s, 	Step: 11697, 	{'train/ssim': 0.7433898108346122, 'train/loss': 0.2704073360988072, 'validation/ssim': 0.7241875214327167, 'validation/loss': 0.2866851171215532, 'validation/num_examples': 3554, 'test/ssim': 0.7413603125654495, 'test/loss': 0.28809118710293913, 'test/num_examples': 3581, 'score': 2348.883147239685, 'total_duration': 3336.754744052887, 'accumulated_submission_time': 2348.883147239685, 'accumulated_eval_time': 986.7252702713013, 'accumulated_logging_time': 0.4961555004119873}
I0307 15:51:25.827021 140465546450688 logging_writer.py:48] [11697] accumulated_eval_time=986.725, accumulated_logging_time=0.496156, accumulated_submission_time=2348.88, global_step=11697, preemption_count=0, score=2348.88, test/loss=0.288091, test/num_examples=3581, test/ssim=0.74136, total_duration=3336.75, train/loss=0.270407, train/ssim=0.74339, validation/loss=0.286685, validation/num_examples=3554, validation/ssim=0.724188
I0307 15:51:25.839234 140465538057984 logging_writer.py:48] [11697] global_step=11697, preemption_count=0, score=2348.88
I0307 15:51:26.900710 140623735375040 submission_runner.py:646] Tuning trial 2/5
I0307 15:51:26.900896 140623735375040 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.2, learning_rate=0.0008445074561975979, one_minus_beta1=0.11042418465, beta2=0.9978504782314613, weight_decay=0.08135402759553023, warmup_factor=0.05)
I0307 15:51:26.901924 140623735375040 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/ssim': 0.17906481879098074, 'train/loss': 1.1395844050816126, 'validation/ssim': 0.1789098942487778, 'validation/loss': 1.1338836549706317, 'validation/num_examples': 3554, 'test/ssim': 0.19996194378752444, 'test/loss': 1.1312351647584473, 'test/num_examples': 3581, 'score': 250.8077085018158, 'total_duration': 1136.0656123161316, 'accumulated_submission_time': 250.8077085018158, 'accumulated_eval_time': 885.257749080658, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (251, {'train/ssim': 0.6924285207475934, 'train/loss': 0.31238923754010883, 'validation/ssim': 0.6732763699352842, 'validation/loss': 0.328164018535453, 'validation/num_examples': 3554, 'test/ssim': 0.6923177719648841, 'test/loss': 0.3293103194376571, 'test/num_examples': 3581, 'score': 330.92598128318787, 'total_duration': 1220.661774635315, 'accumulated_submission_time': 330.92598128318787, 'accumulated_eval_time': 889.6762204170227, 'accumulated_logging_time': 0.015365123748779297, 'global_step': 251, 'preemption_count': 0}), (301, {'train/ssim': 0.6996287618364606, 'train/loss': 0.30705574580601286, 'validation/ssim': 0.6811961022131753, 'validation/loss': 0.32210433006823297, 'validation/num_examples': 3554, 'test/ssim': 0.699741051404112, 'test/loss': 0.3233556675531451, 'test/num_examples': 3581, 'score': 410.9870569705963, 'total_duration': 1304.6111092567444, 'accumulated_submission_time': 410.9870569705963, 'accumulated_eval_time': 893.5436208248138, 'accumulated_logging_time': 0.03296637535095215, 'global_step': 301, 'preemption_count': 0}), (350, {'train/ssim': 0.7018409456525531, 'train/loss': 0.30473388944353375, 'validation/ssim': 0.6844619124138295, 'validation/loss': 0.3190767527565771, 'validation/num_examples': 3554, 'test/ssim': 0.7025477482066811, 'test/loss': 0.3206780291708845, 'test/num_examples': 3581, 'score': 491.2459542751312, 'total_duration': 1388.7649295330048, 'accumulated_submission_time': 491.2459542751312, 'accumulated_eval_time': 897.4186515808105, 'accumulated_logging_time': 0.049484968185424805, 'global_step': 350, 'preemption_count': 0}), (404, {'train/ssim': 0.709798880985805, 'train/loss': 0.2986880711146763, 'validation/ssim': 0.6921411448807682, 'validation/loss': 0.313466017878183, 'validation/num_examples': 3554, 'test/ssim': 0.7098529456681094, 'test/loss': 0.31518241074856884, 'test/num_examples': 3581, 'score': 572.3216826915741, 'total_duration': 1473.768880367279, 'accumulated_submission_time': 572.3216826915741, 'accumulated_eval_time': 901.3268578052521, 'accumulated_logging_time': 0.06607556343078613, 'global_step': 404, 'preemption_count': 0}), (454, {'train/ssim': 0.7116919245038714, 'train/loss': 0.29752087593078613, 'validation/ssim': 0.6948462697180994, 'validation/loss': 0.31156802029843134, 'validation/num_examples': 3554, 'test/ssim': 0.7122706946165527, 'test/loss': 0.3135348876339535, 'test/num_examples': 3581, 'score': 653.5565819740295, 'total_duration': 1558.8956327438354, 'accumulated_submission_time': 653.5565819740295, 'accumulated_eval_time': 905.1993541717529, 'accumulated_logging_time': 0.08144307136535645, 'global_step': 454, 'preemption_count': 0}), (511, {'train/ssim': 0.7140427998134068, 'train/loss': 0.29519735063825336, 'validation/ssim': 0.6971081082714898, 'validation/loss': 0.3092242290816685, 'validation/num_examples': 3554, 'test/ssim': 0.7144494161896119, 'test/loss': 0.3111541586127304, 'test/num_examples': 3581, 'score': 735.1677482128143, 'total_duration': 1644.4100835323334, 'accumulated_submission_time': 735.1677482128143, 'accumulated_eval_time': 909.0810461044312, 'accumulated_logging_time': 0.0994408130645752, 'global_step': 511, 'preemption_count': 0}), (562, {'train/ssim': 0.7124046598161969, 'train/loss': 0.3007247107369559, 'validation/ssim': 0.6950257687201041, 'validation/loss': 0.3154120673339019, 'validation/num_examples': 3554, 'test/ssim': 0.7124596803223611, 'test/loss': 0.3174884522370672, 'test/num_examples': 3581, 'score': 815.287659406662, 'total_duration': 1728.4437811374664, 'accumulated_submission_time': 815.287659406662, 'accumulated_eval_time': 912.9546277523041, 'accumulated_logging_time': 0.13651657104492188, 'global_step': 562, 'preemption_count': 0}), (619, {'train/ssim': 0.7162919044494629, 'train/loss': 0.29481448446001324, 'validation/ssim': 0.6989487115090391, 'validation/loss': 0.3093231836596968, 'validation/num_examples': 3554, 'test/ssim': 0.7164238804846761, 'test/loss': 0.3113341449992146, 'test/num_examples': 3581, 'score': 896.9630463123322, 'total_duration': 1814.0347595214844, 'accumulated_submission_time': 896.9630463123322, 'accumulated_eval_time': 916.8346300125122, 'accumulated_logging_time': 0.1676318645477295, 'global_step': 619, 'preemption_count': 0}), (667, {'train/ssim': 0.7168348857334682, 'train/loss': 0.2931731769016811, 'validation/ssim': 0.7001612399760833, 'validation/loss': 0.3072727184048783, 'validation/num_examples': 3554, 'test/ssim': 0.7174219186330634, 'test/loss': 0.3093600556757889, 'test/num_examples': 3581, 'score': 978.3921360969543, 'total_duration': 1899.3594720363617, 'accumulated_submission_time': 978.3921360969543, 'accumulated_eval_time': 920.7060179710388, 'accumulated_logging_time': 0.18357396125793457, 'global_step': 667, 'preemption_count': 0}), (719, {'train/ssim': 0.716047831944057, 'train/loss': 0.2948411192212786, 'validation/ssim': 0.6996615554217079, 'validation/loss': 0.30818515449141815, 'validation/num_examples': 3554, 'test/ssim': 0.7168266682010961, 'test/loss': 0.31048115269826865, 'test/num_examples': 3581, 'score': 1058.4057312011719, 'total_duration': 1983.266755104065, 'accumulated_submission_time': 1058.4057312011719, 'accumulated_eval_time': 924.5793662071228, 'accumulated_logging_time': 0.20059847831726074, 'global_step': 719, 'preemption_count': 0}), (771, {'train/ssim': 0.7196765627179827, 'train/loss': 0.2906554767063686, 'validation/ssim': 0.702253196772123, 'validation/loss': 0.30507947141425157, 'validation/num_examples': 3554, 'test/ssim': 0.7196376601333426, 'test/loss': 0.3068244633678616, 'test/num_examples': 3581, 'score': 1139.4371428489685, 'total_duration': 2068.2031099796295, 'accumulated_submission_time': 1139.4371428489685, 'accumulated_eval_time': 928.4632980823517, 'accumulated_logging_time': 0.21805620193481445, 'global_step': 771, 'preemption_count': 0}), (821, {'train/ssim': 0.7168703760419574, 'train/loss': 0.2906712463923863, 'validation/ssim': 0.6997936551464898, 'validation/loss': 0.3054154223783941, 'validation/num_examples': 3554, 'test/ssim': 0.7171724602284627, 'test/loss': 0.3069323188464291, 'test/num_examples': 3581, 'score': 1221.5134983062744, 'total_duration': 2154.1666975021362, 'accumulated_submission_time': 1221.5134983062744, 'accumulated_eval_time': 932.3296048641205, 'accumulated_logging_time': 0.23600363731384277, 'global_step': 821, 'preemption_count': 0}), (874, {'train/ssim': 0.7226708275931222, 'train/loss': 0.28791260719299316, 'validation/ssim': 0.7047189209121765, 'validation/loss': 0.3030704290060495, 'validation/num_examples': 3554, 'test/ssim': 0.7221570604841525, 'test/loss': 0.3045435108908126, 'test/num_examples': 3581, 'score': 1302.9680111408234, 'total_duration': 2239.533702611923, 'accumulated_submission_time': 1302.9680111408234, 'accumulated_eval_time': 936.2156701087952, 'accumulated_logging_time': 0.2590818405151367, 'global_step': 874, 'preemption_count': 0}), (925, {'train/ssim': 0.7242587634495327, 'train/loss': 0.2865838663918631, 'validation/ssim': 0.7066541166203574, 'validation/loss': 0.3011712292707161, 'validation/num_examples': 3554, 'test/ssim': 0.7238684310423066, 'test/loss': 0.3028802389673799, 'test/num_examples': 3581, 'score': 1384.5517058372498, 'total_duration': 2325.0897550582886, 'accumulated_submission_time': 1384.5517058372498, 'accumulated_eval_time': 940.1688132286072, 'accumulated_logging_time': 0.27503418922424316, 'global_step': 925, 'preemption_count': 0}), (1042, {'train/ssim': 0.7244524274553571, 'train/loss': 0.28546881675720215, 'validation/ssim': 0.7069051954004291, 'validation/loss': 0.30002694889341236, 'validation/num_examples': 3554, 'test/ssim': 0.7241503415378037, 'test/loss': 0.3017451998176138, 'test/num_examples': 3581, 'score': 1469.1055796146393, 'total_duration': 2413.556563138962, 'accumulated_submission_time': 1469.1055796146393, 'accumulated_eval_time': 944.0546050071716, 'accumulated_logging_time': 0.29069089889526367, 'global_step': 1042, 'preemption_count': 0}), (1985, {'train/ssim': 0.7296934127807617, 'train/loss': 0.28225294181278776, 'validation/ssim': 0.7117914426306626, 'validation/loss': 0.2975085359915764, 'validation/num_examples': 3554, 'test/ssim': 0.7288630532672438, 'test/loss': 0.29915452076715654, 'test/num_examples': 3581, 'score': 1549.088383436203, 'total_duration': 2497.4871985912323, 'accumulated_submission_time': 1549.088383436203, 'accumulated_eval_time': 947.9362678527832, 'accumulated_logging_time': 0.3070566654205322, 'global_step': 1985, 'preemption_count': 0}), (2959, {'train/ssim': 0.732860633305141, 'train/loss': 0.2771135228020804, 'validation/ssim': 0.7151523948587859, 'validation/loss': 0.29223907590918685, 'validation/num_examples': 3554, 'test/ssim': 0.7322617961986875, 'test/loss': 0.2937847564620567, 'test/num_examples': 3581, 'score': 1629.0843486785889, 'total_duration': 2581.430034160614, 'accumulated_submission_time': 1629.0843486785889, 'accumulated_eval_time': 951.8155510425568, 'accumulated_logging_time': 0.324265718460083, 'global_step': 2959, 'preemption_count': 0}), (3933, {'train/ssim': 0.7367858205522809, 'train/loss': 0.275369541985648, 'validation/ssim': 0.7182082743475662, 'validation/loss': 0.2909572689333322, 'validation/num_examples': 3554, 'test/ssim': 0.7353945137967747, 'test/loss': 0.29253811211733804, 'test/num_examples': 3581, 'score': 1709.0345633029938, 'total_duration': 2665.327283859253, 'accumulated_submission_time': 1709.0345633029938, 'accumulated_eval_time': 955.6953058242798, 'accumulated_logging_time': 0.3417844772338867, 'global_step': 3933, 'preemption_count': 0}), (4908, {'train/ssim': 0.7360732214791434, 'train/loss': 0.2768406016486032, 'validation/ssim': 0.7177403267005487, 'validation/loss': 0.29224968922560846, 'validation/num_examples': 3554, 'test/ssim': 0.7349819086410919, 'test/loss': 0.2939701288048031, 'test/num_examples': 3581, 'score': 1788.9964122772217, 'total_duration': 2749.2374958992004, 'accumulated_submission_time': 1788.9964122772217, 'accumulated_eval_time': 959.5765860080719, 'accumulated_logging_time': 0.35947442054748535, 'global_step': 4908, 'preemption_count': 0}), (5847, {'train/ssim': 0.738384314945766, 'train/loss': 0.2753558499472482, 'validation/ssim': 0.7201313798053249, 'validation/loss': 0.290738820090479, 'validation/num_examples': 3554, 'test/ssim': 0.737227170635821, 'test/loss': 0.2923655910752932, 'test/num_examples': 3581, 'score': 1868.9860956668854, 'total_duration': 2833.1768052577972, 'accumulated_submission_time': 1868.9860956668854, 'accumulated_eval_time': 963.4547030925751, 'accumulated_logging_time': 0.37937378883361816, 'global_step': 5847, 'preemption_count': 0}), (6822, {'train/ssim': 0.7388275010245187, 'train/loss': 0.2733966282435826, 'validation/ssim': 0.7199950210150534, 'validation/loss': 0.2893448004778946, 'validation/num_examples': 3554, 'test/ssim': 0.7372138080101578, 'test/loss': 0.29082496896598364, 'test/num_examples': 3581, 'score': 1948.9933586120605, 'total_duration': 2917.129576921463, 'accumulated_submission_time': 1948.9933586120605, 'accumulated_eval_time': 967.3331134319305, 'accumulated_logging_time': 0.39739108085632324, 'global_step': 6822, 'preemption_count': 0}), (7797, {'train/ssim': 0.7402552877153669, 'train/loss': 0.27263457434517996, 'validation/ssim': 0.720736098410242, 'validation/loss': 0.2891081132175014, 'validation/num_examples': 3554, 'test/ssim': 0.7378831664732267, 'test/loss': 0.2906445394311994, 'test/num_examples': 3581, 'score': 2028.9461615085602, 'total_duration': 3001.0250585079193, 'accumulated_submission_time': 2028.9461615085602, 'accumulated_eval_time': 971.2081315517426, 'accumulated_logging_time': 0.415452241897583, 'global_step': 7797, 'preemption_count': 0}), (8772, {'train/ssim': 0.7415261268615723, 'train/loss': 0.272073711667742, 'validation/ssim': 0.722594699634215, 'validation/loss': 0.2882488467549768, 'validation/num_examples': 3554, 'test/ssim': 0.7397861816269896, 'test/loss': 0.28965826175692894, 'test/num_examples': 3581, 'score': 2108.9076297283173, 'total_duration': 3084.9335582256317, 'accumulated_submission_time': 2108.9076297283173, 'accumulated_eval_time': 975.0866611003876, 'accumulated_logging_time': 0.43488478660583496, 'global_step': 8772, 'preemption_count': 0}), (9747, {'train/ssim': 0.7413732664925712, 'train/loss': 0.27183447565351215, 'validation/ssim': 0.7225546506796919, 'validation/loss': 0.28767826936858115, 'validation/num_examples': 3554, 'test/ssim': 0.7396875299977311, 'test/loss': 0.2891334378163397, 'test/num_examples': 3581, 'score': 2188.909674167633, 'total_duration': 3168.8822083473206, 'accumulated_submission_time': 2188.909674167633, 'accumulated_eval_time': 978.9655377864838, 'accumulated_logging_time': 0.4535958766937256, 'global_step': 9747, 'preemption_count': 0}), (10722, {'train/ssim': 0.7422718320574079, 'train/loss': 0.2709884984152658, 'validation/ssim': 0.7230590064671849, 'validation/loss': 0.28717144057532007, 'validation/num_examples': 3554, 'test/ssim': 0.7402164445380132, 'test/loss': 0.2885682532921146, 'test/num_examples': 3581, 'score': 2268.889263153076, 'total_duration': 3252.8103988170624, 'accumulated_submission_time': 2268.889263153076, 'accumulated_eval_time': 982.8446590900421, 'accumulated_logging_time': 0.4746363162994385, 'global_step': 10722, 'preemption_count': 0}), (11697, {'train/ssim': 0.7433898108346122, 'train/loss': 0.2704073360988072, 'validation/ssim': 0.7241875214327167, 'validation/loss': 0.2866851171215532, 'validation/num_examples': 3554, 'test/ssim': 0.7413603125654495, 'test/loss': 0.28809118710293913, 'test/num_examples': 3581, 'score': 2348.883147239685, 'total_duration': 3336.754744052887, 'accumulated_submission_time': 2348.883147239685, 'accumulated_eval_time': 986.7252702713013, 'accumulated_logging_time': 0.4961555004119873, 'global_step': 11697, 'preemption_count': 0})], 'global_step': 11697}
I0307 15:51:26.902015 140623735375040 submission_runner.py:649] Timing: 2348.883147239685
I0307 15:51:26.902053 140623735375040 submission_runner.py:651] Total number of evals: 27
I0307 15:51:26.902087 140623735375040 submission_runner.py:652] ====================
I0307 15:51:26.902207 140623735375040 submission_runner.py:750] Final fastmri score: 1
