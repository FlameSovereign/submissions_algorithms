python submission_runner.py --framework=jax --workload=fastmri --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_0 --overwrite=True --save_checkpoints=False --rng_seed=91121625 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=4 --hparam_end_index=5 2>&1 | tee -a /logs/fastmri_jax_03-07-2025-15-15-13.log
2025-03-07 15:15:31.834438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741360532.360712       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741360532.500993       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0307 15:16:20.983943 140545907463360 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax.
I0307 15:16:24.407613 140545907463360 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0307 15:16:24.410911 140545907463360 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0307 15:16:24.430446 140545907463360 submission_runner.py:606] Using RNG seed 91121625
I0307 15:16:27.783987 140545907463360 submission_runner.py:615] --- Tuning run 5/5 ---
I0307 15:16:27.784189 140545907463360 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_5.
I0307 15:16:27.784379 140545907463360 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_5/hparams.json.
I0307 15:16:28.019864 140545907463360 submission_runner.py:218] Initializing dataset.
I0307 15:16:34.101118 140545907463360 submission_runner.py:229] Initializing model.
I0307 15:16:45.870666 140545907463360 submission_runner.py:272] Initializing optimizer.
I0307 15:16:46.391737 140545907463360 submission_runner.py:279] Initializing metrics bundle.
I0307 15:16:46.391970 140545907463360 submission_runner.py:301] Initializing checkpoint and logger.
I0307 15:16:46.392875 140545907463360 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_5 with prefix checkpoint_
I0307 15:16:46.393004 140545907463360 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_5/meta_data_0.json.
I0307 15:16:46.393198 140545907463360 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0307 15:16:46.393257 140545907463360 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0307 15:16:47.105187 140545907463360 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_5/flags_0.json.
I0307 15:16:47.333745 140545907463360 submission_runner.py:337] Starting training loop.
E0307 15:20:42.788657       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:20:43.000178       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:20:43.406073       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:20:43.615404       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:20:46.156956       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:20:46.367086       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
I0307 15:21:04.610134 140409272841984 logging_writer.py:48] [0] global_step=0, grad_norm=4.460206508636475, loss=1.154383897781372
I0307 15:21:04.939567 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:28:19.748820 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:32:23.842503 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:36:36.977839 140545907463360 submission_runner.py:469] Time since start: 1189.64s, 	Step: 1, 	{'train/ssim': 0.20131874084472656, 'train/loss': 1.2105323246547155, 'validation/ssim': 0.19433537076951146, 'validation/loss': 1.2141275400517022, 'validation/num_examples': 3554, 'test/ssim': 0.21488866137579413, 'test/loss': 1.2124597484990227, 'test/num_examples': 3581, 'score': 257.6056706905365, 'total_duration': 1189.643996477127, 'accumulated_submission_time': 257.6056706905365, 'accumulated_eval_time': 932.0381655693054, 'accumulated_logging_time': 0}
I0307 15:36:36.985712 140390694889216 logging_writer.py:48] [1] accumulated_eval_time=932.038, accumulated_logging_time=0, accumulated_submission_time=257.606, global_step=1, preemption_count=0, score=257.606, test/loss=1.21246, test/num_examples=3581, test/ssim=0.214889, total_duration=1189.64, train/loss=1.21053, train/ssim=0.201319, validation/loss=1.21413, validation/num_examples=3554, validation/ssim=0.194335
I0307 15:36:50.153547 140390686496512 logging_writer.py:48] [100] global_step=100, grad_norm=0.18957006931304932, loss=0.3745841383934021
I0307 15:37:08.919178 140390694889216 logging_writer.py:48] [200] global_step=200, grad_norm=0.12396910041570663, loss=0.31860560178756714
I0307 15:37:58.414952 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:38:00.593500 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:38:01.910441 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:38:03.222377 140545907463360 submission_runner.py:469] Time since start: 1275.89s, 	Step: 245, 	{'train/ssim': 0.6934787205287388, 'train/loss': 0.31765055656433105, 'validation/ssim': 0.6731690002681837, 'validation/loss': 0.3340730940819323, 'validation/num_examples': 3554, 'test/ssim': 0.6919718435841944, 'test/loss': 0.33537991717353743, 'test/num_examples': 3581, 'score': 338.98561120033264, 'total_duration': 1275.8885860443115, 'accumulated_submission_time': 338.98561120033264, 'accumulated_eval_time': 936.8455543518066, 'accumulated_logging_time': 0.016571998596191406}
I0307 15:38:03.230942 140390686496512 logging_writer.py:48] [245] accumulated_eval_time=936.846, accumulated_logging_time=0.016572, accumulated_submission_time=338.986, global_step=245, preemption_count=0, score=338.986, test/loss=0.33538, test/num_examples=3581, test/ssim=0.691972, total_duration=1275.89, train/loss=0.317651, train/ssim=0.693479, validation/loss=0.334073, validation/num_examples=3554, validation/ssim=0.673169
I0307 15:39:23.889096 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:39:25.197141 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:39:26.509981 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:39:27.827004 140545907463360 submission_runner.py:469] Time since start: 1360.49s, 	Step: 287, 	{'train/ssim': 0.6991327149527413, 'train/loss': 0.3128558226994106, 'validation/ssim': 0.6795797181652715, 'validation/loss': 0.3283787578696539, 'validation/num_examples': 3554, 'test/ssim': 0.6981606482127897, 'test/loss': 0.32993549942404354, 'test/num_examples': 3581, 'score': 419.6313986778259, 'total_duration': 1360.4931252002716, 'accumulated_submission_time': 419.6313986778259, 'accumulated_eval_time': 940.783328294754, 'accumulated_logging_time': 0.03460264205932617}
I0307 15:39:27.882493 140390694889216 logging_writer.py:48] [287] accumulated_eval_time=940.783, accumulated_logging_time=0.0346026, accumulated_submission_time=419.631, global_step=287, preemption_count=0, score=419.631, test/loss=0.329935, test/num_examples=3581, test/ssim=0.698161, total_duration=1360.49, train/loss=0.312856, train/ssim=0.699133, validation/loss=0.328379, validation/num_examples=3554, validation/ssim=0.67958
I0307 15:39:57.129239 140390686496512 logging_writer.py:48] [300] global_step=300, grad_norm=0.11843834072351456, loss=0.37654799222946167
I0307 15:40:48.864473 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:40:50.176396 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:40:51.490918 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:40:52.805974 140545907463360 submission_runner.py:469] Time since start: 1445.47s, 	Step: 323, 	{'train/ssim': 0.7017188753400531, 'train/loss': 0.3123376710074289, 'validation/ssim': 0.6828578933947664, 'validation/loss': 0.3273175636166995, 'validation/num_examples': 3554, 'test/ssim': 0.7011261284601019, 'test/loss': 0.32916677347676976, 'test/num_examples': 3581, 'score': 500.576872587204, 'total_duration': 1445.4720141887665, 'accumulated_submission_time': 500.576872587204, 'accumulated_eval_time': 944.7246146202087, 'accumulated_logging_time': 0.12395620346069336}
I0307 15:40:52.843568 140390694889216 logging_writer.py:48] [323] accumulated_eval_time=944.725, accumulated_logging_time=0.123956, accumulated_submission_time=500.577, global_step=323, preemption_count=0, score=500.577, test/loss=0.329167, test/num_examples=3581, test/ssim=0.701126, total_duration=1445.47, train/loss=0.312338, train/ssim=0.701719, validation/loss=0.327318, validation/num_examples=3554, validation/ssim=0.682858
I0307 15:42:13.917039 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:42:15.227527 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:42:16.537451 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:42:17.852380 140545907463360 submission_runner.py:469] Time since start: 1530.52s, 	Step: 366, 	{'train/ssim': 0.7062311172485352, 'train/loss': 0.3063415118626186, 'validation/ssim': 0.6874691561225028, 'validation/loss': 0.321555425829611, 'validation/num_examples': 3554, 'test/ssim': 0.7054770266467119, 'test/loss': 0.3234238783030229, 'test/num_examples': 3581, 'score': 581.6043388843536, 'total_duration': 1530.5185878276825, 'accumulated_submission_time': 581.6043388843536, 'accumulated_eval_time': 948.6599049568176, 'accumulated_logging_time': 0.2041318416595459}
I0307 15:42:17.901477 140390686496512 logging_writer.py:48] [366] accumulated_eval_time=948.66, accumulated_logging_time=0.204132, accumulated_submission_time=581.604, global_step=366, preemption_count=0, score=581.604, test/loss=0.323424, test/num_examples=3581, test/ssim=0.705477, total_duration=1530.52, train/loss=0.306342, train/ssim=0.706231, validation/loss=0.321555, validation/num_examples=3554, validation/ssim=0.687469
I0307 15:43:35.553083 140390694889216 logging_writer.py:48] [400] global_step=400, grad_norm=0.2091907113790512, loss=0.33949753642082214
I0307 15:43:39.163140 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:43:40.476275 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:43:41.788497 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:43:43.100775 140545907463360 submission_runner.py:469] Time since start: 1615.77s, 	Step: 404, 	{'train/ssim': 0.709153379712786, 'train/loss': 0.30632046290806364, 'validation/ssim': 0.6909369284608892, 'validation/loss': 0.3210447501384883, 'validation/num_examples': 3554, 'test/ssim': 0.7087407797882924, 'test/loss': 0.3230555538890149, 'test/num_examples': 3581, 'score': 662.8552556037903, 'total_duration': 1615.7669820785522, 'accumulated_submission_time': 662.8552556037903, 'accumulated_eval_time': 952.5974872112274, 'accumulated_logging_time': 0.26107287406921387}
I0307 15:43:43.110303 140390686496512 logging_writer.py:48] [404] accumulated_eval_time=952.597, accumulated_logging_time=0.261073, accumulated_submission_time=662.855, global_step=404, preemption_count=0, score=662.855, test/loss=0.323056, test/num_examples=3581, test/ssim=0.708741, total_duration=1615.77, train/loss=0.30632, train/ssim=0.709153, validation/loss=0.321045, validation/num_examples=3554, validation/ssim=0.690937
I0307 15:45:03.837969 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:45:05.147191 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:45:06.456957 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:45:07.771715 140545907463360 submission_runner.py:469] Time since start: 1700.44s, 	Step: 441, 	{'train/ssim': 0.7082914624895368, 'train/loss': 0.30632972717285156, 'validation/ssim': 0.6893056376837718, 'validation/loss': 0.321843805780019, 'validation/num_examples': 3554, 'test/ssim': 0.7067220006632225, 'test/loss': 0.3240722724426662, 'test/num_examples': 3581, 'score': 743.5722634792328, 'total_duration': 1700.4379181861877, 'accumulated_submission_time': 743.5722634792328, 'accumulated_eval_time': 956.5311770439148, 'accumulated_logging_time': 0.2785453796386719}
I0307 15:45:07.781136 140390694889216 logging_writer.py:48] [441] accumulated_eval_time=956.531, accumulated_logging_time=0.278545, accumulated_submission_time=743.572, global_step=441, preemption_count=0, score=743.572, test/loss=0.324072, test/num_examples=3581, test/ssim=0.706722, total_duration=1700.44, train/loss=0.30633, train/ssim=0.708291, validation/loss=0.321844, validation/num_examples=3554, validation/ssim=0.689306
I0307 15:46:29.407990 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:46:30.717500 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:46:32.030170 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:46:33.343499 140545907463360 submission_runner.py:469] Time since start: 1786.01s, 	Step: 483, 	{'train/ssim': 0.710026468549456, 'train/loss': 0.3017918382372175, 'validation/ssim': 0.6910751420054868, 'validation/loss': 0.3168116512094647, 'validation/num_examples': 3554, 'test/ssim': 0.708769277632819, 'test/loss': 0.31897494207710836, 'test/num_examples': 3581, 'score': 825.1876840591431, 'total_duration': 1786.0097117424011, 'accumulated_submission_time': 825.1876840591431, 'accumulated_eval_time': 960.466639995575, 'accumulated_logging_time': 0.29638099670410156}
I0307 15:46:33.353224 140390686496512 logging_writer.py:48] [483] accumulated_eval_time=960.467, accumulated_logging_time=0.296381, accumulated_submission_time=825.188, global_step=483, preemption_count=0, score=825.188, test/loss=0.318975, test/num_examples=3581, test/ssim=0.708769, total_duration=1786.01, train/loss=0.301792, train/ssim=0.710026, validation/loss=0.316812, validation/num_examples=3554, validation/ssim=0.691075
I0307 15:46:57.689350 140390694889216 logging_writer.py:48] [500] global_step=500, grad_norm=0.09520387649536133, loss=0.4548501670360565
I0307 15:47:54.503618 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:47:55.812409 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:47:57.122366 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:47:58.435206 140545907463360 submission_runner.py:469] Time since start: 1871.10s, 	Step: 521, 	{'train/ssim': 0.7115982600620815, 'train/loss': 0.30224738802228657, 'validation/ssim': 0.693065156008195, 'validation/loss': 0.3170971803337788, 'validation/num_examples': 3554, 'test/ssim': 0.7105540744554594, 'test/loss': 0.31926513603698337, 'test/num_examples': 3581, 'score': 906.32736992836, 'total_duration': 1871.1014235019684, 'accumulated_submission_time': 906.32736992836, 'accumulated_eval_time': 964.3981850147247, 'accumulated_logging_time': 0.314345121383667}
I0307 15:47:58.444520 140390686496512 logging_writer.py:48] [521] accumulated_eval_time=964.398, accumulated_logging_time=0.314345, accumulated_submission_time=906.327, global_step=521, preemption_count=0, score=906.327, test/loss=0.319265, test/num_examples=3581, test/ssim=0.710554, total_duration=1871.1, train/loss=0.302247, train/ssim=0.711598, validation/loss=0.317097, validation/num_examples=3554, validation/ssim=0.693065
I0307 15:49:19.663314 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:49:20.972355 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:49:22.280593 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:49:23.599143 140545907463360 submission_runner.py:469] Time since start: 1956.27s, 	Step: 564, 	{'train/ssim': 0.7141413688659668, 'train/loss': 0.2994446413857596, 'validation/ssim': 0.6961040679296215, 'validation/loss': 0.3139397015246905, 'validation/num_examples': 3554, 'test/ssim': 0.7135573927499302, 'test/loss': 0.3161552235321837, 'test/num_examples': 3581, 'score': 987.5353055000305, 'total_duration': 1956.2653486728668, 'accumulated_submission_time': 987.5353055000305, 'accumulated_eval_time': 968.3339655399323, 'accumulated_logging_time': 0.3316490650177002}
I0307 15:49:23.608954 140390694889216 logging_writer.py:48] [564] accumulated_eval_time=968.334, accumulated_logging_time=0.331649, accumulated_submission_time=987.535, global_step=564, preemption_count=0, score=987.535, test/loss=0.316155, test/num_examples=3581, test/ssim=0.713557, total_duration=1956.27, train/loss=0.299445, train/ssim=0.714141, validation/loss=0.31394, validation/num_examples=3554, validation/ssim=0.696104
I0307 15:50:36.649197 140390686496512 logging_writer.py:48] [600] global_step=600, grad_norm=0.25165611505508423, loss=0.3479265570640564
I0307 15:50:44.579053 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:50:45.887908 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:50:47.200752 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:50:48.518988 140545907463360 submission_runner.py:469] Time since start: 2041.19s, 	Step: 604, 	{'train/ssim': 0.7154714039393834, 'train/loss': 0.2991128649030413, 'validation/ssim': 0.6973831614685917, 'validation/loss': 0.3134528972086909, 'validation/num_examples': 3554, 'test/ssim': 0.7148601123987713, 'test/loss': 0.31573607341699245, 'test/num_examples': 3581, 'score': 1068.4938399791718, 'total_duration': 2041.1851961612701, 'accumulated_submission_time': 1068.4938399791718, 'accumulated_eval_time': 972.2738420963287, 'accumulated_logging_time': 0.34977078437805176}
I0307 15:50:48.534185 140390694889216 logging_writer.py:48] [604] accumulated_eval_time=972.274, accumulated_logging_time=0.349771, accumulated_submission_time=1068.49, global_step=604, preemption_count=0, score=1068.49, test/loss=0.315736, test/num_examples=3581, test/ssim=0.71486, total_duration=2041.19, train/loss=0.299113, train/ssim=0.715471, validation/loss=0.313453, validation/num_examples=3554, validation/ssim=0.697383
I0307 15:52:09.287081 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:52:10.597595 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:52:11.908145 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:52:13.222738 140545907463360 submission_runner.py:469] Time since start: 2125.89s, 	Step: 646, 	{'train/ssim': 0.7139509746006557, 'train/loss': 0.30063322612217497, 'validation/ssim': 0.6946952789770329, 'validation/loss': 0.3165364606231535, 'validation/num_examples': 3554, 'test/ssim': 0.7119855116413013, 'test/loss': 0.3188721657598262, 'test/num_examples': 3581, 'score': 1149.2278916835785, 'total_duration': 2125.888920068741, 'accumulated_submission_time': 1149.2278916835785, 'accumulated_eval_time': 976.2094264030457, 'accumulated_logging_time': 0.3804922103881836}
I0307 15:52:13.357620 140390686496512 logging_writer.py:48] [646] accumulated_eval_time=976.209, accumulated_logging_time=0.380492, accumulated_submission_time=1149.23, global_step=646, preemption_count=0, score=1149.23, test/loss=0.318872, test/num_examples=3581, test/ssim=0.711986, total_duration=2125.89, train/loss=0.300633, train/ssim=0.713951, validation/loss=0.316536, validation/num_examples=3554, validation/ssim=0.694695
I0307 15:53:33.354292 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:53:34.664757 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:53:35.977011 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:53:37.290137 140545907463360 submission_runner.py:469] Time since start: 2209.96s, 	Step: 688, 	{'train/ssim': 0.7172619955880302, 'train/loss': 0.2963770457676479, 'validation/ssim': 0.6983347878270962, 'validation/loss': 0.31129234884988743, 'validation/num_examples': 3554, 'test/ssim': 0.715815335603707, 'test/loss': 0.3135630786835032, 'test/num_examples': 3581, 'score': 1229.2125027179718, 'total_duration': 2209.9563467502594, 'accumulated_submission_time': 1229.2125027179718, 'accumulated_eval_time': 980.1452226638794, 'accumulated_logging_time': 0.5245342254638672}
I0307 15:53:37.301113 140390694889216 logging_writer.py:48] [688] accumulated_eval_time=980.145, accumulated_logging_time=0.524534, accumulated_submission_time=1229.21, global_step=688, preemption_count=0, score=1229.21, test/loss=0.313563, test/num_examples=3581, test/ssim=0.715815, total_duration=2209.96, train/loss=0.296377, train/ssim=0.717262, validation/loss=0.311292, validation/num_examples=3554, validation/ssim=0.698335
I0307 15:54:07.497246 140390686496512 logging_writer.py:48] [700] global_step=700, grad_norm=0.5247050523757935, loss=0.29146015644073486
I0307 15:54:57.493942 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:54:58.801228 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:55:00.114699 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:55:01.431646 140545907463360 submission_runner.py:469] Time since start: 2294.10s, 	Step: 724, 	{'train/ssim': 0.7180110386439732, 'train/loss': 0.29560256004333496, 'validation/ssim': 0.7001668729336663, 'validation/loss': 0.3098867198491137, 'validation/num_examples': 3554, 'test/ssim': 0.7174664379930537, 'test/loss': 0.31231115064751463, 'test/num_examples': 3581, 'score': 1309.3920044898987, 'total_duration': 2294.097860813141, 'accumulated_submission_time': 1309.3920044898987, 'accumulated_eval_time': 984.0828812122345, 'accumulated_logging_time': 0.5464646816253662}
I0307 15:55:01.441396 140390694889216 logging_writer.py:48] [724] accumulated_eval_time=984.083, accumulated_logging_time=0.546465, accumulated_submission_time=1309.39, global_step=724, preemption_count=0, score=1309.39, test/loss=0.312311, test/num_examples=3581, test/ssim=0.717466, total_duration=2294.1, train/loss=0.295603, train/ssim=0.718011, validation/loss=0.309887, validation/num_examples=3554, validation/ssim=0.700167
I0307 15:56:21.685970 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:56:23.002543 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:56:24.312263 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:56:25.624216 140545907463360 submission_runner.py:469] Time since start: 2378.29s, 	Step: 764, 	{'train/ssim': 0.7169515745980399, 'train/loss': 0.29640953881399973, 'validation/ssim': 0.6980400879730585, 'validation/loss': 0.3111243218468627, 'validation/num_examples': 3554, 'test/ssim': 0.7152648090617146, 'test/loss': 0.31357374833103535, 'test/num_examples': 3581, 'score': 1389.6225373744965, 'total_duration': 2378.2904348373413, 'accumulated_submission_time': 1389.6225373744965, 'accumulated_eval_time': 988.0210826396942, 'accumulated_logging_time': 0.5648376941680908}
I0307 15:56:25.635764 140390686496512 logging_writer.py:48] [764] accumulated_eval_time=988.021, accumulated_logging_time=0.564838, accumulated_submission_time=1389.62, global_step=764, preemption_count=0, score=1389.62, test/loss=0.313574, test/num_examples=3581, test/ssim=0.715265, total_duration=2378.29, train/loss=0.29641, train/ssim=0.716952, validation/loss=0.311124, validation/num_examples=3554, validation/ssim=0.69804
I0307 15:57:36.566205 140390694889216 logging_writer.py:48] [800] global_step=800, grad_norm=0.2806825041770935, loss=0.25694239139556885
I0307 15:57:46.755888 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:57:48.064750 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:57:49.378914 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:57:50.695560 140545907463360 submission_runner.py:469] Time since start: 2463.36s, 	Step: 806, 	{'train/ssim': 0.7194410732814244, 'train/loss': 0.29479527473449707, 'validation/ssim': 0.7009223761958356, 'validation/loss': 0.3095204058697067, 'validation/num_examples': 3554, 'test/ssim': 0.7180290999808014, 'test/loss': 0.3119281000746125, 'test/num_examples': 3581, 'score': 1470.7271733283997, 'total_duration': 2463.3617770671844, 'accumulated_submission_time': 1470.7271733283997, 'accumulated_eval_time': 991.9607055187225, 'accumulated_logging_time': 0.5875678062438965}
I0307 15:57:50.705749 140390686496512 logging_writer.py:48] [806] accumulated_eval_time=991.961, accumulated_logging_time=0.587568, accumulated_submission_time=1470.73, global_step=806, preemption_count=0, score=1470.73, test/loss=0.311928, test/num_examples=3581, test/ssim=0.718029, total_duration=2463.36, train/loss=0.294795, train/ssim=0.719441, validation/loss=0.30952, validation/num_examples=3554, validation/ssim=0.700922
I0307 15:59:13.094511 140545907463360 spec.py:321] Evaluating on the training split.
I0307 15:59:14.401883 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 15:59:15.712181 140545907463360 spec.py:349] Evaluating on the test split.
I0307 15:59:17.027129 140545907463360 submission_runner.py:469] Time since start: 2549.69s, 	Step: 843, 	{'train/ssim': 0.7208996500287738, 'train/loss': 0.293203490121024, 'validation/ssim': 0.7027378372080754, 'validation/loss': 0.30764724138954347, 'validation/num_examples': 3554, 'test/ssim': 0.7198229642994275, 'test/loss': 0.31013876950397934, 'test/num_examples': 3581, 'score': 1553.1048185825348, 'total_duration': 2549.6933467388153, 'accumulated_submission_time': 1553.1048185825348, 'accumulated_eval_time': 995.8932812213898, 'accumulated_logging_time': 0.6063234806060791}
I0307 15:59:17.038444 140390694889216 logging_writer.py:48] [843] accumulated_eval_time=995.893, accumulated_logging_time=0.606323, accumulated_submission_time=1553.1, global_step=843, preemption_count=0, score=1553.1, test/loss=0.310139, test/num_examples=3581, test/ssim=0.719823, total_duration=2549.69, train/loss=0.293203, train/ssim=0.7209, validation/loss=0.307647, validation/num_examples=3554, validation/ssim=0.702738
I0307 16:00:39.734175 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:00:41.046250 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:00:42.356490 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:00:43.669605 140545907463360 submission_runner.py:469] Time since start: 2636.34s, 	Step: 885, 	{'train/ssim': 0.7177916935511998, 'train/loss': 0.2937345504760742, 'validation/ssim': 0.700300071772123, 'validation/loss': 0.30770013623514, 'validation/num_examples': 3554, 'test/ssim': 0.7175280015184307, 'test/loss': 0.31003728854326656, 'test/num_examples': 3581, 'score': 1635.7886583805084, 'total_duration': 2636.335819721222, 'accumulated_submission_time': 1635.7886583805084, 'accumulated_eval_time': 999.828663110733, 'accumulated_logging_time': 0.6257760524749756}
I0307 16:00:43.680870 140390686496512 logging_writer.py:48] [885] accumulated_eval_time=999.829, accumulated_logging_time=0.625776, accumulated_submission_time=1635.79, global_step=885, preemption_count=0, score=1635.79, test/loss=0.310037, test/num_examples=3581, test/ssim=0.717528, total_duration=2636.34, train/loss=0.293735, train/ssim=0.717792, validation/loss=0.3077, validation/num_examples=3554, validation/ssim=0.7003
I0307 16:01:15.902416 140390694889216 logging_writer.py:48] [900] global_step=900, grad_norm=0.08721638470888138, loss=0.31594109535217285
I0307 16:02:06.516496 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:02:07.827697 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:02:09.138726 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:02:10.452845 140545907463360 submission_runner.py:469] Time since start: 2723.12s, 	Step: 928, 	{'train/ssim': 0.7228571346827916, 'train/loss': 0.2915998526981899, 'validation/ssim': 0.7043287355576463, 'validation/loss': 0.30618782451331245, 'validation/num_examples': 3554, 'test/ssim': 0.7214254567290911, 'test/loss': 0.3086399737765289, 'test/num_examples': 3581, 'score': 1718.6132566928864, 'total_duration': 2723.119059085846, 'accumulated_submission_time': 1718.6132566928864, 'accumulated_eval_time': 1003.7649624347687, 'accumulated_logging_time': 0.6450037956237793}
I0307 16:02:10.463689 140390686496512 logging_writer.py:48] [928] accumulated_eval_time=1003.76, accumulated_logging_time=0.645004, accumulated_submission_time=1718.61, global_step=928, preemption_count=0, score=1718.61, test/loss=0.30864, test/num_examples=3581, test/ssim=0.721425, total_duration=2723.12, train/loss=0.2916, train/ssim=0.722857, validation/loss=0.306188, validation/num_examples=3554, validation/ssim=0.704329
I0307 16:03:26.049748 140390694889216 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.1588604897260666, loss=0.2848835587501526
I0307 16:03:33.740359 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:03:35.060772 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:03:36.373189 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:03:37.686330 140545907463360 submission_runner.py:469] Time since start: 2810.35s, 	Step: 1036, 	{'train/ssim': 0.7203072139195034, 'train/loss': 0.2914558819362095, 'validation/ssim': 0.7023729314680641, 'validation/loss': 0.30587402755917625, 'validation/num_examples': 3554, 'test/ssim': 0.7196316605871265, 'test/loss': 0.30805399537053196, 'test/num_examples': 3581, 'score': 1801.8736760616302, 'total_duration': 2810.352548122406, 'accumulated_submission_time': 1801.8736760616302, 'accumulated_eval_time': 1007.7108891010284, 'accumulated_logging_time': 0.6638028621673584}
I0307 16:03:37.696737 140390686496512 logging_writer.py:48] [1036] accumulated_eval_time=1007.71, accumulated_logging_time=0.663803, accumulated_submission_time=1801.87, global_step=1036, preemption_count=0, score=1801.87, test/loss=0.308054, test/num_examples=3581, test/ssim=0.719632, total_duration=2810.35, train/loss=0.291456, train/ssim=0.720307, validation/loss=0.305874, validation/num_examples=3554, validation/ssim=0.702373
I0307 16:03:54.523433 140390694889216 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.13656213879585266, loss=0.2675151228904724
I0307 16:04:02.742634 140390686496512 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.21027612686157227, loss=0.3657017648220062
I0307 16:04:10.988607 140390694889216 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.3259919583797455, loss=0.2737317383289337
I0307 16:04:19.248783 140390686496512 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.15619443356990814, loss=0.29047104716300964
I0307 16:04:27.499750 140390694889216 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.1095912754535675, loss=0.34237903356552124
I0307 16:04:35.729743 140390686496512 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.19238218665122986, loss=0.41199856996536255
I0307 16:04:43.978642 140390694889216 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.35741621255874634, loss=0.31450796127319336
I0307 16:04:52.242219 140390686496512 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.12716400623321533, loss=0.34246981143951416
I0307 16:04:57.693035 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:04:59.008721 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:05:00.330663 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:05:01.648267 140545907463360 submission_runner.py:469] Time since start: 2894.31s, 	Step: 1867, 	{'train/ssim': 0.7280985287257603, 'train/loss': 0.28644323348999023, 'validation/ssim': 0.7092301642955121, 'validation/loss': 0.30109779473832304, 'validation/num_examples': 3554, 'test/ssim': 0.7259941793493437, 'test/loss': 0.30357826571662944, 'test/num_examples': 3581, 'score': 1881.817658662796, 'total_duration': 2894.314464569092, 'accumulated_submission_time': 1881.817658662796, 'accumulated_eval_time': 1011.666056394577, 'accumulated_logging_time': 0.6829276084899902}
I0307 16:05:01.661554 140390694889216 logging_writer.py:48] [1867] accumulated_eval_time=1011.67, accumulated_logging_time=0.682928, accumulated_submission_time=1881.82, global_step=1867, preemption_count=0, score=1881.82, test/loss=0.303578, test/num_examples=3581, test/ssim=0.725994, total_duration=2894.31, train/loss=0.286443, train/ssim=0.728099, validation/loss=0.301098, validation/num_examples=3554, validation/ssim=0.70923
I0307 16:05:04.478564 140390686496512 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.32953619956970215, loss=0.23626059293746948
I0307 16:05:12.703896 140390694889216 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.14588391780853271, loss=0.31532737612724304
I0307 16:05:20.952917 140390686496512 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.18975022435188293, loss=0.37336286902427673
I0307 16:05:29.205122 140390694889216 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.2571144700050354, loss=0.2531830072402954
I0307 16:05:37.460612 140390686496512 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.1542680859565735, loss=0.32052338123321533
I0307 16:05:45.705020 140390694889216 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.201229989528656, loss=0.2326846718788147
I0307 16:05:53.957642 140390686496512 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.26485422253608704, loss=0.29887884855270386
I0307 16:06:02.187163 140390694889216 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.10973794013261795, loss=0.3044688105583191
I0307 16:06:10.429463 140390686496512 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.09874442964792252, loss=0.3109736442565918
I0307 16:06:18.676861 140390694889216 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.1825408637523651, loss=0.31291142106056213
I0307 16:06:21.650246 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:06:22.969214 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:06:24.287201 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:06:25.608724 140545907463360 submission_runner.py:469] Time since start: 2978.27s, 	Step: 2837, 	{'train/ssim': 0.7328900609697614, 'train/loss': 0.28015383652278353, 'validation/ssim': 0.7136244207670934, 'validation/loss': 0.2947093338931486, 'validation/num_examples': 3554, 'test/ssim': 0.731026571444778, 'test/loss': 0.29656810275804596, 'test/num_examples': 3581, 'score': 1961.7479076385498, 'total_duration': 2978.274920463562, 'accumulated_submission_time': 1961.7479076385498, 'accumulated_eval_time': 1015.6244695186615, 'accumulated_logging_time': 0.7047760486602783}
I0307 16:06:25.620503 140390686496512 logging_writer.py:48] [2837] accumulated_eval_time=1015.62, accumulated_logging_time=0.704776, accumulated_submission_time=1961.75, global_step=2837, preemption_count=0, score=1961.75, test/loss=0.296568, test/num_examples=3581, test/ssim=0.731027, total_duration=2978.27, train/loss=0.280154, train/ssim=0.73289, validation/loss=0.294709, validation/num_examples=3554, validation/ssim=0.713624
I0307 16:06:30.909026 140390694889216 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.10422300547361374, loss=0.2854473292827606
I0307 16:06:39.122581 140390686496512 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.08422508835792542, loss=0.23442119359970093
I0307 16:06:47.398960 140390694889216 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.17867548763751984, loss=0.3662030100822449
I0307 16:06:55.673126 140390686496512 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.16988879442214966, loss=0.292532742023468
I0307 16:07:03.902528 140390694889216 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.1662416011095047, loss=0.22935408353805542
I0307 16:07:12.137072 140390686496512 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.08704439550638199, loss=0.32654133439064026
I0307 16:07:20.368991 140390694889216 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.19534234702587128, loss=0.2257407009601593
I0307 16:07:28.628190 140390686496512 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.1991378664970398, loss=0.32280316948890686
I0307 16:07:36.861939 140390694889216 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.1913856416940689, loss=0.24499566853046417
I0307 16:07:45.112061 140390686496512 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.0686444416642189, loss=0.22776584327220917
I0307 16:07:45.615923 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:07:46.933828 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:07:48.254271 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:07:49.575749 140545907463360 submission_runner.py:469] Time since start: 3062.24s, 	Step: 3807, 	{'train/ssim': 0.7367397035871234, 'train/loss': 0.2792292152132307, 'validation/ssim': 0.7176286979679586, 'validation/loss': 0.2936873986067635, 'validation/num_examples': 3554, 'test/ssim': 0.7347739016467119, 'test/loss': 0.2953810448155194, 'test/num_examples': 3581, 'score': 2041.6854329109192, 'total_duration': 3062.2419352531433, 'accumulated_submission_time': 2041.6854329109192, 'accumulated_eval_time': 1019.5842185020447, 'accumulated_logging_time': 0.724376916885376}
I0307 16:07:49.587254 140390694889216 logging_writer.py:48] [3807] accumulated_eval_time=1019.58, accumulated_logging_time=0.724377, accumulated_submission_time=2041.69, global_step=3807, preemption_count=0, score=2041.69, test/loss=0.295381, test/num_examples=3581, test/ssim=0.734774, total_duration=3062.24, train/loss=0.279229, train/ssim=0.73674, validation/loss=0.293687, validation/num_examples=3554, validation/ssim=0.717629
I0307 16:08:02.692238 140390686496512 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.13137447834014893, loss=0.26633766293525696
I0307 16:08:10.931003 140390694889216 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.23715533316135406, loss=0.2857361435890198
I0307 16:08:19.195079 140390686496512 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.18969377875328064, loss=0.2631061375141144
I0307 16:08:27.429899 140390694889216 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.10240181535482407, loss=0.28473961353302
I0307 16:08:35.688835 140390686496512 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.31939369440078735, loss=0.3158026933670044
I0307 16:08:43.949154 140390694889216 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.13771560788154602, loss=0.22217780351638794
I0307 16:08:52.206755 140390686496512 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.16392815113067627, loss=0.2982029318809509
I0307 16:09:00.453768 140390694889216 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.09185470640659332, loss=0.3372443914413452
I0307 16:09:08.690710 140390686496512 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.16653423011302948, loss=0.2686254382133484
I0307 16:09:09.598680 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:09:10.918653 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:09:12.238984 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:09:13.561316 140545907463360 submission_runner.py:469] Time since start: 3146.23s, 	Step: 4712, 	{'train/ssim': 0.7346679823739188, 'train/loss': 0.27733354909079416, 'validation/ssim': 0.715737054639139, 'validation/loss': 0.29193740355277503, 'validation/num_examples': 3554, 'test/ssim': 0.7333337378481919, 'test/loss': 0.2933386765655543, 'test/num_examples': 3581, 'score': 2116.345298051834, 'total_duration': 3146.227527141571, 'accumulated_submission_time': 2116.345298051834, 'accumulated_eval_time': 1023.5468060970306, 'accumulated_logging_time': 6.040001630783081}
I0307 16:09:13.573477 140390694889216 logging_writer.py:48] [4712] accumulated_eval_time=1023.55, accumulated_logging_time=6.04, accumulated_submission_time=2116.35, global_step=4712, preemption_count=0, score=2116.35, test/loss=0.293339, test/num_examples=3581, test/ssim=0.733334, total_duration=3146.23, train/loss=0.277334, train/ssim=0.734668, validation/loss=0.291937, validation/num_examples=3554, validation/ssim=0.715737
I0307 16:09:20.933660 140390686496512 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.06653759628534317, loss=0.3645567297935486
I0307 16:09:29.177460 140390694889216 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.11565109342336655, loss=0.2741720974445343
I0307 16:09:37.414400 140390686496512 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.18385280668735504, loss=0.39838212728500366
I0307 16:09:45.665885 140390694889216 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.12886156141757965, loss=0.2359931468963623
I0307 16:09:53.923985 140390686496512 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.1316959261894226, loss=0.33976733684539795
I0307 16:10:02.166211 140390694889216 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.082286037504673, loss=0.3382953405380249
I0307 16:10:10.411157 140390686496512 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.13059452176094055, loss=0.22530657052993774
I0307 16:10:18.644560 140390694889216 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.13204962015151978, loss=0.19958041608333588
I0307 16:10:26.902172 140390686496512 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.13378793001174927, loss=0.3430299758911133
I0307 16:10:33.569095 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:10:34.888606 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:10:36.209133 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:10:37.534101 140545907463360 submission_runner.py:469] Time since start: 3230.20s, 	Step: 5682, 	{'train/ssim': 0.7357995169503349, 'train/loss': 0.27629891463688444, 'validation/ssim': 0.7161711358460537, 'validation/loss': 0.2910175484489308, 'validation/num_examples': 3554, 'test/ssim': 0.7338151332553756, 'test/loss': 0.2924048608323443, 'test/num_examples': 3581, 'score': 2196.282222509384, 'total_duration': 3230.2003178596497, 'accumulated_submission_time': 2196.282222509384, 'accumulated_eval_time': 1027.5117647647858, 'accumulated_logging_time': 6.06099271774292}
I0307 16:10:37.545780 140390694889216 logging_writer.py:48] [5682] accumulated_eval_time=1027.51, accumulated_logging_time=6.06099, accumulated_submission_time=2196.28, global_step=5682, preemption_count=0, score=2196.28, test/loss=0.292405, test/num_examples=3581, test/ssim=0.733815, total_duration=3230.2, train/loss=0.276299, train/ssim=0.7358, validation/loss=0.291018, validation/num_examples=3554, validation/ssim=0.716171
I0307 16:10:39.135878 140390686496512 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.15946243703365326, loss=0.2912139892578125
I0307 16:10:47.397591 140390694889216 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.10453420132398605, loss=0.3633042871952057
I0307 16:10:55.632624 140390686496512 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.15085214376449585, loss=0.27405521273612976
I0307 16:11:03.868149 140390694889216 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.09783659130334854, loss=0.3557336628437042
I0307 16:11:12.092621 140390686496512 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.1486942023038864, loss=0.29274889826774597
I0307 16:11:20.355238 140390694889216 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.15981464087963104, loss=0.25871914625167847
I0307 16:11:28.614417 140390686496512 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.36683177947998047, loss=0.2902807593345642
I0307 16:11:36.871170 140390694889216 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.11832401901483536, loss=0.2693091034889221
I0307 16:11:45.089460 140390686496512 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.09060821682214737, loss=0.21578852832317352
I0307 16:11:53.323846 140390694889216 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.14441408216953278, loss=0.2640853524208069
I0307 16:11:57.597836 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:11:58.915776 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:12:00.234935 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:12:01.553189 140545907463360 submission_runner.py:469] Time since start: 3314.22s, 	Step: 6653, 	{'train/ssim': 0.7392710958208356, 'train/loss': 0.2754725899015154, 'validation/ssim': 0.7197093201542276, 'validation/loss': 0.2902531148881542, 'validation/num_examples': 3554, 'test/ssim': 0.7371022028152052, 'test/loss': 0.2917131404242879, 'test/num_examples': 3581, 'score': 2276.2766897678375, 'total_duration': 3314.2194068431854, 'accumulated_submission_time': 2276.2766897678375, 'accumulated_eval_time': 1031.467073917389, 'accumulated_logging_time': 6.080403089523315}
I0307 16:12:01.564983 140390686496512 logging_writer.py:48] [6653] accumulated_eval_time=1031.47, accumulated_logging_time=6.0804, accumulated_submission_time=2276.28, global_step=6653, preemption_count=0, score=2276.28, test/loss=0.291713, test/num_examples=3581, test/ssim=0.737102, total_duration=3314.22, train/loss=0.275473, train/ssim=0.739271, validation/loss=0.290253, validation/num_examples=3554, validation/ssim=0.719709
I0307 16:12:05.545588 140390694889216 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.14261673390865326, loss=0.2796582579612732
I0307 16:12:13.782349 140390686496512 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.14530155062675476, loss=0.24964605271816254
I0307 16:12:22.018462 140390694889216 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.19455060362815857, loss=0.3657582700252533
I0307 16:12:30.258585 140390686496512 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.09300641715526581, loss=0.2684641480445862
I0307 16:12:38.502906 140390694889216 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.11146494001150131, loss=0.4232238531112671
I0307 16:12:46.751286 140390686496512 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.10334121435880661, loss=0.34043532609939575
I0307 16:12:55.013232 140390694889216 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.2197222262620926, loss=0.26668450236320496
I0307 16:13:03.283029 140390686496512 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.1594950407743454, loss=0.24375322461128235
I0307 16:13:11.559736 140390694889216 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.12480492144823074, loss=0.2953896224498749
I0307 16:13:19.791763 140390686496512 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.13820916414260864, loss=0.23389288783073425
I0307 16:13:21.616614 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:13:22.937831 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:13:24.263120 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:13:25.587936 140545907463360 submission_runner.py:469] Time since start: 3398.25s, 	Step: 7623, 	{'train/ssim': 0.7384654453822544, 'train/loss': 0.2749414954866682, 'validation/ssim': 0.7187267125290167, 'validation/loss': 0.2897435039634039, 'validation/num_examples': 3554, 'test/ssim': 0.736107300793249, 'test/loss': 0.29128553640306476, 'test/num_examples': 3581, 'score': 2356.271887779236, 'total_duration': 3398.254152536392, 'accumulated_submission_time': 2356.271887779236, 'accumulated_eval_time': 1035.438351392746, 'accumulated_logging_time': 6.0999979972839355}
I0307 16:13:25.600371 140390694889216 logging_writer.py:48] [7623] accumulated_eval_time=1035.44, accumulated_logging_time=6.1, accumulated_submission_time=2356.27, global_step=7623, preemption_count=0, score=2356.27, test/loss=0.291286, test/num_examples=3581, test/ssim=0.736107, total_duration=3398.25, train/loss=0.274941, train/ssim=0.738465, validation/loss=0.289744, validation/num_examples=3554, validation/ssim=0.718727
I0307 16:13:32.034227 140390686496512 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.13651615381240845, loss=0.2406819611787796
I0307 16:13:40.289476 140390694889216 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.07098270207643509, loss=0.24040824174880981
I0307 16:13:48.532430 140390686496512 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.1467345654964447, loss=0.32555896043777466
I0307 16:13:56.786604 140390694889216 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.17237971723079681, loss=0.4596884250640869
I0307 16:14:05.026661 140390686496512 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.1995970606803894, loss=0.32322484254837036
I0307 16:14:13.282737 140390694889216 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.15610921382904053, loss=0.32958948612213135
I0307 16:14:21.532768 140390686496512 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.13059303164482117, loss=0.23038466274738312
I0307 16:14:29.772692 140390694889216 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.23612917959690094, loss=0.2217719703912735
I0307 16:14:38.016586 140390686496512 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.16308961808681488, loss=0.29633697867393494
I0307 16:14:45.631939 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:14:46.948939 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:14:48.269796 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:14:49.592900 140545907463360 submission_runner.py:469] Time since start: 3482.26s, 	Step: 8593, 	{'train/ssim': 0.7375209672110421, 'train/loss': 0.27534488269260954, 'validation/ssim': 0.7176506802414533, 'validation/loss': 0.29002271318408834, 'validation/num_examples': 3554, 'test/ssim': 0.7351834388526249, 'test/loss': 0.29150186095015357, 'test/num_examples': 3581, 'score': 2436.2463290691376, 'total_duration': 3482.259114742279, 'accumulated_submission_time': 2436.2463290691376, 'accumulated_eval_time': 1039.3992652893066, 'accumulated_logging_time': 6.1215174198150635}
I0307 16:14:49.605049 140390694889216 logging_writer.py:48] [8593] accumulated_eval_time=1039.4, accumulated_logging_time=6.12152, accumulated_submission_time=2436.25, global_step=8593, preemption_count=0, score=2436.25, test/loss=0.291502, test/num_examples=3581, test/ssim=0.735183, total_duration=3482.26, train/loss=0.275345, train/ssim=0.737521, validation/loss=0.290023, validation/num_examples=3554, validation/ssim=0.717651
I0307 16:14:50.277795 140390686496512 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.23686665296554565, loss=0.36045655608177185
I0307 16:14:58.533474 140390694889216 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.19441960752010345, loss=0.2987554967403412
I0307 16:15:06.775070 140390686496512 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.23134884238243103, loss=0.30973750352859497
I0307 16:15:15.024560 140390694889216 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.11543983966112137, loss=0.21829470992088318
I0307 16:15:23.279906 140390686496512 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.20298072695732117, loss=0.3163706958293915
I0307 16:15:31.517354 140390694889216 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.1598692238330841, loss=0.31213247776031494
I0307 16:15:39.777672 140390686496512 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.16407844424247742, loss=0.2072700411081314
I0307 16:15:48.021219 140390694889216 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.09066559374332428, loss=0.3034058213233948
I0307 16:15:56.251510 140390686496512 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.17721432447433472, loss=0.2111559808254242
I0307 16:16:04.499016 140390694889216 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.07930354028940201, loss=0.2684178948402405
I0307 16:16:09.612729 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:16:10.931571 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:16:12.254338 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:16:13.576326 140545907463360 submission_runner.py:469] Time since start: 3566.24s, 	Step: 9563, 	{'train/ssim': 0.7404016086033413, 'train/loss': 0.27452114650181364, 'validation/ssim': 0.7207052545327448, 'validation/loss': 0.2895181856600837, 'validation/num_examples': 3554, 'test/ssim': 0.7381288069847808, 'test/loss': 0.29086959059096623, 'test/num_examples': 3581, 'score': 2516.19789147377, 'total_duration': 3566.242546081543, 'accumulated_submission_time': 2516.19789147377, 'accumulated_eval_time': 1043.3628237247467, 'accumulated_logging_time': 6.14155125617981}
I0307 16:16:13.588680 140390686496512 logging_writer.py:48] [9563] accumulated_eval_time=1043.36, accumulated_logging_time=6.14155, accumulated_submission_time=2516.2, global_step=9563, preemption_count=0, score=2516.2, test/loss=0.29087, test/num_examples=3581, test/ssim=0.738129, total_duration=3566.24, train/loss=0.274521, train/ssim=0.740402, validation/loss=0.289518, validation/num_examples=3554, validation/ssim=0.720705
I0307 16:16:16.738694 140390694889216 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.2167198807001114, loss=0.3200220465660095
I0307 16:16:24.981045 140390686496512 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.1491476148366928, loss=0.2774023413658142
I0307 16:16:33.221367 140390694889216 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.16746337711811066, loss=0.2796764373779297
I0307 16:16:41.464457 140390686496512 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.14361849427223206, loss=0.2986980676651001
I0307 16:16:49.737206 140390694889216 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.26557308435440063, loss=0.25373855233192444
I0307 16:16:57.977677 140390686496512 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.14336475729942322, loss=0.33907389640808105
I0307 16:17:06.217065 140390694889216 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.2213675081729889, loss=0.2690843641757965
I0307 16:17:14.473327 140390686496512 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.21039457619190216, loss=0.2717086970806122
I0307 16:17:22.697185 140390694889216 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.14383386075496674, loss=0.2555008828639984
I0307 16:17:30.941868 140390686496512 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.19836831092834473, loss=0.2705855667591095
I0307 16:17:33.588405 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:17:34.906910 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:17:36.231440 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:17:37.553411 140545907463360 submission_runner.py:469] Time since start: 3650.22s, 	Step: 10533, 	{'train/ssim': 0.7383284568786621, 'train/loss': 0.27480808326176237, 'validation/ssim': 0.719604904355128, 'validation/loss': 0.2893448691724993, 'validation/num_examples': 3554, 'test/ssim': 0.7367932943617356, 'test/loss': 0.2907890398653484, 'test/num_examples': 3581, 'score': 2596.140430688858, 'total_duration': 3650.2196164131165, 'accumulated_submission_time': 2596.140430688858, 'accumulated_eval_time': 1047.3277714252472, 'accumulated_logging_time': 6.162447929382324}
I0307 16:17:37.568055 140390694889216 logging_writer.py:48] [10533] accumulated_eval_time=1047.33, accumulated_logging_time=6.16245, accumulated_submission_time=2596.14, global_step=10533, preemption_count=0, score=2596.14, test/loss=0.290789, test/num_examples=3581, test/ssim=0.736793, total_duration=3650.22, train/loss=0.274808, train/ssim=0.738328, validation/loss=0.289345, validation/num_examples=3554, validation/ssim=0.719605
I0307 16:17:43.182885 140390686496512 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.18349698185920715, loss=0.3186246454715729
I0307 16:17:51.439922 140390694889216 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.3063281178474426, loss=0.2789314091205597
I0307 16:17:59.680958 140390686496512 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.1375209093093872, loss=0.422668993473053
I0307 16:18:07.931186 140390694889216 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.2708740532398224, loss=0.28686076402664185
I0307 16:18:16.204016 140390686496512 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.11142245680093765, loss=0.2871836721897125
I0307 16:18:24.466110 140390694889216 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.17830364406108856, loss=0.37097251415252686
I0307 16:18:32.718801 140390686496512 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.1528802514076233, loss=0.2472747564315796
I0307 16:18:40.967638 140390694889216 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.19352678954601288, loss=0.2664438486099243
I0307 16:18:49.195331 140390686496512 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.15931876003742218, loss=0.23890765011310577
I0307 16:18:57.448076 140390694889216 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.13385380804538727, loss=0.3615531325340271
I0307 16:18:57.617314 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:18:58.934114 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:19:00.260048 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:19:01.584741 140545907463360 submission_runner.py:469] Time since start: 3734.25s, 	Step: 11503, 	{'train/ssim': 0.7406071254185268, 'train/loss': 0.2739080360957554, 'validation/ssim': 0.7204275222460608, 'validation/loss': 0.28917258310398497, 'validation/num_examples': 3554, 'test/ssim': 0.7378591001117006, 'test/loss': 0.29069072911939753, 'test/num_examples': 3581, 'score': 2676.13227891922, 'total_duration': 3734.250948190689, 'accumulated_submission_time': 2676.13227891922, 'accumulated_eval_time': 1051.2951412200928, 'accumulated_logging_time': 6.185567140579224}
I0307 16:19:01.597277 140390686496512 logging_writer.py:48] [11503] accumulated_eval_time=1051.3, accumulated_logging_time=6.18557, accumulated_submission_time=2676.13, global_step=11503, preemption_count=0, score=2676.13, test/loss=0.290691, test/num_examples=3581, test/ssim=0.737859, total_duration=3734.25, train/loss=0.273908, train/ssim=0.740607, validation/loss=0.289173, validation/num_examples=3554, validation/ssim=0.720428
I0307 16:19:09.695212 140390694889216 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.23824439942836761, loss=0.2691698968410492
I0307 16:19:17.920582 140390686496512 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.14784900844097137, loss=0.28113532066345215
I0307 16:19:26.176380 140390694889216 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.12573085725307465, loss=0.25961580872535706
I0307 16:19:34.443074 140390686496512 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.1494419127702713, loss=0.2767459452152252
I0307 16:19:42.700927 140390694889216 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.281800240278244, loss=0.25913599133491516
I0307 16:19:50.940133 140390686496512 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.2128143012523651, loss=0.23843437433242798
I0307 16:19:59.194235 140390694889216 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.10493398457765579, loss=0.2876840829849243
I0307 16:20:07.468355 140390686496512 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.12093588709831238, loss=0.2922786772251129
I0307 16:20:15.712520 140390694889216 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.08341942727565765, loss=0.336110919713974
I0307 16:20:21.650658 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:20:22.968053 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:20:24.290039 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:20:25.612171 140545907463360 submission_runner.py:469] Time since start: 3818.28s, 	Step: 12473, 	{'train/ssim': 0.7407779693603516, 'train/loss': 0.2735851151602609, 'validation/ssim': 0.7211138500413267, 'validation/loss': 0.28863480739131964, 'validation/num_examples': 3554, 'test/ssim': 0.7386281328539515, 'test/loss': 0.29000950791721936, 'test/num_examples': 3581, 'score': 2756.128397703171, 'total_duration': 3818.2783908843994, 'accumulated_submission_time': 2756.128397703171, 'accumulated_eval_time': 1055.2566134929657, 'accumulated_logging_time': 6.206440687179565}
I0307 16:20:25.624868 140390686496512 logging_writer.py:48] [12473] accumulated_eval_time=1055.26, accumulated_logging_time=6.20644, accumulated_submission_time=2756.13, global_step=12473, preemption_count=0, score=2756.13, test/loss=0.29001, test/num_examples=3581, test/ssim=0.738628, total_duration=3818.28, train/loss=0.273585, train/ssim=0.740778, validation/loss=0.288635, validation/num_examples=3554, validation/ssim=0.721114
I0307 16:20:27.937880 140390694889216 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.35080087184906006, loss=0.2728763520717621
I0307 16:20:36.178323 140390686496512 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.106232188642025, loss=0.29753589630126953
I0307 16:20:44.427735 140390694889216 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.13303761184215546, loss=0.27426400780677795
I0307 16:20:52.676655 140390686496512 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.164279505610466, loss=0.3095466196537018
I0307 16:21:00.945169 140390694889216 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.21579673886299133, loss=0.31723693013191223
I0307 16:21:09.203874 140390686496512 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.08609623461961746, loss=0.26265907287597656
I0307 16:21:17.465970 140390694889216 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.12039151042699814, loss=0.21264074742794037
I0307 16:21:25.712641 140390686496512 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.08421771973371506, loss=0.27223077416419983
I0307 16:21:33.983464 140390694889216 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.06324101239442825, loss=0.2923855483531952
I0307 16:21:42.224768 140390686496512 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.19935455918312073, loss=0.3428056836128235
I0307 16:21:45.613461 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:21:46.932851 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:21:48.252605 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:21:49.574052 140545907463360 submission_runner.py:469] Time since start: 3902.24s, 	Step: 13442, 	{'train/ssim': 0.7430000305175781, 'train/loss': 0.2728091648646763, 'validation/ssim': 0.7231090848339898, 'validation/loss': 0.28801020169835045, 'validation/num_examples': 3554, 'test/ssim': 0.7403315267427045, 'test/loss': 0.28955742847450083, 'test/num_examples': 3581, 'score': 2836.060392141342, 'total_duration': 3902.2402725219727, 'accumulated_submission_time': 2836.060392141342, 'accumulated_eval_time': 1059.2171614170074, 'accumulated_logging_time': 6.227145433425903}
I0307 16:21:49.587405 140390694889216 logging_writer.py:48] [13442] accumulated_eval_time=1059.22, accumulated_logging_time=6.22715, accumulated_submission_time=2836.06, global_step=13442, preemption_count=0, score=2836.06, test/loss=0.289557, test/num_examples=3581, test/ssim=0.740332, total_duration=3902.24, train/loss=0.272809, train/ssim=0.743, validation/loss=0.28801, validation/num_examples=3554, validation/ssim=0.723109
I0307 16:21:54.482171 140390686496512 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.11339818686246872, loss=0.22317086160182953
I0307 16:22:02.738340 140390694889216 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.16820545494556427, loss=0.27935516834259033
I0307 16:22:10.970293 140390686496512 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.08363096415996552, loss=0.37310707569122314
I0307 16:22:19.218581 140390694889216 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.13012786209583282, loss=0.2539270520210266
I0307 16:22:27.464962 140390686496512 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.29928824305534363, loss=0.30891185998916626
I0307 16:22:35.729800 140390694889216 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.07664419710636139, loss=0.3057762384414673
I0307 16:22:43.978816 140390686496512 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.14153970777988434, loss=0.1741645336151123
I0307 16:22:52.228562 140390694889216 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.12938329577445984, loss=0.29785069823265076
I0307 16:23:00.477432 140390686496512 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.15182888507843018, loss=0.29851609468460083
I0307 16:23:08.719426 140390694889216 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.09895233064889908, loss=0.29109668731689453
I0307 16:23:09.628375 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:23:10.947391 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:23:12.271577 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:23:13.594144 140545907463360 submission_runner.py:469] Time since start: 3986.26s, 	Step: 14412, 	{'train/ssim': 0.741492748260498, 'train/loss': 0.2732466459274292, 'validation/ssim': 0.7212862048044457, 'validation/loss': 0.2884703525077378, 'validation/num_examples': 3554, 'test/ssim': 0.7386060436156102, 'test/loss': 0.28990001619877476, 'test/num_examples': 3581, 'score': 2916.0443081855774, 'total_duration': 3986.2603616714478, 'accumulated_submission_time': 2916.0443081855774, 'accumulated_eval_time': 1063.182886838913, 'accumulated_logging_time': 6.248644828796387}
I0307 16:23:13.606855 140390686496512 logging_writer.py:48] [14412] accumulated_eval_time=1063.18, accumulated_logging_time=6.24864, accumulated_submission_time=2916.04, global_step=14412, preemption_count=0, score=2916.04, test/loss=0.2899, test/num_examples=3581, test/ssim=0.738606, total_duration=3986.26, train/loss=0.273247, train/ssim=0.741493, validation/loss=0.28847, validation/num_examples=3554, validation/ssim=0.721286
I0307 16:23:20.966881 140390694889216 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.12338076531887054, loss=0.30055758357048035
I0307 16:23:29.235264 140390686496512 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.1474272906780243, loss=0.2535300850868225
I0307 16:23:37.501560 140390694889216 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.13205143809318542, loss=0.28350189328193665
I0307 16:23:45.752243 140390686496512 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.1841958463191986, loss=0.3264090418815613
I0307 16:23:53.991299 140390694889216 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.10107061266899109, loss=0.24117594957351685
I0307 16:24:02.245505 140390686496512 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.10798830538988113, loss=0.2932794690132141
I0307 16:24:10.514334 140390694889216 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.16819296777248383, loss=0.3793698847293854
I0307 16:24:18.756567 140390686496512 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.12679383158683777, loss=0.3015529215335846
I0307 16:24:27.012864 140390694889216 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.13367502391338348, loss=0.28165388107299805
I0307 16:24:33.616129 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:24:34.936054 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:24:36.259886 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:24:37.587574 140545907463360 submission_runner.py:469] Time since start: 4070.25s, 	Step: 15381, 	{'train/ssim': 0.7424077306474958, 'train/loss': 0.2725856304168701, 'validation/ssim': 0.7224305882236565, 'validation/loss': 0.28774711853611246, 'validation/num_examples': 3554, 'test/ssim': 0.7398191791311785, 'test/loss': 0.2891470731486491, 'test/num_examples': 3581, 'score': 2995.995940208435, 'total_duration': 4070.2537894248962, 'accumulated_submission_time': 2995.995940208435, 'accumulated_eval_time': 1067.154284477234, 'accumulated_logging_time': 6.270179510116577}
I0307 16:24:37.600936 140390686496512 logging_writer.py:48] [15381] accumulated_eval_time=1067.15, accumulated_logging_time=6.27018, accumulated_submission_time=2996, global_step=15381, preemption_count=0, score=2996, test/loss=0.289147, test/num_examples=3581, test/ssim=0.739819, total_duration=4070.25, train/loss=0.272586, train/ssim=0.742408, validation/loss=0.287747, validation/num_examples=3554, validation/ssim=0.722431
I0307 16:24:39.275152 140390694889216 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.07912653684616089, loss=0.29744991660118103
I0307 16:24:47.533931 140390686496512 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.13370674848556519, loss=0.25081223249435425
I0307 16:24:55.785514 140390694889216 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.16214467585086823, loss=0.36913353204727173
I0307 16:25:04.043621 140390686496512 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.1546439230442047, loss=0.359477698802948
I0307 16:25:12.307476 140390694889216 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.22579066455364227, loss=0.30491507053375244
I0307 16:25:20.561505 140390686496512 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.12818321585655212, loss=0.28218409419059753
I0307 16:25:28.821408 140390694889216 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.1268516629934311, loss=0.2506222128868103
I0307 16:25:37.056221 140390686496512 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.10144172608852386, loss=0.32209643721580505
I0307 16:25:45.312755 140390694889216 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.07342357933521271, loss=0.3349778652191162
I0307 16:25:53.557928 140390686496512 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.1478591114282608, loss=0.24028463661670685
I0307 16:25:57.604326 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:25:58.922173 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:26:00.245048 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:26:01.567239 140545907463360 submission_runner.py:469] Time since start: 4154.23s, 	Step: 16350, 	{'train/ssim': 0.7423705373491559, 'train/loss': 0.27240889413016184, 'validation/ssim': 0.7222190775358751, 'validation/loss': 0.2876405560306169, 'validation/num_examples': 3554, 'test/ssim': 0.7395841741788257, 'test/loss': 0.28908387338339503, 'test/num_examples': 3581, 'score': 3075.942631959915, 'total_duration': 4154.233460187912, 'accumulated_submission_time': 3075.942631959915, 'accumulated_eval_time': 1071.1171562671661, 'accumulated_logging_time': 6.291675806045532}
I0307 16:26:01.580625 140390694889216 logging_writer.py:48] [16350] accumulated_eval_time=1071.12, accumulated_logging_time=6.29168, accumulated_submission_time=3075.94, global_step=16350, preemption_count=0, score=3075.94, test/loss=0.289084, test/num_examples=3581, test/ssim=0.739584, total_duration=4154.23, train/loss=0.272409, train/ssim=0.742371, validation/loss=0.287641, validation/num_examples=3554, validation/ssim=0.722219
I0307 16:26:05.788620 140390686496512 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.09434732049703598, loss=0.2716684341430664
I0307 16:26:14.060154 140390694889216 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.22567987442016602, loss=0.27726078033447266
I0307 16:26:22.326324 140390686496512 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.0927039161324501, loss=0.3427473306655884
I0307 16:26:30.582296 140390694889216 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.10316230356693268, loss=0.3142199218273163
I0307 16:26:38.847767 140390686496512 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.10743746906518936, loss=0.30040648579597473
I0307 16:26:47.100703 140390694889216 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.07079116255044937, loss=0.294892281293869
I0307 16:26:55.342330 140390686496512 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.20728638768196106, loss=0.30667784810066223
I0307 16:27:03.587861 140390694889216 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.10469333082437515, loss=0.2961370348930359
I0307 16:27:11.835196 140390686496512 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.06499050557613373, loss=0.2879383862018585
I0307 16:27:20.083880 140390694889216 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.16861209273338318, loss=0.2088293731212616
I0307 16:27:21.569134 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:27:22.888879 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:27:24.216489 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:27:25.540838 140545907463360 submission_runner.py:469] Time since start: 4238.21s, 	Step: 17319, 	{'train/ssim': 0.7423131125313895, 'train/loss': 0.2722296714782715, 'validation/ssim': 0.7221608245111142, 'validation/loss': 0.2874483141794457, 'validation/num_examples': 3554, 'test/ssim': 0.7395646074769617, 'test/loss': 0.28887249164426837, 'test/num_examples': 3581, 'score': 3155.8739941120148, 'total_duration': 4238.207042217255, 'accumulated_submission_time': 3155.8739941120148, 'accumulated_eval_time': 1075.0888013839722, 'accumulated_logging_time': 6.313649892807007}
I0307 16:27:25.554212 140390686496512 logging_writer.py:48] [17319] accumulated_eval_time=1075.09, accumulated_logging_time=6.31365, accumulated_submission_time=3155.87, global_step=17319, preemption_count=0, score=3155.87, test/loss=0.288872, test/num_examples=3581, test/ssim=0.739565, total_duration=4238.21, train/loss=0.27223, train/ssim=0.742313, validation/loss=0.287448, validation/num_examples=3554, validation/ssim=0.722161
I0307 16:27:32.337523 140390694889216 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.13595373928546906, loss=0.2773877680301666
I0307 16:27:40.590777 140390686496512 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.11679648607969284, loss=0.3034602403640747
I0307 16:27:48.845751 140390694889216 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.13224096596240997, loss=0.24174602329730988
I0307 16:27:57.083111 140390686496512 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.11294995993375778, loss=0.3000633418560028
I0307 16:28:05.327563 140390694889216 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.22624406218528748, loss=0.34040579199790955
I0307 16:28:13.579992 140390686496512 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.08286827802658081, loss=0.27145880460739136
I0307 16:28:21.827501 140390694889216 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.12134125828742981, loss=0.2380949705839157
I0307 16:28:30.083293 140390686496512 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.08845508098602295, loss=0.33383411169052124
I0307 16:28:38.316614 140390694889216 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.09988796710968018, loss=0.23777331411838531
I0307 16:28:45.561101 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:28:46.878881 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:28:48.199535 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:28:49.522749 140545907463360 submission_runner.py:469] Time since start: 4322.19s, 	Step: 18289, 	{'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3235.8228435516357, 'total_duration': 4322.188955307007, 'accumulated_submission_time': 3235.8228435516357, 'accumulated_eval_time': 1079.0503914356232, 'accumulated_logging_time': 6.335398435592651}
I0307 16:28:49.536504 140390686496512 logging_writer.py:48] [18289] accumulated_eval_time=1079.05, accumulated_logging_time=6.3354, accumulated_submission_time=3235.82, global_step=18289, preemption_count=0, score=3235.82, test/loss=0.288812, test/num_examples=3581, test/ssim=0.739937, total_duration=4322.19, train/loss=0.272175, train/ssim=0.742635, validation/loss=0.287399, validation/num_examples=3554, validation/ssim=0.722545
I0307 16:28:50.543445 140390694889216 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.07012032717466354, loss=0.28484201431274414
I0307 16:28:58.810355 140390686496512 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.1679752916097641, loss=0.29305747151374817
I0307 16:29:07.064304 140390694889216 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.14466147124767303, loss=0.3061155378818512
I0307 16:29:15.314849 140390686496512 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.24114468693733215, loss=0.2875051200389862
I0307 16:29:23.570988 140390694889216 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.18049941956996918, loss=0.21577605605125427
I0307 16:29:31.825057 140390686496512 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.0878276601433754, loss=0.31865882873535156
I0307 16:29:40.079398 140390694889216 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.13261620700359344, loss=0.2578083872795105
I0307 16:29:48.335922 140390686496512 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.13945698738098145, loss=0.26156339049339294
I0307 16:29:56.574519 140390694889216 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.27084487676620483, loss=0.3994559645652771
I0307 16:30:04.824558 140390686496512 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.23486073315143585, loss=0.3148057758808136
I0307 16:30:09.600190 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:30:10.918719 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:30:12.243511 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:30:13.564863 140545907463360 submission_runner.py:469] Time since start: 4406.23s, 	Step: 19259, 	{'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3315.829579114914, 'total_duration': 4406.231065273285, 'accumulated_submission_time': 3315.829579114914, 'accumulated_eval_time': 1083.0150055885315, 'accumulated_logging_time': 6.35699725151062}
I0307 16:30:13.578460 140390694889216 logging_writer.py:48] [19259] accumulated_eval_time=1083.02, accumulated_logging_time=6.357, accumulated_submission_time=3315.83, global_step=19259, preemption_count=0, score=3315.83, test/loss=0.288812, test/num_examples=3581, test/ssim=0.739937, total_duration=4406.23, train/loss=0.272175, train/ssim=0.742635, validation/loss=0.287399, validation/num_examples=3554, validation/ssim=0.722545
I0307 16:30:17.062877 140390686496512 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.2656232416629791, loss=0.26708728075027466
I0307 16:30:25.315153 140390694889216 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.1218886598944664, loss=0.3246214687824249
I0307 16:30:33.579769 140390686496512 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.1638006865978241, loss=0.26906508207321167
I0307 16:30:41.838518 140390694889216 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.1755649745464325, loss=0.22312402725219727
I0307 16:30:50.089220 140390686496512 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.19186359643936157, loss=0.24574121832847595
I0307 16:30:58.347221 140390694889216 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.18995776772499084, loss=0.28456392884254456
I0307 16:31:06.595688 140390686496512 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.10123753547668457, loss=0.2731698751449585
I0307 16:31:14.833207 140390694889216 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.20481865108013153, loss=0.27587220072746277
I0307 16:31:23.079388 140390686496512 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.11620282381772995, loss=0.30232739448547363
I0307 16:31:31.308938 140390694889216 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.20893007516860962, loss=0.26054713129997253
I0307 16:31:33.618772 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:31:34.937136 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:31:36.257092 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:31:37.581204 140545907463360 submission_runner.py:469] Time since start: 4490.25s, 	Step: 20229, 	{'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3395.8141696453094, 'total_duration': 4490.247409105301, 'accumulated_submission_time': 3395.8141696453094, 'accumulated_eval_time': 1086.9773797988892, 'accumulated_logging_time': 6.378014326095581}
I0307 16:31:37.597305 140390686496512 logging_writer.py:48] [20229] accumulated_eval_time=1086.98, accumulated_logging_time=6.37801, accumulated_submission_time=3395.81, global_step=20229, preemption_count=0, score=3395.81, test/loss=0.288812, test/num_examples=3581, test/ssim=0.739937, total_duration=4490.25, train/loss=0.272175, train/ssim=0.742635, validation/loss=0.287399, validation/num_examples=3554, validation/ssim=0.722545
I0307 16:31:43.568304 140390694889216 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.0877472534775734, loss=0.27986854314804077
I0307 16:31:51.820136 140390686496512 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.06546811014413834, loss=0.27603188157081604
I0307 16:32:00.088032 140390694889216 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.08940102159976959, loss=0.2940977215766907
I0307 16:32:08.338041 140390686496512 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.13122615218162537, loss=0.2540408670902252
I0307 16:32:16.588323 140390694889216 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.08783133327960968, loss=0.28521350026130676
I0307 16:32:24.839082 140390686496512 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.07314255833625793, loss=0.380714476108551
I0307 16:32:33.068421 140390694889216 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.1305428147315979, loss=0.2383231222629547
I0307 16:32:41.310083 140390686496512 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.18146705627441406, loss=0.3536107838153839
I0307 16:32:49.559475 140390694889216 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.062184520065784454, loss=0.28485068678855896
I0307 16:32:57.663083 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:32:58.979608 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:33:00.300697 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:33:01.624333 140545907463360 submission_runner.py:469] Time since start: 4574.29s, 	Step: 21199, 	{'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3475.8233230113983, 'total_duration': 4574.290541410446, 'accumulated_submission_time': 3475.8233230113983, 'accumulated_eval_time': 1090.938575744629, 'accumulated_logging_time': 6.402001619338989}
I0307 16:33:01.638337 140390686496512 logging_writer.py:48] [21199] accumulated_eval_time=1090.94, accumulated_logging_time=6.402, accumulated_submission_time=3475.82, global_step=21199, preemption_count=0, score=3475.82, test/loss=0.288812, test/num_examples=3581, test/ssim=0.739937, total_duration=4574.29, train/loss=0.272175, train/ssim=0.742635, validation/loss=0.287399, validation/num_examples=3554, validation/ssim=0.722545
I0307 16:33:01.817597 140390694889216 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.29701587557792664, loss=0.31786829233169556
I0307 16:33:10.063072 140390686496512 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.14452938735485077, loss=0.33894288539886475
I0307 16:33:18.334605 140390694889216 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.08345016092061996, loss=0.29042696952819824
I0307 16:33:26.606525 140390686496512 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.12450756132602692, loss=0.331758052110672
I0307 16:33:34.866213 140390694889216 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.08258214592933655, loss=0.2922164499759674
I0307 16:33:43.119881 140390686496512 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.0839923694729805, loss=0.2312413454055786
I0307 16:33:51.383864 140390694889216 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.26292407512664795, loss=0.2349657118320465
I0307 16:33:59.657420 140390686496512 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.08651447296142578, loss=0.22645531594753265
I0307 16:34:07.906519 140390694889216 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.09518406540155411, loss=0.2762070596218109
I0307 16:34:16.149116 140390686496512 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.11023393273353577, loss=0.30521291494369507
I0307 16:34:21.679985 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:34:22.999558 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:34:24.323185 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:34:25.648055 140545907463360 submission_runner.py:469] Time since start: 4658.31s, 	Step: 22168, 	{'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3555.8084588050842, 'total_duration': 4658.314262628555, 'accumulated_submission_time': 3555.8084588050842, 'accumulated_eval_time': 1094.9066054821014, 'accumulated_logging_time': 6.423353910446167}
I0307 16:34:25.663469 140390694889216 logging_writer.py:48] [22168] accumulated_eval_time=1094.91, accumulated_logging_time=6.42335, accumulated_submission_time=3555.81, global_step=22168, preemption_count=0, score=3555.81, test/loss=0.288812, test/num_examples=3581, test/ssim=0.739937, total_duration=4658.31, train/loss=0.272175, train/ssim=0.742635, validation/loss=0.287399, validation/num_examples=3554, validation/ssim=0.722545
I0307 16:34:28.400567 140390686496512 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.16107240319252014, loss=0.2593262493610382
I0307 16:34:36.636173 140390694889216 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.0616435743868351, loss=0.27095597982406616
I0307 16:34:44.880067 140390686496512 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.15326973795890808, loss=0.3197326064109802
I0307 16:34:53.130898 140390694889216 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.12553821504116058, loss=0.23487159609794617
I0307 16:35:01.367438 140390686496512 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.09515822678804398, loss=0.23403802514076233
I0307 16:35:09.629280 140390694889216 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.08419976383447647, loss=0.3278519809246063
I0307 16:35:17.880665 140390686496512 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.06936655193567276, loss=0.26560506224632263
I0307 16:35:26.132292 140390694889216 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.11440769582986832, loss=0.32652732729911804
I0307 16:35:34.386781 140390686496512 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.07257381826639175, loss=0.2579885721206665
I0307 16:35:42.637898 140390694889216 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.10958641767501831, loss=0.3146192729473114
I0307 16:35:45.702941 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:35:47.020447 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:35:48.345577 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:35:49.665710 140545907463360 submission_runner.py:469] Time since start: 4742.33s, 	Step: 23138, 	{'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3635.790990591049, 'total_duration': 4742.331930875778, 'accumulated_submission_time': 3635.790990591049, 'accumulated_eval_time': 1098.8693342208862, 'accumulated_logging_time': 6.446757555007935}
I0307 16:35:49.679582 140390686496512 logging_writer.py:48] [23138] accumulated_eval_time=1098.87, accumulated_logging_time=6.44676, accumulated_submission_time=3635.79, global_step=23138, preemption_count=0, score=3635.79, test/loss=0.288812, test/num_examples=3581, test/ssim=0.739937, total_duration=4742.33, train/loss=0.272175, train/ssim=0.742635, validation/loss=0.287399, validation/num_examples=3554, validation/ssim=0.722545
I0307 16:35:54.885375 140390694889216 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.09659914672374725, loss=0.29078084230422974
I0307 16:36:03.127298 140390686496512 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.1463382989168167, loss=0.29171469807624817
I0307 16:36:11.367680 140390694889216 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.08175210654735565, loss=0.3224233090877533
I0307 16:36:19.607473 140390686496512 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.19915734231472015, loss=0.25965848565101624
I0307 16:36:27.851989 140390694889216 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.11283477395772934, loss=0.25248983502388
I0307 16:36:36.090603 140390686496512 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.0566982664167881, loss=0.2793547809123993
I0307 16:36:44.329329 140390694889216 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.08566608279943466, loss=0.3661779761314392
I0307 16:36:52.577205 140390686496512 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.18743319809436798, loss=0.30657047033309937
I0307 16:37:00.817566 140390694889216 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.15542961657047272, loss=0.34098970890045166
I0307 16:37:09.053708 140390686496512 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.3707422912120819, loss=0.2744904160499573
I0307 16:37:09.715386 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:37:11.030618 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:37:12.352406 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:37:13.676532 140545907463360 submission_runner.py:469] Time since start: 4826.34s, 	Step: 24109, 	{'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3715.769942998886, 'total_duration': 4826.342738628387, 'accumulated_submission_time': 3715.769942998886, 'accumulated_eval_time': 1102.8304250240326, 'accumulated_logging_time': 6.468543767929077}
I0307 16:37:13.693997 140390694889216 logging_writer.py:48] [24109] accumulated_eval_time=1102.83, accumulated_logging_time=6.46854, accumulated_submission_time=3715.77, global_step=24109, preemption_count=0, score=3715.77, test/loss=0.288812, test/num_examples=3581, test/ssim=0.739937, total_duration=4826.34, train/loss=0.272175, train/ssim=0.742635, validation/loss=0.287399, validation/num_examples=3554, validation/ssim=0.722545
I0307 16:37:21.290227 140390686496512 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.12429489940404892, loss=0.2574895918369293
I0307 16:37:29.537508 140390694889216 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.21493938565254211, loss=0.24256451427936554
I0307 16:37:37.791661 140390686496512 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.11115829646587372, loss=0.2547625005245209
I0307 16:37:46.048068 140390694889216 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.06819112598896027, loss=0.28091126680374146
I0307 16:37:54.291672 140390686496512 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.11919969320297241, loss=0.29704049229621887
I0307 16:38:02.527462 140390694889216 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.1280495524406433, loss=0.21823912858963013
I0307 16:38:10.792697 140390686496512 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.08221358060836792, loss=0.2980646789073944
I0307 16:38:19.031286 140390694889216 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.05161189287900925, loss=0.35179686546325684
I0307 16:38:27.290912 140390686496512 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.10624923557043076, loss=0.283768892288208
I0307 16:38:33.747977 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:38:35.063817 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:38:36.384336 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:38:37.707395 140545907463360 submission_runner.py:469] Time since start: 4910.37s, 	Step: 25079, 	{'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3795.767014980316, 'total_duration': 4910.3736140728, 'accumulated_submission_time': 3795.767014980316, 'accumulated_eval_time': 1106.7897999286652, 'accumulated_logging_time': 6.49429178237915}
I0307 16:38:37.721444 140390694889216 logging_writer.py:48] [25079] accumulated_eval_time=1106.79, accumulated_logging_time=6.49429, accumulated_submission_time=3795.77, global_step=25079, preemption_count=0, score=3795.77, test/loss=0.288812, test/num_examples=3581, test/ssim=0.739937, total_duration=4910.37, train/loss=0.272175, train/ssim=0.742635, validation/loss=0.287399, validation/num_examples=3554, validation/ssim=0.722545
I0307 16:38:39.549216 140390686496512 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.12247267365455627, loss=0.37364086508750916
I0307 16:38:47.813198 140390694889216 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.10605785995721817, loss=0.217151939868927
I0307 16:38:56.080195 140390686496512 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.0673241913318634, loss=0.31122148036956787
I0307 16:39:04.338205 140390694889216 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.11068837344646454, loss=0.3379819989204407
I0307 16:39:12.582045 140390686496512 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.21172383427619934, loss=0.32427459955215454
I0307 16:39:20.824606 140390694889216 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.09989568591117859, loss=0.32798269391059875
I0307 16:39:29.066122 140390686496512 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.08976373076438904, loss=0.1992514282464981
I0307 16:39:37.319196 140390694889216 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.1419808268547058, loss=0.38233059644699097
I0307 16:39:45.550776 140390686496512 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.11530578881502151, loss=0.29389843344688416
I0307 16:39:53.814695 140390694889216 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.04885898530483246, loss=0.301616370677948
I0307 16:39:57.772747 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:39:59.094495 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:40:00.418160 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:40:01.742706 140545907463360 submission_runner.py:469] Time since start: 4994.41s, 	Step: 26049, 	{'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3875.76162981987, 'total_duration': 4994.408915042877, 'accumulated_submission_time': 3875.76162981987, 'accumulated_eval_time': 1110.759708404541, 'accumulated_logging_time': 6.515716791152954}
I0307 16:40:01.756946 140390686496512 logging_writer.py:48] [26049] accumulated_eval_time=1110.76, accumulated_logging_time=6.51572, accumulated_submission_time=3875.76, global_step=26049, preemption_count=0, score=3875.76, test/loss=0.288812, test/num_examples=3581, test/ssim=0.739937, total_duration=4994.41, train/loss=0.272175, train/ssim=0.742635, validation/loss=0.287399, validation/num_examples=3554, validation/ssim=0.722545
I0307 16:40:06.063120 140390694889216 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.25863397121429443, loss=0.2986837923526764
I0307 16:40:14.303023 140390686496512 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.06663130223751068, loss=0.38806068897247314
I0307 16:40:22.552732 140390694889216 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.11453509330749512, loss=0.2965622544288635
I0307 16:40:30.804121 140390686496512 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.10309560596942902, loss=0.272172749042511
I0307 16:40:39.053001 140390694889216 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.17665648460388184, loss=0.31178218126296997
I0307 16:40:47.298479 140390686496512 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.14860835671424866, loss=0.2784018814563751
I0307 16:40:55.553399 140390694889216 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.0987842008471489, loss=0.3055590093135834
I0307 16:41:03.801835 140390686496512 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.08389297872781754, loss=0.24819926917552948
I0307 16:41:12.038459 140390694889216 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.22171320021152496, loss=0.29368171095848083
I0307 16:41:20.286189 140390686496512 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.11909858137369156, loss=0.27053266763687134
I0307 16:41:21.775193 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:41:23.096640 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:41:24.420837 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:41:25.747955 140545907463360 submission_runner.py:469] Time since start: 5078.41s, 	Step: 27019, 	{'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3955.7228622436523, 'total_duration': 5078.414175033569, 'accumulated_submission_time': 3955.7228622436523, 'accumulated_eval_time': 1114.7324283123016, 'accumulated_logging_time': 6.538309574127197}
I0307 16:41:25.762342 140390694889216 logging_writer.py:48] [27019] accumulated_eval_time=1114.73, accumulated_logging_time=6.53831, accumulated_submission_time=3955.72, global_step=27019, preemption_count=0, score=3955.72, test/loss=0.288812, test/num_examples=3581, test/ssim=0.739937, total_duration=5078.41, train/loss=0.272175, train/ssim=0.742635, validation/loss=0.287399, validation/num_examples=3554, validation/ssim=0.722545
I0307 16:41:32.524265 140390686496512 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.16352376341819763, loss=0.23005400598049164
I0307 16:41:40.772014 140390694889216 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.38724642992019653, loss=0.2386743426322937
I0307 16:41:49.021245 140390686496512 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.15747757256031036, loss=0.2989349365234375
I0307 16:41:57.261234 140390694889216 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.11511478573083878, loss=0.3057664930820465
I0307 16:42:05.489749 140390686496512 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.23618873953819275, loss=0.29405447840690613
I0307 16:42:13.718770 140390694889216 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.05633287504315376, loss=0.2745397388935089
I0307 16:42:21.971053 140390686496512 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.07644962519407272, loss=0.24470704793930054
I0307 16:42:30.232451 140390694889216 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.17079579830169678, loss=0.30688488483428955
I0307 16:42:38.472106 140390686496512 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.15174119174480438, loss=0.2607230842113495
I0307 16:42:45.750801 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:42:47.073839 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:42:48.399513 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:42:49.720924 140545907463360 submission_runner.py:469] Time since start: 5162.39s, 	Step: 27989, 	{'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 4035.656488418579, 'total_duration': 5162.387141704559, 'accumulated_submission_time': 4035.656488418579, 'accumulated_eval_time': 1118.702505350113, 'accumulated_logging_time': 6.559993028640747}
I0307 16:42:49.735838 140390694889216 logging_writer.py:48] [27989] accumulated_eval_time=1118.7, accumulated_logging_time=6.55999, accumulated_submission_time=4035.66, global_step=27989, preemption_count=0, score=4035.66, test/loss=0.288812, test/num_examples=3581, test/ssim=0.739937, total_duration=5162.39, train/loss=0.272175, train/ssim=0.742635, validation/loss=0.287399, validation/num_examples=3554, validation/ssim=0.722545
I0307 16:42:50.742336 140390686496512 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.15949147939682007, loss=0.26962801814079285
I0307 16:42:58.983190 140390694889216 logging_writer.py:48] [28100] global_step=28100, grad_norm=0.2726691961288452, loss=0.30529284477233887
I0307 16:43:07.218855 140390686496512 logging_writer.py:48] [28200] global_step=28200, grad_norm=0.09490688145160675, loss=0.22826215624809265
I0307 16:43:15.475004 140390694889216 logging_writer.py:48] [28300] global_step=28300, grad_norm=0.0733681470155716, loss=0.2678123712539673
I0307 16:43:23.739075 140390686496512 logging_writer.py:48] [28400] global_step=28400, grad_norm=0.10541775077581406, loss=0.26522666215896606
I0307 16:43:32.006222 140390694889216 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.153397798538208, loss=0.29346615076065063
I0307 16:43:40.255533 140390686496512 logging_writer.py:48] [28600] global_step=28600, grad_norm=0.09348613768815994, loss=0.35276278853416443
I0307 16:43:48.500364 140390694889216 logging_writer.py:48] [28700] global_step=28700, grad_norm=0.13217127323150635, loss=0.2925717830657959
I0307 16:43:56.732923 140390686496512 logging_writer.py:48] [28800] global_step=28800, grad_norm=0.09813246876001358, loss=0.2684404253959656
I0307 16:44:04.998277 140390694889216 logging_writer.py:48] [28900] global_step=28900, grad_norm=0.07243072241544724, loss=0.3629879951477051
I0307 16:44:09.788710 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:44:11.105833 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:44:12.425282 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:44:13.749538 140545907463360 submission_runner.py:469] Time since start: 5246.42s, 	Step: 28959, 	{'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 4115.652072668076, 'total_duration': 5246.415754079819, 'accumulated_submission_time': 4115.652072668076, 'accumulated_eval_time': 1122.6632940769196, 'accumulated_logging_time': 6.583688259124756}
I0307 16:44:13.764833 140390686496512 logging_writer.py:48] [28959] accumulated_eval_time=1122.66, accumulated_logging_time=6.58369, accumulated_submission_time=4115.65, global_step=28959, preemption_count=0, score=4115.65, test/loss=0.288812, test/num_examples=3581, test/ssim=0.739937, total_duration=5246.42, train/loss=0.272175, train/ssim=0.742635, validation/loss=0.287399, validation/num_examples=3554, validation/ssim=0.722545
I0307 16:44:17.235086 140390694889216 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.19156502187252045, loss=0.24503183364868164
I0307 16:44:25.465005 140390686496512 logging_writer.py:48] [29100] global_step=29100, grad_norm=0.10478682816028595, loss=0.24005712568759918
I0307 16:44:33.713016 140390694889216 logging_writer.py:48] [29200] global_step=29200, grad_norm=0.13498198986053467, loss=0.3865044116973877
I0307 16:44:41.941627 140390686496512 logging_writer.py:48] [29300] global_step=29300, grad_norm=0.06949926912784576, loss=0.24643753468990326
I0307 16:44:50.212628 140390694889216 logging_writer.py:48] [29400] global_step=29400, grad_norm=0.2230985164642334, loss=0.22632703185081482
I0307 16:44:58.472222 140390686496512 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.16099430620670319, loss=0.30905234813690186
I0307 16:45:06.733488 140390694889216 logging_writer.py:48] [29600] global_step=29600, grad_norm=0.09673934429883957, loss=0.2663666605949402
I0307 16:45:14.980466 140390686496512 logging_writer.py:48] [29700] global_step=29700, grad_norm=0.0750185176730156, loss=0.37720969319343567
I0307 16:45:23.219539 140390694889216 logging_writer.py:48] [29800] global_step=29800, grad_norm=0.18689632415771484, loss=0.2776513397693634
I0307 16:45:31.469377 140390686496512 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.21064332127571106, loss=0.25726497173309326
I0307 16:45:33.778640 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:45:35.096931 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:45:36.415952 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:45:37.736441 140545907463360 submission_runner.py:469] Time since start: 5330.40s, 	Step: 29929, 	{'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 4195.61047077179, 'total_duration': 5330.402661323547, 'accumulated_submission_time': 4195.61047077179, 'accumulated_eval_time': 1126.6210520267487, 'accumulated_logging_time': 6.6062681674957275}
I0307 16:45:37.751472 140390694889216 logging_writer.py:48] [29929] accumulated_eval_time=1126.62, accumulated_logging_time=6.60627, accumulated_submission_time=4195.61, global_step=29929, preemption_count=0, score=4195.61, test/loss=0.288812, test/num_examples=3581, test/ssim=0.739937, total_duration=5330.4, train/loss=0.272175, train/ssim=0.742635, validation/loss=0.287399, validation/num_examples=3554, validation/ssim=0.722545
I0307 16:45:43.697625 140390686496512 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.08403709530830383, loss=0.2742035984992981
I0307 16:45:51.934184 140390694889216 logging_writer.py:48] [30100] global_step=30100, grad_norm=0.1573394387960434, loss=0.3026103377342224
I0307 16:46:00.239812 140390686496512 logging_writer.py:48] [30200] global_step=30200, grad_norm=0.06492608040571213, loss=0.21681761741638184
I0307 16:46:08.496751 140390694889216 logging_writer.py:48] [30300] global_step=30300, grad_norm=0.0817103460431099, loss=0.294840931892395
I0307 16:46:16.733800 140390686496512 logging_writer.py:48] [30400] global_step=30400, grad_norm=0.18195407092571259, loss=0.2986944019794464
I0307 16:46:24.976205 140390694889216 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.1123138964176178, loss=0.3197922110557556
I0307 16:46:33.233295 140390686496512 logging_writer.py:48] [30600] global_step=30600, grad_norm=0.08804637938737869, loss=0.2797243297100067
I0307 16:46:41.479971 140390694889216 logging_writer.py:48] [30700] global_step=30700, grad_norm=0.06211483106017113, loss=0.28607261180877686
I0307 16:46:49.719135 140390686496512 logging_writer.py:48] [30800] global_step=30800, grad_norm=0.11191221326589584, loss=0.3425807058811188
I0307 16:46:57.800616 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:46:59.120367 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:47:00.443850 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:47:01.767667 140545907463360 submission_runner.py:469] Time since start: 5414.43s, 	Step: 30899, 	{'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 4275.603677749634, 'total_duration': 5414.433887004852, 'accumulated_submission_time': 4275.603677749634, 'accumulated_eval_time': 1130.5880634784698, 'accumulated_logging_time': 6.6291961669921875}
I0307 16:47:01.782690 140390694889216 logging_writer.py:48] [30899] accumulated_eval_time=1130.59, accumulated_logging_time=6.6292, accumulated_submission_time=4275.6, global_step=30899, preemption_count=0, score=4275.6, test/loss=0.288812, test/num_examples=3581, test/ssim=0.739937, total_duration=5414.43, train/loss=0.272175, train/ssim=0.742635, validation/loss=0.287399, validation/num_examples=3554, validation/ssim=0.722545
I0307 16:47:01.961523 140390686496512 logging_writer.py:48] [30900] global_step=30900, grad_norm=0.061943020671606064, loss=0.310439795255661
I0307 16:47:10.210997 140390694889216 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.09995882958173752, loss=0.2687610685825348
I0307 16:47:18.450008 140390686496512 logging_writer.py:48] [31100] global_step=31100, grad_norm=0.09523007273674011, loss=0.2572042942047119
I0307 16:47:26.710742 140390694889216 logging_writer.py:48] [31200] global_step=31200, grad_norm=0.21037015318870544, loss=0.3090565800666809
I0307 16:47:34.942938 140390686496512 logging_writer.py:48] [31300] global_step=31300, grad_norm=0.1262316107749939, loss=0.31901824474334717
I0307 16:47:43.186540 140390694889216 logging_writer.py:48] [31400] global_step=31400, grad_norm=0.13032826781272888, loss=0.2983876168727875
I0307 16:47:51.421552 140390686496512 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.16979597508907318, loss=0.27640312910079956
I0307 16:47:59.664586 140390694889216 logging_writer.py:48] [31600] global_step=31600, grad_norm=0.25926652550697327, loss=0.30300936102867126
I0307 16:48:07.916152 140390686496512 logging_writer.py:48] [31700] global_step=31700, grad_norm=0.13355009257793427, loss=0.33603304624557495
I0307 16:48:16.182396 140390694889216 logging_writer.py:48] [31800] global_step=31800, grad_norm=0.09735482931137085, loss=0.3041134774684906
I0307 16:48:21.798568 140545907463360 spec.py:321] Evaluating on the training split.
I0307 16:48:23.116733 140545907463360 spec.py:333] Evaluating on the validation split.
I0307 16:48:24.438339 140545907463360 spec.py:349] Evaluating on the test split.
I0307 16:48:25.759785 140545907463360 submission_runner.py:469] Time since start: 5498.43s, 	Step: 31869, 	{'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 4355.563270330429, 'total_duration': 5498.425994634628, 'accumulated_submission_time': 4355.563270330429, 'accumulated_eval_time': 1134.549230337143, 'accumulated_logging_time': 6.651534080505371}
I0307 16:48:25.775020 140390686496512 logging_writer.py:48] [31869] accumulated_eval_time=1134.55, accumulated_logging_time=6.65153, accumulated_submission_time=4355.56, global_step=31869, preemption_count=0, score=4355.56, test/loss=0.288812, test/num_examples=3581, test/ssim=0.739937, total_duration=5498.43, train/loss=0.272175, train/ssim=0.742635, validation/loss=0.287399, validation/num_examples=3554, validation/ssim=0.722545
I0307 16:48:28.421970 140390694889216 logging_writer.py:48] [31900] global_step=31900, grad_norm=0.04808836057782173, loss=0.2720085084438324
I0307 16:48:36.670468 140390686496512 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.07737448066473007, loss=0.2651456594467163
I0307 16:48:44.917283 140390694889216 logging_writer.py:48] [32100] global_step=32100, grad_norm=0.10863951593637466, loss=0.2593781650066376
I0307 16:48:53.156268 140390686496512 logging_writer.py:48] [32200] global_step=32200, grad_norm=0.19800905883312225, loss=0.2762554883956909
I0307 16:49:01.407398 140390694889216 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.10435539484024048, loss=0.2594347298145294
I0307 16:49:09.681401 140390686496512 logging_writer.py:48] [32400] global_step=32400, grad_norm=0.19339577853679657, loss=0.3222750127315521
I0307 16:49:17.941073 140390694889216 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.15187330543994904, loss=0.2637022137641907
I0307 16:49:26.217473 140390686496512 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.17603689432144165, loss=0.2757437229156494
I0307 16:49:34.451529 140390694889216 logging_writer.py:48] [32700] global_step=32700, grad_norm=0.1590672880411148, loss=0.2522086203098297
I0307 16:49:42.675195 140390686496512 logging_writer.py:48] [32800] global_step=32800, grad_norm=0.1294979602098465, loss=0.2526533603668213
I0307 16:49:45.824924 140390694889216 logging_writer.py:48] [32839] global_step=32839, preemption_count=0, score=4435.55
I0307 16:49:47.618903 140545907463360 submission_runner.py:646] Tuning trial 5/5
I0307 16:49:47.619122 140545907463360 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.1, label_smoothing=0.0, learning_rate=0.0017486387539278373, one_minus_beta1=0.06733926164, beta2=0.9955159689799007, weight_decay=0.08121616522670176, warmup_factor=0.02)
I0307 16:49:47.620779 140545907463360 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/ssim': 0.20131874084472656, 'train/loss': 1.2105323246547155, 'validation/ssim': 0.19433537076951146, 'validation/loss': 1.2141275400517022, 'validation/num_examples': 3554, 'test/ssim': 0.21488866137579413, 'test/loss': 1.2124597484990227, 'test/num_examples': 3581, 'score': 257.6056706905365, 'total_duration': 1189.643996477127, 'accumulated_submission_time': 257.6056706905365, 'accumulated_eval_time': 932.0381655693054, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (245, {'train/ssim': 0.6934787205287388, 'train/loss': 0.31765055656433105, 'validation/ssim': 0.6731690002681837, 'validation/loss': 0.3340730940819323, 'validation/num_examples': 3554, 'test/ssim': 0.6919718435841944, 'test/loss': 0.33537991717353743, 'test/num_examples': 3581, 'score': 338.98561120033264, 'total_duration': 1275.8885860443115, 'accumulated_submission_time': 338.98561120033264, 'accumulated_eval_time': 936.8455543518066, 'accumulated_logging_time': 0.016571998596191406, 'global_step': 245, 'preemption_count': 0}), (287, {'train/ssim': 0.6991327149527413, 'train/loss': 0.3128558226994106, 'validation/ssim': 0.6795797181652715, 'validation/loss': 0.3283787578696539, 'validation/num_examples': 3554, 'test/ssim': 0.6981606482127897, 'test/loss': 0.32993549942404354, 'test/num_examples': 3581, 'score': 419.6313986778259, 'total_duration': 1360.4931252002716, 'accumulated_submission_time': 419.6313986778259, 'accumulated_eval_time': 940.783328294754, 'accumulated_logging_time': 0.03460264205932617, 'global_step': 287, 'preemption_count': 0}), (323, {'train/ssim': 0.7017188753400531, 'train/loss': 0.3123376710074289, 'validation/ssim': 0.6828578933947664, 'validation/loss': 0.3273175636166995, 'validation/num_examples': 3554, 'test/ssim': 0.7011261284601019, 'test/loss': 0.32916677347676976, 'test/num_examples': 3581, 'score': 500.576872587204, 'total_duration': 1445.4720141887665, 'accumulated_submission_time': 500.576872587204, 'accumulated_eval_time': 944.7246146202087, 'accumulated_logging_time': 0.12395620346069336, 'global_step': 323, 'preemption_count': 0}), (366, {'train/ssim': 0.7062311172485352, 'train/loss': 0.3063415118626186, 'validation/ssim': 0.6874691561225028, 'validation/loss': 0.321555425829611, 'validation/num_examples': 3554, 'test/ssim': 0.7054770266467119, 'test/loss': 0.3234238783030229, 'test/num_examples': 3581, 'score': 581.6043388843536, 'total_duration': 1530.5185878276825, 'accumulated_submission_time': 581.6043388843536, 'accumulated_eval_time': 948.6599049568176, 'accumulated_logging_time': 0.2041318416595459, 'global_step': 366, 'preemption_count': 0}), (404, {'train/ssim': 0.709153379712786, 'train/loss': 0.30632046290806364, 'validation/ssim': 0.6909369284608892, 'validation/loss': 0.3210447501384883, 'validation/num_examples': 3554, 'test/ssim': 0.7087407797882924, 'test/loss': 0.3230555538890149, 'test/num_examples': 3581, 'score': 662.8552556037903, 'total_duration': 1615.7669820785522, 'accumulated_submission_time': 662.8552556037903, 'accumulated_eval_time': 952.5974872112274, 'accumulated_logging_time': 0.26107287406921387, 'global_step': 404, 'preemption_count': 0}), (441, {'train/ssim': 0.7082914624895368, 'train/loss': 0.30632972717285156, 'validation/ssim': 0.6893056376837718, 'validation/loss': 0.321843805780019, 'validation/num_examples': 3554, 'test/ssim': 0.7067220006632225, 'test/loss': 0.3240722724426662, 'test/num_examples': 3581, 'score': 743.5722634792328, 'total_duration': 1700.4379181861877, 'accumulated_submission_time': 743.5722634792328, 'accumulated_eval_time': 956.5311770439148, 'accumulated_logging_time': 0.2785453796386719, 'global_step': 441, 'preemption_count': 0}), (483, {'train/ssim': 0.710026468549456, 'train/loss': 0.3017918382372175, 'validation/ssim': 0.6910751420054868, 'validation/loss': 0.3168116512094647, 'validation/num_examples': 3554, 'test/ssim': 0.708769277632819, 'test/loss': 0.31897494207710836, 'test/num_examples': 3581, 'score': 825.1876840591431, 'total_duration': 1786.0097117424011, 'accumulated_submission_time': 825.1876840591431, 'accumulated_eval_time': 960.466639995575, 'accumulated_logging_time': 0.29638099670410156, 'global_step': 483, 'preemption_count': 0}), (521, {'train/ssim': 0.7115982600620815, 'train/loss': 0.30224738802228657, 'validation/ssim': 0.693065156008195, 'validation/loss': 0.3170971803337788, 'validation/num_examples': 3554, 'test/ssim': 0.7105540744554594, 'test/loss': 0.31926513603698337, 'test/num_examples': 3581, 'score': 906.32736992836, 'total_duration': 1871.1014235019684, 'accumulated_submission_time': 906.32736992836, 'accumulated_eval_time': 964.3981850147247, 'accumulated_logging_time': 0.314345121383667, 'global_step': 521, 'preemption_count': 0}), (564, {'train/ssim': 0.7141413688659668, 'train/loss': 0.2994446413857596, 'validation/ssim': 0.6961040679296215, 'validation/loss': 0.3139397015246905, 'validation/num_examples': 3554, 'test/ssim': 0.7135573927499302, 'test/loss': 0.3161552235321837, 'test/num_examples': 3581, 'score': 987.5353055000305, 'total_duration': 1956.2653486728668, 'accumulated_submission_time': 987.5353055000305, 'accumulated_eval_time': 968.3339655399323, 'accumulated_logging_time': 0.3316490650177002, 'global_step': 564, 'preemption_count': 0}), (604, {'train/ssim': 0.7154714039393834, 'train/loss': 0.2991128649030413, 'validation/ssim': 0.6973831614685917, 'validation/loss': 0.3134528972086909, 'validation/num_examples': 3554, 'test/ssim': 0.7148601123987713, 'test/loss': 0.31573607341699245, 'test/num_examples': 3581, 'score': 1068.4938399791718, 'total_duration': 2041.1851961612701, 'accumulated_submission_time': 1068.4938399791718, 'accumulated_eval_time': 972.2738420963287, 'accumulated_logging_time': 0.34977078437805176, 'global_step': 604, 'preemption_count': 0}), (646, {'train/ssim': 0.7139509746006557, 'train/loss': 0.30063322612217497, 'validation/ssim': 0.6946952789770329, 'validation/loss': 0.3165364606231535, 'validation/num_examples': 3554, 'test/ssim': 0.7119855116413013, 'test/loss': 0.3188721657598262, 'test/num_examples': 3581, 'score': 1149.2278916835785, 'total_duration': 2125.888920068741, 'accumulated_submission_time': 1149.2278916835785, 'accumulated_eval_time': 976.2094264030457, 'accumulated_logging_time': 0.3804922103881836, 'global_step': 646, 'preemption_count': 0}), (688, {'train/ssim': 0.7172619955880302, 'train/loss': 0.2963770457676479, 'validation/ssim': 0.6983347878270962, 'validation/loss': 0.31129234884988743, 'validation/num_examples': 3554, 'test/ssim': 0.715815335603707, 'test/loss': 0.3135630786835032, 'test/num_examples': 3581, 'score': 1229.2125027179718, 'total_duration': 2209.9563467502594, 'accumulated_submission_time': 1229.2125027179718, 'accumulated_eval_time': 980.1452226638794, 'accumulated_logging_time': 0.5245342254638672, 'global_step': 688, 'preemption_count': 0}), (724, {'train/ssim': 0.7180110386439732, 'train/loss': 0.29560256004333496, 'validation/ssim': 0.7001668729336663, 'validation/loss': 0.3098867198491137, 'validation/num_examples': 3554, 'test/ssim': 0.7174664379930537, 'test/loss': 0.31231115064751463, 'test/num_examples': 3581, 'score': 1309.3920044898987, 'total_duration': 2294.097860813141, 'accumulated_submission_time': 1309.3920044898987, 'accumulated_eval_time': 984.0828812122345, 'accumulated_logging_time': 0.5464646816253662, 'global_step': 724, 'preemption_count': 0}), (764, {'train/ssim': 0.7169515745980399, 'train/loss': 0.29640953881399973, 'validation/ssim': 0.6980400879730585, 'validation/loss': 0.3111243218468627, 'validation/num_examples': 3554, 'test/ssim': 0.7152648090617146, 'test/loss': 0.31357374833103535, 'test/num_examples': 3581, 'score': 1389.6225373744965, 'total_duration': 2378.2904348373413, 'accumulated_submission_time': 1389.6225373744965, 'accumulated_eval_time': 988.0210826396942, 'accumulated_logging_time': 0.5648376941680908, 'global_step': 764, 'preemption_count': 0}), (806, {'train/ssim': 0.7194410732814244, 'train/loss': 0.29479527473449707, 'validation/ssim': 0.7009223761958356, 'validation/loss': 0.3095204058697067, 'validation/num_examples': 3554, 'test/ssim': 0.7180290999808014, 'test/loss': 0.3119281000746125, 'test/num_examples': 3581, 'score': 1470.7271733283997, 'total_duration': 2463.3617770671844, 'accumulated_submission_time': 1470.7271733283997, 'accumulated_eval_time': 991.9607055187225, 'accumulated_logging_time': 0.5875678062438965, 'global_step': 806, 'preemption_count': 0}), (843, {'train/ssim': 0.7208996500287738, 'train/loss': 0.293203490121024, 'validation/ssim': 0.7027378372080754, 'validation/loss': 0.30764724138954347, 'validation/num_examples': 3554, 'test/ssim': 0.7198229642994275, 'test/loss': 0.31013876950397934, 'test/num_examples': 3581, 'score': 1553.1048185825348, 'total_duration': 2549.6933467388153, 'accumulated_submission_time': 1553.1048185825348, 'accumulated_eval_time': 995.8932812213898, 'accumulated_logging_time': 0.6063234806060791, 'global_step': 843, 'preemption_count': 0}), (885, {'train/ssim': 0.7177916935511998, 'train/loss': 0.2937345504760742, 'validation/ssim': 0.700300071772123, 'validation/loss': 0.30770013623514, 'validation/num_examples': 3554, 'test/ssim': 0.7175280015184307, 'test/loss': 0.31003728854326656, 'test/num_examples': 3581, 'score': 1635.7886583805084, 'total_duration': 2636.335819721222, 'accumulated_submission_time': 1635.7886583805084, 'accumulated_eval_time': 999.828663110733, 'accumulated_logging_time': 0.6257760524749756, 'global_step': 885, 'preemption_count': 0}), (928, {'train/ssim': 0.7228571346827916, 'train/loss': 0.2915998526981899, 'validation/ssim': 0.7043287355576463, 'validation/loss': 0.30618782451331245, 'validation/num_examples': 3554, 'test/ssim': 0.7214254567290911, 'test/loss': 0.3086399737765289, 'test/num_examples': 3581, 'score': 1718.6132566928864, 'total_duration': 2723.119059085846, 'accumulated_submission_time': 1718.6132566928864, 'accumulated_eval_time': 1003.7649624347687, 'accumulated_logging_time': 0.6450037956237793, 'global_step': 928, 'preemption_count': 0}), (1036, {'train/ssim': 0.7203072139195034, 'train/loss': 0.2914558819362095, 'validation/ssim': 0.7023729314680641, 'validation/loss': 0.30587402755917625, 'validation/num_examples': 3554, 'test/ssim': 0.7196316605871265, 'test/loss': 0.30805399537053196, 'test/num_examples': 3581, 'score': 1801.8736760616302, 'total_duration': 2810.352548122406, 'accumulated_submission_time': 1801.8736760616302, 'accumulated_eval_time': 1007.7108891010284, 'accumulated_logging_time': 0.6638028621673584, 'global_step': 1036, 'preemption_count': 0}), (1867, {'train/ssim': 0.7280985287257603, 'train/loss': 0.28644323348999023, 'validation/ssim': 0.7092301642955121, 'validation/loss': 0.30109779473832304, 'validation/num_examples': 3554, 'test/ssim': 0.7259941793493437, 'test/loss': 0.30357826571662944, 'test/num_examples': 3581, 'score': 1881.817658662796, 'total_duration': 2894.314464569092, 'accumulated_submission_time': 1881.817658662796, 'accumulated_eval_time': 1011.666056394577, 'accumulated_logging_time': 0.6829276084899902, 'global_step': 1867, 'preemption_count': 0}), (2837, {'train/ssim': 0.7328900609697614, 'train/loss': 0.28015383652278353, 'validation/ssim': 0.7136244207670934, 'validation/loss': 0.2947093338931486, 'validation/num_examples': 3554, 'test/ssim': 0.731026571444778, 'test/loss': 0.29656810275804596, 'test/num_examples': 3581, 'score': 1961.7479076385498, 'total_duration': 2978.274920463562, 'accumulated_submission_time': 1961.7479076385498, 'accumulated_eval_time': 1015.6244695186615, 'accumulated_logging_time': 0.7047760486602783, 'global_step': 2837, 'preemption_count': 0}), (3807, {'train/ssim': 0.7367397035871234, 'train/loss': 0.2792292152132307, 'validation/ssim': 0.7176286979679586, 'validation/loss': 0.2936873986067635, 'validation/num_examples': 3554, 'test/ssim': 0.7347739016467119, 'test/loss': 0.2953810448155194, 'test/num_examples': 3581, 'score': 2041.6854329109192, 'total_duration': 3062.2419352531433, 'accumulated_submission_time': 2041.6854329109192, 'accumulated_eval_time': 1019.5842185020447, 'accumulated_logging_time': 0.724376916885376, 'global_step': 3807, 'preemption_count': 0}), (4712, {'train/ssim': 0.7346679823739188, 'train/loss': 0.27733354909079416, 'validation/ssim': 0.715737054639139, 'validation/loss': 0.29193740355277503, 'validation/num_examples': 3554, 'test/ssim': 0.7333337378481919, 'test/loss': 0.2933386765655543, 'test/num_examples': 3581, 'score': 2116.345298051834, 'total_duration': 3146.227527141571, 'accumulated_submission_time': 2116.345298051834, 'accumulated_eval_time': 1023.5468060970306, 'accumulated_logging_time': 6.040001630783081, 'global_step': 4712, 'preemption_count': 0}), (5682, {'train/ssim': 0.7357995169503349, 'train/loss': 0.27629891463688444, 'validation/ssim': 0.7161711358460537, 'validation/loss': 0.2910175484489308, 'validation/num_examples': 3554, 'test/ssim': 0.7338151332553756, 'test/loss': 0.2924048608323443, 'test/num_examples': 3581, 'score': 2196.282222509384, 'total_duration': 3230.2003178596497, 'accumulated_submission_time': 2196.282222509384, 'accumulated_eval_time': 1027.5117647647858, 'accumulated_logging_time': 6.06099271774292, 'global_step': 5682, 'preemption_count': 0}), (6653, {'train/ssim': 0.7392710958208356, 'train/loss': 0.2754725899015154, 'validation/ssim': 0.7197093201542276, 'validation/loss': 0.2902531148881542, 'validation/num_examples': 3554, 'test/ssim': 0.7371022028152052, 'test/loss': 0.2917131404242879, 'test/num_examples': 3581, 'score': 2276.2766897678375, 'total_duration': 3314.2194068431854, 'accumulated_submission_time': 2276.2766897678375, 'accumulated_eval_time': 1031.467073917389, 'accumulated_logging_time': 6.080403089523315, 'global_step': 6653, 'preemption_count': 0}), (7623, {'train/ssim': 0.7384654453822544, 'train/loss': 0.2749414954866682, 'validation/ssim': 0.7187267125290167, 'validation/loss': 0.2897435039634039, 'validation/num_examples': 3554, 'test/ssim': 0.736107300793249, 'test/loss': 0.29128553640306476, 'test/num_examples': 3581, 'score': 2356.271887779236, 'total_duration': 3398.254152536392, 'accumulated_submission_time': 2356.271887779236, 'accumulated_eval_time': 1035.438351392746, 'accumulated_logging_time': 6.0999979972839355, 'global_step': 7623, 'preemption_count': 0}), (8593, {'train/ssim': 0.7375209672110421, 'train/loss': 0.27534488269260954, 'validation/ssim': 0.7176506802414533, 'validation/loss': 0.29002271318408834, 'validation/num_examples': 3554, 'test/ssim': 0.7351834388526249, 'test/loss': 0.29150186095015357, 'test/num_examples': 3581, 'score': 2436.2463290691376, 'total_duration': 3482.259114742279, 'accumulated_submission_time': 2436.2463290691376, 'accumulated_eval_time': 1039.3992652893066, 'accumulated_logging_time': 6.1215174198150635, 'global_step': 8593, 'preemption_count': 0}), (9563, {'train/ssim': 0.7404016086033413, 'train/loss': 0.27452114650181364, 'validation/ssim': 0.7207052545327448, 'validation/loss': 0.2895181856600837, 'validation/num_examples': 3554, 'test/ssim': 0.7381288069847808, 'test/loss': 0.29086959059096623, 'test/num_examples': 3581, 'score': 2516.19789147377, 'total_duration': 3566.242546081543, 'accumulated_submission_time': 2516.19789147377, 'accumulated_eval_time': 1043.3628237247467, 'accumulated_logging_time': 6.14155125617981, 'global_step': 9563, 'preemption_count': 0}), (10533, {'train/ssim': 0.7383284568786621, 'train/loss': 0.27480808326176237, 'validation/ssim': 0.719604904355128, 'validation/loss': 0.2893448691724993, 'validation/num_examples': 3554, 'test/ssim': 0.7367932943617356, 'test/loss': 0.2907890398653484, 'test/num_examples': 3581, 'score': 2596.140430688858, 'total_duration': 3650.2196164131165, 'accumulated_submission_time': 2596.140430688858, 'accumulated_eval_time': 1047.3277714252472, 'accumulated_logging_time': 6.162447929382324, 'global_step': 10533, 'preemption_count': 0}), (11503, {'train/ssim': 0.7406071254185268, 'train/loss': 0.2739080360957554, 'validation/ssim': 0.7204275222460608, 'validation/loss': 0.28917258310398497, 'validation/num_examples': 3554, 'test/ssim': 0.7378591001117006, 'test/loss': 0.29069072911939753, 'test/num_examples': 3581, 'score': 2676.13227891922, 'total_duration': 3734.250948190689, 'accumulated_submission_time': 2676.13227891922, 'accumulated_eval_time': 1051.2951412200928, 'accumulated_logging_time': 6.185567140579224, 'global_step': 11503, 'preemption_count': 0}), (12473, {'train/ssim': 0.7407779693603516, 'train/loss': 0.2735851151602609, 'validation/ssim': 0.7211138500413267, 'validation/loss': 0.28863480739131964, 'validation/num_examples': 3554, 'test/ssim': 0.7386281328539515, 'test/loss': 0.29000950791721936, 'test/num_examples': 3581, 'score': 2756.128397703171, 'total_duration': 3818.2783908843994, 'accumulated_submission_time': 2756.128397703171, 'accumulated_eval_time': 1055.2566134929657, 'accumulated_logging_time': 6.206440687179565, 'global_step': 12473, 'preemption_count': 0}), (13442, {'train/ssim': 0.7430000305175781, 'train/loss': 0.2728091648646763, 'validation/ssim': 0.7231090848339898, 'validation/loss': 0.28801020169835045, 'validation/num_examples': 3554, 'test/ssim': 0.7403315267427045, 'test/loss': 0.28955742847450083, 'test/num_examples': 3581, 'score': 2836.060392141342, 'total_duration': 3902.2402725219727, 'accumulated_submission_time': 2836.060392141342, 'accumulated_eval_time': 1059.2171614170074, 'accumulated_logging_time': 6.227145433425903, 'global_step': 13442, 'preemption_count': 0}), (14412, {'train/ssim': 0.741492748260498, 'train/loss': 0.2732466459274292, 'validation/ssim': 0.7212862048044457, 'validation/loss': 0.2884703525077378, 'validation/num_examples': 3554, 'test/ssim': 0.7386060436156102, 'test/loss': 0.28990001619877476, 'test/num_examples': 3581, 'score': 2916.0443081855774, 'total_duration': 3986.2603616714478, 'accumulated_submission_time': 2916.0443081855774, 'accumulated_eval_time': 1063.182886838913, 'accumulated_logging_time': 6.248644828796387, 'global_step': 14412, 'preemption_count': 0}), (15381, {'train/ssim': 0.7424077306474958, 'train/loss': 0.2725856304168701, 'validation/ssim': 0.7224305882236565, 'validation/loss': 0.28774711853611246, 'validation/num_examples': 3554, 'test/ssim': 0.7398191791311785, 'test/loss': 0.2891470731486491, 'test/num_examples': 3581, 'score': 2995.995940208435, 'total_duration': 4070.2537894248962, 'accumulated_submission_time': 2995.995940208435, 'accumulated_eval_time': 1067.154284477234, 'accumulated_logging_time': 6.270179510116577, 'global_step': 15381, 'preemption_count': 0}), (16350, {'train/ssim': 0.7423705373491559, 'train/loss': 0.27240889413016184, 'validation/ssim': 0.7222190775358751, 'validation/loss': 0.2876405560306169, 'validation/num_examples': 3554, 'test/ssim': 0.7395841741788257, 'test/loss': 0.28908387338339503, 'test/num_examples': 3581, 'score': 3075.942631959915, 'total_duration': 4154.233460187912, 'accumulated_submission_time': 3075.942631959915, 'accumulated_eval_time': 1071.1171562671661, 'accumulated_logging_time': 6.291675806045532, 'global_step': 16350, 'preemption_count': 0}), (17319, {'train/ssim': 0.7423131125313895, 'train/loss': 0.2722296714782715, 'validation/ssim': 0.7221608245111142, 'validation/loss': 0.2874483141794457, 'validation/num_examples': 3554, 'test/ssim': 0.7395646074769617, 'test/loss': 0.28887249164426837, 'test/num_examples': 3581, 'score': 3155.8739941120148, 'total_duration': 4238.207042217255, 'accumulated_submission_time': 3155.8739941120148, 'accumulated_eval_time': 1075.0888013839722, 'accumulated_logging_time': 6.313649892807007, 'global_step': 17319, 'preemption_count': 0}), (18289, {'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3235.8228435516357, 'total_duration': 4322.188955307007, 'accumulated_submission_time': 3235.8228435516357, 'accumulated_eval_time': 1079.0503914356232, 'accumulated_logging_time': 6.335398435592651, 'global_step': 18289, 'preemption_count': 0}), (19259, {'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3315.829579114914, 'total_duration': 4406.231065273285, 'accumulated_submission_time': 3315.829579114914, 'accumulated_eval_time': 1083.0150055885315, 'accumulated_logging_time': 6.35699725151062, 'global_step': 19259, 'preemption_count': 0}), (20229, {'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3395.8141696453094, 'total_duration': 4490.247409105301, 'accumulated_submission_time': 3395.8141696453094, 'accumulated_eval_time': 1086.9773797988892, 'accumulated_logging_time': 6.378014326095581, 'global_step': 20229, 'preemption_count': 0}), (21199, {'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3475.8233230113983, 'total_duration': 4574.290541410446, 'accumulated_submission_time': 3475.8233230113983, 'accumulated_eval_time': 1090.938575744629, 'accumulated_logging_time': 6.402001619338989, 'global_step': 21199, 'preemption_count': 0}), (22168, {'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3555.8084588050842, 'total_duration': 4658.314262628555, 'accumulated_submission_time': 3555.8084588050842, 'accumulated_eval_time': 1094.9066054821014, 'accumulated_logging_time': 6.423353910446167, 'global_step': 22168, 'preemption_count': 0}), (23138, {'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3635.790990591049, 'total_duration': 4742.331930875778, 'accumulated_submission_time': 3635.790990591049, 'accumulated_eval_time': 1098.8693342208862, 'accumulated_logging_time': 6.446757555007935, 'global_step': 23138, 'preemption_count': 0}), (24109, {'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3715.769942998886, 'total_duration': 4826.342738628387, 'accumulated_submission_time': 3715.769942998886, 'accumulated_eval_time': 1102.8304250240326, 'accumulated_logging_time': 6.468543767929077, 'global_step': 24109, 'preemption_count': 0}), (25079, {'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3795.767014980316, 'total_duration': 4910.3736140728, 'accumulated_submission_time': 3795.767014980316, 'accumulated_eval_time': 1106.7897999286652, 'accumulated_logging_time': 6.49429178237915, 'global_step': 25079, 'preemption_count': 0}), (26049, {'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3875.76162981987, 'total_duration': 4994.408915042877, 'accumulated_submission_time': 3875.76162981987, 'accumulated_eval_time': 1110.759708404541, 'accumulated_logging_time': 6.515716791152954, 'global_step': 26049, 'preemption_count': 0}), (27019, {'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 3955.7228622436523, 'total_duration': 5078.414175033569, 'accumulated_submission_time': 3955.7228622436523, 'accumulated_eval_time': 1114.7324283123016, 'accumulated_logging_time': 6.538309574127197, 'global_step': 27019, 'preemption_count': 0}), (27989, {'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 4035.656488418579, 'total_duration': 5162.387141704559, 'accumulated_submission_time': 4035.656488418579, 'accumulated_eval_time': 1118.702505350113, 'accumulated_logging_time': 6.559993028640747, 'global_step': 27989, 'preemption_count': 0}), (28959, {'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 4115.652072668076, 'total_duration': 5246.415754079819, 'accumulated_submission_time': 4115.652072668076, 'accumulated_eval_time': 1122.6632940769196, 'accumulated_logging_time': 6.583688259124756, 'global_step': 28959, 'preemption_count': 0}), (29929, {'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 4195.61047077179, 'total_duration': 5330.402661323547, 'accumulated_submission_time': 4195.61047077179, 'accumulated_eval_time': 1126.6210520267487, 'accumulated_logging_time': 6.6062681674957275, 'global_step': 29929, 'preemption_count': 0}), (30899, {'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 4275.603677749634, 'total_duration': 5414.433887004852, 'accumulated_submission_time': 4275.603677749634, 'accumulated_eval_time': 1130.5880634784698, 'accumulated_logging_time': 6.6291961669921875, 'global_step': 30899, 'preemption_count': 0}), (31869, {'train/ssim': 0.7426350457327706, 'train/loss': 0.272174596786499, 'validation/ssim': 0.722545239518852, 'validation/loss': 0.2873988025431292, 'validation/num_examples': 3554, 'test/ssim': 0.7399367838723471, 'test/loss': 0.2888123939171146, 'test/num_examples': 3581, 'score': 4355.563270330429, 'total_duration': 5498.425994634628, 'accumulated_submission_time': 4355.563270330429, 'accumulated_eval_time': 1134.549230337143, 'accumulated_logging_time': 6.651534080505371, 'global_step': 31869, 'preemption_count': 0})], 'global_step': 32839}
I0307 16:49:47.620938 140545907463360 submission_runner.py:649] Timing: 4435.547511816025
I0307 16:49:47.620978 140545907463360 submission_runner.py:651] Total number of evals: 52
I0307 16:49:47.621008 140545907463360 submission_runner.py:652] ====================
I0307 16:49:47.621158 140545907463360 submission_runner.py:750] Final fastmri score: 4
