python submission_runner.py --framework=jax --workload=fastmri --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_0 --overwrite=True --save_checkpoints=False --rng_seed=-2103641590 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=2 --hparam_end_index=3 2>&1 | tee -a /logs/fastmri_jax_03-07-2025-14-57-09.log
2025-03-07 14:57:10.321990: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741359430.345063       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741359430.351985       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0307 14:57:16.308775 139843350590656 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax.
I0307 14:57:17.261630 139843350590656 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0307 14:57:17.264849 139843350590656 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0307 14:57:17.266803 139843350590656 submission_runner.py:606] Using RNG seed -2103641590
I0307 14:57:17.854792 139843350590656 submission_runner.py:615] --- Tuning run 3/5 ---
I0307 14:57:17.855001 139843350590656 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_3.
I0307 14:57:17.855238 139843350590656 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_3/hparams.json.
I0307 14:57:18.097218 139843350590656 submission_runner.py:218] Initializing dataset.
I0307 14:57:23.223504 139843350590656 submission_runner.py:229] Initializing model.
I0307 14:57:33.731219 139843350590656 submission_runner.py:272] Initializing optimizer.
I0307 14:57:34.216419 139843350590656 submission_runner.py:279] Initializing metrics bundle.
I0307 14:57:34.216660 139843350590656 submission_runner.py:301] Initializing checkpoint and logger.
I0307 14:57:34.217514 139843350590656 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_3 with prefix checkpoint_
I0307 14:57:34.217629 139843350590656 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_3/meta_data_0.json.
I0307 14:57:34.217819 139843350590656 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0307 14:57:34.217871 139843350590656 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0307 14:57:34.375518 139843350590656 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_3/flags_0.json.
I0307 14:57:34.408164 139843350590656 submission_runner.py:337] Starting training loop.
E0307 15:01:22.225819       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:01:22.440776       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:01:22.855434       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:01:23.070421       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:01:25.556968       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:01:25.772399       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
I0307 15:01:38.096257 139706125760256 logging_writer.py:48] [0] global_step=0, grad_norm=3.950305461883545, loss=0.7488994002342224
I0307 15:01:38.147859 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:08:25.466888 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:12:18.105186 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:16:02.686607 139843350590656 submission_runner.py:469] Time since start: 1108.28s, 	Step: 1, 	{'train/ssim': 0.2944158485957554, 'train/loss': 0.8066951887948173, 'validation/ssim': 0.2885739439715813, 'validation/loss': 0.8114827702940349, 'validation/num_examples': 3554, 'test/ssim': 0.31238467917699314, 'test/loss': 0.8113508141929628, 'test/num_examples': 3581, 'score': 243.73952722549438, 'total_duration': 1108.2783551216125, 'accumulated_submission_time': 243.73952722549438, 'accumulated_eval_time': 864.538666009903, 'accumulated_logging_time': 0}
I0307 15:16:02.694303 139686555150080 logging_writer.py:48] [1] accumulated_eval_time=864.539, accumulated_logging_time=0, accumulated_submission_time=243.74, global_step=1, preemption_count=0, score=243.74, test/loss=0.811351, test/num_examples=3581, test/ssim=0.312385, total_duration=1108.28, train/loss=0.806695, train/ssim=0.294416, validation/loss=0.811483, validation/num_examples=3554, validation/ssim=0.288574
I0307 15:16:15.812261 139686546757376 logging_writer.py:48] [100] global_step=100, grad_norm=0.47864964604377747, loss=0.34979474544525146
I0307 15:16:32.970624 139686555150080 logging_writer.py:48] [200] global_step=200, grad_norm=0.20818305015563965, loss=0.3379088342189789
I0307 15:17:22.842493 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:17:24.735864 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:17:26.025680 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:17:27.321277 139843350590656 submission_runner.py:469] Time since start: 1192.91s, 	Step: 252, 	{'train/ssim': 0.6823936871119908, 'train/loss': 0.327028717313494, 'validation/ssim': 0.6619234187051561, 'validation/loss': 0.34512512859629996, 'validation/num_examples': 3554, 'test/ssim': 0.6810166040168598, 'test/loss': 0.3460456445476124, 'test/num_examples': 3581, 'score': 323.8344979286194, 'total_duration': 1192.913048505783, 'accumulated_submission_time': 323.8344979286194, 'accumulated_eval_time': 869.0174033641815, 'accumulated_logging_time': 0.01610708236694336}
I0307 15:17:27.330303 139686546757376 logging_writer.py:48] [252] accumulated_eval_time=869.017, accumulated_logging_time=0.0161071, accumulated_submission_time=323.834, global_step=252, preemption_count=0, score=323.834, test/loss=0.346046, test/num_examples=3581, test/ssim=0.681017, total_duration=1192.91, train/loss=0.327029, train/ssim=0.682394, validation/loss=0.345125, validation/num_examples=3554, validation/ssim=0.661923
I0307 15:18:39.154006 139686555150080 logging_writer.py:48] [300] global_step=300, grad_norm=0.1569749414920807, loss=0.42484474182128906
I0307 15:18:48.757584 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:18:50.046075 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:18:51.339620 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:18:52.635180 139843350590656 submission_runner.py:469] Time since start: 1278.23s, 	Step: 305, 	{'train/ssim': 0.6908362252371651, 'train/loss': 0.3203676428113665, 'validation/ssim': 0.6713110172956528, 'validation/loss': 0.33760093985210327, 'validation/num_examples': 3554, 'test/ssim': 0.6900729190301242, 'test/loss': 0.33869715490610164, 'test/num_examples': 3581, 'score': 405.25019240379333, 'total_duration': 1278.226955652237, 'accumulated_submission_time': 405.25019240379333, 'accumulated_eval_time': 872.894956111908, 'accumulated_logging_time': 0.03304123878479004}
I0307 15:18:52.645488 139686546757376 logging_writer.py:48] [305] accumulated_eval_time=872.895, accumulated_logging_time=0.0330412, accumulated_submission_time=405.25, global_step=305, preemption_count=0, score=405.25, test/loss=0.338697, test/num_examples=3581, test/ssim=0.690073, total_duration=1278.23, train/loss=0.320368, train/ssim=0.690836, validation/loss=0.337601, validation/num_examples=3554, validation/ssim=0.671311
I0307 15:20:14.814680 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:20:16.104162 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:20:17.398674 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:20:18.691664 139843350590656 submission_runner.py:469] Time since start: 1364.28s, 	Step: 356, 	{'train/ssim': 0.6972564288548061, 'train/loss': 0.3134587492261614, 'validation/ssim': 0.6780589570070695, 'validation/loss': 0.3302598909239589, 'validation/num_examples': 3554, 'test/ssim': 0.6963725789103952, 'test/loss': 0.33196590266990716, 'test/num_examples': 3581, 'score': 487.3917098045349, 'total_duration': 1364.2834341526031, 'accumulated_submission_time': 487.3917098045349, 'accumulated_eval_time': 876.7719123363495, 'accumulated_logging_time': 0.06744837760925293}
I0307 15:20:18.700699 139686555150080 logging_writer.py:48] [356] accumulated_eval_time=876.772, accumulated_logging_time=0.0674484, accumulated_submission_time=487.392, global_step=356, preemption_count=0, score=487.392, test/loss=0.331966, test/num_examples=3581, test/ssim=0.696373, total_duration=1364.28, train/loss=0.313459, train/ssim=0.697256, validation/loss=0.33026, validation/num_examples=3554, validation/ssim=0.678059
I0307 15:21:17.635004 139686546757376 logging_writer.py:48] [400] global_step=400, grad_norm=0.13852523267269135, loss=0.31170907616615295
I0307 15:21:38.731521 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:21:40.020003 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:21:41.313910 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:21:42.607580 139843350590656 submission_runner.py:469] Time since start: 1448.20s, 	Step: 418, 	{'train/ssim': 0.7043632779802594, 'train/loss': 0.3067689282553537, 'validation/ssim': 0.6864069314504784, 'validation/loss': 0.32280226725168826, 'validation/num_examples': 3554, 'test/ssim': 0.7040250001090826, 'test/loss': 0.3249420362023527, 'test/num_examples': 3581, 'score': 567.4101531505585, 'total_duration': 1448.1993503570557, 'accumulated_submission_time': 567.4101531505585, 'accumulated_eval_time': 880.6479294300079, 'accumulated_logging_time': 0.08466339111328125}
I0307 15:21:42.616463 139686555150080 logging_writer.py:48] [418] accumulated_eval_time=880.648, accumulated_logging_time=0.0846634, accumulated_submission_time=567.41, global_step=418, preemption_count=0, score=567.41, test/loss=0.324942, test/num_examples=3581, test/ssim=0.704025, total_duration=1448.2, train/loss=0.306769, train/ssim=0.704363, validation/loss=0.322802, validation/num_examples=3554, validation/ssim=0.686407
I0307 15:23:05.252300 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:23:06.541380 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:23:07.834531 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:23:09.132486 139843350590656 submission_runner.py:469] Time since start: 1534.72s, 	Step: 473, 	{'train/ssim': 0.7092381204877581, 'train/loss': 0.3018697329929897, 'validation/ssim': 0.6909316389763295, 'validation/loss': 0.317638528165887, 'validation/num_examples': 3554, 'test/ssim': 0.7085382951034976, 'test/loss': 0.3198864981303232, 'test/num_examples': 3581, 'score': 650.0340402126312, 'total_duration': 1534.7242629528046, 'accumulated_submission_time': 650.0340402126312, 'accumulated_eval_time': 884.5280754566193, 'accumulated_logging_time': 0.10140562057495117}
I0307 15:23:09.142033 139686546757376 logging_writer.py:48] [473] accumulated_eval_time=884.528, accumulated_logging_time=0.101406, accumulated_submission_time=650.034, global_step=473, preemption_count=0, score=650.034, test/loss=0.319886, test/num_examples=3581, test/ssim=0.708538, total_duration=1534.72, train/loss=0.30187, train/ssim=0.709238, validation/loss=0.317639, validation/num_examples=3554, validation/ssim=0.690932
I0307 15:23:49.865047 139686555150080 logging_writer.py:48] [500] global_step=500, grad_norm=0.2465161830186844, loss=0.3356090486049652
I0307 15:24:29.260307 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:24:30.551866 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:24:31.858592 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:24:33.157126 139843350590656 submission_runner.py:469] Time since start: 1618.75s, 	Step: 523, 	{'train/ssim': 0.7130947113037109, 'train/loss': 0.2981229509626116, 'validation/ssim': 0.6946353085871553, 'validation/loss': 0.31389261137318863, 'validation/num_examples': 3554, 'test/ssim': 0.7121185924846412, 'test/loss': 0.31620608332169786, 'test/num_examples': 3581, 'score': 730.1384196281433, 'total_duration': 1618.7489039897919, 'accumulated_submission_time': 730.1384196281433, 'accumulated_eval_time': 888.4248521327972, 'accumulated_logging_time': 0.12153506278991699}
I0307 15:24:33.165668 139686546757376 logging_writer.py:48] [523] accumulated_eval_time=888.425, accumulated_logging_time=0.121535, accumulated_submission_time=730.138, global_step=523, preemption_count=0, score=730.138, test/loss=0.316206, test/num_examples=3581, test/ssim=0.712119, total_duration=1618.75, train/loss=0.298123, train/ssim=0.713095, validation/loss=0.313893, validation/num_examples=3554, validation/ssim=0.694635
I0307 15:25:54.937004 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:25:56.230685 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:25:57.524152 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:25:58.822285 139843350590656 submission_runner.py:469] Time since start: 1704.41s, 	Step: 583, 	{'train/ssim': 0.7156468118940081, 'train/loss': 0.295475823538644, 'validation/ssim': 0.6973504628367684, 'validation/loss': 0.31109086757438803, 'validation/num_examples': 3554, 'test/ssim': 0.7148258877146747, 'test/loss': 0.3132729869886205, 'test/num_examples': 3581, 'score': 811.8974611759186, 'total_duration': 1704.4140586853027, 'accumulated_submission_time': 811.8974611759186, 'accumulated_eval_time': 892.3101162910461, 'accumulated_logging_time': 0.13779735565185547}
I0307 15:25:58.831895 139686555150080 logging_writer.py:48] [583] accumulated_eval_time=892.31, accumulated_logging_time=0.137797, accumulated_submission_time=811.897, global_step=583, preemption_count=0, score=811.897, test/loss=0.313273, test/num_examples=3581, test/ssim=0.714826, total_duration=1704.41, train/loss=0.295476, train/ssim=0.715647, validation/loss=0.311091, validation/num_examples=3554, validation/ssim=0.69735
I0307 15:26:24.432431 139686546757376 logging_writer.py:48] [600] global_step=600, grad_norm=0.18856365978717804, loss=0.33739250898361206
I0307 15:27:18.909432 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:27:20.198904 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:27:21.491400 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:27:22.787201 139843350590656 submission_runner.py:469] Time since start: 1788.38s, 	Step: 636, 	{'train/ssim': 0.7181860378810337, 'train/loss': 0.29295178822108675, 'validation/ssim': 0.6999029482625211, 'validation/loss': 0.30858313668357834, 'validation/num_examples': 3554, 'test/ssim': 0.7171917542236805, 'test/loss': 0.31091097246099203, 'test/num_examples': 3581, 'score': 891.9625923633575, 'total_duration': 1788.3789587020874, 'accumulated_submission_time': 891.9625923633575, 'accumulated_eval_time': 896.187825679779, 'accumulated_logging_time': 0.15587639808654785}
I0307 15:27:22.796406 139686555150080 logging_writer.py:48] [636] accumulated_eval_time=896.188, accumulated_logging_time=0.155876, accumulated_submission_time=891.963, global_step=636, preemption_count=0, score=891.963, test/loss=0.310911, test/num_examples=3581, test/ssim=0.717192, total_duration=1788.38, train/loss=0.292952, train/ssim=0.718186, validation/loss=0.308583, validation/num_examples=3554, validation/ssim=0.699903
I0307 15:28:44.515396 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:28:45.812971 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:28:47.106251 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:28:48.406087 139843350590656 submission_runner.py:469] Time since start: 1874.00s, 	Step: 693, 	{'train/ssim': 0.7206095286778041, 'train/loss': 0.2912842205592564, 'validation/ssim': 0.7024129117279826, 'validation/loss': 0.30710029494715463, 'validation/num_examples': 3554, 'test/ssim': 0.7197046096149818, 'test/loss': 0.3092901064210416, 'test/num_examples': 3581, 'score': 973.6636910438538, 'total_duration': 1873.9978604316711, 'accumulated_submission_time': 973.6636910438538, 'accumulated_eval_time': 900.078476190567, 'accumulated_logging_time': 0.17908430099487305}
I0307 15:28:48.415069 139686546757376 logging_writer.py:48] [693] accumulated_eval_time=900.078, accumulated_logging_time=0.179084, accumulated_submission_time=973.664, global_step=693, preemption_count=0, score=973.664, test/loss=0.30929, test/num_examples=3581, test/ssim=0.719705, total_duration=1874, train/loss=0.291284, train/ssim=0.72061, validation/loss=0.3071, validation/num_examples=3554, validation/ssim=0.702413
I0307 15:29:01.114323 139686555150080 logging_writer.py:48] [700] global_step=700, grad_norm=0.35770758986473083, loss=0.21370622515678406
I0307 15:30:10.507280 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:30:11.801320 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:30:13.093845 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:30:14.389689 139843350590656 submission_runner.py:469] Time since start: 1959.98s, 	Step: 745, 	{'train/ssim': 0.7139700480869838, 'train/loss': 0.2932803971426828, 'validation/ssim': 0.6975031022483469, 'validation/loss': 0.3079909891913161, 'validation/num_examples': 3554, 'test/ssim': 0.7144318947875943, 'test/loss': 0.31014187154207973, 'test/num_examples': 3581, 'score': 1055.7441716194153, 'total_duration': 1959.9814624786377, 'accumulated_submission_time': 1055.7441716194153, 'accumulated_eval_time': 903.9608447551727, 'accumulated_logging_time': 0.19590020179748535}
I0307 15:30:14.400089 139686546757376 logging_writer.py:48] [745] accumulated_eval_time=903.961, accumulated_logging_time=0.1959, accumulated_submission_time=1055.74, global_step=745, preemption_count=0, score=1055.74, test/loss=0.310142, test/num_examples=3581, test/ssim=0.714432, total_duration=1959.98, train/loss=0.29328, train/ssim=0.71397, validation/loss=0.307991, validation/num_examples=3554, validation/ssim=0.697503
I0307 15:31:34.872357 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:31:36.160407 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:31:37.450586 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:31:38.754668 139843350590656 submission_runner.py:469] Time since start: 2044.35s, 	Step: 797, 	{'train/ssim': 0.7220843178885323, 'train/loss': 0.288353545325143, 'validation/ssim': 0.7036388356429375, 'validation/loss': 0.30379763009109456, 'validation/num_examples': 3554, 'test/ssim': 0.720866885341036, 'test/loss': 0.3059263381169715, 'test/num_examples': 3581, 'score': 1136.1999423503876, 'total_duration': 2044.3464357852936, 'accumulated_submission_time': 1136.1999423503876, 'accumulated_eval_time': 907.8431022167206, 'accumulated_logging_time': 0.2190229892730713}
I0307 15:31:38.765346 139686555150080 logging_writer.py:48] [797] accumulated_eval_time=907.843, accumulated_logging_time=0.219023, accumulated_submission_time=1136.2, global_step=797, preemption_count=0, score=1136.2, test/loss=0.305926, test/num_examples=3581, test/ssim=0.720867, total_duration=2044.35, train/loss=0.288354, train/ssim=0.722084, validation/loss=0.303798, validation/num_examples=3554, validation/ssim=0.703639
I0307 15:31:42.494145 139686546757376 logging_writer.py:48] [800] global_step=800, grad_norm=0.29649296402931213, loss=0.23458553850650787
I0307 15:32:59.211402 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:33:00.502024 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:33:01.793426 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:33:03.094879 139843350590656 submission_runner.py:469] Time since start: 2128.69s, 	Step: 848, 	{'train/ssim': 0.7240603991917202, 'train/loss': 0.28637811115809847, 'validation/ssim': 0.7057296246306978, 'validation/loss': 0.3018446424803039, 'validation/num_examples': 3554, 'test/ssim': 0.7229109580075398, 'test/loss': 0.30392112614754957, 'test/num_examples': 3581, 'score': 1216.63405251503, 'total_duration': 2128.6866466999054, 'accumulated_submission_time': 1216.63405251503, 'accumulated_eval_time': 911.7265243530273, 'accumulated_logging_time': 0.2378857135772705}
I0307 15:33:03.104175 139686555150080 logging_writer.py:48] [848] accumulated_eval_time=911.727, accumulated_logging_time=0.237886, accumulated_submission_time=1216.63, global_step=848, preemption_count=0, score=1216.63, test/loss=0.303921, test/num_examples=3581, test/ssim=0.722911, total_duration=2128.69, train/loss=0.286378, train/ssim=0.72406, validation/loss=0.301845, validation/num_examples=3554, validation/ssim=0.70573
I0307 15:34:23.712154 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:34:25.001447 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:34:26.295534 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:34:27.600014 139843350590656 submission_runner.py:469] Time since start: 2213.19s, 	Step: 898, 	{'train/ssim': 0.7254883221217564, 'train/loss': 0.28498123373304096, 'validation/ssim': 0.7075790207776449, 'validation/loss': 0.300392404190261, 'validation/num_examples': 3554, 'test/ssim': 0.724787588793284, 'test/loss': 0.3023204063110863, 'test/num_examples': 3581, 'score': 1297.2299404144287, 'total_duration': 2213.1917798519135, 'accumulated_submission_time': 1297.2299404144287, 'accumulated_eval_time': 915.6143319606781, 'accumulated_logging_time': 0.2556583881378174}
I0307 15:34:27.609121 139686546757376 logging_writer.py:48] [898] accumulated_eval_time=915.614, accumulated_logging_time=0.255658, accumulated_submission_time=1297.23, global_step=898, preemption_count=0, score=1297.23, test/loss=0.30232, test/num_examples=3581, test/ssim=0.724788, total_duration=2213.19, train/loss=0.284981, train/ssim=0.725488, validation/loss=0.300392, validation/num_examples=3554, validation/ssim=0.707579
I0307 15:34:31.199011 139686555150080 logging_writer.py:48] [900] global_step=900, grad_norm=0.19996000826358795, loss=0.32430118322372437
I0307 15:35:49.523325 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:35:50.814527 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:35:52.107884 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:35:53.411999 139843350590656 submission_runner.py:469] Time since start: 2299.00s, 	Step: 946, 	{'train/ssim': 0.7235208920070103, 'train/loss': 0.2858325072697231, 'validation/ssim': 0.7061262672780669, 'validation/loss': 0.3010981725586487, 'validation/num_examples': 3554, 'test/ssim': 0.7233762637225984, 'test/loss': 0.3029359052115331, 'test/num_examples': 3581, 'score': 1379.132319688797, 'total_duration': 2299.003766298294, 'accumulated_submission_time': 1379.132319688797, 'accumulated_eval_time': 919.5029566287994, 'accumulated_logging_time': 0.2723381519317627}
I0307 15:35:53.421734 139686546757376 logging_writer.py:48] [946] accumulated_eval_time=919.503, accumulated_logging_time=0.272338, accumulated_submission_time=1379.13, global_step=946, preemption_count=0, score=1379.13, test/loss=0.302936, test/num_examples=3581, test/ssim=0.723376, total_duration=2299, train/loss=0.285833, train/ssim=0.723521, validation/loss=0.301098, validation/num_examples=3554, validation/ssim=0.706126
I0307 15:36:25.307525 139686555150080 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.18255768716335297, loss=0.27300623059272766
I0307 15:36:46.573805 139686546757376 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.20798712968826294, loss=0.31010085344314575
I0307 15:36:54.762377 139686555150080 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.19112548232078552, loss=0.28402361273765564
I0307 15:37:02.962210 139686546757376 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.22536726295948029, loss=0.24849528074264526
I0307 15:37:11.170347 139686555150080 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.2784634530544281, loss=0.29711809754371643
I0307 15:37:13.471798 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:37:14.765921 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:37:16.066497 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:37:17.376776 139843350590656 submission_runner.py:469] Time since start: 2382.97s, 	Step: 1429, 	{'train/ssim': 0.7298066956656319, 'train/loss': 0.27989840507507324, 'validation/ssim': 0.7112550751573931, 'validation/loss': 0.2955143659652856, 'validation/num_examples': 3554, 'test/ssim': 0.72823446444778, 'test/loss': 0.2973932789810807, 'test/num_examples': 3581, 'score': 1459.1451761722565, 'total_duration': 2382.9685564041138, 'accumulated_submission_time': 1459.1451761722565, 'accumulated_eval_time': 923.4078936576843, 'accumulated_logging_time': 0.2896392345428467}
I0307 15:37:17.386216 139686546757376 logging_writer.py:48] [1429] accumulated_eval_time=923.408, accumulated_logging_time=0.289639, accumulated_submission_time=1459.15, global_step=1429, preemption_count=0, score=1459.15, test/loss=0.297393, test/num_examples=3581, test/ssim=0.728234, total_duration=2382.97, train/loss=0.279898, train/ssim=0.729807, validation/loss=0.295514, validation/num_examples=3554, validation/ssim=0.711255
I0307 15:37:23.279325 139686555150080 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.21511736512184143, loss=0.42710447311401367
I0307 15:37:31.471344 139686546757376 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.14761656522750854, loss=0.25828853249549866
I0307 15:37:39.662705 139686555150080 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.1614631861448288, loss=0.2625187933444977
I0307 15:37:47.849125 139686546757376 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.21137963235378265, loss=0.23140296339988708
I0307 15:37:56.050788 139686555150080 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.2933177947998047, loss=0.3058571517467499
I0307 15:38:04.243335 139686546757376 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.20146268606185913, loss=0.21437843143939972
I0307 15:38:12.443748 139686555150080 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.07175645232200623, loss=0.40471601486206055
I0307 15:38:20.628760 139686546757376 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.19064152240753174, loss=0.28586119413375854
I0307 15:38:28.823726 139686555150080 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.0672483891248703, loss=0.36482688784599304
I0307 15:38:37.009825 139686546757376 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.20369981229305267, loss=0.25094011425971985
I0307 15:38:37.420591 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:38:38.717531 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:38:40.014934 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:38:41.314221 139843350590656 submission_runner.py:469] Time since start: 2466.91s, 	Step: 2406, 	{'train/ssim': 0.7349422318594796, 'train/loss': 0.2756263869149344, 'validation/ssim': 0.7160040018728897, 'validation/loss': 0.2916270413288724, 'validation/num_examples': 3554, 'test/ssim': 0.7332946726211254, 'test/loss': 0.29315562222930047, 'test/num_examples': 3581, 'score': 1539.1212358474731, 'total_duration': 2466.906001806259, 'accumulated_submission_time': 1539.1212358474731, 'accumulated_eval_time': 927.3014771938324, 'accumulated_logging_time': 0.30704665184020996}
I0307 15:38:41.324174 139686555150080 logging_writer.py:48] [2406] accumulated_eval_time=927.301, accumulated_logging_time=0.307047, accumulated_submission_time=1539.12, global_step=2406, preemption_count=0, score=1539.12, test/loss=0.293156, test/num_examples=3581, test/ssim=0.733295, total_duration=2466.91, train/loss=0.275626, train/ssim=0.734942, validation/loss=0.291627, validation/num_examples=3554, validation/ssim=0.716004
I0307 15:38:49.122648 139686546757376 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.09078624844551086, loss=0.3814844787120819
I0307 15:38:57.309539 139686555150080 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.15547677874565125, loss=0.271545946598053
I0307 15:39:05.494667 139686546757376 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.1529136300086975, loss=0.2658740282058716
I0307 15:39:13.669355 139686555150080 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.12011454254388809, loss=0.2526763379573822
I0307 15:39:21.875602 139686546757376 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.18808715045452118, loss=0.29361864924430847
I0307 15:39:30.099457 139686555150080 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.14851650595664978, loss=0.2555341124534607
I0307 15:39:38.305839 139686546757376 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.05730398744344711, loss=0.31681352853775024
I0307 15:39:46.516041 139686555150080 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.41354864835739136, loss=0.24561500549316406
I0307 15:39:54.712794 139686546757376 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.16613127291202545, loss=0.24557973444461823
I0307 15:40:01.349597 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:40:02.645412 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:40:03.943568 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:40:05.243756 139843350590656 submission_runner.py:469] Time since start: 2550.84s, 	Step: 3382, 	{'train/ssim': 0.7380215781075614, 'train/loss': 0.2740461826324463, 'validation/ssim': 0.7189316285347496, 'validation/loss': 0.29024136811075546, 'validation/num_examples': 3554, 'test/ssim': 0.7360739624057526, 'test/loss': 0.29185989068826795, 'test/num_examples': 3581, 'score': 1619.089319229126, 'total_duration': 2550.8355345726013, 'accumulated_submission_time': 1619.089319229126, 'accumulated_eval_time': 931.1955900192261, 'accumulated_logging_time': 0.32555246353149414}
I0307 15:40:05.253878 139686555150080 logging_writer.py:48] [3382] accumulated_eval_time=931.196, accumulated_logging_time=0.325552, accumulated_submission_time=1619.09, global_step=3382, preemption_count=0, score=1619.09, test/loss=0.29186, test/num_examples=3581, test/ssim=0.736074, total_duration=2550.84, train/loss=0.274046, train/ssim=0.738022, validation/loss=0.290241, validation/num_examples=3554, validation/ssim=0.718932
I0307 15:40:06.836245 139686546757376 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.0679057389497757, loss=0.2960778772830963
I0307 15:40:15.028871 139686555150080 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.11958159506320953, loss=0.2515595257282257
I0307 15:40:23.223078 139686546757376 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.142927885055542, loss=0.2685936987400055
I0307 15:40:31.421943 139686555150080 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.1195501759648323, loss=0.2802581489086151
I0307 15:40:39.607483 139686546757376 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.1403631716966629, loss=0.330303430557251
I0307 15:40:47.794204 139686555150080 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.36669856309890747, loss=0.27486249804496765
I0307 15:40:55.973796 139686546757376 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.13706795871257782, loss=0.22313755750656128
I0307 15:41:04.182966 139686555150080 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.0910557210445404, loss=0.27540290355682373
I0307 15:41:12.399812 139686546757376 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.10479965060949326, loss=0.2571210563182831
I0307 15:41:20.605110 139686555150080 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.3530632555484772, loss=0.27457648515701294
I0307 15:41:25.261742 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:41:26.557882 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:41:27.859773 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:41:29.159611 139843350590656 submission_runner.py:469] Time since start: 2634.75s, 	Step: 4358, 	{'train/ssim': 0.7389967782156808, 'train/loss': 0.2729316438947405, 'validation/ssim': 0.7203784056037211, 'validation/loss': 0.28887070466375914, 'validation/num_examples': 3554, 'test/ssim': 0.7375939610749441, 'test/loss': 0.2903237341502897, 'test/num_examples': 3581, 'score': 1699.0384857654572, 'total_duration': 2634.7513875961304, 'accumulated_submission_time': 1699.0384857654572, 'accumulated_eval_time': 935.0934150218964, 'accumulated_logging_time': 0.34468579292297363}
I0307 15:41:29.169937 139686546757376 logging_writer.py:48] [4358] accumulated_eval_time=935.093, accumulated_logging_time=0.344686, accumulated_submission_time=1699.04, global_step=4358, preemption_count=0, score=1699.04, test/loss=0.290324, test/num_examples=3581, test/ssim=0.737594, total_duration=2634.75, train/loss=0.272932, train/ssim=0.738997, validation/loss=0.288871, validation/num_examples=3554, validation/ssim=0.720378
I0307 15:41:32.703109 139686555150080 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.2639105021953583, loss=0.19206300377845764
I0307 15:41:40.879181 139686546757376 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.14378324151039124, loss=0.3314857482910156
I0307 15:41:49.084134 139686555150080 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.0899333655834198, loss=0.3070477843284607
I0307 15:41:57.304354 139686546757376 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.23524703085422516, loss=0.21855272352695465
I0307 15:42:05.492507 139686555150080 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.12397340685129166, loss=0.3520883023738861
I0307 15:42:13.662354 139686546757376 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.08332056552171707, loss=0.31085699796676636
I0307 15:42:21.853343 139686555150080 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.10590356588363647, loss=0.29537084698677063
I0307 15:42:30.037443 139686546757376 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.22344927489757538, loss=0.25625571608543396
I0307 15:42:38.235705 139686555150080 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.10034581273794174, loss=0.3421459496021271
I0307 15:42:46.432768 139686546757376 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.207869291305542, loss=0.3068174123764038
I0307 15:42:49.228503 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:42:50.525387 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:42:51.824860 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:42:53.127674 139843350590656 submission_runner.py:469] Time since start: 2718.72s, 	Step: 5335, 	{'train/ssim': 0.7397311074393136, 'train/loss': 0.27297488280705046, 'validation/ssim': 0.72062591226435, 'validation/loss': 0.28912068433015614, 'validation/num_examples': 3554, 'test/ssim': 0.7375925975417132, 'test/loss': 0.2906999329687064, 'test/num_examples': 3581, 'score': 1779.0380289554596, 'total_duration': 2718.719444990158, 'accumulated_submission_time': 1779.0380289554596, 'accumulated_eval_time': 938.9925382137299, 'accumulated_logging_time': 0.36331772804260254}
I0307 15:42:53.138649 139686555150080 logging_writer.py:48] [5335] accumulated_eval_time=938.993, accumulated_logging_time=0.363318, accumulated_submission_time=1779.04, global_step=5335, preemption_count=0, score=1779.04, test/loss=0.2907, test/num_examples=3581, test/ssim=0.737593, total_duration=2718.72, train/loss=0.272975, train/ssim=0.739731, validation/loss=0.289121, validation/num_examples=3554, validation/ssim=0.720626
I0307 15:43:01.765333 139686546757376 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.24402333796024323, loss=0.22584329545497894
I0307 15:43:09.985337 139686555150080 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.16015592217445374, loss=0.2731720805168152
I0307 15:43:18.161170 139686546757376 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.1291465163230896, loss=0.3376134932041168
I0307 15:43:26.561650 139686555150080 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.05956336110830307, loss=0.31849753856658936
I0307 15:43:34.756505 139686546757376 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.10922355949878693, loss=0.3467918634414673
I0307 15:43:42.975789 139686555150080 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.08548231422901154, loss=0.33742353320121765
I0307 15:43:51.178305 139686546757376 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.09578627347946167, loss=0.28983578085899353
I0307 15:43:59.384316 139686555150080 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.07716277986764908, loss=0.3229551613330841
I0307 15:44:07.571588 139686546757376 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.17294085025787354, loss=0.203810453414917
I0307 15:44:13.159884 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:44:14.456646 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:44:15.757621 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:44:17.059007 139843350590656 submission_runner.py:469] Time since start: 2802.65s, 	Step: 6269, 	{'train/ssim': 0.7376200131007603, 'train/loss': 0.2740216425486973, 'validation/ssim': 0.7197025193883653, 'validation/loss': 0.2897142400618142, 'validation/num_examples': 3554, 'test/ssim': 0.7366480780726403, 'test/loss': 0.29127977547516404, 'test/num_examples': 3581, 'score': 1855.8149678707123, 'total_duration': 2802.650787591934, 'accumulated_submission_time': 1855.8149678707123, 'accumulated_eval_time': 942.8916182518005, 'accumulated_logging_time': 3.568582534790039}
I0307 15:44:17.069738 139686555150080 logging_writer.py:48] [6269] accumulated_eval_time=942.892, accumulated_logging_time=3.56858, accumulated_submission_time=1855.81, global_step=6269, preemption_count=0, score=1855.81, test/loss=0.29128, test/num_examples=3581, test/ssim=0.736648, total_duration=2802.65, train/loss=0.274022, train/ssim=0.73762, validation/loss=0.289714, validation/num_examples=3554, validation/ssim=0.719703
I0307 15:44:19.704288 139686546757376 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.15563352406024933, loss=0.31209367513656616
I0307 15:44:27.904114 139686555150080 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.06118457391858101, loss=0.2843519151210785
I0307 15:44:36.095954 139686546757376 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.19518440961837769, loss=0.2464248090982437
I0307 15:44:44.287799 139686555150080 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.042654234915971756, loss=0.2887682616710663
I0307 15:44:52.491092 139686546757376 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.04845374450087547, loss=0.3156394064426422
I0307 15:45:00.668962 139686555150080 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.12919288873672485, loss=0.3123241066932678
I0307 15:45:08.841591 139686546757376 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.27934935688972473, loss=0.2856272757053375
I0307 15:45:17.048497 139686555150080 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.14200784265995026, loss=0.238641619682312
I0307 15:45:25.218703 139686546757376 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.11502118408679962, loss=0.30244481563568115
I0307 15:45:33.403158 139686555150080 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.2678753733634949, loss=0.28297704458236694
I0307 15:45:37.080106 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:45:38.378873 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:45:39.679369 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:45:40.981766 139843350590656 submission_runner.py:469] Time since start: 2886.57s, 	Step: 7246, 	{'train/ssim': 0.7389991624014718, 'train/loss': 0.2730445521218436, 'validation/ssim': 0.7206398572690982, 'validation/loss': 0.288896190362092, 'validation/num_examples': 3554, 'test/ssim': 0.7378464192526529, 'test/loss': 0.2903801503377199, 'test/num_examples': 3581, 'score': 1935.7681798934937, 'total_duration': 2886.5735490322113, 'accumulated_submission_time': 1935.7681798934937, 'accumulated_eval_time': 946.7932369709015, 'accumulated_logging_time': 3.5873923301696777}
I0307 15:45:40.992467 139686546757376 logging_writer.py:48] [7246] accumulated_eval_time=946.793, accumulated_logging_time=3.58739, accumulated_submission_time=1935.77, global_step=7246, preemption_count=0, score=1935.77, test/loss=0.29038, test/num_examples=3581, test/ssim=0.737846, total_duration=2886.57, train/loss=0.273045, train/ssim=0.738999, validation/loss=0.288896, validation/num_examples=3554, validation/ssim=0.72064
I0307 15:45:45.525429 139686555150080 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.1312810629606247, loss=0.29641780257225037
I0307 15:45:53.723094 139686546757376 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.20196661353111267, loss=0.29029613733291626
I0307 15:46:01.916428 139686555150080 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.08320801705121994, loss=0.3053140640258789
I0307 15:46:10.099024 139686546757376 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.12068308144807816, loss=0.27674445509910583
I0307 15:46:18.306803 139686555150080 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.1668679118156433, loss=0.23900455236434937
I0307 15:46:26.514648 139686546757376 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.23226265609264374, loss=0.24809309840202332
I0307 15:46:34.721732 139686555150080 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.1354152113199234, loss=0.29203611612319946
I0307 15:46:42.904900 139686546757376 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.18492378294467926, loss=0.37253040075302124
I0307 15:46:51.097999 139686555150080 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.09324590861797333, loss=0.30503612756729126
I0307 15:46:59.303621 139686546757376 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.18160754442214966, loss=0.3750702738761902
I0307 15:47:01.024193 139843350590656 spec.py:321] Evaluating on the training split.
I0307 15:47:02.319991 139843350590656 spec.py:333] Evaluating on the validation split.
I0307 15:47:03.617781 139843350590656 spec.py:349] Evaluating on the test split.
I0307 15:47:04.921428 139843350590656 submission_runner.py:469] Time since start: 2970.51s, 	Step: 8222, 	{'train/ssim': 0.743293217250279, 'train/loss': 0.2702170269829886, 'validation/ssim': 0.723816433178285, 'validation/loss': 0.2868929354743335, 'validation/num_examples': 3554, 'test/ssim': 0.7410782657166294, 'test/loss': 0.28825597009389836, 'test/num_examples': 3581, 'score': 2015.7434239387512, 'total_duration': 2970.513213634491, 'accumulated_submission_time': 2015.7434239387512, 'accumulated_eval_time': 950.6904292106628, 'accumulated_logging_time': 3.6058096885681152}
I0307 15:47:04.932571 139686555150080 logging_writer.py:48] [8222] accumulated_eval_time=950.69, accumulated_logging_time=3.60581, accumulated_submission_time=2015.74, global_step=8222, preemption_count=0, score=2015.74, test/loss=0.288256, test/num_examples=3581, test/ssim=0.741078, total_duration=2970.51, train/loss=0.270217, train/ssim=0.743293, validation/loss=0.286893, validation/num_examples=3554, validation/ssim=0.723816
I0307 15:47:04.944539 139686546757376 logging_writer.py:48] [8222] global_step=8222, preemption_count=0, score=2015.74
I0307 15:47:06.018670 139843350590656 submission_runner.py:646] Tuning trial 3/5
I0307 15:47:06.018856 139843350590656 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.0, learning_rate=0.001308209823469072, one_minus_beta1=0.02686663061, beta2=0.9981232922116359, weight_decay=0.16375311233774334, warmup_factor=0.1)
I0307 15:47:06.019784 139843350590656 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/ssim': 0.2944158485957554, 'train/loss': 0.8066951887948173, 'validation/ssim': 0.2885739439715813, 'validation/loss': 0.8114827702940349, 'validation/num_examples': 3554, 'test/ssim': 0.31238467917699314, 'test/loss': 0.8113508141929628, 'test/num_examples': 3581, 'score': 243.73952722549438, 'total_duration': 1108.2783551216125, 'accumulated_submission_time': 243.73952722549438, 'accumulated_eval_time': 864.538666009903, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (252, {'train/ssim': 0.6823936871119908, 'train/loss': 0.327028717313494, 'validation/ssim': 0.6619234187051561, 'validation/loss': 0.34512512859629996, 'validation/num_examples': 3554, 'test/ssim': 0.6810166040168598, 'test/loss': 0.3460456445476124, 'test/num_examples': 3581, 'score': 323.8344979286194, 'total_duration': 1192.913048505783, 'accumulated_submission_time': 323.8344979286194, 'accumulated_eval_time': 869.0174033641815, 'accumulated_logging_time': 0.01610708236694336, 'global_step': 252, 'preemption_count': 0}), (305, {'train/ssim': 0.6908362252371651, 'train/loss': 0.3203676428113665, 'validation/ssim': 0.6713110172956528, 'validation/loss': 0.33760093985210327, 'validation/num_examples': 3554, 'test/ssim': 0.6900729190301242, 'test/loss': 0.33869715490610164, 'test/num_examples': 3581, 'score': 405.25019240379333, 'total_duration': 1278.226955652237, 'accumulated_submission_time': 405.25019240379333, 'accumulated_eval_time': 872.894956111908, 'accumulated_logging_time': 0.03304123878479004, 'global_step': 305, 'preemption_count': 0}), (356, {'train/ssim': 0.6972564288548061, 'train/loss': 0.3134587492261614, 'validation/ssim': 0.6780589570070695, 'validation/loss': 0.3302598909239589, 'validation/num_examples': 3554, 'test/ssim': 0.6963725789103952, 'test/loss': 0.33196590266990716, 'test/num_examples': 3581, 'score': 487.3917098045349, 'total_duration': 1364.2834341526031, 'accumulated_submission_time': 487.3917098045349, 'accumulated_eval_time': 876.7719123363495, 'accumulated_logging_time': 0.06744837760925293, 'global_step': 356, 'preemption_count': 0}), (418, {'train/ssim': 0.7043632779802594, 'train/loss': 0.3067689282553537, 'validation/ssim': 0.6864069314504784, 'validation/loss': 0.32280226725168826, 'validation/num_examples': 3554, 'test/ssim': 0.7040250001090826, 'test/loss': 0.3249420362023527, 'test/num_examples': 3581, 'score': 567.4101531505585, 'total_duration': 1448.1993503570557, 'accumulated_submission_time': 567.4101531505585, 'accumulated_eval_time': 880.6479294300079, 'accumulated_logging_time': 0.08466339111328125, 'global_step': 418, 'preemption_count': 0}), (473, {'train/ssim': 0.7092381204877581, 'train/loss': 0.3018697329929897, 'validation/ssim': 0.6909316389763295, 'validation/loss': 0.317638528165887, 'validation/num_examples': 3554, 'test/ssim': 0.7085382951034976, 'test/loss': 0.3198864981303232, 'test/num_examples': 3581, 'score': 650.0340402126312, 'total_duration': 1534.7242629528046, 'accumulated_submission_time': 650.0340402126312, 'accumulated_eval_time': 884.5280754566193, 'accumulated_logging_time': 0.10140562057495117, 'global_step': 473, 'preemption_count': 0}), (523, {'train/ssim': 0.7130947113037109, 'train/loss': 0.2981229509626116, 'validation/ssim': 0.6946353085871553, 'validation/loss': 0.31389261137318863, 'validation/num_examples': 3554, 'test/ssim': 0.7121185924846412, 'test/loss': 0.31620608332169786, 'test/num_examples': 3581, 'score': 730.1384196281433, 'total_duration': 1618.7489039897919, 'accumulated_submission_time': 730.1384196281433, 'accumulated_eval_time': 888.4248521327972, 'accumulated_logging_time': 0.12153506278991699, 'global_step': 523, 'preemption_count': 0}), (583, {'train/ssim': 0.7156468118940081, 'train/loss': 0.295475823538644, 'validation/ssim': 0.6973504628367684, 'validation/loss': 0.31109086757438803, 'validation/num_examples': 3554, 'test/ssim': 0.7148258877146747, 'test/loss': 0.3132729869886205, 'test/num_examples': 3581, 'score': 811.8974611759186, 'total_duration': 1704.4140586853027, 'accumulated_submission_time': 811.8974611759186, 'accumulated_eval_time': 892.3101162910461, 'accumulated_logging_time': 0.13779735565185547, 'global_step': 583, 'preemption_count': 0}), (636, {'train/ssim': 0.7181860378810337, 'train/loss': 0.29295178822108675, 'validation/ssim': 0.6999029482625211, 'validation/loss': 0.30858313668357834, 'validation/num_examples': 3554, 'test/ssim': 0.7171917542236805, 'test/loss': 0.31091097246099203, 'test/num_examples': 3581, 'score': 891.9625923633575, 'total_duration': 1788.3789587020874, 'accumulated_submission_time': 891.9625923633575, 'accumulated_eval_time': 896.187825679779, 'accumulated_logging_time': 0.15587639808654785, 'global_step': 636, 'preemption_count': 0}), (693, {'train/ssim': 0.7206095286778041, 'train/loss': 0.2912842205592564, 'validation/ssim': 0.7024129117279826, 'validation/loss': 0.30710029494715463, 'validation/num_examples': 3554, 'test/ssim': 0.7197046096149818, 'test/loss': 0.3092901064210416, 'test/num_examples': 3581, 'score': 973.6636910438538, 'total_duration': 1873.9978604316711, 'accumulated_submission_time': 973.6636910438538, 'accumulated_eval_time': 900.078476190567, 'accumulated_logging_time': 0.17908430099487305, 'global_step': 693, 'preemption_count': 0}), (745, {'train/ssim': 0.7139700480869838, 'train/loss': 0.2932803971426828, 'validation/ssim': 0.6975031022483469, 'validation/loss': 0.3079909891913161, 'validation/num_examples': 3554, 'test/ssim': 0.7144318947875943, 'test/loss': 0.31014187154207973, 'test/num_examples': 3581, 'score': 1055.7441716194153, 'total_duration': 1959.9814624786377, 'accumulated_submission_time': 1055.7441716194153, 'accumulated_eval_time': 903.9608447551727, 'accumulated_logging_time': 0.19590020179748535, 'global_step': 745, 'preemption_count': 0}), (797, {'train/ssim': 0.7220843178885323, 'train/loss': 0.288353545325143, 'validation/ssim': 0.7036388356429375, 'validation/loss': 0.30379763009109456, 'validation/num_examples': 3554, 'test/ssim': 0.720866885341036, 'test/loss': 0.3059263381169715, 'test/num_examples': 3581, 'score': 1136.1999423503876, 'total_duration': 2044.3464357852936, 'accumulated_submission_time': 1136.1999423503876, 'accumulated_eval_time': 907.8431022167206, 'accumulated_logging_time': 0.2190229892730713, 'global_step': 797, 'preemption_count': 0}), (848, {'train/ssim': 0.7240603991917202, 'train/loss': 0.28637811115809847, 'validation/ssim': 0.7057296246306978, 'validation/loss': 0.3018446424803039, 'validation/num_examples': 3554, 'test/ssim': 0.7229109580075398, 'test/loss': 0.30392112614754957, 'test/num_examples': 3581, 'score': 1216.63405251503, 'total_duration': 2128.6866466999054, 'accumulated_submission_time': 1216.63405251503, 'accumulated_eval_time': 911.7265243530273, 'accumulated_logging_time': 0.2378857135772705, 'global_step': 848, 'preemption_count': 0}), (898, {'train/ssim': 0.7254883221217564, 'train/loss': 0.28498123373304096, 'validation/ssim': 0.7075790207776449, 'validation/loss': 0.300392404190261, 'validation/num_examples': 3554, 'test/ssim': 0.724787588793284, 'test/loss': 0.3023204063110863, 'test/num_examples': 3581, 'score': 1297.2299404144287, 'total_duration': 2213.1917798519135, 'accumulated_submission_time': 1297.2299404144287, 'accumulated_eval_time': 915.6143319606781, 'accumulated_logging_time': 0.2556583881378174, 'global_step': 898, 'preemption_count': 0}), (946, {'train/ssim': 0.7235208920070103, 'train/loss': 0.2858325072697231, 'validation/ssim': 0.7061262672780669, 'validation/loss': 0.3010981725586487, 'validation/num_examples': 3554, 'test/ssim': 0.7233762637225984, 'test/loss': 0.3029359052115331, 'test/num_examples': 3581, 'score': 1379.132319688797, 'total_duration': 2299.003766298294, 'accumulated_submission_time': 1379.132319688797, 'accumulated_eval_time': 919.5029566287994, 'accumulated_logging_time': 0.2723381519317627, 'global_step': 946, 'preemption_count': 0}), (1429, {'train/ssim': 0.7298066956656319, 'train/loss': 0.27989840507507324, 'validation/ssim': 0.7112550751573931, 'validation/loss': 0.2955143659652856, 'validation/num_examples': 3554, 'test/ssim': 0.72823446444778, 'test/loss': 0.2973932789810807, 'test/num_examples': 3581, 'score': 1459.1451761722565, 'total_duration': 2382.9685564041138, 'accumulated_submission_time': 1459.1451761722565, 'accumulated_eval_time': 923.4078936576843, 'accumulated_logging_time': 0.2896392345428467, 'global_step': 1429, 'preemption_count': 0}), (2406, {'train/ssim': 0.7349422318594796, 'train/loss': 0.2756263869149344, 'validation/ssim': 0.7160040018728897, 'validation/loss': 0.2916270413288724, 'validation/num_examples': 3554, 'test/ssim': 0.7332946726211254, 'test/loss': 0.29315562222930047, 'test/num_examples': 3581, 'score': 1539.1212358474731, 'total_duration': 2466.906001806259, 'accumulated_submission_time': 1539.1212358474731, 'accumulated_eval_time': 927.3014771938324, 'accumulated_logging_time': 0.30704665184020996, 'global_step': 2406, 'preemption_count': 0}), (3382, {'train/ssim': 0.7380215781075614, 'train/loss': 0.2740461826324463, 'validation/ssim': 0.7189316285347496, 'validation/loss': 0.29024136811075546, 'validation/num_examples': 3554, 'test/ssim': 0.7360739624057526, 'test/loss': 0.29185989068826795, 'test/num_examples': 3581, 'score': 1619.089319229126, 'total_duration': 2550.8355345726013, 'accumulated_submission_time': 1619.089319229126, 'accumulated_eval_time': 931.1955900192261, 'accumulated_logging_time': 0.32555246353149414, 'global_step': 3382, 'preemption_count': 0}), (4358, {'train/ssim': 0.7389967782156808, 'train/loss': 0.2729316438947405, 'validation/ssim': 0.7203784056037211, 'validation/loss': 0.28887070466375914, 'validation/num_examples': 3554, 'test/ssim': 0.7375939610749441, 'test/loss': 0.2903237341502897, 'test/num_examples': 3581, 'score': 1699.0384857654572, 'total_duration': 2634.7513875961304, 'accumulated_submission_time': 1699.0384857654572, 'accumulated_eval_time': 935.0934150218964, 'accumulated_logging_time': 0.34468579292297363, 'global_step': 4358, 'preemption_count': 0}), (5335, {'train/ssim': 0.7397311074393136, 'train/loss': 0.27297488280705046, 'validation/ssim': 0.72062591226435, 'validation/loss': 0.28912068433015614, 'validation/num_examples': 3554, 'test/ssim': 0.7375925975417132, 'test/loss': 0.2906999329687064, 'test/num_examples': 3581, 'score': 1779.0380289554596, 'total_duration': 2718.719444990158, 'accumulated_submission_time': 1779.0380289554596, 'accumulated_eval_time': 938.9925382137299, 'accumulated_logging_time': 0.36331772804260254, 'global_step': 5335, 'preemption_count': 0}), (6269, {'train/ssim': 0.7376200131007603, 'train/loss': 0.2740216425486973, 'validation/ssim': 0.7197025193883653, 'validation/loss': 0.2897142400618142, 'validation/num_examples': 3554, 'test/ssim': 0.7366480780726403, 'test/loss': 0.29127977547516404, 'test/num_examples': 3581, 'score': 1855.8149678707123, 'total_duration': 2802.650787591934, 'accumulated_submission_time': 1855.8149678707123, 'accumulated_eval_time': 942.8916182518005, 'accumulated_logging_time': 3.568582534790039, 'global_step': 6269, 'preemption_count': 0}), (7246, {'train/ssim': 0.7389991624014718, 'train/loss': 0.2730445521218436, 'validation/ssim': 0.7206398572690982, 'validation/loss': 0.288896190362092, 'validation/num_examples': 3554, 'test/ssim': 0.7378464192526529, 'test/loss': 0.2903801503377199, 'test/num_examples': 3581, 'score': 1935.7681798934937, 'total_duration': 2886.5735490322113, 'accumulated_submission_time': 1935.7681798934937, 'accumulated_eval_time': 946.7932369709015, 'accumulated_logging_time': 3.5873923301696777, 'global_step': 7246, 'preemption_count': 0}), (8222, {'train/ssim': 0.743293217250279, 'train/loss': 0.2702170269829886, 'validation/ssim': 0.723816433178285, 'validation/loss': 0.2868929354743335, 'validation/num_examples': 3554, 'test/ssim': 0.7410782657166294, 'test/loss': 0.28825597009389836, 'test/num_examples': 3581, 'score': 2015.7434239387512, 'total_duration': 2970.513213634491, 'accumulated_submission_time': 2015.7434239387512, 'accumulated_eval_time': 950.6904292106628, 'accumulated_logging_time': 3.6058096885681152, 'global_step': 8222, 'preemption_count': 0})], 'global_step': 8222}
I0307 15:47:06.019889 139843350590656 submission_runner.py:649] Timing: 2015.7434239387512
I0307 15:47:06.019924 139843350590656 submission_runner.py:651] Total number of evals: 23
I0307 15:47:06.019956 139843350590656 submission_runner.py:652] ====================
I0307 15:47:06.020070 139843350590656 submission_runner.py:750] Final fastmri score: 2
