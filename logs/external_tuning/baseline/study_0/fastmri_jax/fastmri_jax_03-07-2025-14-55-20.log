python submission_runner.py --framework=jax --workload=fastmri --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_0 --overwrite=True --save_checkpoints=False --rng_seed=1709465553 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=0 --hparam_end_index=1 2>&1 | tee -a /logs/fastmri_jax_03-07-2025-14-55-20.log
2025-03-07 14:55:23.515917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741359323.538669       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741359323.545299       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0307 14:55:31.802562 140017811473600 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax.
I0307 14:55:32.639494 140017811473600 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0307 14:55:32.642379 140017811473600 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0307 14:55:32.644087 140017811473600 submission_runner.py:606] Using RNG seed 1709465553
I0307 14:55:33.214998 140017811473600 submission_runner.py:615] --- Tuning run 1/5 ---
I0307 14:55:33.215208 140017811473600 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_1.
I0307 14:55:33.215410 140017811473600 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_1/hparams.json.
I0307 14:55:33.450101 140017811473600 submission_runner.py:218] Initializing dataset.
I0307 14:55:38.162914 140017811473600 submission_runner.py:229] Initializing model.
I0307 14:55:48.119602 140017811473600 submission_runner.py:272] Initializing optimizer.
I0307 14:55:48.597379 140017811473600 submission_runner.py:279] Initializing metrics bundle.
I0307 14:55:48.597581 140017811473600 submission_runner.py:301] Initializing checkpoint and logger.
I0307 14:55:48.598273 140017811473600 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_1 with prefix checkpoint_
I0307 14:55:48.598371 140017811473600 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_1/meta_data_0.json.
I0307 14:55:48.598550 140017811473600 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0307 14:55:48.598598 140017811473600 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0307 14:55:48.760546 140017811473600 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/fastmri_jax/trial_1/flags_0.json.
I0307 14:55:48.792017 140017811473600 submission_runner.py:337] Starting training loop.
E0307 14:59:34.464251       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 14:59:34.670066       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 14:59:35.082721       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 14:59:35.288728       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 14:59:37.869695       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 14:59:38.075936       9 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
I0307 14:59:49.837812 139880121845504 logging_writer.py:48] [0] global_step=0, grad_norm=6.050497531890869, loss=1.0164982080459595
I0307 14:59:49.886885 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:06:50.298821 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:10:51.163122 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:14:45.569982 140017811473600 submission_runner.py:469] Time since start: 1136.78s, 	Step: 1, 	{'train/ssim': 0.15631413459777832, 'train/loss': 1.027566909790039, 'validation/ssim': 0.15175362899857556, 'validation/loss': 1.031987230497327, 'validation/num_examples': 3554, 'test/ssim': 0.1734260020060301, 'test/loss': 1.0292505830468095, 'test/num_examples': 3581, 'score': 241.0947344303131, 'total_duration': 1136.7778730392456, 'accumulated_submission_time': 241.0947344303131, 'accumulated_eval_time': 895.6830060482025, 'accumulated_logging_time': 0}
I0307 15:14:45.580876 139862371981056 logging_writer.py:48] [1] accumulated_eval_time=895.683, accumulated_logging_time=0, accumulated_submission_time=241.095, global_step=1, preemption_count=0, score=241.095, test/loss=1.02925, test/num_examples=3581, test/ssim=0.173426, total_duration=1136.78, train/loss=1.02757, train/ssim=0.156314, validation/loss=1.03199, validation/num_examples=3554, validation/ssim=0.151754
I0307 15:14:57.543774 139862363588352 logging_writer.py:48] [100] global_step=100, grad_norm=0.37110471725463867, loss=0.3519822657108307
I0307 15:15:14.568111 139862371981056 logging_writer.py:48] [200] global_step=200, grad_norm=0.13605716824531555, loss=0.29840564727783203
I0307 15:16:07.094283 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:16:08.946871 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:16:10.231068 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:16:11.518936 140017811473600 submission_runner.py:469] Time since start: 1222.73s, 	Step: 252, 	{'train/ssim': 0.6824596949986049, 'train/loss': 0.32667074884687153, 'validation/ssim': 0.661116325794879, 'validation/loss': 0.3466710319798115, 'validation/num_examples': 3554, 'test/ssim': 0.6804064228960137, 'test/loss': 0.3474884672359327, 'test/num_examples': 3581, 'score': 322.56643986701965, 'total_duration': 1222.726845741272, 'accumulated_submission_time': 322.56643986701965, 'accumulated_eval_time': 900.1076054573059, 'accumulated_logging_time': 0.019253015518188477}
I0307 15:16:11.529558 139862363588352 logging_writer.py:48] [252] accumulated_eval_time=900.108, accumulated_logging_time=0.019253, accumulated_submission_time=322.566, global_step=252, preemption_count=0, score=322.566, test/loss=0.347488, test/num_examples=3581, test/ssim=0.680406, total_duration=1222.73, train/loss=0.326671, train/ssim=0.68246, validation/loss=0.346671, validation/num_examples=3554, validation/ssim=0.661116
I0307 15:17:28.746359 139862371981056 logging_writer.py:48] [300] global_step=300, grad_norm=0.13334490358829498, loss=0.3316901922225952
I0307 15:17:32.811728 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:17:34.092809 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:17:35.376728 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:17:36.662497 140017811473600 submission_runner.py:469] Time since start: 1307.87s, 	Step: 303, 	{'train/ssim': 0.6891106878008161, 'train/loss': 0.32166337966918945, 'validation/ssim': 0.6683519285048537, 'validation/loss': 0.34097875660567317, 'validation/num_examples': 3554, 'test/ssim': 0.6873534883543354, 'test/loss': 0.34191308211960697, 'test/num_examples': 3581, 'score': 403.8335950374603, 'total_duration': 1307.8704257011414, 'accumulated_submission_time': 403.8335950374603, 'accumulated_eval_time': 903.9583404064178, 'accumulated_logging_time': 0.03814554214477539}
I0307 15:17:36.671751 139862363588352 logging_writer.py:48] [303] accumulated_eval_time=903.958, accumulated_logging_time=0.0381455, accumulated_submission_time=403.834, global_step=303, preemption_count=0, score=403.834, test/loss=0.341913, test/num_examples=3581, test/ssim=0.687353, total_duration=1307.87, train/loss=0.321663, train/ssim=0.689111, validation/loss=0.340979, validation/num_examples=3554, validation/ssim=0.668352
I0307 15:18:57.281575 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:18:58.562752 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:18:59.844200 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:19:01.131509 140017811473600 submission_runner.py:469] Time since start: 1392.34s, 	Step: 352, 	{'train/ssim': 0.6930514744349888, 'train/loss': 0.31724568775721956, 'validation/ssim': 0.6725588547894977, 'validation/loss': 0.33634753809527995, 'validation/num_examples': 3554, 'test/ssim': 0.6915694649277436, 'test/loss': 0.33740718429296984, 'test/num_examples': 3581, 'score': 484.4311594963074, 'total_duration': 1392.3394198417664, 'accumulated_submission_time': 484.4311594963074, 'accumulated_eval_time': 907.8082180023193, 'accumulated_logging_time': 0.05657553672790527}
I0307 15:19:01.140380 139862371981056 logging_writer.py:48] [352] accumulated_eval_time=907.808, accumulated_logging_time=0.0565755, accumulated_submission_time=484.431, global_step=352, preemption_count=0, score=484.431, test/loss=0.337407, test/num_examples=3581, test/ssim=0.691569, total_duration=1392.34, train/loss=0.317246, train/ssim=0.693051, validation/loss=0.336348, validation/num_examples=3554, validation/ssim=0.672559
I0307 15:20:16.731031 139862363588352 logging_writer.py:48] [400] global_step=400, grad_norm=0.11665008962154388, loss=0.33956170082092285
I0307 15:20:22.058883 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:20:23.339079 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:20:24.621142 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:20:25.908053 140017811473600 submission_runner.py:469] Time since start: 1477.12s, 	Step: 404, 	{'train/ssim': 0.698786735534668, 'train/loss': 0.31248375347682406, 'validation/ssim': 0.6788832235685144, 'validation/loss': 0.3310140546413372, 'validation/num_examples': 3554, 'test/ssim': 0.6976247796530298, 'test/loss': 0.33231813739179, 'test/num_examples': 3581, 'score': 565.3365747928619, 'total_duration': 1477.1159796714783, 'accumulated_submission_time': 565.3365747928619, 'accumulated_eval_time': 911.6573510169983, 'accumulated_logging_time': 0.07451725006103516}
I0307 15:20:25.917400 139862371981056 logging_writer.py:48] [404] accumulated_eval_time=911.657, accumulated_logging_time=0.0745173, accumulated_submission_time=565.337, global_step=404, preemption_count=0, score=565.337, test/loss=0.332318, test/num_examples=3581, test/ssim=0.697625, total_duration=1477.12, train/loss=0.312484, train/ssim=0.698787, validation/loss=0.331014, validation/num_examples=3554, validation/ssim=0.678883
I0307 15:21:46.868916 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:21:48.150093 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:21:49.434567 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:21:50.718912 140017811473600 submission_runner.py:469] Time since start: 1561.93s, 	Step: 457, 	{'train/ssim': 0.7037008830479213, 'train/loss': 0.3075072765350342, 'validation/ssim': 0.6837124542768711, 'validation/loss': 0.3258018858592431, 'validation/num_examples': 3554, 'test/ssim': 0.7022205002312553, 'test/loss': 0.32743321141528203, 'test/num_examples': 3581, 'score': 646.2761743068695, 'total_duration': 1561.9268465042114, 'accumulated_submission_time': 646.2761743068695, 'accumulated_eval_time': 915.5073075294495, 'accumulated_logging_time': 0.0921781063079834}
I0307 15:21:50.726879 139862363588352 logging_writer.py:48] [457] accumulated_eval_time=915.507, accumulated_logging_time=0.0921781, accumulated_submission_time=646.276, global_step=457, preemption_count=0, score=646.276, test/loss=0.327433, test/num_examples=3581, test/ssim=0.702221, total_duration=1561.93, train/loss=0.307507, train/ssim=0.703701, validation/loss=0.325802, validation/num_examples=3554, validation/ssim=0.683712
I0307 15:22:53.343716 139862371981056 logging_writer.py:48] [500] global_step=500, grad_norm=0.14902491867542267, loss=0.33213675022125244
I0307 15:23:11.531260 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:23:12.816397 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:23:14.097809 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:23:15.390070 140017811473600 submission_runner.py:469] Time since start: 1646.60s, 	Step: 512, 	{'train/ssim': 0.7072832243783134, 'train/loss': 0.30244033677237375, 'validation/ssim': 0.6879602538512943, 'validation/loss': 0.3199064118444886, 'validation/num_examples': 3554, 'test/ssim': 0.7060445291774294, 'test/loss': 0.3218570763556793, 'test/num_examples': 3581, 'score': 727.069085597992, 'total_duration': 1646.598001241684, 'accumulated_submission_time': 727.069085597992, 'accumulated_eval_time': 919.3660695552826, 'accumulated_logging_time': 0.10801315307617188}
I0307 15:23:15.398634 139862363588352 logging_writer.py:48] [512] accumulated_eval_time=919.366, accumulated_logging_time=0.108013, accumulated_submission_time=727.069, global_step=512, preemption_count=0, score=727.069, test/loss=0.321857, test/num_examples=3581, test/ssim=0.706045, total_duration=1646.6, train/loss=0.30244, train/ssim=0.707283, validation/loss=0.319906, validation/num_examples=3554, validation/ssim=0.68796
I0307 15:24:35.576287 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:24:36.858095 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:24:38.138008 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:24:39.422430 140017811473600 submission_runner.py:469] Time since start: 1730.63s, 	Step: 562, 	{'train/ssim': 0.7114772796630859, 'train/loss': 0.2988025801522391, 'validation/ssim': 0.6920695651027012, 'validation/loss': 0.3162645673778665, 'validation/num_examples': 3554, 'test/ssim': 0.7099136228968863, 'test/loss': 0.31837280580232474, 'test/num_examples': 3581, 'score': 807.2311472892761, 'total_duration': 1730.6303339004517, 'accumulated_submission_time': 807.2311472892761, 'accumulated_eval_time': 923.2121469974518, 'accumulated_logging_time': 0.12763428688049316}
I0307 15:24:39.432636 139862371981056 logging_writer.py:48] [562] accumulated_eval_time=923.212, accumulated_logging_time=0.127634, accumulated_submission_time=807.231, global_step=562, preemption_count=0, score=807.231, test/loss=0.318373, test/num_examples=3581, test/ssim=0.709914, total_duration=1730.63, train/loss=0.298803, train/ssim=0.711477, validation/loss=0.316265, validation/num_examples=3554, validation/ssim=0.69207
I0307 15:25:36.696561 139862363588352 logging_writer.py:48] [600] global_step=600, grad_norm=0.14476069808006287, loss=0.3536628186702728
I0307 15:26:01.635607 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:26:02.921974 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:26:04.205724 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:26:05.496440 140017811473600 submission_runner.py:469] Time since start: 1816.70s, 	Step: 618, 	{'train/ssim': 0.7141968863351005, 'train/loss': 0.296349116734096, 'validation/ssim': 0.6947176734181556, 'validation/loss': 0.31376858326445556, 'validation/num_examples': 3554, 'test/ssim': 0.7124223876884949, 'test/loss': 0.3159117646737992, 'test/num_examples': 3581, 'score': 889.4219582080841, 'total_duration': 1816.7043459415436, 'accumulated_submission_time': 889.4219582080841, 'accumulated_eval_time': 927.0729203224182, 'accumulated_logging_time': 0.14618849754333496}
I0307 15:26:05.509398 139862371981056 logging_writer.py:48] [618] accumulated_eval_time=927.073, accumulated_logging_time=0.146188, accumulated_submission_time=889.422, global_step=618, preemption_count=0, score=889.422, test/loss=0.315912, test/num_examples=3581, test/ssim=0.712422, total_duration=1816.7, train/loss=0.296349, train/ssim=0.714197, validation/loss=0.313769, validation/num_examples=3554, validation/ssim=0.694718
I0307 15:27:25.743104 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:27:27.033735 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:27:28.316488 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:27:29.604871 140017811473600 submission_runner.py:469] Time since start: 1900.81s, 	Step: 668, 	{'train/ssim': 0.7138192994253976, 'train/loss': 0.29433018820626394, 'validation/ssim': 0.6955106152398706, 'validation/loss': 0.3112524716318761, 'validation/num_examples': 3554, 'test/ssim': 0.7131904659574839, 'test/loss': 0.3132420006959474, 'test/num_examples': 3581, 'score': 969.6401927471161, 'total_duration': 1900.8127989768982, 'accumulated_submission_time': 969.6401927471161, 'accumulated_eval_time': 930.934642791748, 'accumulated_logging_time': 0.17119622230529785}
I0307 15:27:29.614294 139862363588352 logging_writer.py:48] [668] accumulated_eval_time=930.935, accumulated_logging_time=0.171196, accumulated_submission_time=969.64, global_step=668, preemption_count=0, score=969.64, test/loss=0.313242, test/num_examples=3581, test/ssim=0.71319, total_duration=1900.81, train/loss=0.29433, train/ssim=0.713819, validation/loss=0.311252, validation/num_examples=3554, validation/ssim=0.695511
I0307 15:28:19.137996 139862371981056 logging_writer.py:48] [700] global_step=700, grad_norm=0.5038612484931946, loss=0.25149792432785034
I0307 15:28:50.355652 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:28:51.634132 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:28:52.917484 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:28:54.201567 140017811473600 submission_runner.py:469] Time since start: 1985.41s, 	Step: 719, 	{'train/ssim': 0.7185471398489816, 'train/loss': 0.29185332570757183, 'validation/ssim': 0.6994941466701252, 'validation/loss': 0.30878925484489306, 'validation/num_examples': 3554, 'test/ssim': 0.716905684951829, 'test/loss': 0.3110395536446698, 'test/num_examples': 3581, 'score': 1050.3698177337646, 'total_duration': 1985.409487247467, 'accumulated_submission_time': 1050.3698177337646, 'accumulated_eval_time': 934.7805023193359, 'accumulated_logging_time': 0.1890866756439209}
I0307 15:28:54.209562 139862363588352 logging_writer.py:48] [719] accumulated_eval_time=934.781, accumulated_logging_time=0.189087, accumulated_submission_time=1050.37, global_step=719, preemption_count=0, score=1050.37, test/loss=0.31104, test/num_examples=3581, test/ssim=0.716906, total_duration=1985.41, train/loss=0.291853, train/ssim=0.718547, validation/loss=0.308789, validation/num_examples=3554, validation/ssim=0.699494
I0307 15:30:17.862380 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:30:19.155621 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:30:20.436689 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:30:21.720873 140017811473600 submission_runner.py:469] Time since start: 2072.93s, 	Step: 775, 	{'train/ssim': 0.716632774897984, 'train/loss': 0.2908531257084438, 'validation/ssim': 0.698937033426245, 'validation/loss': 0.3073879192569112, 'validation/num_examples': 3554, 'test/ssim': 0.716110063311575, 'test/loss': 0.30955967694079867, 'test/num_examples': 3581, 'score': 1134.0109100341797, 'total_duration': 2072.9288024902344, 'accumulated_submission_time': 1134.0109100341797, 'accumulated_eval_time': 938.6389541625977, 'accumulated_logging_time': 0.20478463172912598}
I0307 15:30:21.729336 139862371981056 logging_writer.py:48] [775] accumulated_eval_time=938.639, accumulated_logging_time=0.204785, accumulated_submission_time=1134.01, global_step=775, preemption_count=0, score=1134.01, test/loss=0.30956, test/num_examples=3581, test/ssim=0.71611, total_duration=2072.93, train/loss=0.290853, train/ssim=0.716633, validation/loss=0.307388, validation/num_examples=3554, validation/ssim=0.698937
I0307 15:30:58.529365 139862363588352 logging_writer.py:48] [800] global_step=800, grad_norm=0.27433061599731445, loss=0.2869977056980133
I0307 15:31:42.668751 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:31:43.948879 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:31:45.234041 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:31:46.526453 140017811473600 submission_runner.py:469] Time since start: 2157.73s, 	Step: 823, 	{'train/ssim': 0.7164355686732701, 'train/loss': 0.2900559561593192, 'validation/ssim': 0.6990382205789252, 'validation/loss': 0.30641867273230866, 'validation/num_examples': 3554, 'test/ssim': 0.7161620139276739, 'test/loss': 0.3085851597406451, 'test/num_examples': 3581, 'score': 1214.9399585723877, 'total_duration': 2157.734365463257, 'accumulated_submission_time': 1214.9399585723877, 'accumulated_eval_time': 942.4965958595276, 'accumulated_logging_time': 0.2205970287322998}
I0307 15:31:46.537480 139862371981056 logging_writer.py:48] [823] accumulated_eval_time=942.497, accumulated_logging_time=0.220597, accumulated_submission_time=1214.94, global_step=823, preemption_count=0, score=1214.94, test/loss=0.308585, test/num_examples=3581, test/ssim=0.716162, total_duration=2157.73, train/loss=0.290056, train/ssim=0.716436, validation/loss=0.306419, validation/num_examples=3554, validation/ssim=0.699038
I0307 15:33:06.882037 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:33:08.162462 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:33:09.446305 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:33:10.738882 140017811473600 submission_runner.py:469] Time since start: 2241.95s, 	Step: 873, 	{'train/ssim': 0.7183583123343331, 'train/loss': 0.28862619400024414, 'validation/ssim': 0.701410382667417, 'validation/loss': 0.30482619440683034, 'validation/num_examples': 3554, 'test/ssim': 0.7180933905726403, 'test/loss': 0.3070022340128456, 'test/num_examples': 3581, 'score': 1295.2676992416382, 'total_duration': 2241.946810245514, 'accumulated_submission_time': 1295.2676992416382, 'accumulated_eval_time': 946.353401184082, 'accumulated_logging_time': 0.24514532089233398}
I0307 15:33:10.747633 139862363588352 logging_writer.py:48] [873] accumulated_eval_time=946.353, accumulated_logging_time=0.245145, accumulated_submission_time=1295.27, global_step=873, preemption_count=0, score=1295.27, test/loss=0.307002, test/num_examples=3581, test/ssim=0.718093, total_duration=2241.95, train/loss=0.288626, train/ssim=0.718358, validation/loss=0.304826, validation/num_examples=3554, validation/ssim=0.70141
I0307 15:33:52.014774 139862371981056 logging_writer.py:48] [900] global_step=900, grad_norm=0.19342964887619019, loss=0.3259772062301636
I0307 15:34:31.494782 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:34:32.786230 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:34:34.068635 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:34:35.354725 140017811473600 submission_runner.py:469] Time since start: 2326.56s, 	Step: 926, 	{'train/ssim': 0.7235200745718819, 'train/loss': 0.28734118597848074, 'validation/ssim': 0.7038881970578925, 'validation/loss': 0.304720576452149, 'validation/num_examples': 3554, 'test/ssim': 0.7212991935519059, 'test/loss': 0.30668691695319045, 'test/num_examples': 3581, 'score': 1376.0038604736328, 'total_duration': 2326.562655687332, 'accumulated_submission_time': 1376.0038604736328, 'accumulated_eval_time': 950.2133169174194, 'accumulated_logging_time': 0.26180005073547363}
I0307 15:34:35.365682 139862363588352 logging_writer.py:48] [926] accumulated_eval_time=950.213, accumulated_logging_time=0.2618, accumulated_submission_time=1376, global_step=926, preemption_count=0, score=1376, test/loss=0.306687, test/num_examples=3581, test/ssim=0.721299, total_duration=2326.56, train/loss=0.287341, train/ssim=0.72352, validation/loss=0.304721, validation/num_examples=3554, validation/ssim=0.703888
I0307 15:35:45.387591 139862371981056 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.3163992166519165, loss=0.3062565326690674
I0307 15:35:57.706165 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:35:58.998599 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:36:00.283012 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:36:01.577736 140017811473600 submission_runner.py:469] Time since start: 2412.79s, 	Step: 1042, 	{'train/ssim': 0.725696155003139, 'train/loss': 0.2843394620077951, 'validation/ssim': 0.7071456265167769, 'validation/loss': 0.3007530165174803, 'validation/num_examples': 3554, 'test/ssim': 0.7241781576157149, 'test/loss': 0.30282719752469633, 'test/num_examples': 3581, 'score': 1458.3184332847595, 'total_duration': 2412.7856657505035, 'accumulated_submission_time': 1458.3184332847595, 'accumulated_eval_time': 954.0848453044891, 'accumulated_logging_time': 0.29042959213256836}
I0307 15:36:01.586042 139862363588352 logging_writer.py:48] [1042] accumulated_eval_time=954.085, accumulated_logging_time=0.29043, accumulated_submission_time=1458.32, global_step=1042, preemption_count=0, score=1458.32, test/loss=0.302827, test/num_examples=3581, test/ssim=0.724178, total_duration=2412.79, train/loss=0.284339, train/ssim=0.725696, validation/loss=0.300753, validation/num_examples=3554, validation/ssim=0.707146
I0307 15:36:09.172240 139862371981056 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.12490744143724442, loss=0.3758132755756378
I0307 15:36:17.388661 139862363588352 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.24043774604797363, loss=0.3126610517501831
I0307 15:36:25.601158 139862371981056 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.8994405269622803, loss=0.22742344439029694
I0307 15:36:33.849560 139862363588352 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.16129571199417114, loss=0.33140623569488525
I0307 15:36:42.104940 139862371981056 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.3547976315021515, loss=0.30241259932518005
I0307 15:36:50.299045 139862363588352 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.10404379665851593, loss=0.276644229888916
I0307 15:36:58.516327 139862371981056 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.26855388283729553, loss=0.3034345507621765
I0307 15:37:06.726541 139862363588352 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.10388612747192383, loss=0.27218762040138245
I0307 15:37:14.956066 139862371981056 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.10400258749723434, loss=0.3223792314529419
I0307 15:37:21.615173 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:37:22.901239 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:37:24.189887 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:37:25.490241 140017811473600 submission_runner.py:469] Time since start: 2496.70s, 	Step: 1982, 	{'train/ssim': 0.7349472727094378, 'train/loss': 0.2761965308870588, 'validation/ssim': 0.7150995000131893, 'validation/loss': 0.293218729666397, 'validation/num_examples': 3554, 'test/ssim': 0.7322275033379293, 'test/loss': 0.29498282493542305, 'test/num_examples': 3581, 'score': 1538.2924783229828, 'total_duration': 2496.698174715042, 'accumulated_submission_time': 1538.2924783229828, 'accumulated_eval_time': 957.9598708152771, 'accumulated_logging_time': 0.30618810653686523}
I0307 15:37:25.499155 139862363588352 logging_writer.py:48] [1982] accumulated_eval_time=957.96, accumulated_logging_time=0.306188, accumulated_submission_time=1538.29, global_step=1982, preemption_count=0, score=1538.29, test/loss=0.294983, test/num_examples=3581, test/ssim=0.732228, total_duration=2496.7, train/loss=0.276197, train/ssim=0.734947, validation/loss=0.293219, validation/num_examples=3554, validation/ssim=0.7151
I0307 15:37:27.080021 139862371981056 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.08986598998308182, loss=0.23108702898025513
I0307 15:37:35.305827 139862363588352 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.17568236589431763, loss=0.34975242614746094
I0307 15:37:43.526155 139862371981056 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.22424934804439545, loss=0.26290878653526306
I0307 15:37:51.742679 139862363588352 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.048179756850004196, loss=0.2740761637687683
I0307 15:37:59.951377 139862371981056 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.12621060013771057, loss=0.32950687408447266
I0307 15:38:08.186111 139862363588352 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.06654611229896545, loss=0.3851868510246277
I0307 15:38:16.424675 139862371981056 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.14207768440246582, loss=0.2269866168498993
I0307 15:38:24.648422 139862363588352 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.1320790946483612, loss=0.4436275362968445
I0307 15:38:32.883652 139862371981056 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.39642539620399475, loss=0.24872435629367828
I0307 15:38:41.118771 139862363588352 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.3160237669944763, loss=0.27983608841896057
I0307 15:38:45.546634 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:38:46.831740 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:38:48.122990 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:38:49.413247 140017811473600 submission_runner.py:469] Time since start: 2580.62s, 	Step: 2955, 	{'train/ssim': 0.7373081615992955, 'train/loss': 0.27441724709102083, 'validation/ssim': 0.7172609757491559, 'validation/loss': 0.29147340584552617, 'validation/num_examples': 3554, 'test/ssim': 0.7344780149355976, 'test/loss': 0.2930905476058538, 'test/num_examples': 3581, 'score': 1618.2834293842316, 'total_duration': 2580.621167898178, 'accumulated_submission_time': 1618.2834293842316, 'accumulated_eval_time': 961.8264293670654, 'accumulated_logging_time': 0.3223912715911865}
I0307 15:38:49.424085 139862371981056 logging_writer.py:48] [2955] accumulated_eval_time=961.826, accumulated_logging_time=0.322391, accumulated_submission_time=1618.28, global_step=2955, preemption_count=0, score=1618.28, test/loss=0.293091, test/num_examples=3581, test/ssim=0.734478, total_duration=2580.62, train/loss=0.274417, train/ssim=0.737308, validation/loss=0.291473, validation/num_examples=3554, validation/ssim=0.717261
I0307 15:38:53.238481 139862363588352 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.33729657530784607, loss=0.2728279232978821
I0307 15:39:01.467867 139862371981056 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.17983591556549072, loss=0.3232012689113617
I0307 15:39:09.681673 139862363588352 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.42389190196990967, loss=0.29810118675231934
I0307 15:39:17.886369 139862371981056 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.176040381193161, loss=0.2356211543083191
I0307 15:39:26.126408 139862363588352 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.06457717716693878, loss=0.3497573137283325
I0307 15:39:34.353591 139862371981056 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.19645537436008453, loss=0.21407590806484222
I0307 15:39:42.568703 139862363588352 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.1574486643075943, loss=0.2986719310283661
I0307 15:39:50.811417 139862371981056 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.1308082789182663, loss=0.2761078178882599
I0307 15:39:59.039903 139862363588352 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.15593266487121582, loss=0.28344595432281494
I0307 15:40:07.278284 139862371981056 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.07131825387477875, loss=0.34043174982070923
I0307 15:40:09.421188 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:40:10.712905 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:40:12.003513 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:40:13.294649 140017811473600 submission_runner.py:469] Time since start: 2664.50s, 	Step: 3927, 	{'train/ssim': 0.7388435091291156, 'train/loss': 0.2733594519751413, 'validation/ssim': 0.7190192141557048, 'validation/loss': 0.29029529337542204, 'validation/num_examples': 3554, 'test/ssim': 0.7362152244484781, 'test/loss': 0.29186718559105346, 'test/num_examples': 3581, 'score': 1698.2229347229004, 'total_duration': 2664.502574443817, 'accumulated_submission_time': 1698.2229347229004, 'accumulated_eval_time': 965.6998391151428, 'accumulated_logging_time': 0.3419156074523926}
I0307 15:40:13.304677 139862363588352 logging_writer.py:48] [3927] accumulated_eval_time=965.7, accumulated_logging_time=0.341916, accumulated_submission_time=1698.22, global_step=3927, preemption_count=0, score=1698.22, test/loss=0.291867, test/num_examples=3581, test/ssim=0.736215, total_duration=2664.5, train/loss=0.273359, train/ssim=0.738844, validation/loss=0.290295, validation/num_examples=3554, validation/ssim=0.719019
I0307 15:40:19.404654 139862371981056 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.12340276688337326, loss=0.26012343168258667
I0307 15:40:27.630799 139862363588352 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.16114316880702972, loss=0.2737935483455658
I0307 15:40:35.861112 139862371981056 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.2518284022808075, loss=0.27296334505081177
I0307 15:40:44.086791 139862363588352 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.12912055850028992, loss=0.25910529494285583
I0307 15:40:52.316752 139862371981056 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.17974376678466797, loss=0.22742055356502533
I0307 15:41:00.569449 139862363588352 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.11169589310884476, loss=0.22109751403331757
I0307 15:41:08.785812 139862371981056 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.17467039823532104, loss=0.2089298814535141
I0307 15:41:17.017104 139862363588352 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.14605174958705902, loss=0.3031747341156006
I0307 15:41:25.242594 139862371981056 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.15604625642299652, loss=0.22982917726039886
I0307 15:41:33.310938 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:41:34.598974 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:41:35.892554 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:41:37.185777 140017811473600 submission_runner.py:469] Time since start: 2748.39s, 	Step: 4899, 	{'train/ssim': 0.7415082114083427, 'train/loss': 0.27171710559300016, 'validation/ssim': 0.7210889138998312, 'validation/loss': 0.2891617637037493, 'validation/num_examples': 3554, 'test/ssim': 0.7383559716210556, 'test/loss': 0.2905632387623045, 'test/num_examples': 3581, 'score': 1778.1732008457184, 'total_duration': 2748.3937017917633, 'accumulated_submission_time': 1778.1732008457184, 'accumulated_eval_time': 969.5746285915375, 'accumulated_logging_time': 0.3599400520324707}
I0307 15:41:37.195601 139862363588352 logging_writer.py:48] [4899] accumulated_eval_time=969.575, accumulated_logging_time=0.35994, accumulated_submission_time=1778.17, global_step=4899, preemption_count=0, score=1778.17, test/loss=0.290563, test/num_examples=3581, test/ssim=0.738356, total_duration=2748.39, train/loss=0.271717, train/ssim=0.741508, validation/loss=0.289162, validation/num_examples=3554, validation/ssim=0.721089
I0307 15:41:37.373085 139862371981056 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.13217438757419586, loss=0.20120292901992798
I0307 15:41:45.602697 139862363588352 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.09543481469154358, loss=0.29408109188079834
I0307 15:41:53.814734 139862371981056 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.5381117463111877, loss=0.30331477522850037
I0307 15:42:02.053242 139862363588352 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.21108052134513855, loss=0.21662846207618713
I0307 15:42:10.281804 139862371981056 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.06280409544706345, loss=0.32343873381614685
I0307 15:42:21.055558 139862363588352 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.29589536786079407, loss=0.1946210265159607
I0307 15:42:29.519822 139862371981056 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.07213535904884338, loss=0.17665813863277435
I0307 15:42:37.847663 139862363588352 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.1864209622144699, loss=0.2551112174987793
I0307 15:42:46.062588 139862371981056 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.14174596965312958, loss=0.26204586029052734
I0307 15:42:54.300988 139862363588352 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.1962074339389801, loss=0.28749239444732666
I0307 15:42:57.260295 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:42:58.547877 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:42:59.839714 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:43:01.135377 140017811473600 submission_runner.py:469] Time since start: 2832.34s, 	Step: 5837, 	{'train/ssim': 0.7414670671735492, 'train/loss': 0.2705653054373605, 'validation/ssim': 0.72135730372028, 'validation/loss': 0.28777720677295826, 'validation/num_examples': 3554, 'test/ssim': 0.738615111111596, 'test/loss': 0.2892613031450712, 'test/num_examples': 3581, 'score': 1858.1797263622284, 'total_duration': 2832.343307495117, 'accumulated_submission_time': 1858.1797263622284, 'accumulated_eval_time': 973.4496645927429, 'accumulated_logging_time': 0.377671480178833}
I0307 15:43:01.145411 139862371981056 logging_writer.py:48] [5837] accumulated_eval_time=973.45, accumulated_logging_time=0.377671, accumulated_submission_time=1858.18, global_step=5837, preemption_count=0, score=1858.18, test/loss=0.289261, test/num_examples=3581, test/ssim=0.738615, total_duration=2832.34, train/loss=0.270565, train/ssim=0.741467, validation/loss=0.287777, validation/num_examples=3554, validation/ssim=0.721357
I0307 15:43:06.410892 139862363588352 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.15395487844944, loss=0.31927168369293213
I0307 15:43:14.635907 139862371981056 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.13522939383983612, loss=0.2820584177970886
I0307 15:43:22.848416 139862363588352 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.12502521276474, loss=0.3379475474357605
I0307 15:43:31.066755 139862371981056 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.17966970801353455, loss=0.21398566663265228
I0307 15:43:39.313590 139862363588352 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.18484854698181152, loss=0.28235965967178345
I0307 15:43:47.528569 139862371981056 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.039839018136262894, loss=0.3154720962047577
I0307 15:43:55.753743 139862363588352 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.07446279376745224, loss=0.2553906738758087
I0307 15:44:03.969166 139862371981056 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.15949013829231262, loss=0.21550515294075012
I0307 15:44:12.197151 139862363588352 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.10318870097398758, loss=0.22302499413490295
I0307 15:44:20.440547 139862371981056 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.282162606716156, loss=0.26524925231933594
I0307 15:44:21.185796 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:44:22.475731 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:44:23.767618 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:44:25.058295 140017811473600 submission_runner.py:469] Time since start: 2916.27s, 	Step: 6810, 	{'train/ssim': 0.7429915836879185, 'train/loss': 0.2699623107910156, 'validation/ssim': 0.7224011869328574, 'validation/loss': 0.2875267118970262, 'validation/num_examples': 3554, 'test/ssim': 0.7396861664645001, 'test/loss': 0.2889128522279042, 'test/num_examples': 3581, 'score': 1938.163536787033, 'total_duration': 2916.2662041187286, 'accumulated_submission_time': 1938.163536787033, 'accumulated_eval_time': 977.3220953941345, 'accumulated_logging_time': 0.3955190181732178}
I0307 15:44:25.070319 139862363588352 logging_writer.py:48] [6810] accumulated_eval_time=977.322, accumulated_logging_time=0.395519, accumulated_submission_time=1938.16, global_step=6810, preemption_count=0, score=1938.16, test/loss=0.288913, test/num_examples=3581, test/ssim=0.739686, total_duration=2916.27, train/loss=0.269962, train/ssim=0.742992, validation/loss=0.287527, validation/num_examples=3554, validation/ssim=0.722401
I0307 15:44:32.584226 139862371981056 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.17713959515094757, loss=0.39839571714401245
I0307 15:44:40.830609 139862363588352 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.19945155084133148, loss=0.255258709192276
I0307 15:44:49.056917 139862371981056 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.14717593789100647, loss=0.22767969965934753
I0307 15:44:57.279157 139862363588352 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.0666172131896019, loss=0.3566886782646179
I0307 15:45:05.500607 139862371981056 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.07667825371026993, loss=0.2513430118560791
I0307 15:45:13.711565 139862363588352 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.1683201640844345, loss=0.3167245388031006
I0307 15:45:21.957686 139862371981056 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.08169453591108322, loss=0.31776633858680725
I0307 15:45:30.189887 139862363588352 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.5931828618049622, loss=0.23584172129631042
I0307 15:45:38.413963 139862371981056 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.13146181404590607, loss=0.24099180102348328
I0307 15:45:45.078024 140017811473600 spec.py:321] Evaluating on the training split.
I0307 15:45:46.365394 140017811473600 spec.py:333] Evaluating on the validation split.
I0307 15:45:47.656763 140017811473600 spec.py:349] Evaluating on the test split.
I0307 15:45:48.946464 140017811473600 submission_runner.py:469] Time since start: 3000.15s, 	Step: 7782, 	{'train/ssim': 0.7444451877049038, 'train/loss': 0.2689971923828125, 'validation/ssim': 0.7236962176201112, 'validation/loss': 0.28680421639240117, 'validation/num_examples': 3554, 'test/ssim': 0.7409289588278414, 'test/loss': 0.2881618863009634, 'test/num_examples': 3581, 'score': 2018.1146247386932, 'total_duration': 3000.1543922424316, 'accumulated_submission_time': 2018.1146247386932, 'accumulated_eval_time': 981.1904897689819, 'accumulated_logging_time': 0.41617751121520996}
I0307 15:45:48.956688 139862363588352 logging_writer.py:48] [7782] accumulated_eval_time=981.19, accumulated_logging_time=0.416178, accumulated_submission_time=2018.11, global_step=7782, preemption_count=0, score=2018.11, test/loss=0.288162, test/num_examples=3581, test/ssim=0.740929, total_duration=3000.15, train/loss=0.268997, train/ssim=0.744445, validation/loss=0.286804, validation/num_examples=3554, validation/ssim=0.723696
I0307 15:45:48.968288 139862371981056 logging_writer.py:48] [7782] global_step=7782, preemption_count=0, score=2018.11
I0307 15:45:49.761842 140017811473600 submission_runner.py:646] Tuning trial 1/5
I0307 15:45:49.762013 140017811473600 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.1, learning_rate=0.001308209823469072, one_minus_beta1=0.02686663061, beta2=0.9981232922116359, weight_decay=0.16375311233774334, warmup_factor=0.1)
I0307 15:45:49.762719 140017811473600 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/ssim': 0.15631413459777832, 'train/loss': 1.027566909790039, 'validation/ssim': 0.15175362899857556, 'validation/loss': 1.031987230497327, 'validation/num_examples': 3554, 'test/ssim': 0.1734260020060301, 'test/loss': 1.0292505830468095, 'test/num_examples': 3581, 'score': 241.0947344303131, 'total_duration': 1136.7778730392456, 'accumulated_submission_time': 241.0947344303131, 'accumulated_eval_time': 895.6830060482025, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (252, {'train/ssim': 0.6824596949986049, 'train/loss': 0.32667074884687153, 'validation/ssim': 0.661116325794879, 'validation/loss': 0.3466710319798115, 'validation/num_examples': 3554, 'test/ssim': 0.6804064228960137, 'test/loss': 0.3474884672359327, 'test/num_examples': 3581, 'score': 322.56643986701965, 'total_duration': 1222.726845741272, 'accumulated_submission_time': 322.56643986701965, 'accumulated_eval_time': 900.1076054573059, 'accumulated_logging_time': 0.019253015518188477, 'global_step': 252, 'preemption_count': 0}), (303, {'train/ssim': 0.6891106878008161, 'train/loss': 0.32166337966918945, 'validation/ssim': 0.6683519285048537, 'validation/loss': 0.34097875660567317, 'validation/num_examples': 3554, 'test/ssim': 0.6873534883543354, 'test/loss': 0.34191308211960697, 'test/num_examples': 3581, 'score': 403.8335950374603, 'total_duration': 1307.8704257011414, 'accumulated_submission_time': 403.8335950374603, 'accumulated_eval_time': 903.9583404064178, 'accumulated_logging_time': 0.03814554214477539, 'global_step': 303, 'preemption_count': 0}), (352, {'train/ssim': 0.6930514744349888, 'train/loss': 0.31724568775721956, 'validation/ssim': 0.6725588547894977, 'validation/loss': 0.33634753809527995, 'validation/num_examples': 3554, 'test/ssim': 0.6915694649277436, 'test/loss': 0.33740718429296984, 'test/num_examples': 3581, 'score': 484.4311594963074, 'total_duration': 1392.3394198417664, 'accumulated_submission_time': 484.4311594963074, 'accumulated_eval_time': 907.8082180023193, 'accumulated_logging_time': 0.05657553672790527, 'global_step': 352, 'preemption_count': 0}), (404, {'train/ssim': 0.698786735534668, 'train/loss': 0.31248375347682406, 'validation/ssim': 0.6788832235685144, 'validation/loss': 0.3310140546413372, 'validation/num_examples': 3554, 'test/ssim': 0.6976247796530298, 'test/loss': 0.33231813739179, 'test/num_examples': 3581, 'score': 565.3365747928619, 'total_duration': 1477.1159796714783, 'accumulated_submission_time': 565.3365747928619, 'accumulated_eval_time': 911.6573510169983, 'accumulated_logging_time': 0.07451725006103516, 'global_step': 404, 'preemption_count': 0}), (457, {'train/ssim': 0.7037008830479213, 'train/loss': 0.3075072765350342, 'validation/ssim': 0.6837124542768711, 'validation/loss': 0.3258018858592431, 'validation/num_examples': 3554, 'test/ssim': 0.7022205002312553, 'test/loss': 0.32743321141528203, 'test/num_examples': 3581, 'score': 646.2761743068695, 'total_duration': 1561.9268465042114, 'accumulated_submission_time': 646.2761743068695, 'accumulated_eval_time': 915.5073075294495, 'accumulated_logging_time': 0.0921781063079834, 'global_step': 457, 'preemption_count': 0}), (512, {'train/ssim': 0.7072832243783134, 'train/loss': 0.30244033677237375, 'validation/ssim': 0.6879602538512943, 'validation/loss': 0.3199064118444886, 'validation/num_examples': 3554, 'test/ssim': 0.7060445291774294, 'test/loss': 0.3218570763556793, 'test/num_examples': 3581, 'score': 727.069085597992, 'total_duration': 1646.598001241684, 'accumulated_submission_time': 727.069085597992, 'accumulated_eval_time': 919.3660695552826, 'accumulated_logging_time': 0.10801315307617188, 'global_step': 512, 'preemption_count': 0}), (562, {'train/ssim': 0.7114772796630859, 'train/loss': 0.2988025801522391, 'validation/ssim': 0.6920695651027012, 'validation/loss': 0.3162645673778665, 'validation/num_examples': 3554, 'test/ssim': 0.7099136228968863, 'test/loss': 0.31837280580232474, 'test/num_examples': 3581, 'score': 807.2311472892761, 'total_duration': 1730.6303339004517, 'accumulated_submission_time': 807.2311472892761, 'accumulated_eval_time': 923.2121469974518, 'accumulated_logging_time': 0.12763428688049316, 'global_step': 562, 'preemption_count': 0}), (618, {'train/ssim': 0.7141968863351005, 'train/loss': 0.296349116734096, 'validation/ssim': 0.6947176734181556, 'validation/loss': 0.31376858326445556, 'validation/num_examples': 3554, 'test/ssim': 0.7124223876884949, 'test/loss': 0.3159117646737992, 'test/num_examples': 3581, 'score': 889.4219582080841, 'total_duration': 1816.7043459415436, 'accumulated_submission_time': 889.4219582080841, 'accumulated_eval_time': 927.0729203224182, 'accumulated_logging_time': 0.14618849754333496, 'global_step': 618, 'preemption_count': 0}), (668, {'train/ssim': 0.7138192994253976, 'train/loss': 0.29433018820626394, 'validation/ssim': 0.6955106152398706, 'validation/loss': 0.3112524716318761, 'validation/num_examples': 3554, 'test/ssim': 0.7131904659574839, 'test/loss': 0.3132420006959474, 'test/num_examples': 3581, 'score': 969.6401927471161, 'total_duration': 1900.8127989768982, 'accumulated_submission_time': 969.6401927471161, 'accumulated_eval_time': 930.934642791748, 'accumulated_logging_time': 0.17119622230529785, 'global_step': 668, 'preemption_count': 0}), (719, {'train/ssim': 0.7185471398489816, 'train/loss': 0.29185332570757183, 'validation/ssim': 0.6994941466701252, 'validation/loss': 0.30878925484489306, 'validation/num_examples': 3554, 'test/ssim': 0.716905684951829, 'test/loss': 0.3110395536446698, 'test/num_examples': 3581, 'score': 1050.3698177337646, 'total_duration': 1985.409487247467, 'accumulated_submission_time': 1050.3698177337646, 'accumulated_eval_time': 934.7805023193359, 'accumulated_logging_time': 0.1890866756439209, 'global_step': 719, 'preemption_count': 0}), (775, {'train/ssim': 0.716632774897984, 'train/loss': 0.2908531257084438, 'validation/ssim': 0.698937033426245, 'validation/loss': 0.3073879192569112, 'validation/num_examples': 3554, 'test/ssim': 0.716110063311575, 'test/loss': 0.30955967694079867, 'test/num_examples': 3581, 'score': 1134.0109100341797, 'total_duration': 2072.9288024902344, 'accumulated_submission_time': 1134.0109100341797, 'accumulated_eval_time': 938.6389541625977, 'accumulated_logging_time': 0.20478463172912598, 'global_step': 775, 'preemption_count': 0}), (823, {'train/ssim': 0.7164355686732701, 'train/loss': 0.2900559561593192, 'validation/ssim': 0.6990382205789252, 'validation/loss': 0.30641867273230866, 'validation/num_examples': 3554, 'test/ssim': 0.7161620139276739, 'test/loss': 0.3085851597406451, 'test/num_examples': 3581, 'score': 1214.9399585723877, 'total_duration': 2157.734365463257, 'accumulated_submission_time': 1214.9399585723877, 'accumulated_eval_time': 942.4965958595276, 'accumulated_logging_time': 0.2205970287322998, 'global_step': 823, 'preemption_count': 0}), (873, {'train/ssim': 0.7183583123343331, 'train/loss': 0.28862619400024414, 'validation/ssim': 0.701410382667417, 'validation/loss': 0.30482619440683034, 'validation/num_examples': 3554, 'test/ssim': 0.7180933905726403, 'test/loss': 0.3070022340128456, 'test/num_examples': 3581, 'score': 1295.2676992416382, 'total_duration': 2241.946810245514, 'accumulated_submission_time': 1295.2676992416382, 'accumulated_eval_time': 946.353401184082, 'accumulated_logging_time': 0.24514532089233398, 'global_step': 873, 'preemption_count': 0}), (926, {'train/ssim': 0.7235200745718819, 'train/loss': 0.28734118597848074, 'validation/ssim': 0.7038881970578925, 'validation/loss': 0.304720576452149, 'validation/num_examples': 3554, 'test/ssim': 0.7212991935519059, 'test/loss': 0.30668691695319045, 'test/num_examples': 3581, 'score': 1376.0038604736328, 'total_duration': 2326.562655687332, 'accumulated_submission_time': 1376.0038604736328, 'accumulated_eval_time': 950.2133169174194, 'accumulated_logging_time': 0.26180005073547363, 'global_step': 926, 'preemption_count': 0}), (1042, {'train/ssim': 0.725696155003139, 'train/loss': 0.2843394620077951, 'validation/ssim': 0.7071456265167769, 'validation/loss': 0.3007530165174803, 'validation/num_examples': 3554, 'test/ssim': 0.7241781576157149, 'test/loss': 0.30282719752469633, 'test/num_examples': 3581, 'score': 1458.3184332847595, 'total_duration': 2412.7856657505035, 'accumulated_submission_time': 1458.3184332847595, 'accumulated_eval_time': 954.0848453044891, 'accumulated_logging_time': 0.29042959213256836, 'global_step': 1042, 'preemption_count': 0}), (1982, {'train/ssim': 0.7349472727094378, 'train/loss': 0.2761965308870588, 'validation/ssim': 0.7150995000131893, 'validation/loss': 0.293218729666397, 'validation/num_examples': 3554, 'test/ssim': 0.7322275033379293, 'test/loss': 0.29498282493542305, 'test/num_examples': 3581, 'score': 1538.2924783229828, 'total_duration': 2496.698174715042, 'accumulated_submission_time': 1538.2924783229828, 'accumulated_eval_time': 957.9598708152771, 'accumulated_logging_time': 0.30618810653686523, 'global_step': 1982, 'preemption_count': 0}), (2955, {'train/ssim': 0.7373081615992955, 'train/loss': 0.27441724709102083, 'validation/ssim': 0.7172609757491559, 'validation/loss': 0.29147340584552617, 'validation/num_examples': 3554, 'test/ssim': 0.7344780149355976, 'test/loss': 0.2930905476058538, 'test/num_examples': 3581, 'score': 1618.2834293842316, 'total_duration': 2580.621167898178, 'accumulated_submission_time': 1618.2834293842316, 'accumulated_eval_time': 961.8264293670654, 'accumulated_logging_time': 0.3223912715911865, 'global_step': 2955, 'preemption_count': 0}), (3927, {'train/ssim': 0.7388435091291156, 'train/loss': 0.2733594519751413, 'validation/ssim': 0.7190192141557048, 'validation/loss': 0.29029529337542204, 'validation/num_examples': 3554, 'test/ssim': 0.7362152244484781, 'test/loss': 0.29186718559105346, 'test/num_examples': 3581, 'score': 1698.2229347229004, 'total_duration': 2664.502574443817, 'accumulated_submission_time': 1698.2229347229004, 'accumulated_eval_time': 965.6998391151428, 'accumulated_logging_time': 0.3419156074523926, 'global_step': 3927, 'preemption_count': 0}), (4899, {'train/ssim': 0.7415082114083427, 'train/loss': 0.27171710559300016, 'validation/ssim': 0.7210889138998312, 'validation/loss': 0.2891617637037493, 'validation/num_examples': 3554, 'test/ssim': 0.7383559716210556, 'test/loss': 0.2905632387623045, 'test/num_examples': 3581, 'score': 1778.1732008457184, 'total_duration': 2748.3937017917633, 'accumulated_submission_time': 1778.1732008457184, 'accumulated_eval_time': 969.5746285915375, 'accumulated_logging_time': 0.3599400520324707, 'global_step': 4899, 'preemption_count': 0}), (5837, {'train/ssim': 0.7414670671735492, 'train/loss': 0.2705653054373605, 'validation/ssim': 0.72135730372028, 'validation/loss': 0.28777720677295826, 'validation/num_examples': 3554, 'test/ssim': 0.738615111111596, 'test/loss': 0.2892613031450712, 'test/num_examples': 3581, 'score': 1858.1797263622284, 'total_duration': 2832.343307495117, 'accumulated_submission_time': 1858.1797263622284, 'accumulated_eval_time': 973.4496645927429, 'accumulated_logging_time': 0.377671480178833, 'global_step': 5837, 'preemption_count': 0}), (6810, {'train/ssim': 0.7429915836879185, 'train/loss': 0.2699623107910156, 'validation/ssim': 0.7224011869328574, 'validation/loss': 0.2875267118970262, 'validation/num_examples': 3554, 'test/ssim': 0.7396861664645001, 'test/loss': 0.2889128522279042, 'test/num_examples': 3581, 'score': 1938.163536787033, 'total_duration': 2916.2662041187286, 'accumulated_submission_time': 1938.163536787033, 'accumulated_eval_time': 977.3220953941345, 'accumulated_logging_time': 0.3955190181732178, 'global_step': 6810, 'preemption_count': 0}), (7782, {'train/ssim': 0.7444451877049038, 'train/loss': 0.2689971923828125, 'validation/ssim': 0.7236962176201112, 'validation/loss': 0.28680421639240117, 'validation/num_examples': 3554, 'test/ssim': 0.7409289588278414, 'test/loss': 0.2881618863009634, 'test/num_examples': 3581, 'score': 2018.1146247386932, 'total_duration': 3000.1543922424316, 'accumulated_submission_time': 2018.1146247386932, 'accumulated_eval_time': 981.1904897689819, 'accumulated_logging_time': 0.41617751121520996, 'global_step': 7782, 'preemption_count': 0})], 'global_step': 7782}
I0307 15:45:49.762827 140017811473600 submission_runner.py:649] Timing: 2018.1146247386932
I0307 15:45:49.762866 140017811473600 submission_runner.py:651] Total number of evals: 23
I0307 15:45:49.762912 140017811473600 submission_runner.py:652] ====================
I0307 15:45:49.763028 140017811473600 submission_runner.py:750] Final fastmri score: 0
