python submission_runner.py --framework=jax --workload=criteo1tb --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_0 --overwrite=True --save_checkpoints=False --rng_seed=-1027006238 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=4 --hparam_end_index=5 2>&1 | tee -a /logs/criteo1tb_jax_03-06-2025-12-53-31.log
2025-03-06 12:53:32.171385: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741265612.193653       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741265612.200579       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0306 12:53:37.863668 140297328059584 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax.
I0306 12:53:38.740449 140297328059584 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0306 12:53:38.744114 140297328059584 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0306 12:53:38.745850 140297328059584 submission_runner.py:606] Using RNG seed -1027006238
I0306 12:53:39.340213 140297328059584 submission_runner.py:615] --- Tuning run 5/5 ---
I0306 12:53:39.340428 140297328059584 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax/trial_5.
I0306 12:53:39.340643 140297328059584 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax/trial_5/hparams.json.
I0306 12:53:39.579543 140297328059584 submission_runner.py:218] Initializing dataset.
I0306 12:53:39.579728 140297328059584 submission_runner.py:229] Initializing model.
I0306 12:53:47.466524 140297328059584 submission_runner.py:272] Initializing optimizer.
I0306 12:53:47.937646 140297328059584 submission_runner.py:279] Initializing metrics bundle.
I0306 12:53:47.937855 140297328059584 submission_runner.py:301] Initializing checkpoint and logger.
I0306 12:53:47.938482 140297328059584 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax/trial_5 with prefix checkpoint_
I0306 12:53:47.938576 140297328059584 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax/trial_5/meta_data_0.json.
I0306 12:53:47.938720 140297328059584 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0306 12:53:47.938764 140297328059584 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0306 12:53:48.120061 140297328059584 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax/trial_5/flags_0.json.
I0306 12:53:48.425271 140297328059584 submission_runner.py:337] Starting training loop.
I0306 12:54:01.438404 140156469233408 logging_writer.py:48] [0] global_step=0, grad_norm=9.503229141235352, loss=1.0084214210510254
I0306 12:54:01.477302 140297328059584 spec.py:321] Evaluating on the training split.
I0306 13:00:06.901716 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 13:05:34.134803 140297328059584 spec.py:349] Evaluating on the test split.
I0306 13:12:19.688089 140297328059584 submission_runner.py:469] Time since start: 1111.26s, 	Step: 1, 	{'train/loss': 1.0055958090713188, 'validation/loss': 1.0030629643235491, 'validation/num_examples': 83274637, 'test/loss': 1.0034042074835525, 'test/num_examples': 95000000, 'score': 13.051947832107544, 'total_duration': 1111.2627458572388, 'accumulated_submission_time': 13.051947832107544, 'accumulated_eval_time': 1098.2107038497925, 'accumulated_logging_time': 0}
I0306 13:12:19.695127 140144430536448 logging_writer.py:48] [1] accumulated_eval_time=1098.21, accumulated_logging_time=0, accumulated_submission_time=13.0519, global_step=1, preemption_count=0, score=13.0519, test/loss=1.0034, test/num_examples=95000000, total_duration=1111.26, train/loss=1.0056, validation/loss=1.00306, validation/num_examples=83274637
I0306 13:13:40.586245 140144422143744 logging_writer.py:48] [100] global_step=100, grad_norm=0.08001268655061722, loss=0.1305927038192749
I0306 13:14:20.674769 140297328059584 spec.py:321] Evaluating on the training split.
I0306 13:19:59.289497 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 13:24:34.230471 140297328059584 spec.py:349] Evaluating on the test split.
I0306 13:30:32.192441 140297328059584 submission_runner.py:469] Time since start: 2203.77s, 	Step: 139, 	{'train/loss': 0.12803163627783457, 'validation/loss': 0.12891191217568743, 'validation/num_examples': 83274637, 'test/loss': 0.13162581283922697, 'test/num_examples': 95000000, 'score': 134.01795959472656, 'total_duration': 2203.7670936584473, 'accumulated_submission_time': 134.01795959472656, 'accumulated_eval_time': 2069.7283041477203, 'accumulated_logging_time': 0.013879537582397461}
I0306 13:30:32.200142 140144430536448 logging_writer.py:48] [139] accumulated_eval_time=2069.73, accumulated_logging_time=0.0138795, accumulated_submission_time=134.018, global_step=139, preemption_count=0, score=134.018, test/loss=0.131626, test/num_examples=95000000, total_duration=2203.77, train/loss=0.128032, validation/loss=0.128912, validation/num_examples=83274637
I0306 13:31:12.115428 140144422143744 logging_writer.py:48] [200] global_step=200, grad_norm=0.03987306356430054, loss=0.13006767630577087
I0306 13:32:32.958445 140297328059584 spec.py:321] Evaluating on the training split.
I0306 13:38:04.299394 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 13:42:49.688336 140297328059584 spec.py:349] Evaluating on the test split.
I0306 13:48:17.492874 140297328059584 submission_runner.py:469] Time since start: 3269.07s, 	Step: 276, 	{'train/loss': 0.1275811255587347, 'validation/loss': 0.12935901662764077, 'validation/num_examples': 83274637, 'test/loss': 0.13162962199835526, 'test/num_examples': 95000000, 'score': 254.76304364204407, 'total_duration': 3269.067539215088, 'accumulated_submission_time': 254.76304364204407, 'accumulated_eval_time': 3014.262671470642, 'accumulated_logging_time': 0.027640819549560547}
I0306 13:48:17.500556 140144430536448 logging_writer.py:48] [276] accumulated_eval_time=3014.26, accumulated_logging_time=0.0276408, accumulated_submission_time=254.763, global_step=276, preemption_count=0, score=254.763, test/loss=0.13163, test/num_examples=95000000, total_duration=3269.07, train/loss=0.127581, validation/loss=0.129359, validation/num_examples=83274637
I0306 13:48:20.113169 140144422143744 logging_writer.py:48] [300] global_step=300, grad_norm=0.024059783667325974, loss=0.13172847032546997
I0306 13:50:13.452255 140144430536448 logging_writer.py:48] [400] global_step=400, grad_norm=0.01766079291701317, loss=0.11922309547662735
I0306 13:50:18.322922 140297328059584 spec.py:321] Evaluating on the training split.
I0306 13:55:43.927669 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 14:00:09.488110 140297328059584 spec.py:349] Evaluating on the test split.
I0306 14:05:33.560681 140297328059584 submission_runner.py:469] Time since start: 4305.14s, 	Step: 405, 	{'train/loss': 0.12374780371597728, 'validation/loss': 0.12716473249818286, 'validation/num_examples': 83274637, 'test/loss': 0.1297860095703125, 'test/num_examples': 95000000, 'score': 375.5727803707123, 'total_duration': 4305.135348320007, 'accumulated_submission_time': 375.5727803707123, 'accumulated_eval_time': 3929.5003674030304, 'accumulated_logging_time': 0.04150056838989258}
I0306 14:05:33.568380 140144422143744 logging_writer.py:48] [405] accumulated_eval_time=3929.5, accumulated_logging_time=0.0415006, accumulated_submission_time=375.573, global_step=405, preemption_count=0, score=375.573, test/loss=0.129786, test/num_examples=95000000, total_duration=4305.14, train/loss=0.123748, validation/loss=0.127165, validation/num_examples=83274637
I0306 14:06:51.208258 140144430536448 logging_writer.py:48] [500] global_step=500, grad_norm=0.02321632206439972, loss=0.12168020755052567
I0306 14:07:33.724581 140297328059584 spec.py:321] Evaluating on the training split.
I0306 14:12:58.644016 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 14:17:20.448418 140297328059584 spec.py:349] Evaluating on the test split.
I0306 14:22:44.383847 140297328059584 submission_runner.py:469] Time since start: 5335.96s, 	Step: 540, 	{'train/loss': 0.12625863175815757, 'validation/loss': 0.12730725447423558, 'validation/num_examples': 83274637, 'test/loss': 0.12997460725740131, 'test/num_examples': 95000000, 'score': 495.7154083251953, 'total_duration': 5335.958525419235, 'accumulated_submission_time': 495.7154083251953, 'accumulated_eval_time': 4840.159585475922, 'accumulated_logging_time': 0.055899858474731445}
I0306 14:22:44.390925 140144422143744 logging_writer.py:48] [540] accumulated_eval_time=4840.16, accumulated_logging_time=0.0558999, accumulated_submission_time=495.715, global_step=540, preemption_count=0, score=495.715, test/loss=0.129975, test/num_examples=95000000, total_duration=5335.96, train/loss=0.126259, validation/loss=0.127307, validation/num_examples=83274637
I0306 14:23:21.878954 140144430536448 logging_writer.py:48] [600] global_step=600, grad_norm=0.0374811515212059, loss=0.1301966905593872
I0306 14:24:44.931937 140297328059584 spec.py:321] Evaluating on the training split.
I0306 14:29:35.761750 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 14:33:45.292712 140297328059584 spec.py:349] Evaluating on the test split.
I0306 14:38:47.777747 140297328059584 submission_runner.py:469] Time since start: 6299.35s, 	Step: 681, 	{'train/loss': 0.1273639723072824, 'validation/loss': 0.12647893015817424, 'validation/num_examples': 83274637, 'test/loss': 0.12910336900699013, 'test/num_examples': 95000000, 'score': 616.2423434257507, 'total_duration': 6299.352402448654, 'accumulated_submission_time': 616.2423434257507, 'accumulated_eval_time': 5683.00533747673, 'accumulated_logging_time': 0.06948733329772949}
I0306 14:38:47.785848 140144422143744 logging_writer.py:48] [681] accumulated_eval_time=5683.01, accumulated_logging_time=0.0694873, accumulated_submission_time=616.242, global_step=681, preemption_count=0, score=616.242, test/loss=0.129103, test/num_examples=95000000, total_duration=6299.35, train/loss=0.127364, validation/loss=0.126479, validation/num_examples=83274637
I0306 14:38:49.854169 140144430536448 logging_writer.py:48] [700] global_step=700, grad_norm=0.04937757924199104, loss=0.13276782631874084
I0306 14:40:26.038410 140144422143744 logging_writer.py:48] [800] global_step=800, grad_norm=0.07451967895030975, loss=0.13261020183563232
I0306 14:40:48.426982 140297328059584 spec.py:321] Evaluating on the training split.
I0306 14:45:45.502010 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 14:49:35.807674 140297328059584 spec.py:349] Evaluating on the test split.
I0306 14:54:38.654462 140297328059584 submission_runner.py:469] Time since start: 7250.23s, 	Step: 822, 	{'train/loss': 0.12710321955851414, 'validation/loss': 0.12663667134811218, 'validation/num_examples': 83274637, 'test/loss': 0.12907645984786184, 'test/num_examples': 95000000, 'score': 736.8691575527191, 'total_duration': 7250.229130029678, 'accumulated_submission_time': 736.8691575527191, 'accumulated_eval_time': 6513.232754945755, 'accumulated_logging_time': 0.08390951156616211}
I0306 14:54:38.661629 140144430536448 logging_writer.py:48] [822] accumulated_eval_time=6513.23, accumulated_logging_time=0.0839095, accumulated_submission_time=736.869, global_step=822, preemption_count=0, score=736.869, test/loss=0.129076, test/num_examples=95000000, total_duration=7250.23, train/loss=0.127103, validation/loss=0.126637, validation/num_examples=83274637
I0306 14:55:37.580398 140144422143744 logging_writer.py:48] [900] global_step=900, grad_norm=0.1900666207075119, loss=0.13447536528110504
I0306 14:56:38.753803 140297328059584 spec.py:321] Evaluating on the training split.
I0306 15:01:05.732820 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 15:04:40.560502 140297328059584 spec.py:349] Evaluating on the test split.
I0306 15:09:08.821099 140297328059584 submission_runner.py:469] Time since start: 8120.40s, 	Step: 960, 	{'train/loss': 0.12728949473385917, 'validation/loss': 0.12647431275353382, 'validation/num_examples': 83274637, 'test/loss': 0.12873525131578947, 'test/num_examples': 95000000, 'score': 856.9480307102203, 'total_duration': 8120.395741939545, 'accumulated_submission_time': 856.9480307102203, 'accumulated_eval_time': 7263.2999629974365, 'accumulated_logging_time': 0.09714913368225098}
I0306 15:09:08.850341 140144430536448 logging_writer.py:48] [960] accumulated_eval_time=7263.3, accumulated_logging_time=0.0971491, accumulated_submission_time=856.948, global_step=960, preemption_count=0, score=856.948, test/loss=0.128735, test/num_examples=95000000, total_duration=8120.4, train/loss=0.127289, validation/loss=0.126474, validation/num_examples=83274637
I0306 15:09:25.721762 140144422143744 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.03328116238117218, loss=0.12558811902999878
I0306 15:11:08.347646 140144430536448 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.018059315159916878, loss=0.12228544056415558
I0306 15:11:09.322880 140297328059584 spec.py:321] Evaluating on the training split.
I0306 15:14:28.143848 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 15:17:03.972501 140297328059584 spec.py:349] Evaluating on the test split.
I0306 15:20:53.005481 140297328059584 submission_runner.py:469] Time since start: 8824.58s, 	Step: 1102, 	{'train/loss': 0.12269578105623617, 'validation/loss': 0.1260379391489797, 'validation/num_examples': 83274637, 'test/loss': 0.1282419902549342, 'test/num_examples': 95000000, 'score': 977.4055080413818, 'total_duration': 8824.580132484436, 'accumulated_submission_time': 977.4055080413818, 'accumulated_eval_time': 7846.9824895858765, 'accumulated_logging_time': 0.13350343704223633}
I0306 15:20:53.013076 140144422143744 logging_writer.py:48] [1102] accumulated_eval_time=7846.98, accumulated_logging_time=0.133503, accumulated_submission_time=977.406, global_step=1102, preemption_count=0, score=977.406, test/loss=0.128242, test/num_examples=95000000, total_duration=8824.58, train/loss=0.122696, validation/loss=0.126038, validation/num_examples=83274637
I0306 15:22:10.020251 140144430536448 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.019678296521306038, loss=0.12418957054615021
I0306 15:22:53.825317 140297328059584 spec.py:321] Evaluating on the training split.
I0306 15:23:54.994722 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 15:24:38.929527 140297328059584 spec.py:349] Evaluating on the test split.
I0306 15:27:08.621131 140297328059584 submission_runner.py:469] Time since start: 9200.20s, 	Step: 1243, 	{'train/loss': 0.1253976691631401, 'validation/loss': 0.12603911894481976, 'validation/num_examples': 83274637, 'test/loss': 0.12829449104646382, 'test/num_examples': 95000000, 'score': 1098.2026779651642, 'total_duration': 9200.195816755295, 'accumulated_submission_time': 1098.2026779651642, 'accumulated_eval_time': 8101.77826333046, 'accumulated_logging_time': 0.14707422256469727}
I0306 15:27:08.656970 140144422143744 logging_writer.py:48] [1243] accumulated_eval_time=8101.78, accumulated_logging_time=0.147074, accumulated_submission_time=1098.2, global_step=1243, preemption_count=0, score=1098.2, test/loss=0.128294, test/num_examples=95000000, total_duration=9200.2, train/loss=0.125398, validation/loss=0.126039, validation/num_examples=83274637
I0306 15:27:47.954071 140144430536448 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.025140833109617233, loss=0.12077262252569199
I0306 15:29:09.469769 140297328059584 spec.py:321] Evaluating on the training split.
I0306 15:30:10.792140 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 15:30:18.223415 140297328059584 spec.py:349] Evaluating on the test split.
I0306 15:33:12.114998 140297328059584 submission_runner.py:469] Time since start: 9563.69s, 	Step: 1374, 	{'train/loss': 0.12363157937970926, 'validation/loss': 0.12601557431023386, 'validation/num_examples': 83274637, 'test/loss': 0.1284143660053454, 'test/num_examples': 95000000, 'score': 1218.990701675415, 'total_duration': 9563.689676761627, 'accumulated_submission_time': 1218.990701675415, 'accumulated_eval_time': 8344.423448324203, 'accumulated_logging_time': 0.19753289222717285}
I0306 15:33:12.123003 140144422143744 logging_writer.py:48] [1374] accumulated_eval_time=8344.42, accumulated_logging_time=0.197533, accumulated_submission_time=1218.99, global_step=1374, preemption_count=0, score=1218.99, test/loss=0.128414, test/num_examples=95000000, total_duration=9563.69, train/loss=0.123632, validation/loss=0.126016, validation/num_examples=83274637
I0306 15:33:14.912178 140144430536448 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.03550399839878082, loss=0.12678039073944092
I0306 15:35:07.075408 140144422143744 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.02057374082505703, loss=0.12098991125822067
I0306 15:35:13.026973 140297328059584 spec.py:321] Evaluating on the training split.
I0306 15:36:16.953035 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 15:36:24.407212 140297328059584 spec.py:349] Evaluating on the test split.
I0306 15:39:12.088917 140297328059584 submission_runner.py:469] Time since start: 9923.66s, 	Step: 1506, 	{'train/loss': 0.12349414165899064, 'validation/loss': 0.1257275935923342, 'validation/num_examples': 83274637, 'test/loss': 0.12809038467310854, 'test/num_examples': 95000000, 'score': 1339.879158258438, 'total_duration': 9923.663565158844, 'accumulated_submission_time': 1339.879158258438, 'accumulated_eval_time': 8583.485314846039, 'accumulated_logging_time': 0.2114725112915039}
I0306 15:39:12.098320 140144430536448 logging_writer.py:48] [1506] accumulated_eval_time=8583.49, accumulated_logging_time=0.211473, accumulated_submission_time=1339.88, global_step=1506, preemption_count=0, score=1339.88, test/loss=0.12809, test/num_examples=95000000, total_duration=9923.66, train/loss=0.123494, validation/loss=0.125728, validation/num_examples=83274637
I0306 15:40:29.317698 140144422143744 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.0520617850124836, loss=0.12919701635837555
I0306 15:41:12.569930 140297328059584 spec.py:321] Evaluating on the training split.
I0306 15:42:16.689953 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 15:42:24.096710 140297328059584 spec.py:349] Evaluating on the test split.
I0306 15:45:10.594867 140297328059584 submission_runner.py:469] Time since start: 10282.17s, 	Step: 1641, 	{'train/loss': 0.12387009458206359, 'validation/loss': 0.12618281930360778, 'validation/num_examples': 83274637, 'test/loss': 0.12891717883429277, 'test/num_examples': 95000000, 'score': 1460.3339281082153, 'total_duration': 10282.169552326202, 'accumulated_submission_time': 1460.3339281082153, 'accumulated_eval_time': 8821.510222911835, 'accumulated_logging_time': 0.22738981246948242}
I0306 15:45:10.602390 140144430536448 logging_writer.py:48] [1641] accumulated_eval_time=8821.51, accumulated_logging_time=0.22739, accumulated_submission_time=1460.33, global_step=1641, preemption_count=0, score=1460.33, test/loss=0.128917, test/num_examples=95000000, total_duration=10282.2, train/loss=0.12387, validation/loss=0.126183, validation/num_examples=83274637
I0306 15:45:50.068943 140144422143744 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.0063600679859519005, loss=0.12022954970598221
I0306 15:47:11.595553 140297328059584 spec.py:321] Evaluating on the training split.
I0306 15:48:20.910112 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 15:48:28.411273 140297328059584 spec.py:349] Evaluating on the test split.
I0306 15:51:08.241432 140297328059584 submission_runner.py:469] Time since start: 10639.82s, 	Step: 1774, 	{'train/loss': 0.12651645252773971, 'validation/loss': 0.12577666707159627, 'validation/num_examples': 83274637, 'test/loss': 0.12824076222245065, 'test/num_examples': 95000000, 'score': 1581.3100872039795, 'total_duration': 10639.816109895706, 'accumulated_submission_time': 1581.3100872039795, 'accumulated_eval_time': 9058.156069040298, 'accumulated_logging_time': 0.24125337600708008}
I0306 15:51:08.249562 140144430536448 logging_writer.py:48] [1774] accumulated_eval_time=9058.16, accumulated_logging_time=0.241253, accumulated_submission_time=1581.31, global_step=1774, preemption_count=0, score=1581.31, test/loss=0.128241, test/num_examples=95000000, total_duration=10639.8, train/loss=0.126516, validation/loss=0.125777, validation/num_examples=83274637
I0306 15:51:11.064175 140144422143744 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.02580852061510086, loss=0.12346887588500977
I0306 15:53:02.470855 140144430536448 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.013676786795258522, loss=0.12407243251800537
I0306 15:53:10.050560 140297328059584 spec.py:321] Evaluating on the training split.
I0306 15:54:21.442414 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 15:54:28.929228 140297328059584 spec.py:349] Evaluating on the test split.
I0306 15:57:06.474126 140297328059584 submission_runner.py:469] Time since start: 10998.05s, 	Step: 1907, 	{'train/loss': 0.12487933698034137, 'validation/loss': 0.12573163068588528, 'validation/num_examples': 83274637, 'test/loss': 0.12817673513569078, 'test/num_examples': 95000000, 'score': 1703.0959944725037, 'total_duration': 10998.04880785942, 'accumulated_submission_time': 1703.0959944725037, 'accumulated_eval_time': 9294.579595088959, 'accumulated_logging_time': 0.2551994323730469}
I0306 15:57:06.481879 140144422143744 logging_writer.py:48] [1907] accumulated_eval_time=9294.58, accumulated_logging_time=0.255199, accumulated_submission_time=1703.1, global_step=1907, preemption_count=0, score=1703.1, test/loss=0.128177, test/num_examples=95000000, total_duration=10998, train/loss=0.124879, validation/loss=0.125732, validation/num_examples=83274637
I0306 15:58:23.691802 140144430536448 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.016732245683670044, loss=0.13268154859542847
I0306 15:59:08.083665 140297328059584 spec.py:321] Evaluating on the training split.
I0306 16:00:27.009896 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 16:00:34.465731 140297328059584 spec.py:349] Evaluating on the test split.
I0306 16:03:02.787474 140297328059584 submission_runner.py:469] Time since start: 11354.36s, 	Step: 2041, 	{'train/loss': 0.12563810210510995, 'validation/loss': 0.12541683363247316, 'validation/num_examples': 83274637, 'test/loss': 0.1278120154296875, 'test/num_examples': 95000000, 'score': 1824.6810491085052, 'total_duration': 11354.362147808075, 'accumulated_submission_time': 1824.6810491085052, 'accumulated_eval_time': 9529.283356666565, 'accumulated_logging_time': 0.26982927322387695}
I0306 16:03:02.795662 140144422143744 logging_writer.py:48] [2041] accumulated_eval_time=9529.28, accumulated_logging_time=0.269829, accumulated_submission_time=1824.68, global_step=2041, preemption_count=0, score=1824.68, test/loss=0.127812, test/num_examples=95000000, total_duration=11354.4, train/loss=0.125638, validation/loss=0.125417, validation/num_examples=83274637
I0306 16:03:42.882458 140144430536448 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.029879508540034294, loss=0.12056994438171387
I0306 16:05:03.770261 140297328059584 spec.py:321] Evaluating on the training split.
I0306 16:06:30.115205 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 16:06:37.600089 140297328059584 spec.py:349] Evaluating on the test split.
I0306 16:09:02.726220 140297328059584 submission_runner.py:469] Time since start: 11714.30s, 	Step: 2170, 	{'train/loss': 0.12292043451196367, 'validation/loss': 0.12521289812599432, 'validation/num_examples': 83274637, 'test/loss': 0.1274491687294408, 'test/num_examples': 95000000, 'score': 1945.6395905017853, 'total_duration': 11714.30089354515, 'accumulated_submission_time': 1945.6395905017853, 'accumulated_eval_time': 9768.23926615715, 'accumulated_logging_time': 0.2843194007873535}
I0306 16:09:02.733936 140144422143744 logging_writer.py:48] [2170] accumulated_eval_time=9768.24, accumulated_logging_time=0.284319, accumulated_submission_time=1945.64, global_step=2170, preemption_count=0, score=1945.64, test/loss=0.127449, test/num_examples=95000000, total_duration=11714.3, train/loss=0.12292, validation/loss=0.125213, validation/num_examples=83274637
I0306 16:09:09.253910 140144430536448 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.008554689586162567, loss=0.12473805993795395
I0306 16:11:00.985802 140144422143744 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.004583918955177069, loss=0.11733125150203705
I0306 16:11:03.112317 140297328059584 spec.py:321] Evaluating on the training split.
I0306 16:12:32.257167 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 16:12:39.808764 140297328059584 spec.py:349] Evaluating on the test split.
I0306 16:15:02.361854 140297328059584 submission_runner.py:469] Time since start: 12073.94s, 	Step: 2303, 	{'train/loss': 0.12465287460330522, 'validation/loss': 0.12484877368596335, 'validation/num_examples': 83274637, 'test/loss': 0.12713976009457237, 'test/num_examples': 95000000, 'score': 2066.001902103424, 'total_duration': 12073.936526298523, 'accumulated_submission_time': 2066.001902103424, 'accumulated_eval_time': 10007.488744974136, 'accumulated_logging_time': 0.2986934185028076}
I0306 16:15:02.369707 140144430536448 logging_writer.py:48] [2303] accumulated_eval_time=10007.5, accumulated_logging_time=0.298693, accumulated_submission_time=2066, global_step=2303, preemption_count=0, score=2066, test/loss=0.12714, test/num_examples=95000000, total_duration=12073.9, train/loss=0.124653, validation/loss=0.124849, validation/num_examples=83274637
I0306 16:16:23.632145 140144422143744 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.05528237670660019, loss=0.12805543839931488
I0306 16:17:03.020653 140297328059584 spec.py:321] Evaluating on the training split.
I0306 16:18:49.095472 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 16:18:56.413657 140297328059584 spec.py:349] Evaluating on the test split.
I0306 16:21:01.901991 140297328059584 submission_runner.py:469] Time since start: 12433.48s, 	Step: 2434, 	{'train/loss': 0.1222647784875249, 'validation/loss': 0.12522222898535046, 'validation/num_examples': 83274637, 'test/loss': 0.12770247141241775, 'test/num_examples': 95000000, 'score': 2186.6371216773987, 'total_duration': 12433.476676940918, 'accumulated_submission_time': 2186.6371216773987, 'accumulated_eval_time': 10246.370046138763, 'accumulated_logging_time': 0.3126239776611328}
I0306 16:21:01.910033 140144430536448 logging_writer.py:48] [2434] accumulated_eval_time=10246.4, accumulated_logging_time=0.312624, accumulated_submission_time=2186.64, global_step=2434, preemption_count=0, score=2186.64, test/loss=0.127702, test/num_examples=95000000, total_duration=12433.5, train/loss=0.122265, validation/loss=0.125222, validation/num_examples=83274637
I0306 16:21:50.365209 140144422143744 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.005381064489483833, loss=0.11507052183151245
I0306 16:23:02.445648 140297328059584 spec.py:321] Evaluating on the training split.
I0306 16:25:02.766559 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 16:25:10.085919 140297328059584 spec.py:349] Evaluating on the test split.
I0306 16:26:57.258794 140297328059584 submission_runner.py:469] Time since start: 12788.83s, 	Step: 2565, 	{'train/loss': 0.12399247347277666, 'validation/loss': 0.1251539743394686, 'validation/num_examples': 83274637, 'test/loss': 0.12740302118626645, 'test/num_examples': 95000000, 'score': 2307.1562666893005, 'total_duration': 12788.833476781845, 'accumulated_submission_time': 2307.1562666893005, 'accumulated_eval_time': 10481.183246850967, 'accumulated_logging_time': 0.32639360427856445}
I0306 16:26:57.266724 140144430536448 logging_writer.py:48] [2565] accumulated_eval_time=10481.2, accumulated_logging_time=0.326394, accumulated_submission_time=2307.16, global_step=2565, preemption_count=0, score=2307.16, test/loss=0.127403, test/num_examples=95000000, total_duration=12788.8, train/loss=0.123992, validation/loss=0.125154, validation/num_examples=83274637
I0306 16:27:10.760053 140144422143744 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.010172894224524498, loss=0.12474065274000168
I0306 16:28:58.043462 140297328059584 spec.py:321] Evaluating on the training split.
I0306 16:31:13.567272 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 16:31:21.034803 140297328059584 spec.py:349] Evaluating on the test split.
I0306 16:32:55.582528 140297328059584 submission_runner.py:469] Time since start: 13147.16s, 	Step: 2694, 	{'train/loss': 0.12208010538615896, 'validation/loss': 0.12483705051656928, 'validation/num_examples': 83274637, 'test/loss': 0.1273063630653783, 'test/num_examples': 95000000, 'score': 2427.916276693344, 'total_duration': 13147.157210111618, 'accumulated_submission_time': 2427.916276693344, 'accumulated_eval_time': 10718.722277641296, 'accumulated_logging_time': 0.34047412872314453}
I0306 16:32:55.645167 140144430536448 logging_writer.py:48] [2694] accumulated_eval_time=10718.7, accumulated_logging_time=0.340474, accumulated_submission_time=2427.92, global_step=2694, preemption_count=0, score=2427.92, test/loss=0.127306, test/num_examples=95000000, total_duration=13147.2, train/loss=0.12208, validation/loss=0.124837, validation/num_examples=83274637
I0306 16:32:56.400624 140144422143744 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.0061461846344172955, loss=0.11998002231121063
I0306 16:34:26.746767 140144430536448 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.0062197474762797356, loss=0.13514789938926697
I0306 16:34:55.589941 140297328059584 spec.py:321] Evaluating on the training split.
I0306 16:37:27.822252 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 16:37:35.244115 140297328059584 spec.py:349] Evaluating on the test split.
I0306 16:38:54.120022 140297328059584 submission_runner.py:469] Time since start: 13505.69s, 	Step: 2827, 	{'train/loss': 0.12306471069419533, 'validation/loss': 0.12489181123800261, 'validation/num_examples': 83274637, 'test/loss': 0.12722484136513157, 'test/num_examples': 95000000, 'score': 2547.844516515732, 'total_duration': 13505.694687366486, 'accumulated_submission_time': 2547.844516515732, 'accumulated_eval_time': 10957.252294063568, 'accumulated_logging_time': 0.40915536880493164}
I0306 16:38:54.129271 140144422143744 logging_writer.py:48] [2827] accumulated_eval_time=10957.3, accumulated_logging_time=0.409155, accumulated_submission_time=2547.84, global_step=2827, preemption_count=0, score=2547.84, test/loss=0.127225, test/num_examples=95000000, total_duration=13505.7, train/loss=0.123065, validation/loss=0.124892, validation/num_examples=83274637
I0306 16:39:46.690475 140144430536448 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.007497300859540701, loss=0.1350017488002777
I0306 16:40:55.050713 140297328059584 spec.py:321] Evaluating on the training split.
I0306 16:43:40.829138 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 16:43:48.186372 140297328059584 spec.py:349] Evaluating on the test split.
I0306 16:44:50.451803 140297328059584 submission_runner.py:469] Time since start: 13862.03s, 	Step: 2957, 	{'train/loss': 0.12321453090499407, 'validation/loss': 0.12492303737489761, 'validation/num_examples': 83274637, 'test/loss': 0.12723677593544408, 'test/num_examples': 95000000, 'score': 2668.749763250351, 'total_duration': 13862.026475429535, 'accumulated_submission_time': 2668.749763250351, 'accumulated_eval_time': 11192.653333425522, 'accumulated_logging_time': 0.4252028465270996}
I0306 16:44:50.484716 140144422143744 logging_writer.py:48] [2957] accumulated_eval_time=11192.7, accumulated_logging_time=0.425203, accumulated_submission_time=2668.75, global_step=2957, preemption_count=0, score=2668.75, test/loss=0.127237, test/num_examples=95000000, total_duration=13862, train/loss=0.123215, validation/loss=0.124923, validation/num_examples=83274637
I0306 16:45:10.787160 140144430536448 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.030612055212259293, loss=0.12597766518592834
I0306 16:46:51.067070 140297328059584 spec.py:321] Evaluating on the training split.
I0306 16:49:44.885437 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 16:49:52.317134 140297328059584 spec.py:349] Evaluating on the test split.
I0306 16:50:49.449080 140297328059584 submission_runner.py:469] Time since start: 14221.02s, 	Step: 3091, 	{'train/loss': 0.12523626700137397, 'validation/loss': 0.12487507643120978, 'validation/num_examples': 83274637, 'test/loss': 0.12718088782894738, 'test/num_examples': 95000000, 'score': 2789.315085172653, 'total_duration': 14221.023752689362, 'accumulated_submission_time': 2789.315085172653, 'accumulated_eval_time': 11431.035290718079, 'accumulated_logging_time': 0.4651319980621338}
I0306 16:50:49.457366 140144422143744 logging_writer.py:48] [3091] accumulated_eval_time=11431, accumulated_logging_time=0.465132, accumulated_submission_time=2789.32, global_step=3091, preemption_count=0, score=2789.32, test/loss=0.127181, test/num_examples=95000000, total_duration=14221, train/loss=0.125236, validation/loss=0.124875, validation/num_examples=83274637
I0306 16:50:50.504850 140144430536448 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.016601750627160072, loss=0.137813538312912
I0306 16:52:30.202878 140144422143744 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.013660088181495667, loss=0.13244153559207916
I0306 16:52:50.149166 140297328059584 spec.py:321] Evaluating on the training split.
I0306 16:55:56.043177 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 16:56:03.554641 140297328059584 spec.py:349] Evaluating on the test split.
I0306 16:56:47.001579 140297328059584 submission_runner.py:469] Time since start: 14578.58s, 	Step: 3220, 	{'train/loss': 0.12421269550825814, 'validation/loss': 0.12461929196710653, 'validation/num_examples': 83274637, 'test/loss': 0.1270322575760691, 'test/num_examples': 95000000, 'score': 2909.9900612831116, 'total_duration': 14578.576260328293, 'accumulated_submission_time': 2909.9900612831116, 'accumulated_eval_time': 11667.887652635574, 'accumulated_logging_time': 0.47937560081481934}
I0306 16:56:47.009972 140144430536448 logging_writer.py:48] [3220] accumulated_eval_time=11667.9, accumulated_logging_time=0.479376, accumulated_submission_time=2909.99, global_step=3220, preemption_count=0, score=2909.99, test/loss=0.127032, test/num_examples=95000000, total_duration=14578.6, train/loss=0.124213, validation/loss=0.124619, validation/num_examples=83274637
I0306 16:57:47.755477 140144422143744 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.021593930199742317, loss=0.13015860319137573
I0306 16:58:47.244874 140297328059584 spec.py:321] Evaluating on the training split.
I0306 17:02:11.492609 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 17:02:18.900967 140297328059584 spec.py:349] Evaluating on the test split.
I0306 17:02:48.012599 140297328059584 submission_runner.py:469] Time since start: 14939.59s, 	Step: 3355, 	{'train/loss': 0.12369132970910778, 'validation/loss': 0.12457947874473697, 'validation/num_examples': 83274637, 'test/loss': 0.12695622709703946, 'test/num_examples': 95000000, 'score': 3030.2080039978027, 'total_duration': 14939.587269544601, 'accumulated_submission_time': 3030.2080039978027, 'accumulated_eval_time': 11908.65531539917, 'accumulated_logging_time': 0.49373841285705566}
I0306 17:02:48.020908 140144430536448 logging_writer.py:48] [3355] accumulated_eval_time=11908.7, accumulated_logging_time=0.493738, accumulated_submission_time=3030.21, global_step=3355, preemption_count=0, score=3030.21, test/loss=0.126956, test/num_examples=95000000, total_duration=14939.6, train/loss=0.123691, validation/loss=0.124579, validation/num_examples=83274637
I0306 17:03:14.020804 140144422143744 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.024169720709323883, loss=0.12265489250421524
I0306 17:04:48.090728 140297328059584 spec.py:321] Evaluating on the training split.
I0306 17:08:25.541779 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 17:08:32.954266 140297328059584 spec.py:349] Evaluating on the test split.
I0306 17:08:44.994799 140297328059584 submission_runner.py:469] Time since start: 15296.57s, 	Step: 3488, 	{'train/loss': 0.12418977893982669, 'validation/loss': 0.1243889910814209, 'validation/num_examples': 83274637, 'test/loss': 0.12672019994860198, 'test/num_examples': 95000000, 'score': 3150.261655330658, 'total_duration': 15296.569487810135, 'accumulated_submission_time': 3150.261655330658, 'accumulated_eval_time': 12145.559345006943, 'accumulated_logging_time': 0.5084018707275391}
I0306 17:08:45.002763 140144430536448 logging_writer.py:48] [3488] accumulated_eval_time=12145.6, accumulated_logging_time=0.508402, accumulated_submission_time=3150.26, global_step=3488, preemption_count=0, score=3150.26, test/loss=0.12672, test/num_examples=95000000, total_duration=15296.6, train/loss=0.12419, validation/loss=0.124389, validation/num_examples=83274637
I0306 17:08:46.385572 140144422143744 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.005253795068711042, loss=0.13249526917934418
I0306 17:10:19.605551 140144430536448 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.03601565212011337, loss=0.11823203414678574
I0306 17:10:45.073497 140297328059584 spec.py:321] Evaluating on the training split.
I0306 17:14:37.255451 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 17:14:44.670607 140297328059584 spec.py:349] Evaluating on the test split.
I0306 17:14:53.085649 140297328059584 submission_runner.py:469] Time since start: 15664.66s, 	Step: 3623, 	{'train/loss': 0.1243354635043714, 'validation/loss': 0.12462082098157705, 'validation/num_examples': 83274637, 'test/loss': 0.12695898432360198, 'test/num_examples': 95000000, 'score': 3270.314610719681, 'total_duration': 15664.660328865051, 'accumulated_submission_time': 3270.314610719681, 'accumulated_eval_time': 12393.571444511414, 'accumulated_logging_time': 0.5223855972290039}
I0306 17:14:53.104746 140144422143744 logging_writer.py:48] [3623] accumulated_eval_time=12393.6, accumulated_logging_time=0.522386, accumulated_submission_time=3270.31, global_step=3623, preemption_count=0, score=3270.31, test/loss=0.126959, test/num_examples=95000000, total_duration=15664.7, train/loss=0.124335, validation/loss=0.124621, validation/num_examples=83274637
I0306 17:15:53.750894 140144430536448 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.01516761351376772, loss=0.12061618268489838
I0306 17:16:53.497200 140297328059584 spec.py:321] Evaluating on the training split.
I0306 17:20:49.551800 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 17:20:56.984645 140297328059584 spec.py:349] Evaluating on the test split.
I0306 17:21:05.389384 140297328059584 submission_runner.py:469] Time since start: 16036.96s, 	Step: 3756, 	{'train/loss': 0.12444046873060412, 'validation/loss': 0.12450998716902242, 'validation/num_examples': 83274637, 'test/loss': 0.12682162776521383, 'test/num_examples': 95000000, 'score': 3390.644497871399, 'total_duration': 16036.96407365799, 'accumulated_submission_time': 3390.644497871399, 'accumulated_eval_time': 12645.463589429855, 'accumulated_logging_time': 0.5936586856842041}
I0306 17:21:05.397378 140144422143744 logging_writer.py:48] [3756] accumulated_eval_time=12645.5, accumulated_logging_time=0.593659, accumulated_submission_time=3390.64, global_step=3756, preemption_count=0, score=3390.64, test/loss=0.126822, test/num_examples=95000000, total_duration=16037, train/loss=0.12444, validation/loss=0.12451, validation/num_examples=83274637
I0306 17:21:27.129831 140144430536448 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.014826769940555096, loss=0.12108342349529266
I0306 17:23:07.177195 140297328059584 spec.py:321] Evaluating on the training split.
I0306 17:26:56.026216 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 17:27:03.429047 140297328059584 spec.py:349] Evaluating on the test split.
I0306 17:27:11.926012 140297328059584 submission_runner.py:469] Time since start: 16403.50s, 	Step: 3892, 	{'train/loss': 0.12260062443151039, 'validation/loss': 0.12458397260532715, 'validation/num_examples': 83274637, 'test/loss': 0.12708308637952304, 'test/num_examples': 95000000, 'score': 3512.407565832138, 'total_duration': 16403.500685691833, 'accumulated_submission_time': 3512.407565832138, 'accumulated_eval_time': 12890.212359905243, 'accumulated_logging_time': 0.607527494430542}
I0306 17:27:11.934447 140144422143744 logging_writer.py:48] [3892] accumulated_eval_time=12890.2, accumulated_logging_time=0.607527, accumulated_submission_time=3512.41, global_step=3892, preemption_count=0, score=3512.41, test/loss=0.127083, test/num_examples=95000000, total_duration=16403.5, train/loss=0.122601, validation/loss=0.124584, validation/num_examples=83274637
I0306 17:27:12.922251 140144430536448 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.008362937718629837, loss=0.11936502158641815
I0306 17:28:47.138457 140144422143744 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.015857817605137825, loss=0.1191079318523407
I0306 17:29:12.017553 140297328059584 spec.py:321] Evaluating on the training split.
I0306 17:33:11.434389 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 17:33:18.822306 140297328059584 spec.py:349] Evaluating on the test split.
I0306 17:33:27.327614 140297328059584 submission_runner.py:469] Time since start: 16778.90s, 	Step: 4023, 	{'train/loss': 0.12294040500836552, 'validation/loss': 0.1245512149561085, 'validation/num_examples': 83274637, 'test/loss': 0.12688287624383224, 'test/num_examples': 95000000, 'score': 3632.4745349884033, 'total_duration': 16778.90229988098, 'accumulated_submission_time': 3632.4745349884033, 'accumulated_eval_time': 13145.522379159927, 'accumulated_logging_time': 0.6216855049133301}
I0306 17:33:27.336087 140144430536448 logging_writer.py:48] [4023] accumulated_eval_time=13145.5, accumulated_logging_time=0.621686, accumulated_submission_time=3632.47, global_step=4023, preemption_count=0, score=3632.47, test/loss=0.126883, test/num_examples=95000000, total_duration=16778.9, train/loss=0.12294, validation/loss=0.124551, validation/num_examples=83274637
I0306 17:34:24.345978 140144422143744 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.014023827388882637, loss=0.11902407556772232
I0306 17:35:27.603612 140297328059584 spec.py:321] Evaluating on the training split.
I0306 17:39:06.402659 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 17:39:13.780758 140297328059584 spec.py:349] Evaluating on the test split.
I0306 17:39:22.238750 140297328059584 submission_runner.py:469] Time since start: 17133.81s, 	Step: 4159, 	{'train/loss': 0.12469953004528517, 'validation/loss': 0.1248084668502893, 'validation/num_examples': 83274637, 'test/loss': 0.12718039888980262, 'test/num_examples': 95000000, 'score': 3752.6994366645813, 'total_duration': 17133.813440084457, 'accumulated_submission_time': 3752.6994366645813, 'accumulated_eval_time': 13380.157555818558, 'accumulated_logging_time': 0.6613891124725342}
I0306 17:39:22.247442 140144430536448 logging_writer.py:48] [4159] accumulated_eval_time=13380.2, accumulated_logging_time=0.661389, accumulated_submission_time=3752.7, global_step=4159, preemption_count=0, score=3752.7, test/loss=0.12718, test/num_examples=95000000, total_duration=17133.8, train/loss=0.1247, validation/loss=0.124808, validation/num_examples=83274637
I0306 17:39:40.880612 140144422143744 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.01004696637392044, loss=0.1264207661151886
I0306 17:41:22.767281 140297328059584 spec.py:321] Evaluating on the training split.
I0306 17:45:09.280909 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 17:45:16.698577 140297328059584 spec.py:349] Evaluating on the test split.
I0306 17:45:25.225656 140297328059584 submission_runner.py:469] Time since start: 17496.80s, 	Step: 4294, 	{'train/loss': 0.12214228706492943, 'validation/loss': 0.12465372504837893, 'validation/num_examples': 83274637, 'test/loss': 0.12705352816611842, 'test/num_examples': 95000000, 'score': 3873.2019741535187, 'total_duration': 17496.80033683777, 'accumulated_submission_time': 3873.2019741535187, 'accumulated_eval_time': 13622.615884065628, 'accumulated_logging_time': 0.6768202781677246}
I0306 17:45:25.233910 140144430536448 logging_writer.py:48] [4294] accumulated_eval_time=13622.6, accumulated_logging_time=0.67682, accumulated_submission_time=3873.2, global_step=4294, preemption_count=0, score=3873.2, test/loss=0.127054, test/num_examples=95000000, total_duration=17496.8, train/loss=0.122142, validation/loss=0.124654, validation/num_examples=83274637
I0306 17:45:25.952271 140144422143744 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.014897872693836689, loss=0.12681451439857483
I0306 17:46:58.782830 140144430536448 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.015020164661109447, loss=0.11944600939750671
I0306 17:47:26.084290 140297328059584 spec.py:321] Evaluating on the training split.
I0306 17:51:14.974559 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 17:51:22.405523 140297328059584 spec.py:349] Evaluating on the test split.
I0306 17:51:30.827234 140297328059584 submission_runner.py:469] Time since start: 17862.40s, 	Step: 4426, 	{'train/loss': 0.12377210323400092, 'validation/loss': 0.12437510918643738, 'validation/num_examples': 83274637, 'test/loss': 0.12674171805098683, 'test/num_examples': 95000000, 'score': 3994.036600828171, 'total_duration': 17862.401925086975, 'accumulated_submission_time': 3994.036600828171, 'accumulated_eval_time': 13867.358794212341, 'accumulated_logging_time': 0.6909189224243164}
I0306 17:51:30.835809 140144422143744 logging_writer.py:48] [4426] accumulated_eval_time=13867.4, accumulated_logging_time=0.690919, accumulated_submission_time=3994.04, global_step=4426, preemption_count=0, score=3994.04, test/loss=0.126742, test/num_examples=95000000, total_duration=17862.4, train/loss=0.123772, validation/loss=0.124375, validation/num_examples=83274637
I0306 17:52:27.457553 140144430536448 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.027831202372908592, loss=0.1274927705526352
I0306 17:53:30.930107 140297328059584 spec.py:321] Evaluating on the training split.
I0306 17:57:12.969439 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 17:57:20.387891 140297328059584 spec.py:349] Evaluating on the test split.
I0306 17:57:28.918028 140297328059584 submission_runner.py:469] Time since start: 18220.49s, 	Step: 4555, 	{'train/loss': 0.12417121373304406, 'validation/loss': 0.12442230821455914, 'validation/num_examples': 83274637, 'test/loss': 0.12683432771381578, 'test/num_examples': 95000000, 'score': 4114.113206148148, 'total_duration': 18220.492697000504, 'accumulated_submission_time': 4114.113206148148, 'accumulated_eval_time': 14105.34665465355, 'accumulated_logging_time': 0.705838680267334}
I0306 17:57:28.926628 140144422143744 logging_writer.py:48] [4555] accumulated_eval_time=14105.3, accumulated_logging_time=0.705839, accumulated_submission_time=4114.11, global_step=4555, preemption_count=0, score=4114.11, test/loss=0.126834, test/num_examples=95000000, total_duration=18220.5, train/loss=0.124171, validation/loss=0.124422, validation/num_examples=83274637
I0306 17:57:51.729134 140144430536448 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.028452642261981964, loss=0.11602010577917099
I0306 17:59:29.368933 140297328059584 spec.py:321] Evaluating on the training split.
I0306 18:03:09.456826 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 18:03:16.948999 140297328059584 spec.py:349] Evaluating on the test split.
I0306 18:03:25.330202 140297328059584 submission_runner.py:469] Time since start: 18576.90s, 	Step: 4686, 	{'train/loss': 0.12288243913987898, 'validation/loss': 0.12434627151312103, 'validation/num_examples': 83274637, 'test/loss': 0.12658879933182565, 'test/num_examples': 95000000, 'score': 4234.517445325851, 'total_duration': 18576.904880285263, 'accumulated_submission_time': 4234.517445325851, 'accumulated_eval_time': 14341.307885408401, 'accumulated_logging_time': 0.7416894435882568}
I0306 18:03:25.340693 140144422143744 logging_writer.py:48] [4686] accumulated_eval_time=14341.3, accumulated_logging_time=0.741689, accumulated_submission_time=4234.52, global_step=4686, preemption_count=0, score=4234.52, test/loss=0.126589, test/num_examples=95000000, total_duration=18576.9, train/loss=0.122882, validation/loss=0.124346, validation/num_examples=83274637
I0306 18:03:26.914535 140144430536448 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.006846402771770954, loss=0.1265181452035904
I0306 18:05:05.399525 140144422143744 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.015513851307332516, loss=0.12855346500873566
I0306 18:05:26.405905 140297328059584 spec.py:321] Evaluating on the training split.
I0306 18:09:17.521840 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 18:09:24.957465 140297328059584 spec.py:349] Evaluating on the test split.
I0306 18:09:33.454395 140297328059584 submission_runner.py:469] Time since start: 18945.03s, 	Step: 4820, 	{'train/loss': 0.12169555473908689, 'validation/loss': 0.12440474033856716, 'validation/num_examples': 83274637, 'test/loss': 0.1267647280838816, 'test/num_examples': 95000000, 'score': 4355.565670251846, 'total_duration': 18945.029086112976, 'accumulated_submission_time': 4355.565670251846, 'accumulated_eval_time': 14588.356337070465, 'accumulated_logging_time': 0.7590618133544922}
I0306 18:09:33.463641 140144430536448 logging_writer.py:48] [4820] accumulated_eval_time=14588.4, accumulated_logging_time=0.759062, accumulated_submission_time=4355.57, global_step=4820, preemption_count=0, score=4355.57, test/loss=0.126765, test/num_examples=95000000, total_duration=18945, train/loss=0.121696, validation/loss=0.124405, validation/num_examples=83274637
I0306 18:10:35.894856 140144422143744 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.020251162350177765, loss=0.12257726490497589
I0306 18:11:34.131391 140297328059584 spec.py:321] Evaluating on the training split.
I0306 18:15:28.832574 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 18:15:36.232647 140297328059584 spec.py:349] Evaluating on the test split.
I0306 18:15:44.625719 140297328059584 submission_runner.py:469] Time since start: 19316.20s, 	Step: 4952, 	{'train/loss': 0.12018597293527997, 'validation/loss': 0.12435859268966253, 'validation/num_examples': 83274637, 'test/loss': 0.1267597370888158, 'test/num_examples': 95000000, 'score': 4476.217046022415, 'total_duration': 19316.200394153595, 'accumulated_submission_time': 4476.217046022415, 'accumulated_eval_time': 14838.85061955452, 'accumulated_logging_time': 0.7745811939239502}
I0306 18:15:44.650458 140144430536448 logging_writer.py:48] [4952] accumulated_eval_time=14838.9, accumulated_logging_time=0.774581, accumulated_submission_time=4476.22, global_step=4952, preemption_count=0, score=4476.22, test/loss=0.12676, test/num_examples=95000000, total_duration=19316.2, train/loss=0.120186, validation/loss=0.124359, validation/num_examples=83274637
I0306 18:16:10.011943 140144422143744 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.006756668444722891, loss=0.1262052059173584
I0306 18:17:45.072261 140297328059584 spec.py:321] Evaluating on the training split.
I0306 18:21:40.160264 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 18:21:47.643656 140297328059584 spec.py:349] Evaluating on the test split.
I0306 18:21:56.111446 140297328059584 submission_runner.py:469] Time since start: 19687.69s, 	Step: 5088, 	{'train/loss': 0.12336215602948605, 'validation/loss': 0.12439137241497747, 'validation/num_examples': 83274637, 'test/loss': 0.12672934497327304, 'test/num_examples': 95000000, 'score': 4596.596885442734, 'total_duration': 19687.68613767624, 'accumulated_submission_time': 4596.596885442734, 'accumulated_eval_time': 15089.88978099823, 'accumulated_logging_time': 0.829240083694458}
I0306 18:21:56.120264 140144430536448 logging_writer.py:48] [5088] accumulated_eval_time=15089.9, accumulated_logging_time=0.82924, accumulated_submission_time=4596.6, global_step=5088, preemption_count=0, score=4596.6, test/loss=0.126729, test/num_examples=95000000, total_duration=19687.7, train/loss=0.123362, validation/loss=0.124391, validation/num_examples=83274637
I0306 18:21:57.485351 140144422143744 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.006938675884157419, loss=0.12276962399482727
I0306 18:23:34.276260 140144430536448 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.021546868607401848, loss=0.12905608117580414
I0306 18:23:56.247465 140297328059584 spec.py:321] Evaluating on the training split.
I0306 18:27:53.947120 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 18:28:01.406246 140297328059584 spec.py:349] Evaluating on the test split.
I0306 18:28:09.915493 140297328059584 submission_runner.py:469] Time since start: 20061.49s, 	Step: 5219, 	{'train/loss': 0.12116270859099035, 'validation/loss': 0.12442855942623135, 'validation/num_examples': 83274637, 'test/loss': 0.12668526418585527, 'test/num_examples': 95000000, 'score': 4716.696996927261, 'total_duration': 20061.490166187286, 'accumulated_submission_time': 4716.696996927261, 'accumulated_eval_time': 15343.557789802551, 'accumulated_logging_time': 0.854938268661499}
I0306 18:28:09.926386 140144422143744 logging_writer.py:48] [5219] accumulated_eval_time=15343.6, accumulated_logging_time=0.854938, accumulated_submission_time=4716.7, global_step=5219, preemption_count=0, score=4716.7, test/loss=0.126685, test/num_examples=95000000, total_duration=20061.5, train/loss=0.121163, validation/loss=0.124429, validation/num_examples=83274637
I0306 18:29:12.518063 140144430536448 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.017897315323352814, loss=0.12838253378868103
I0306 18:30:09.965916 140297328059584 spec.py:321] Evaluating on the training split.
I0306 18:34:04.972214 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 18:34:12.435211 140297328059584 spec.py:349] Evaluating on the test split.
I0306 18:34:20.942890 140297328059584 submission_runner.py:469] Time since start: 20432.52s, 	Step: 5352, 	{'train/loss': 0.12112950445767844, 'validation/loss': 0.1243879166234481, 'validation/num_examples': 83274637, 'test/loss': 0.12668755268297696, 'test/num_examples': 95000000, 'score': 4836.719299077988, 'total_duration': 20432.517562389374, 'accumulated_submission_time': 4836.719299077988, 'accumulated_eval_time': 15594.534707546234, 'accumulated_logging_time': 0.8722660541534424}
I0306 18:34:20.954578 140144422143744 logging_writer.py:48] [5352] accumulated_eval_time=15594.5, accumulated_logging_time=0.872266, accumulated_submission_time=4836.72, global_step=5352, preemption_count=0, score=4836.72, test/loss=0.126688, test/num_examples=95000000, total_duration=20432.5, train/loss=0.12113, validation/loss=0.124388, validation/num_examples=83274637
I0306 18:34:51.588961 140144430536448 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.018022101372480392, loss=0.12083019316196442
I0306 18:36:21.983774 140297328059584 spec.py:321] Evaluating on the training split.
I0306 18:40:13.554097 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 18:40:21.019886 140297328059584 spec.py:349] Evaluating on the test split.
I0306 18:40:29.462339 140297328059584 submission_runner.py:469] Time since start: 20801.04s, 	Step: 5481, 	{'train/loss': 0.12271321839037931, 'validation/loss': 0.12430029521928634, 'validation/num_examples': 83274637, 'test/loss': 0.1266145986430921, 'test/num_examples': 95000000, 'score': 4957.732013702393, 'total_duration': 20801.037008285522, 'accumulated_submission_time': 4957.732013702393, 'accumulated_eval_time': 15842.013211727142, 'accumulated_logging_time': 0.8899929523468018}
I0306 18:40:29.471483 140144422143744 logging_writer.py:48] [5481] accumulated_eval_time=15842, accumulated_logging_time=0.889993, accumulated_submission_time=4957.73, global_step=5481, preemption_count=0, score=4957.73, test/loss=0.126615, test/num_examples=95000000, total_duration=20801, train/loss=0.122713, validation/loss=0.1243, validation/num_examples=83274637
I0306 18:40:31.565915 140144430536448 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.005836481228470802, loss=0.12073710560798645
I0306 18:42:15.742744 140144422143744 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.010515019297599792, loss=0.12207528948783875
I0306 18:42:30.713454 140297328059584 spec.py:321] Evaluating on the training split.
I0306 18:46:33.023838 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 18:46:40.471125 140297328059584 spec.py:349] Evaluating on the test split.
I0306 18:46:48.803904 140297328059584 submission_runner.py:469] Time since start: 21180.38s, 	Step: 5615, 	{'train/loss': 0.12255451996933739, 'validation/loss': 0.1243210344423169, 'validation/num_examples': 83274637, 'test/loss': 0.1266459945620888, 'test/num_examples': 95000000, 'score': 5078.940350055695, 'total_duration': 21180.378577947617, 'accumulated_submission_time': 5078.940350055695, 'accumulated_eval_time': 16100.103604793549, 'accumulated_logging_time': 0.9224791526794434}
I0306 18:46:48.813160 140144430536448 logging_writer.py:48] [5615] accumulated_eval_time=16100.1, accumulated_logging_time=0.922479, accumulated_submission_time=5078.94, global_step=5615, preemption_count=0, score=5078.94, test/loss=0.126646, test/num_examples=95000000, total_duration=21180.4, train/loss=0.122555, validation/loss=0.124321, validation/num_examples=83274637
I0306 18:47:56.905953 140144422143744 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.006329149939119816, loss=0.12552058696746826
I0306 18:48:49.227128 140297328059584 spec.py:321] Evaluating on the training split.
I0306 18:52:43.113100 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 18:52:50.616987 140297328059584 spec.py:349] Evaluating on the test split.
I0306 18:52:59.128454 140297328059584 submission_runner.py:469] Time since start: 21550.70s, 	Step: 5749, 	{'train/loss': 0.12309719475700795, 'validation/loss': 0.12407539415848415, 'validation/num_examples': 83274637, 'test/loss': 0.12642385478001644, 'test/num_examples': 95000000, 'score': 5199.336631059647, 'total_duration': 21550.703128814697, 'accumulated_submission_time': 5199.336631059647, 'accumulated_eval_time': 16350.004873275757, 'accumulated_logging_time': 0.9385032653808594}
I0306 18:52:59.137179 140144430536448 logging_writer.py:48] [5749] accumulated_eval_time=16350, accumulated_logging_time=0.938503, accumulated_submission_time=5199.34, global_step=5749, preemption_count=0, score=5199.34, test/loss=0.126424, test/num_examples=95000000, total_duration=21550.7, train/loss=0.123097, validation/loss=0.124075, validation/num_examples=83274637
I0306 18:53:30.715572 140144422143744 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.009469895623624325, loss=0.12342455983161926
I0306 18:54:59.906028 140297328059584 spec.py:321] Evaluating on the training split.
I0306 18:58:55.463607 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 18:59:02.502235 140297328059584 spec.py:349] Evaluating on the test split.
I0306 18:59:11.024335 140297328059584 submission_runner.py:469] Time since start: 21922.60s, 	Step: 5883, 	{'train/loss': 0.12253716378326311, 'validation/loss': 0.12438904102675644, 'validation/num_examples': 83274637, 'test/loss': 0.1267537851665296, 'test/num_examples': 95000000, 'score': 5320.088996648788, 'total_duration': 21922.59902358055, 'accumulated_submission_time': 5320.088996648788, 'accumulated_eval_time': 16601.123138666153, 'accumulated_logging_time': 0.9532616138458252}
I0306 18:59:11.033269 140144430536448 logging_writer.py:48] [5883] accumulated_eval_time=16601.1, accumulated_logging_time=0.953262, accumulated_submission_time=5320.09, global_step=5883, preemption_count=0, score=5320.09, test/loss=0.126754, test/num_examples=95000000, total_duration=21922.6, train/loss=0.122537, validation/loss=0.124389, validation/num_examples=83274637
I0306 18:59:12.965069 140144422143744 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.007940072566270828, loss=0.1161021739244461
I0306 19:00:54.238091 140144430536448 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.01666279509663582, loss=0.12041760981082916
I0306 19:01:11.572971 140297328059584 spec.py:321] Evaluating on the training split.
I0306 19:04:59.990544 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 19:05:07.095358 140297328059584 spec.py:349] Evaluating on the test split.
I0306 19:05:15.595928 140297328059584 submission_runner.py:469] Time since start: 22287.17s, 	Step: 6017, 	{'train/loss': 0.12371699168762695, 'validation/loss': 0.12418183324472755, 'validation/num_examples': 83274637, 'test/loss': 0.1266114693256579, 'test/num_examples': 95000000, 'score': 5440.556627750397, 'total_duration': 22287.17061829567, 'accumulated_submission_time': 5440.556627750397, 'accumulated_eval_time': 16845.14606308937, 'accumulated_logging_time': 1.024336338043213}
I0306 19:05:15.605356 140144422143744 logging_writer.py:48] [6017] accumulated_eval_time=16845.1, accumulated_logging_time=1.02434, accumulated_submission_time=5440.56, global_step=6017, preemption_count=0, score=5440.56, test/loss=0.126611, test/num_examples=95000000, total_duration=22287.2, train/loss=0.123717, validation/loss=0.124182, validation/num_examples=83274637
I0306 19:06:21.518815 140144430536448 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.020552515983581543, loss=0.1218656599521637
I0306 19:07:16.008212 140297328059584 spec.py:321] Evaluating on the training split.
I0306 19:11:15.424172 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 19:11:22.569230 140297328059584 spec.py:349] Evaluating on the test split.
I0306 19:11:31.043399 140297328059584 submission_runner.py:469] Time since start: 22662.62s, 	Step: 6148, 	{'train/loss': 0.12374170505260147, 'validation/loss': 0.12408645483390286, 'validation/num_examples': 83274637, 'test/loss': 0.12641451487458882, 'test/num_examples': 95000000, 'score': 5560.942054033279, 'total_duration': 22662.618089914322, 'accumulated_submission_time': 5560.942054033279, 'accumulated_eval_time': 17100.181215286255, 'accumulated_logging_time': 1.0410521030426025}
I0306 19:11:31.104554 140144422143744 logging_writer.py:48] [6148] accumulated_eval_time=17100.2, accumulated_logging_time=1.04105, accumulated_submission_time=5560.94, global_step=6148, preemption_count=0, score=5560.94, test/loss=0.126415, test/num_examples=95000000, total_duration=22662.6, train/loss=0.123742, validation/loss=0.124086, validation/num_examples=83274637
I0306 19:12:02.123737 140144430536448 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.005708879325538874, loss=0.11418215930461884
I0306 19:13:31.510583 140297328059584 spec.py:321] Evaluating on the training split.
I0306 19:17:15.568642 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 19:17:23.014794 140297328059584 spec.py:349] Evaluating on the test split.
I0306 19:17:31.441898 140297328059584 submission_runner.py:469] Time since start: 23023.02s, 	Step: 6278, 	{'train/loss': 0.12233605647002752, 'validation/loss': 0.12406516682784932, 'validation/num_examples': 83274637, 'test/loss': 0.12628427745682566, 'test/num_examples': 95000000, 'score': 5681.332220315933, 'total_duration': 23023.016587734222, 'accumulated_submission_time': 5681.332220315933, 'accumulated_eval_time': 17340.112494945526, 'accumulated_logging_time': 1.1083061695098877}
I0306 19:17:31.452087 140144422143744 logging_writer.py:48] [6278] accumulated_eval_time=17340.1, accumulated_logging_time=1.10831, accumulated_submission_time=5681.33, global_step=6278, preemption_count=0, score=5681.33, test/loss=0.126284, test/num_examples=95000000, total_duration=23023, train/loss=0.122336, validation/loss=0.124065, validation/num_examples=83274637
I0306 19:17:33.822876 140144430536448 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.012644154950976372, loss=0.11894655972719193
I0306 19:19:31.732674 140144422143744 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.005089469254016876, loss=0.11718270182609558
I0306 19:19:31.752143 140297328059584 spec.py:321] Evaluating on the training split.
I0306 19:23:20.029263 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 19:23:27.207781 140297328059584 spec.py:349] Evaluating on the test split.
I0306 19:23:35.735461 140297328059584 submission_runner.py:469] Time since start: 23387.31s, 	Step: 6401, 	{'train/loss': 0.12244254171426566, 'validation/loss': 0.12413853091439324, 'validation/num_examples': 83274637, 'test/loss': 0.12645147837171053, 'test/num_examples': 95000000, 'score': 5801.614855527878, 'total_duration': 23387.310149669647, 'accumulated_submission_time': 5801.614855527878, 'accumulated_eval_time': 17584.09576511383, 'accumulated_logging_time': 1.1268351078033447}
I0306 19:23:35.760136 140144430536448 logging_writer.py:48] [6401] accumulated_eval_time=17584.1, accumulated_logging_time=1.12684, accumulated_submission_time=5801.61, global_step=6401, preemption_count=0, score=5801.61, test/loss=0.126451, test/num_examples=95000000, total_duration=23387.3, train/loss=0.122443, validation/loss=0.124139, validation/num_examples=83274637
I0306 19:25:01.326605 140144422143744 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.010699148289859295, loss=0.11998691409826279
I0306 19:25:37.149082 140297328059584 spec.py:321] Evaluating on the training split.
I0306 19:29:25.463652 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 19:29:32.632756 140297328059584 spec.py:349] Evaluating on the test split.
I0306 19:29:41.164947 140297328059584 submission_runner.py:469] Time since start: 23752.74s, 	Step: 6532, 	{'train/loss': 0.11959335002931035, 'validation/loss': 0.12412106536829043, 'validation/num_examples': 83274637, 'test/loss': 0.1264286463199013, 'test/num_examples': 95000000, 'score': 5922.96987247467, 'total_duration': 23752.73962855339, 'accumulated_submission_time': 5922.96987247467, 'accumulated_eval_time': 17828.111590862274, 'accumulated_logging_time': 1.174377679824829}
I0306 19:29:41.174084 140144430536448 logging_writer.py:48] [6532] accumulated_eval_time=17828.1, accumulated_logging_time=1.17438, accumulated_submission_time=5922.97, global_step=6532, preemption_count=0, score=5922.97, test/loss=0.126429, test/num_examples=95000000, total_duration=23752.7, train/loss=0.119593, validation/loss=0.124121, validation/num_examples=83274637
I0306 19:30:32.785798 140144422143744 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.006533768959343433, loss=0.1243230402469635
I0306 19:31:42.641237 140297328059584 spec.py:321] Evaluating on the training split.
I0306 19:35:34.763362 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 19:35:41.886326 140297328059584 spec.py:349] Evaluating on the test split.
I0306 19:35:50.323256 140297328059584 submission_runner.py:469] Time since start: 24121.90s, 	Step: 6662, 	{'train/loss': 0.12142501286459419, 'validation/loss': 0.12396547918647975, 'validation/num_examples': 83274637, 'test/loss': 0.12633042135074013, 'test/num_examples': 95000000, 'score': 6044.42129945755, 'total_duration': 24121.89791536331, 'accumulated_submission_time': 6044.42129945755, 'accumulated_eval_time': 18075.7935423851, 'accumulated_logging_time': 1.190136432647705}
I0306 19:35:50.334977 140144430536448 logging_writer.py:48] [6662] accumulated_eval_time=18075.8, accumulated_logging_time=1.19014, accumulated_submission_time=6044.42, global_step=6662, preemption_count=0, score=6044.42, test/loss=0.12633, test/num_examples=95000000, total_duration=24121.9, train/loss=0.121425, validation/loss=0.123965, validation/num_examples=83274637
I0306 19:36:05.371279 140144422143744 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.009228549897670746, loss=0.12338382005691528
I0306 19:37:51.078736 140297328059584 spec.py:321] Evaluating on the training split.
I0306 19:41:46.671017 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 19:41:53.734511 140297328059584 spec.py:349] Evaluating on the test split.
I0306 19:42:02.258087 140297328059584 submission_runner.py:469] Time since start: 24493.83s, 	Step: 6796, 	{'train/loss': 0.12201318811367518, 'validation/loss': 0.12394417900192634, 'validation/num_examples': 83274637, 'test/loss': 0.12625128408717104, 'test/num_examples': 95000000, 'score': 6165.148801803589, 'total_duration': 24493.832753181458, 'accumulated_submission_time': 6165.148801803589, 'accumulated_eval_time': 18326.97283101082, 'accumulated_logging_time': 1.2083868980407715}
I0306 19:42:02.268086 140144430536448 logging_writer.py:48] [6796] accumulated_eval_time=18327, accumulated_logging_time=1.20839, accumulated_submission_time=6165.15, global_step=6796, preemption_count=0, score=6165.15, test/loss=0.126251, test/num_examples=95000000, total_duration=24493.8, train/loss=0.122013, validation/loss=0.123944, validation/num_examples=83274637
I0306 19:42:02.825976 140144422143744 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.016752464696764946, loss=0.11785448342561722
I0306 19:43:30.878027 140144430536448 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.009046425111591816, loss=0.12391505390405655
I0306 19:44:02.600813 140297328059584 spec.py:321] Evaluating on the training split.
I0306 19:48:03.816905 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 19:48:10.874568 140297328059584 spec.py:349] Evaluating on the test split.
I0306 19:48:19.393941 140297328059584 submission_runner.py:469] Time since start: 24870.97s, 	Step: 6930, 	{'train/loss': 0.12420260279480391, 'validation/loss': 0.12382429438274113, 'validation/num_examples': 83274637, 'test/loss': 0.12610550717516447, 'test/num_examples': 95000000, 'score': 6285.4327046871185, 'total_duration': 24870.968617916107, 'accumulated_submission_time': 6285.4327046871185, 'accumulated_eval_time': 18583.765906095505, 'accumulated_logging_time': 1.2559783458709717}
I0306 19:48:19.403718 140144422143744 logging_writer.py:48] [6930] accumulated_eval_time=18583.8, accumulated_logging_time=1.25598, accumulated_submission_time=6285.43, global_step=6930, preemption_count=0, score=6285.43, test/loss=0.126106, test/num_examples=95000000, total_duration=24871, train/loss=0.124203, validation/loss=0.123824, validation/num_examples=83274637
I0306 19:49:11.412275 140144430536448 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.007251890376210213, loss=0.12057484686374664
I0306 19:50:20.453452 140297328059584 spec.py:321] Evaluating on the training split.
I0306 19:54:12.931596 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 19:54:20.184805 140297328059584 spec.py:349] Evaluating on the test split.
I0306 19:54:28.742707 140297328059584 submission_runner.py:469] Time since start: 25240.32s, 	Step: 7060, 	{'train/loss': 0.12070242487737592, 'validation/loss': 0.12393014057481347, 'validation/num_examples': 83274637, 'test/loss': 0.12627194285567434, 'test/num_examples': 95000000, 'score': 6406.465177774429, 'total_duration': 25240.31740117073, 'accumulated_submission_time': 6406.465177774429, 'accumulated_eval_time': 18832.05512571335, 'accumulated_logging_time': 1.2728314399719238}
I0306 19:54:28.752290 140144422143744 logging_writer.py:48] [7060] accumulated_eval_time=18832.1, accumulated_logging_time=1.27283, accumulated_submission_time=6406.47, global_step=7060, preemption_count=0, score=6406.47, test/loss=0.126272, test/num_examples=95000000, total_duration=25240.3, train/loss=0.120702, validation/loss=0.12393, validation/num_examples=83274637
I0306 19:54:46.468765 140144430536448 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.006630140822380781, loss=0.1265607625246048
I0306 19:56:29.781008 140297328059584 spec.py:321] Evaluating on the training split.
I0306 20:00:28.567258 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 20:00:35.669309 140297328059584 spec.py:349] Evaluating on the test split.
I0306 20:00:44.262555 140297328059584 submission_runner.py:469] Time since start: 25615.84s, 	Step: 7190, 	{'train/loss': 0.12403063654149853, 'validation/loss': 0.12394785645153503, 'validation/num_examples': 83274637, 'test/loss': 0.12623032284128288, 'test/num_examples': 95000000, 'score': 6527.478362083435, 'total_duration': 25615.837240695953, 'accumulated_submission_time': 6527.478362083435, 'accumulated_eval_time': 19086.536630392075, 'accumulated_logging_time': 1.2881660461425781}
I0306 20:00:44.290465 140144422143744 logging_writer.py:48] [7190] accumulated_eval_time=19086.5, accumulated_logging_time=1.28817, accumulated_submission_time=6527.48, global_step=7190, preemption_count=0, score=6527.48, test/loss=0.12623, test/num_examples=95000000, total_duration=25615.8, train/loss=0.124031, validation/loss=0.123948, validation/num_examples=83274637
I0306 20:00:45.423602 140144430536448 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.010962911881506443, loss=0.12026320397853851
I0306 20:02:16.059992 140144422143744 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.009144306182861328, loss=0.12058395892381668
I0306 20:02:44.541699 140297328059584 spec.py:321] Evaluating on the training split.
I0306 20:06:48.246922 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 20:06:55.392867 140297328059584 spec.py:349] Evaluating on the test split.
I0306 20:07:03.963929 140297328059584 submission_runner.py:469] Time since start: 25995.54s, 	Step: 7326, 	{'train/loss': 0.12415979073951079, 'validation/loss': 0.12382311867376408, 'validation/num_examples': 83274637, 'test/loss': 0.12609636374383223, 'test/num_examples': 95000000, 'score': 6647.713103055954, 'total_duration': 25995.538591623306, 'accumulated_submission_time': 6647.713103055954, 'accumulated_eval_time': 19345.958792209625, 'accumulated_logging_time': 1.3223984241485596}
I0306 20:07:03.982397 140144430536448 logging_writer.py:48] [7326] accumulated_eval_time=19346, accumulated_logging_time=1.3224, accumulated_submission_time=6647.71, global_step=7326, preemption_count=0, score=6647.71, test/loss=0.126096, test/num_examples=95000000, total_duration=25995.5, train/loss=0.12416, validation/loss=0.123823, validation/num_examples=83274637
I0306 20:08:02.050822 140144422143744 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.005549033638089895, loss=0.12215147167444229
I0306 20:09:04.024544 140297328059584 spec.py:321] Evaluating on the training split.
I0306 20:13:05.206276 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 20:13:12.301668 140297328059584 spec.py:349] Evaluating on the test split.
I0306 20:13:20.934922 140297328059584 submission_runner.py:469] Time since start: 26372.51s, 	Step: 7455, 	{'train/loss': 0.12406818785429376, 'validation/loss': 0.1239211624463273, 'validation/num_examples': 83274637, 'test/loss': 0.12619554462376645, 'test/num_examples': 95000000, 'score': 6767.724573373795, 'total_duration': 26372.50960278511, 'accumulated_submission_time': 6767.724573373795, 'accumulated_eval_time': 19602.869124412537, 'accumulated_logging_time': 1.3599214553833008}
I0306 20:13:20.944720 140144430536448 logging_writer.py:48] [7455] accumulated_eval_time=19602.9, accumulated_logging_time=1.35992, accumulated_submission_time=6767.72, global_step=7455, preemption_count=0, score=6767.72, test/loss=0.126196, test/num_examples=95000000, total_duration=26372.5, train/loss=0.124068, validation/loss=0.123921, validation/num_examples=83274637
I0306 20:13:44.274743 140144422143744 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.008284598588943481, loss=0.12385749816894531
I0306 20:15:21.383534 140297328059584 spec.py:321] Evaluating on the training split.
I0306 20:19:16.118214 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 20:19:23.284028 140297328059584 spec.py:349] Evaluating on the test split.
I0306 20:19:31.837490 140297328059584 submission_runner.py:469] Time since start: 26743.41s, 	Step: 7585, 	{'train/loss': 0.12225502001929958, 'validation/loss': 0.12379609389651257, 'validation/num_examples': 83274637, 'test/loss': 0.1260547798622533, 'test/num_examples': 95000000, 'score': 6888.147087574005, 'total_duration': 26743.412158966064, 'accumulated_submission_time': 6888.147087574005, 'accumulated_eval_time': 19853.323021650314, 'accumulated_logging_time': 1.3760862350463867}
I0306 20:19:31.849083 140144430536448 logging_writer.py:48] [7585] accumulated_eval_time=19853.3, accumulated_logging_time=1.37609, accumulated_submission_time=6888.15, global_step=7585, preemption_count=0, score=6888.15, test/loss=0.126055, test/num_examples=95000000, total_duration=26743.4, train/loss=0.122255, validation/loss=0.123796, validation/num_examples=83274637
I0306 20:19:33.504354 140144422143744 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.01288321428000927, loss=0.11972162127494812
I0306 20:21:21.874677 140144430536448 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.00783624965697527, loss=0.12052293121814728
I0306 20:21:32.336972 140297328059584 spec.py:321] Evaluating on the training split.
I0306 20:25:35.703558 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 20:25:42.782017 140297328059584 spec.py:349] Evaluating on the test split.
I0306 20:25:51.172325 140297328059584 submission_runner.py:469] Time since start: 27122.75s, 	Step: 7710, 	{'train/loss': 0.12037444030338863, 'validation/loss': 0.12385859118443042, 'validation/num_examples': 83274637, 'test/loss': 0.12613770321751644, 'test/num_examples': 95000000, 'score': 7008.618648529053, 'total_duration': 27122.74698615074, 'accumulated_submission_time': 7008.618648529053, 'accumulated_eval_time': 20112.158304929733, 'accumulated_logging_time': 1.3942656517028809}
I0306 20:25:51.184951 140144422143744 logging_writer.py:48] [7710] accumulated_eval_time=20112.2, accumulated_logging_time=1.39427, accumulated_submission_time=7008.62, global_step=7710, preemption_count=0, score=7008.62, test/loss=0.126138, test/num_examples=95000000, total_duration=27122.7, train/loss=0.120374, validation/loss=0.123859, validation/num_examples=83274637
I0306 20:27:05.146704 140144430536448 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.008826181292533875, loss=0.11885644495487213
I0306 20:27:51.288165 140297328059584 spec.py:321] Evaluating on the training split.
I0306 20:31:45.743459 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 20:31:52.897222 140297328059584 spec.py:349] Evaluating on the test split.
I0306 20:32:01.450790 140297328059584 submission_runner.py:469] Time since start: 27493.03s, 	Step: 7844, 	{'train/loss': 0.12178445018171889, 'validation/loss': 0.12387356153943667, 'validation/num_examples': 83274637, 'test/loss': 0.12618381217105262, 'test/num_examples': 95000000, 'score': 7128.705009222031, 'total_duration': 27493.025454044342, 'accumulated_submission_time': 7128.705009222031, 'accumulated_eval_time': 20362.320864915848, 'accumulated_logging_time': 1.4134676456451416}
I0306 20:32:01.471500 140144422143744 logging_writer.py:48] [7844] accumulated_eval_time=20362.3, accumulated_logging_time=1.41347, accumulated_submission_time=7128.71, global_step=7844, preemption_count=0, score=7128.71, test/loss=0.126184, test/num_examples=95000000, total_duration=27493, train/loss=0.121784, validation/loss=0.123874, validation/num_examples=83274637
I0306 20:32:36.860635 140144430536448 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.005284349899739027, loss=0.12013629078865051
I0306 20:34:02.945528 140297328059584 spec.py:321] Evaluating on the training split.
I0306 20:37:50.770349 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 20:37:57.996134 140297328059584 spec.py:349] Evaluating on the test split.
I0306 20:38:06.484079 140297328059584 submission_runner.py:469] Time since start: 27858.06s, 	Step: 7974, 	{'train/loss': 0.1216661118369245, 'validation/loss': 0.12382509147347363, 'validation/num_examples': 83274637, 'test/loss': 0.1261137941303454, 'test/num_examples': 95000000, 'score': 7250.145509004593, 'total_duration': 27858.058771133423, 'accumulated_submission_time': 7250.145509004593, 'accumulated_eval_time': 20605.85937809944, 'accumulated_logging_time': 1.4582197666168213}
I0306 20:38:06.503956 140144422143744 logging_writer.py:48] [7974] accumulated_eval_time=20605.9, accumulated_logging_time=1.45822, accumulated_submission_time=7250.15, global_step=7974, preemption_count=0, score=7250.15, test/loss=0.126114, test/num_examples=95000000, total_duration=27858.1, train/loss=0.121666, validation/loss=0.123825, validation/num_examples=83274637
I0306 20:38:09.353433 140144430536448 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.009435438551008701, loss=0.1211315467953682
I0306 20:40:02.913541 140144422143744 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.0059990109875798225, loss=0.1199837401509285
I0306 20:40:07.619728 140297328059584 spec.py:321] Evaluating on the training split.
I0306 20:44:02.257363 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 20:44:09.462585 140297328059584 spec.py:349] Evaluating on the test split.
I0306 20:44:17.950768 140297328059584 submission_runner.py:469] Time since start: 28229.53s, 	Step: 8105, 	{'train/loss': 0.122281786698684, 'validation/loss': 0.12373731599399114, 'validation/num_examples': 83274637, 'test/loss': 0.125995873488898, 'test/num_examples': 95000000, 'score': 7371.243496179581, 'total_duration': 28229.52544260025, 'accumulated_submission_time': 7371.243496179581, 'accumulated_eval_time': 20856.190372228622, 'accumulated_logging_time': 1.485053300857544}
I0306 20:44:17.962291 140144430536448 logging_writer.py:48] [8105] accumulated_eval_time=20856.2, accumulated_logging_time=1.48505, accumulated_submission_time=7371.24, global_step=8105, preemption_count=0, score=7371.24, test/loss=0.125996, test/num_examples=95000000, total_duration=28229.5, train/loss=0.122282, validation/loss=0.123737, validation/num_examples=83274637
I0306 20:45:43.818264 140144422143744 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.0121306786313653, loss=0.12625938653945923
I0306 20:46:18.223672 140297328059584 spec.py:321] Evaluating on the training split.
I0306 20:50:10.101841 140297328059584 spec.py:333] Evaluating on the validation split.
I0306 20:50:17.234741 140297328059584 spec.py:349] Evaluating on the test split.
I0306 20:50:25.719788 140297328059584 submission_runner.py:469] Time since start: 28597.29s, 	Step: 8231, 	{'train/loss': 0.12260836693194677, 'validation/loss': 0.12368094837315044, 'validation/num_examples': 83274637, 'test/loss': 0.12597771477179276, 'test/num_examples': 95000000, 'score': 7491.487124443054, 'total_duration': 28597.294452905655, 'accumulated_submission_time': 7491.487124443054, 'accumulated_eval_time': 21103.68643474579, 'accumulated_logging_time': 1.5033371448516846}
I0306 20:50:25.730063 140144430536448 logging_writer.py:48] [8231] accumulated_eval_time=21103.7, accumulated_logging_time=1.50334, accumulated_submission_time=7491.49, global_step=8231, preemption_count=0, score=7491.49, test/loss=0.125978, test/num_examples=95000000, total_duration=28597.3, train/loss=0.122608, validation/loss=0.123681, validation/num_examples=83274637
I0306 20:50:25.777573 140144422143744 logging_writer.py:48] [8231] global_step=8231, preemption_count=0, score=7491.49
I0306 20:50:26.938301 140297328059584 submission_runner.py:646] Tuning trial 5/5
I0306 20:50:26.946434 140297328059584 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.1, label_smoothing=0.0, learning_rate=0.0017486387539278373, one_minus_beta1=0.06733926164, beta2=0.9955159689799007, weight_decay=0.08121616522670176, warmup_factor=0.02)
I0306 20:50:26.947273 140297328059584 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/loss': 1.0055958090713188, 'validation/loss': 1.0030629643235491, 'validation/num_examples': 83274637, 'test/loss': 1.0034042074835525, 'test/num_examples': 95000000, 'score': 13.051947832107544, 'total_duration': 1111.2627458572388, 'accumulated_submission_time': 13.051947832107544, 'accumulated_eval_time': 1098.2107038497925, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (139, {'train/loss': 0.12803163627783457, 'validation/loss': 0.12891191217568743, 'validation/num_examples': 83274637, 'test/loss': 0.13162581283922697, 'test/num_examples': 95000000, 'score': 134.01795959472656, 'total_duration': 2203.7670936584473, 'accumulated_submission_time': 134.01795959472656, 'accumulated_eval_time': 2069.7283041477203, 'accumulated_logging_time': 0.013879537582397461, 'global_step': 139, 'preemption_count': 0}), (276, {'train/loss': 0.1275811255587347, 'validation/loss': 0.12935901662764077, 'validation/num_examples': 83274637, 'test/loss': 0.13162962199835526, 'test/num_examples': 95000000, 'score': 254.76304364204407, 'total_duration': 3269.067539215088, 'accumulated_submission_time': 254.76304364204407, 'accumulated_eval_time': 3014.262671470642, 'accumulated_logging_time': 0.027640819549560547, 'global_step': 276, 'preemption_count': 0}), (405, {'train/loss': 0.12374780371597728, 'validation/loss': 0.12716473249818286, 'validation/num_examples': 83274637, 'test/loss': 0.1297860095703125, 'test/num_examples': 95000000, 'score': 375.5727803707123, 'total_duration': 4305.135348320007, 'accumulated_submission_time': 375.5727803707123, 'accumulated_eval_time': 3929.5003674030304, 'accumulated_logging_time': 0.04150056838989258, 'global_step': 405, 'preemption_count': 0}), (540, {'train/loss': 0.12625863175815757, 'validation/loss': 0.12730725447423558, 'validation/num_examples': 83274637, 'test/loss': 0.12997460725740131, 'test/num_examples': 95000000, 'score': 495.7154083251953, 'total_duration': 5335.958525419235, 'accumulated_submission_time': 495.7154083251953, 'accumulated_eval_time': 4840.159585475922, 'accumulated_logging_time': 0.055899858474731445, 'global_step': 540, 'preemption_count': 0}), (681, {'train/loss': 0.1273639723072824, 'validation/loss': 0.12647893015817424, 'validation/num_examples': 83274637, 'test/loss': 0.12910336900699013, 'test/num_examples': 95000000, 'score': 616.2423434257507, 'total_duration': 6299.352402448654, 'accumulated_submission_time': 616.2423434257507, 'accumulated_eval_time': 5683.00533747673, 'accumulated_logging_time': 0.06948733329772949, 'global_step': 681, 'preemption_count': 0}), (822, {'train/loss': 0.12710321955851414, 'validation/loss': 0.12663667134811218, 'validation/num_examples': 83274637, 'test/loss': 0.12907645984786184, 'test/num_examples': 95000000, 'score': 736.8691575527191, 'total_duration': 7250.229130029678, 'accumulated_submission_time': 736.8691575527191, 'accumulated_eval_time': 6513.232754945755, 'accumulated_logging_time': 0.08390951156616211, 'global_step': 822, 'preemption_count': 0}), (960, {'train/loss': 0.12728949473385917, 'validation/loss': 0.12647431275353382, 'validation/num_examples': 83274637, 'test/loss': 0.12873525131578947, 'test/num_examples': 95000000, 'score': 856.9480307102203, 'total_duration': 8120.395741939545, 'accumulated_submission_time': 856.9480307102203, 'accumulated_eval_time': 7263.2999629974365, 'accumulated_logging_time': 0.09714913368225098, 'global_step': 960, 'preemption_count': 0}), (1102, {'train/loss': 0.12269578105623617, 'validation/loss': 0.1260379391489797, 'validation/num_examples': 83274637, 'test/loss': 0.1282419902549342, 'test/num_examples': 95000000, 'score': 977.4055080413818, 'total_duration': 8824.580132484436, 'accumulated_submission_time': 977.4055080413818, 'accumulated_eval_time': 7846.9824895858765, 'accumulated_logging_time': 0.13350343704223633, 'global_step': 1102, 'preemption_count': 0}), (1243, {'train/loss': 0.1253976691631401, 'validation/loss': 0.12603911894481976, 'validation/num_examples': 83274637, 'test/loss': 0.12829449104646382, 'test/num_examples': 95000000, 'score': 1098.2026779651642, 'total_duration': 9200.195816755295, 'accumulated_submission_time': 1098.2026779651642, 'accumulated_eval_time': 8101.77826333046, 'accumulated_logging_time': 0.14707422256469727, 'global_step': 1243, 'preemption_count': 0}), (1374, {'train/loss': 0.12363157937970926, 'validation/loss': 0.12601557431023386, 'validation/num_examples': 83274637, 'test/loss': 0.1284143660053454, 'test/num_examples': 95000000, 'score': 1218.990701675415, 'total_duration': 9563.689676761627, 'accumulated_submission_time': 1218.990701675415, 'accumulated_eval_time': 8344.423448324203, 'accumulated_logging_time': 0.19753289222717285, 'global_step': 1374, 'preemption_count': 0}), (1506, {'train/loss': 0.12349414165899064, 'validation/loss': 0.1257275935923342, 'validation/num_examples': 83274637, 'test/loss': 0.12809038467310854, 'test/num_examples': 95000000, 'score': 1339.879158258438, 'total_duration': 9923.663565158844, 'accumulated_submission_time': 1339.879158258438, 'accumulated_eval_time': 8583.485314846039, 'accumulated_logging_time': 0.2114725112915039, 'global_step': 1506, 'preemption_count': 0}), (1641, {'train/loss': 0.12387009458206359, 'validation/loss': 0.12618281930360778, 'validation/num_examples': 83274637, 'test/loss': 0.12891717883429277, 'test/num_examples': 95000000, 'score': 1460.3339281082153, 'total_duration': 10282.169552326202, 'accumulated_submission_time': 1460.3339281082153, 'accumulated_eval_time': 8821.510222911835, 'accumulated_logging_time': 0.22738981246948242, 'global_step': 1641, 'preemption_count': 0}), (1774, {'train/loss': 0.12651645252773971, 'validation/loss': 0.12577666707159627, 'validation/num_examples': 83274637, 'test/loss': 0.12824076222245065, 'test/num_examples': 95000000, 'score': 1581.3100872039795, 'total_duration': 10639.816109895706, 'accumulated_submission_time': 1581.3100872039795, 'accumulated_eval_time': 9058.156069040298, 'accumulated_logging_time': 0.24125337600708008, 'global_step': 1774, 'preemption_count': 0}), (1907, {'train/loss': 0.12487933698034137, 'validation/loss': 0.12573163068588528, 'validation/num_examples': 83274637, 'test/loss': 0.12817673513569078, 'test/num_examples': 95000000, 'score': 1703.0959944725037, 'total_duration': 10998.04880785942, 'accumulated_submission_time': 1703.0959944725037, 'accumulated_eval_time': 9294.579595088959, 'accumulated_logging_time': 0.2551994323730469, 'global_step': 1907, 'preemption_count': 0}), (2041, {'train/loss': 0.12563810210510995, 'validation/loss': 0.12541683363247316, 'validation/num_examples': 83274637, 'test/loss': 0.1278120154296875, 'test/num_examples': 95000000, 'score': 1824.6810491085052, 'total_duration': 11354.362147808075, 'accumulated_submission_time': 1824.6810491085052, 'accumulated_eval_time': 9529.283356666565, 'accumulated_logging_time': 0.26982927322387695, 'global_step': 2041, 'preemption_count': 0}), (2170, {'train/loss': 0.12292043451196367, 'validation/loss': 0.12521289812599432, 'validation/num_examples': 83274637, 'test/loss': 0.1274491687294408, 'test/num_examples': 95000000, 'score': 1945.6395905017853, 'total_duration': 11714.30089354515, 'accumulated_submission_time': 1945.6395905017853, 'accumulated_eval_time': 9768.23926615715, 'accumulated_logging_time': 0.2843194007873535, 'global_step': 2170, 'preemption_count': 0}), (2303, {'train/loss': 0.12465287460330522, 'validation/loss': 0.12484877368596335, 'validation/num_examples': 83274637, 'test/loss': 0.12713976009457237, 'test/num_examples': 95000000, 'score': 2066.001902103424, 'total_duration': 12073.936526298523, 'accumulated_submission_time': 2066.001902103424, 'accumulated_eval_time': 10007.488744974136, 'accumulated_logging_time': 0.2986934185028076, 'global_step': 2303, 'preemption_count': 0}), (2434, {'train/loss': 0.1222647784875249, 'validation/loss': 0.12522222898535046, 'validation/num_examples': 83274637, 'test/loss': 0.12770247141241775, 'test/num_examples': 95000000, 'score': 2186.6371216773987, 'total_duration': 12433.476676940918, 'accumulated_submission_time': 2186.6371216773987, 'accumulated_eval_time': 10246.370046138763, 'accumulated_logging_time': 0.3126239776611328, 'global_step': 2434, 'preemption_count': 0}), (2565, {'train/loss': 0.12399247347277666, 'validation/loss': 0.1251539743394686, 'validation/num_examples': 83274637, 'test/loss': 0.12740302118626645, 'test/num_examples': 95000000, 'score': 2307.1562666893005, 'total_duration': 12788.833476781845, 'accumulated_submission_time': 2307.1562666893005, 'accumulated_eval_time': 10481.183246850967, 'accumulated_logging_time': 0.32639360427856445, 'global_step': 2565, 'preemption_count': 0}), (2694, {'train/loss': 0.12208010538615896, 'validation/loss': 0.12483705051656928, 'validation/num_examples': 83274637, 'test/loss': 0.1273063630653783, 'test/num_examples': 95000000, 'score': 2427.916276693344, 'total_duration': 13147.157210111618, 'accumulated_submission_time': 2427.916276693344, 'accumulated_eval_time': 10718.722277641296, 'accumulated_logging_time': 0.34047412872314453, 'global_step': 2694, 'preemption_count': 0}), (2827, {'train/loss': 0.12306471069419533, 'validation/loss': 0.12489181123800261, 'validation/num_examples': 83274637, 'test/loss': 0.12722484136513157, 'test/num_examples': 95000000, 'score': 2547.844516515732, 'total_duration': 13505.694687366486, 'accumulated_submission_time': 2547.844516515732, 'accumulated_eval_time': 10957.252294063568, 'accumulated_logging_time': 0.40915536880493164, 'global_step': 2827, 'preemption_count': 0}), (2957, {'train/loss': 0.12321453090499407, 'validation/loss': 0.12492303737489761, 'validation/num_examples': 83274637, 'test/loss': 0.12723677593544408, 'test/num_examples': 95000000, 'score': 2668.749763250351, 'total_duration': 13862.026475429535, 'accumulated_submission_time': 2668.749763250351, 'accumulated_eval_time': 11192.653333425522, 'accumulated_logging_time': 0.4252028465270996, 'global_step': 2957, 'preemption_count': 0}), (3091, {'train/loss': 0.12523626700137397, 'validation/loss': 0.12487507643120978, 'validation/num_examples': 83274637, 'test/loss': 0.12718088782894738, 'test/num_examples': 95000000, 'score': 2789.315085172653, 'total_duration': 14221.023752689362, 'accumulated_submission_time': 2789.315085172653, 'accumulated_eval_time': 11431.035290718079, 'accumulated_logging_time': 0.4651319980621338, 'global_step': 3091, 'preemption_count': 0}), (3220, {'train/loss': 0.12421269550825814, 'validation/loss': 0.12461929196710653, 'validation/num_examples': 83274637, 'test/loss': 0.1270322575760691, 'test/num_examples': 95000000, 'score': 2909.9900612831116, 'total_duration': 14578.576260328293, 'accumulated_submission_time': 2909.9900612831116, 'accumulated_eval_time': 11667.887652635574, 'accumulated_logging_time': 0.47937560081481934, 'global_step': 3220, 'preemption_count': 0}), (3355, {'train/loss': 0.12369132970910778, 'validation/loss': 0.12457947874473697, 'validation/num_examples': 83274637, 'test/loss': 0.12695622709703946, 'test/num_examples': 95000000, 'score': 3030.2080039978027, 'total_duration': 14939.587269544601, 'accumulated_submission_time': 3030.2080039978027, 'accumulated_eval_time': 11908.65531539917, 'accumulated_logging_time': 0.49373841285705566, 'global_step': 3355, 'preemption_count': 0}), (3488, {'train/loss': 0.12418977893982669, 'validation/loss': 0.1243889910814209, 'validation/num_examples': 83274637, 'test/loss': 0.12672019994860198, 'test/num_examples': 95000000, 'score': 3150.261655330658, 'total_duration': 15296.569487810135, 'accumulated_submission_time': 3150.261655330658, 'accumulated_eval_time': 12145.559345006943, 'accumulated_logging_time': 0.5084018707275391, 'global_step': 3488, 'preemption_count': 0}), (3623, {'train/loss': 0.1243354635043714, 'validation/loss': 0.12462082098157705, 'validation/num_examples': 83274637, 'test/loss': 0.12695898432360198, 'test/num_examples': 95000000, 'score': 3270.314610719681, 'total_duration': 15664.660328865051, 'accumulated_submission_time': 3270.314610719681, 'accumulated_eval_time': 12393.571444511414, 'accumulated_logging_time': 0.5223855972290039, 'global_step': 3623, 'preemption_count': 0}), (3756, {'train/loss': 0.12444046873060412, 'validation/loss': 0.12450998716902242, 'validation/num_examples': 83274637, 'test/loss': 0.12682162776521383, 'test/num_examples': 95000000, 'score': 3390.644497871399, 'total_duration': 16036.96407365799, 'accumulated_submission_time': 3390.644497871399, 'accumulated_eval_time': 12645.463589429855, 'accumulated_logging_time': 0.5936586856842041, 'global_step': 3756, 'preemption_count': 0}), (3892, {'train/loss': 0.12260062443151039, 'validation/loss': 0.12458397260532715, 'validation/num_examples': 83274637, 'test/loss': 0.12708308637952304, 'test/num_examples': 95000000, 'score': 3512.407565832138, 'total_duration': 16403.500685691833, 'accumulated_submission_time': 3512.407565832138, 'accumulated_eval_time': 12890.212359905243, 'accumulated_logging_time': 0.607527494430542, 'global_step': 3892, 'preemption_count': 0}), (4023, {'train/loss': 0.12294040500836552, 'validation/loss': 0.1245512149561085, 'validation/num_examples': 83274637, 'test/loss': 0.12688287624383224, 'test/num_examples': 95000000, 'score': 3632.4745349884033, 'total_duration': 16778.90229988098, 'accumulated_submission_time': 3632.4745349884033, 'accumulated_eval_time': 13145.522379159927, 'accumulated_logging_time': 0.6216855049133301, 'global_step': 4023, 'preemption_count': 0}), (4159, {'train/loss': 0.12469953004528517, 'validation/loss': 0.1248084668502893, 'validation/num_examples': 83274637, 'test/loss': 0.12718039888980262, 'test/num_examples': 95000000, 'score': 3752.6994366645813, 'total_duration': 17133.813440084457, 'accumulated_submission_time': 3752.6994366645813, 'accumulated_eval_time': 13380.157555818558, 'accumulated_logging_time': 0.6613891124725342, 'global_step': 4159, 'preemption_count': 0}), (4294, {'train/loss': 0.12214228706492943, 'validation/loss': 0.12465372504837893, 'validation/num_examples': 83274637, 'test/loss': 0.12705352816611842, 'test/num_examples': 95000000, 'score': 3873.2019741535187, 'total_duration': 17496.80033683777, 'accumulated_submission_time': 3873.2019741535187, 'accumulated_eval_time': 13622.615884065628, 'accumulated_logging_time': 0.6768202781677246, 'global_step': 4294, 'preemption_count': 0}), (4426, {'train/loss': 0.12377210323400092, 'validation/loss': 0.12437510918643738, 'validation/num_examples': 83274637, 'test/loss': 0.12674171805098683, 'test/num_examples': 95000000, 'score': 3994.036600828171, 'total_duration': 17862.401925086975, 'accumulated_submission_time': 3994.036600828171, 'accumulated_eval_time': 13867.358794212341, 'accumulated_logging_time': 0.6909189224243164, 'global_step': 4426, 'preemption_count': 0}), (4555, {'train/loss': 0.12417121373304406, 'validation/loss': 0.12442230821455914, 'validation/num_examples': 83274637, 'test/loss': 0.12683432771381578, 'test/num_examples': 95000000, 'score': 4114.113206148148, 'total_duration': 18220.492697000504, 'accumulated_submission_time': 4114.113206148148, 'accumulated_eval_time': 14105.34665465355, 'accumulated_logging_time': 0.705838680267334, 'global_step': 4555, 'preemption_count': 0}), (4686, {'train/loss': 0.12288243913987898, 'validation/loss': 0.12434627151312103, 'validation/num_examples': 83274637, 'test/loss': 0.12658879933182565, 'test/num_examples': 95000000, 'score': 4234.517445325851, 'total_duration': 18576.904880285263, 'accumulated_submission_time': 4234.517445325851, 'accumulated_eval_time': 14341.307885408401, 'accumulated_logging_time': 0.7416894435882568, 'global_step': 4686, 'preemption_count': 0}), (4820, {'train/loss': 0.12169555473908689, 'validation/loss': 0.12440474033856716, 'validation/num_examples': 83274637, 'test/loss': 0.1267647280838816, 'test/num_examples': 95000000, 'score': 4355.565670251846, 'total_duration': 18945.029086112976, 'accumulated_submission_time': 4355.565670251846, 'accumulated_eval_time': 14588.356337070465, 'accumulated_logging_time': 0.7590618133544922, 'global_step': 4820, 'preemption_count': 0}), (4952, {'train/loss': 0.12018597293527997, 'validation/loss': 0.12435859268966253, 'validation/num_examples': 83274637, 'test/loss': 0.1267597370888158, 'test/num_examples': 95000000, 'score': 4476.217046022415, 'total_duration': 19316.200394153595, 'accumulated_submission_time': 4476.217046022415, 'accumulated_eval_time': 14838.85061955452, 'accumulated_logging_time': 0.7745811939239502, 'global_step': 4952, 'preemption_count': 0}), (5088, {'train/loss': 0.12336215602948605, 'validation/loss': 0.12439137241497747, 'validation/num_examples': 83274637, 'test/loss': 0.12672934497327304, 'test/num_examples': 95000000, 'score': 4596.596885442734, 'total_duration': 19687.68613767624, 'accumulated_submission_time': 4596.596885442734, 'accumulated_eval_time': 15089.88978099823, 'accumulated_logging_time': 0.829240083694458, 'global_step': 5088, 'preemption_count': 0}), (5219, {'train/loss': 0.12116270859099035, 'validation/loss': 0.12442855942623135, 'validation/num_examples': 83274637, 'test/loss': 0.12668526418585527, 'test/num_examples': 95000000, 'score': 4716.696996927261, 'total_duration': 20061.490166187286, 'accumulated_submission_time': 4716.696996927261, 'accumulated_eval_time': 15343.557789802551, 'accumulated_logging_time': 0.854938268661499, 'global_step': 5219, 'preemption_count': 0}), (5352, {'train/loss': 0.12112950445767844, 'validation/loss': 0.1243879166234481, 'validation/num_examples': 83274637, 'test/loss': 0.12668755268297696, 'test/num_examples': 95000000, 'score': 4836.719299077988, 'total_duration': 20432.517562389374, 'accumulated_submission_time': 4836.719299077988, 'accumulated_eval_time': 15594.534707546234, 'accumulated_logging_time': 0.8722660541534424, 'global_step': 5352, 'preemption_count': 0}), (5481, {'train/loss': 0.12271321839037931, 'validation/loss': 0.12430029521928634, 'validation/num_examples': 83274637, 'test/loss': 0.1266145986430921, 'test/num_examples': 95000000, 'score': 4957.732013702393, 'total_duration': 20801.037008285522, 'accumulated_submission_time': 4957.732013702393, 'accumulated_eval_time': 15842.013211727142, 'accumulated_logging_time': 0.8899929523468018, 'global_step': 5481, 'preemption_count': 0}), (5615, {'train/loss': 0.12255451996933739, 'validation/loss': 0.1243210344423169, 'validation/num_examples': 83274637, 'test/loss': 0.1266459945620888, 'test/num_examples': 95000000, 'score': 5078.940350055695, 'total_duration': 21180.378577947617, 'accumulated_submission_time': 5078.940350055695, 'accumulated_eval_time': 16100.103604793549, 'accumulated_logging_time': 0.9224791526794434, 'global_step': 5615, 'preemption_count': 0}), (5749, {'train/loss': 0.12309719475700795, 'validation/loss': 0.12407539415848415, 'validation/num_examples': 83274637, 'test/loss': 0.12642385478001644, 'test/num_examples': 95000000, 'score': 5199.336631059647, 'total_duration': 21550.703128814697, 'accumulated_submission_time': 5199.336631059647, 'accumulated_eval_time': 16350.004873275757, 'accumulated_logging_time': 0.9385032653808594, 'global_step': 5749, 'preemption_count': 0}), (5883, {'train/loss': 0.12253716378326311, 'validation/loss': 0.12438904102675644, 'validation/num_examples': 83274637, 'test/loss': 0.1267537851665296, 'test/num_examples': 95000000, 'score': 5320.088996648788, 'total_duration': 21922.59902358055, 'accumulated_submission_time': 5320.088996648788, 'accumulated_eval_time': 16601.123138666153, 'accumulated_logging_time': 0.9532616138458252, 'global_step': 5883, 'preemption_count': 0}), (6017, {'train/loss': 0.12371699168762695, 'validation/loss': 0.12418183324472755, 'validation/num_examples': 83274637, 'test/loss': 0.1266114693256579, 'test/num_examples': 95000000, 'score': 5440.556627750397, 'total_duration': 22287.17061829567, 'accumulated_submission_time': 5440.556627750397, 'accumulated_eval_time': 16845.14606308937, 'accumulated_logging_time': 1.024336338043213, 'global_step': 6017, 'preemption_count': 0}), (6148, {'train/loss': 0.12374170505260147, 'validation/loss': 0.12408645483390286, 'validation/num_examples': 83274637, 'test/loss': 0.12641451487458882, 'test/num_examples': 95000000, 'score': 5560.942054033279, 'total_duration': 22662.618089914322, 'accumulated_submission_time': 5560.942054033279, 'accumulated_eval_time': 17100.181215286255, 'accumulated_logging_time': 1.0410521030426025, 'global_step': 6148, 'preemption_count': 0}), (6278, {'train/loss': 0.12233605647002752, 'validation/loss': 0.12406516682784932, 'validation/num_examples': 83274637, 'test/loss': 0.12628427745682566, 'test/num_examples': 95000000, 'score': 5681.332220315933, 'total_duration': 23023.016587734222, 'accumulated_submission_time': 5681.332220315933, 'accumulated_eval_time': 17340.112494945526, 'accumulated_logging_time': 1.1083061695098877, 'global_step': 6278, 'preemption_count': 0}), (6401, {'train/loss': 0.12244254171426566, 'validation/loss': 0.12413853091439324, 'validation/num_examples': 83274637, 'test/loss': 0.12645147837171053, 'test/num_examples': 95000000, 'score': 5801.614855527878, 'total_duration': 23387.310149669647, 'accumulated_submission_time': 5801.614855527878, 'accumulated_eval_time': 17584.09576511383, 'accumulated_logging_time': 1.1268351078033447, 'global_step': 6401, 'preemption_count': 0}), (6532, {'train/loss': 0.11959335002931035, 'validation/loss': 0.12412106536829043, 'validation/num_examples': 83274637, 'test/loss': 0.1264286463199013, 'test/num_examples': 95000000, 'score': 5922.96987247467, 'total_duration': 23752.73962855339, 'accumulated_submission_time': 5922.96987247467, 'accumulated_eval_time': 17828.111590862274, 'accumulated_logging_time': 1.174377679824829, 'global_step': 6532, 'preemption_count': 0}), (6662, {'train/loss': 0.12142501286459419, 'validation/loss': 0.12396547918647975, 'validation/num_examples': 83274637, 'test/loss': 0.12633042135074013, 'test/num_examples': 95000000, 'score': 6044.42129945755, 'total_duration': 24121.89791536331, 'accumulated_submission_time': 6044.42129945755, 'accumulated_eval_time': 18075.7935423851, 'accumulated_logging_time': 1.190136432647705, 'global_step': 6662, 'preemption_count': 0}), (6796, {'train/loss': 0.12201318811367518, 'validation/loss': 0.12394417900192634, 'validation/num_examples': 83274637, 'test/loss': 0.12625128408717104, 'test/num_examples': 95000000, 'score': 6165.148801803589, 'total_duration': 24493.832753181458, 'accumulated_submission_time': 6165.148801803589, 'accumulated_eval_time': 18326.97283101082, 'accumulated_logging_time': 1.2083868980407715, 'global_step': 6796, 'preemption_count': 0}), (6930, {'train/loss': 0.12420260279480391, 'validation/loss': 0.12382429438274113, 'validation/num_examples': 83274637, 'test/loss': 0.12610550717516447, 'test/num_examples': 95000000, 'score': 6285.4327046871185, 'total_duration': 24870.968617916107, 'accumulated_submission_time': 6285.4327046871185, 'accumulated_eval_time': 18583.765906095505, 'accumulated_logging_time': 1.2559783458709717, 'global_step': 6930, 'preemption_count': 0}), (7060, {'train/loss': 0.12070242487737592, 'validation/loss': 0.12393014057481347, 'validation/num_examples': 83274637, 'test/loss': 0.12627194285567434, 'test/num_examples': 95000000, 'score': 6406.465177774429, 'total_duration': 25240.31740117073, 'accumulated_submission_time': 6406.465177774429, 'accumulated_eval_time': 18832.05512571335, 'accumulated_logging_time': 1.2728314399719238, 'global_step': 7060, 'preemption_count': 0}), (7190, {'train/loss': 0.12403063654149853, 'validation/loss': 0.12394785645153503, 'validation/num_examples': 83274637, 'test/loss': 0.12623032284128288, 'test/num_examples': 95000000, 'score': 6527.478362083435, 'total_duration': 25615.837240695953, 'accumulated_submission_time': 6527.478362083435, 'accumulated_eval_time': 19086.536630392075, 'accumulated_logging_time': 1.2881660461425781, 'global_step': 7190, 'preemption_count': 0}), (7326, {'train/loss': 0.12415979073951079, 'validation/loss': 0.12382311867376408, 'validation/num_examples': 83274637, 'test/loss': 0.12609636374383223, 'test/num_examples': 95000000, 'score': 6647.713103055954, 'total_duration': 25995.538591623306, 'accumulated_submission_time': 6647.713103055954, 'accumulated_eval_time': 19345.958792209625, 'accumulated_logging_time': 1.3223984241485596, 'global_step': 7326, 'preemption_count': 0}), (7455, {'train/loss': 0.12406818785429376, 'validation/loss': 0.1239211624463273, 'validation/num_examples': 83274637, 'test/loss': 0.12619554462376645, 'test/num_examples': 95000000, 'score': 6767.724573373795, 'total_duration': 26372.50960278511, 'accumulated_submission_time': 6767.724573373795, 'accumulated_eval_time': 19602.869124412537, 'accumulated_logging_time': 1.3599214553833008, 'global_step': 7455, 'preemption_count': 0}), (7585, {'train/loss': 0.12225502001929958, 'validation/loss': 0.12379609389651257, 'validation/num_examples': 83274637, 'test/loss': 0.1260547798622533, 'test/num_examples': 95000000, 'score': 6888.147087574005, 'total_duration': 26743.412158966064, 'accumulated_submission_time': 6888.147087574005, 'accumulated_eval_time': 19853.323021650314, 'accumulated_logging_time': 1.3760862350463867, 'global_step': 7585, 'preemption_count': 0}), (7710, {'train/loss': 0.12037444030338863, 'validation/loss': 0.12385859118443042, 'validation/num_examples': 83274637, 'test/loss': 0.12613770321751644, 'test/num_examples': 95000000, 'score': 7008.618648529053, 'total_duration': 27122.74698615074, 'accumulated_submission_time': 7008.618648529053, 'accumulated_eval_time': 20112.158304929733, 'accumulated_logging_time': 1.3942656517028809, 'global_step': 7710, 'preemption_count': 0}), (7844, {'train/loss': 0.12178445018171889, 'validation/loss': 0.12387356153943667, 'validation/num_examples': 83274637, 'test/loss': 0.12618381217105262, 'test/num_examples': 95000000, 'score': 7128.705009222031, 'total_duration': 27493.025454044342, 'accumulated_submission_time': 7128.705009222031, 'accumulated_eval_time': 20362.320864915848, 'accumulated_logging_time': 1.4134676456451416, 'global_step': 7844, 'preemption_count': 0}), (7974, {'train/loss': 0.1216661118369245, 'validation/loss': 0.12382509147347363, 'validation/num_examples': 83274637, 'test/loss': 0.1261137941303454, 'test/num_examples': 95000000, 'score': 7250.145509004593, 'total_duration': 27858.058771133423, 'accumulated_submission_time': 7250.145509004593, 'accumulated_eval_time': 20605.85937809944, 'accumulated_logging_time': 1.4582197666168213, 'global_step': 7974, 'preemption_count': 0}), (8105, {'train/loss': 0.122281786698684, 'validation/loss': 0.12373731599399114, 'validation/num_examples': 83274637, 'test/loss': 0.125995873488898, 'test/num_examples': 95000000, 'score': 7371.243496179581, 'total_duration': 28229.52544260025, 'accumulated_submission_time': 7371.243496179581, 'accumulated_eval_time': 20856.190372228622, 'accumulated_logging_time': 1.485053300857544, 'global_step': 8105, 'preemption_count': 0}), (8231, {'train/loss': 0.12260836693194677, 'validation/loss': 0.12368094837315044, 'validation/num_examples': 83274637, 'test/loss': 0.12597771477179276, 'test/num_examples': 95000000, 'score': 7491.487124443054, 'total_duration': 28597.294452905655, 'accumulated_submission_time': 7491.487124443054, 'accumulated_eval_time': 21103.68643474579, 'accumulated_logging_time': 1.5033371448516846, 'global_step': 8231, 'preemption_count': 0})], 'global_step': 8231}
I0306 20:50:26.947363 140297328059584 submission_runner.py:649] Timing: 7491.487124443054
I0306 20:50:26.947400 140297328059584 submission_runner.py:651] Total number of evals: 63
I0306 20:50:26.947427 140297328059584 submission_runner.py:652] ====================
I0306 20:50:26.947546 140297328059584 submission_runner.py:750] Final criteo1tb score: 4
