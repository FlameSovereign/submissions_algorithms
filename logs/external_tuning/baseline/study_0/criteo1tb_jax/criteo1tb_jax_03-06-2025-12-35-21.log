python submission_runner.py --framework=jax --workload=criteo1tb --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_0 --overwrite=True --save_checkpoints=False --rng_seed=-1021462318 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=1 --hparam_end_index=2 2>&1 | tee -a /logs/criteo1tb_jax_03-06-2025-12-35-21.log
2025-03-06 12:35:22.078852: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741264522.101219       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741264522.107767       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0306 12:35:27.719317 140339787351232 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax.
I0306 12:35:28.582662 140339787351232 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0306 12:35:28.585498 140339787351232 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0306 12:35:28.587167 140339787351232 submission_runner.py:606] Using RNG seed -1021462318
I0306 12:35:29.184836 140339787351232 submission_runner.py:615] --- Tuning run 2/5 ---
I0306 12:35:29.185039 140339787351232 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax/trial_2.
I0306 12:35:29.185229 140339787351232 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax/trial_2/hparams.json.
I0306 12:35:29.419094 140339787351232 submission_runner.py:218] Initializing dataset.
I0306 12:35:29.419293 140339787351232 submission_runner.py:229] Initializing model.
I0306 12:35:37.481307 140339787351232 submission_runner.py:272] Initializing optimizer.
I0306 12:35:37.957270 140339787351232 submission_runner.py:279] Initializing metrics bundle.
I0306 12:35:37.957466 140339787351232 submission_runner.py:301] Initializing checkpoint and logger.
I0306 12:35:37.958162 140339787351232 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax/trial_2 with prefix checkpoint_
I0306 12:35:37.958253 140339787351232 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax/trial_2/meta_data_0.json.
I0306 12:35:37.958415 140339787351232 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0306 12:35:37.958462 140339787351232 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0306 12:35:38.140495 140339787351232 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax/trial_2/flags_0.json.
I0306 12:35:38.448994 140339787351232 submission_runner.py:337] Starting training loop.
I0306 12:35:51.348716 140198352492288 logging_writer.py:48] [0] global_step=0, grad_norm=6.695862770080566, loss=0.6642411351203918
I0306 12:35:51.388614 140339787351232 spec.py:321] Evaluating on the training split.
I0306 12:41:48.910297 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 12:47:45.271781 140339787351232 spec.py:349] Evaluating on the test split.
I0306 12:54:09.436742 140339787351232 submission_runner.py:469] Time since start: 1110.99s, 	Step: 1, 	{'train/loss': 0.6638776870831004, 'validation/loss': 0.6720217353851989, 'validation/num_examples': 83274637, 'test/loss': 0.6659842837171053, 'test/num_examples': 95000000, 'score': 12.939538955688477, 'total_duration': 1110.987648487091, 'accumulated_submission_time': 12.939538955688477, 'accumulated_eval_time': 1098.0480163097382, 'accumulated_logging_time': 0}
I0306 12:54:09.445225 140185668916992 logging_writer.py:48] [1] accumulated_eval_time=1098.05, accumulated_logging_time=0, accumulated_submission_time=12.9395, global_step=1, preemption_count=0, score=12.9395, test/loss=0.665984, test/num_examples=95000000, total_duration=1110.99, train/loss=0.663878, validation/loss=0.672022, validation/num_examples=83274637
I0306 12:55:35.541243 140185585055488 logging_writer.py:48] [100] global_step=100, grad_norm=0.26982346177101135, loss=0.1373593956232071
I0306 12:56:10.237379 140339787351232 spec.py:321] Evaluating on the training split.
I0306 13:01:41.006822 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 13:06:47.792355 140339787351232 spec.py:349] Evaluating on the test split.
I0306 13:12:13.763747 140339787351232 submission_runner.py:469] Time since start: 2195.31s, 	Step: 133, 	{'train/loss': 0.13226640463437675, 'validation/loss': 0.13193598768188342, 'validation/num_examples': 83274637, 'test/loss': 0.13511449777960527, 'test/num_examples': 95000000, 'score': 133.71610736846924, 'total_duration': 2195.314699411392, 'accumulated_submission_time': 133.71610736846924, 'accumulated_eval_time': 2061.574338912964, 'accumulated_logging_time': 0.016852855682373047}
I0306 13:12:13.771835 140185668916992 logging_writer.py:48] [133] accumulated_eval_time=2061.57, accumulated_logging_time=0.0168529, accumulated_submission_time=133.716, global_step=133, preemption_count=0, score=133.716, test/loss=0.135114, test/num_examples=95000000, total_duration=2195.31, train/loss=0.132266, validation/loss=0.131936, validation/num_examples=83274637
I0306 13:13:03.335933 140185585055488 logging_writer.py:48] [200] global_step=200, grad_norm=0.2950275242328644, loss=0.13371562957763672
I0306 13:14:14.079505 140339787351232 spec.py:321] Evaluating on the training split.
I0306 13:20:08.658093 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 13:25:03.818991 140339787351232 spec.py:349] Evaluating on the test split.
I0306 13:30:45.081506 140339787351232 submission_runner.py:469] Time since start: 3306.63s, 	Step: 268, 	{'train/loss': 0.1280522385155255, 'validation/loss': 0.1288916950098241, 'validation/num_examples': 83274637, 'test/loss': 0.13150973726356907, 'test/num_examples': 95000000, 'score': 254.01084756851196, 'total_duration': 3306.6324026584625, 'accumulated_submission_time': 254.01084756851196, 'accumulated_eval_time': 3052.5762355327606, 'accumulated_logging_time': 0.030802011489868164}
I0306 13:30:45.091122 140185668916992 logging_writer.py:48] [268] accumulated_eval_time=3052.58, accumulated_logging_time=0.030802, accumulated_submission_time=254.011, global_step=268, preemption_count=0, score=254.011, test/loss=0.13151, test/num_examples=95000000, total_duration=3306.63, train/loss=0.128052, validation/loss=0.128892, validation/num_examples=83274637
I0306 13:30:54.778852 140185585055488 logging_writer.py:48] [300] global_step=300, grad_norm=0.14513637125492096, loss=0.1344013810157776
I0306 13:32:45.262759 140339787351232 spec.py:321] Evaluating on the training split.
I0306 13:38:24.162451 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 13:43:34.199035 140339787351232 spec.py:349] Evaluating on the test split.
I0306 13:48:49.041584 140339787351232 submission_runner.py:469] Time since start: 4390.59s, 	Step: 400, 	{'train/loss': 0.12667035487181735, 'validation/loss': 0.12827270590785494, 'validation/num_examples': 83274637, 'test/loss': 0.13079889851973683, 'test/num_examples': 95000000, 'score': 374.1688508987427, 'total_duration': 4390.592525482178, 'accumulated_submission_time': 374.1688508987427, 'accumulated_eval_time': 4016.355004787445, 'accumulated_logging_time': 0.04709219932556152}
I0306 13:48:49.049108 140185668916992 logging_writer.py:48] [400] accumulated_eval_time=4016.36, accumulated_logging_time=0.0470922, accumulated_submission_time=374.169, global_step=400, preemption_count=0, score=374.169, test/loss=0.130799, test/num_examples=95000000, total_duration=4390.59, train/loss=0.12667, validation/loss=0.128273, validation/num_examples=83274637
I0306 13:48:49.164440 140185585055488 logging_writer.py:48] [400] global_step=400, grad_norm=0.043306928128004074, loss=0.12299894541501999
I0306 13:50:15.370809 140185668916992 logging_writer.py:48] [500] global_step=500, grad_norm=0.1256512999534607, loss=0.13366971909999847
I0306 13:50:49.090480 140339787351232 spec.py:321] Evaluating on the training split.
I0306 13:56:13.189206 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 14:01:09.911985 140339787351232 spec.py:349] Evaluating on the test split.
I0306 14:06:27.269848 140339787351232 submission_runner.py:469] Time since start: 5448.82s, 	Step: 530, 	{'train/loss': 0.12712972105111717, 'validation/loss': 0.1269337720854554, 'validation/num_examples': 83274637, 'test/loss': 0.12950648403577303, 'test/num_examples': 95000000, 'score': 494.19627928733826, 'total_duration': 5448.820786476135, 'accumulated_submission_time': 494.19627928733826, 'accumulated_eval_time': 4954.534299135208, 'accumulated_logging_time': 0.0614016056060791}
I0306 14:06:27.277643 140185585055488 logging_writer.py:48] [530] accumulated_eval_time=4954.53, accumulated_logging_time=0.0614016, accumulated_submission_time=494.196, global_step=530, preemption_count=0, score=494.196, test/loss=0.129506, test/num_examples=95000000, total_duration=5448.82, train/loss=0.12713, validation/loss=0.126934, validation/num_examples=83274637
I0306 14:07:19.198290 140185668916992 logging_writer.py:48] [600] global_step=600, grad_norm=0.05362505093216896, loss=0.1161203384399414
I0306 14:08:27.811878 140339787351232 spec.py:321] Evaluating on the training split.
I0306 14:13:35.839866 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 14:17:48.392009 140339787351232 spec.py:349] Evaluating on the test split.
I0306 14:22:47.963426 140339787351232 submission_runner.py:469] Time since start: 6429.51s, 	Step: 665, 	{'train/loss': 0.12759532422155329, 'validation/loss': 0.12700153259618083, 'validation/num_examples': 83274637, 'test/loss': 0.1296096310855263, 'test/num_examples': 95000000, 'score': 614.716376543045, 'total_duration': 6429.514367341995, 'accumulated_submission_time': 614.716376543045, 'accumulated_eval_time': 5814.685781002045, 'accumulated_logging_time': 0.07641434669494629}
I0306 14:22:47.972053 140185585055488 logging_writer.py:48] [665] accumulated_eval_time=5814.69, accumulated_logging_time=0.0764143, accumulated_submission_time=614.716, global_step=665, preemption_count=0, score=614.716, test/loss=0.12961, test/num_examples=95000000, total_duration=6429.51, train/loss=0.127595, validation/loss=0.127002, validation/num_examples=83274637
I0306 14:23:00.364449 140185668916992 logging_writer.py:48] [700] global_step=700, grad_norm=0.0861484706401825, loss=0.12035549432039261
I0306 14:24:49.591772 140339787351232 spec.py:321] Evaluating on the training split.
I0306 14:29:35.606988 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 14:34:06.959201 140339787351232 spec.py:349] Evaluating on the test split.
I0306 14:39:06.303797 140339787351232 submission_runner.py:469] Time since start: 7407.85s, 	Step: 795, 	{'train/loss': 0.12442182039596, 'validation/loss': 0.12653519639901356, 'validation/num_examples': 83274637, 'test/loss': 0.12901377006578948, 'test/num_examples': 95000000, 'score': 736.322979927063, 'total_duration': 7407.854723453522, 'accumulated_submission_time': 736.322979927063, 'accumulated_eval_time': 6671.397732496262, 'accumulated_logging_time': 0.09142756462097168}
I0306 14:39:06.352361 140185585055488 logging_writer.py:48] [795] accumulated_eval_time=6671.4, accumulated_logging_time=0.0914276, accumulated_submission_time=736.323, global_step=795, preemption_count=0, score=736.323, test/loss=0.129014, test/num_examples=95000000, total_duration=7407.85, train/loss=0.124422, validation/loss=0.126535, validation/num_examples=83274637
I0306 14:39:07.011467 140185668916992 logging_writer.py:48] [800] global_step=800, grad_norm=0.05146341770887375, loss=0.11933306604623795
I0306 14:40:40.089641 140185585055488 logging_writer.py:48] [900] global_step=900, grad_norm=0.012474942952394485, loss=0.12974806129932404
I0306 14:41:07.571071 140339787351232 spec.py:321] Evaluating on the training split.
I0306 14:45:37.306187 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 14:49:32.385454 140339787351232 spec.py:349] Evaluating on the test split.
I0306 14:53:50.761903 140339787351232 submission_runner.py:469] Time since start: 8292.31s, 	Step: 925, 	{'train/loss': 0.12567190574072068, 'validation/loss': 0.12644808397640292, 'validation/num_examples': 83274637, 'test/loss': 0.12891937269736842, 'test/num_examples': 95000000, 'score': 857.528754234314, 'total_duration': 8292.312840223312, 'accumulated_submission_time': 857.528754234314, 'accumulated_eval_time': 7434.588493347168, 'accumulated_logging_time': 0.1459064483642578}
I0306 14:53:50.802011 140185668916992 logging_writer.py:48] [925] accumulated_eval_time=7434.59, accumulated_logging_time=0.145906, accumulated_submission_time=857.529, global_step=925, preemption_count=0, score=857.529, test/loss=0.128919, test/num_examples=95000000, total_duration=8292.31, train/loss=0.125672, validation/loss=0.126448, validation/num_examples=83274637
I0306 14:54:46.584895 140185585055488 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.024151796475052834, loss=0.11959689855575562
I0306 14:55:51.320151 140339787351232 spec.py:321] Evaluating on the training split.
I0306 14:59:05.287354 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 15:01:53.211399 140339787351232 spec.py:349] Evaluating on the test split.
I0306 15:05:19.014240 140339787351232 submission_runner.py:469] Time since start: 8980.57s, 	Step: 1054, 	{'train/loss': 0.12718734387659802, 'validation/loss': 0.12646198999384597, 'validation/num_examples': 83274637, 'test/loss': 0.12904312219366776, 'test/num_examples': 95000000, 'score': 978.0316066741943, 'total_duration': 8980.565180301666, 'accumulated_submission_time': 978.0316066741943, 'accumulated_eval_time': 8002.282534360886, 'accumulated_logging_time': 0.1928858757019043}
I0306 15:05:19.022009 140185668916992 logging_writer.py:48] [1054] accumulated_eval_time=8002.28, accumulated_logging_time=0.192886, accumulated_submission_time=978.032, global_step=1054, preemption_count=0, score=978.032, test/loss=0.129043, test/num_examples=95000000, total_duration=8980.57, train/loss=0.127187, validation/loss=0.126462, validation/num_examples=83274637
I0306 15:05:43.720497 140185585055488 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.03401464223861694, loss=0.1233765259385109
I0306 15:07:20.602870 140339787351232 spec.py:321] Evaluating on the training split.
I0306 15:08:18.534027 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 15:09:06.471817 140339787351232 spec.py:349] Evaluating on the test split.
I0306 15:10:59.240758 140339787351232 submission_runner.py:469] Time since start: 9320.79s, 	Step: 1187, 	{'train/loss': 0.12726230020839838, 'validation/loss': 0.1270163713799985, 'validation/num_examples': 83274637, 'test/loss': 0.12952042274876643, 'test/num_examples': 95000000, 'score': 1099.5975060462952, 'total_duration': 9320.791712284088, 'accumulated_submission_time': 1099.5975060462952, 'accumulated_eval_time': 8220.920379161835, 'accumulated_logging_time': 0.20662689208984375}
I0306 15:10:59.248384 140185668916992 logging_writer.py:48] [1187] accumulated_eval_time=8220.92, accumulated_logging_time=0.206627, accumulated_submission_time=1099.6, global_step=1187, preemption_count=0, score=1099.6, test/loss=0.12952, test/num_examples=95000000, total_duration=9320.79, train/loss=0.127262, validation/loss=0.127016, validation/num_examples=83274637
I0306 15:11:00.710474 140185585055488 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.04452367499470711, loss=0.13619056344032288
I0306 15:12:39.959594 140185668916992 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.047397125512361526, loss=0.12138962745666504
I0306 15:12:59.512437 140339787351232 spec.py:321] Evaluating on the training split.
I0306 15:14:33.383992 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 15:14:41.290114 140339787351232 spec.py:349] Evaluating on the test split.
I0306 15:16:45.483086 140339787351232 submission_runner.py:469] Time since start: 9667.03s, 	Step: 1317, 	{'train/loss': 0.12280835854416748, 'validation/loss': 0.1256999730888387, 'validation/num_examples': 83274637, 'test/loss': 0.12811381315789475, 'test/num_examples': 95000000, 'score': 1219.8451099395752, 'total_duration': 9667.034027338028, 'accumulated_submission_time': 1219.8451099395752, 'accumulated_eval_time': 8446.89096403122, 'accumulated_logging_time': 0.22112822532653809}
I0306 15:16:45.510092 140185585055488 logging_writer.py:48] [1317] accumulated_eval_time=8446.89, accumulated_logging_time=0.221128, accumulated_submission_time=1219.85, global_step=1317, preemption_count=0, score=1219.85, test/loss=0.128114, test/num_examples=95000000, total_duration=9667.03, train/loss=0.122808, validation/loss=0.1257, validation/num_examples=83274637
I0306 15:17:49.015715 140185668916992 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.007200730033218861, loss=0.11803676933050156
I0306 15:18:47.222370 140339787351232 spec.py:321] Evaluating on the training split.
I0306 15:20:56.047260 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 15:21:04.025298 140339787351232 spec.py:349] Evaluating on the test split.
I0306 15:22:36.339727 140339787351232 submission_runner.py:469] Time since start: 10017.89s, 	Step: 1447, 	{'train/loss': 0.12611478691299757, 'validation/loss': 0.12582369590562206, 'validation/num_examples': 83274637, 'test/loss': 0.12824267183388158, 'test/num_examples': 95000000, 'score': 1341.5407948493958, 'total_duration': 10017.890672206879, 'accumulated_submission_time': 1341.5407948493958, 'accumulated_eval_time': 8676.008271932602, 'accumulated_logging_time': 0.2550997734069824}
I0306 15:22:36.347639 140185585055488 logging_writer.py:48] [1447] accumulated_eval_time=8676.01, accumulated_logging_time=0.2551, accumulated_submission_time=1341.54, global_step=1447, preemption_count=0, score=1341.54, test/loss=0.128243, test/num_examples=95000000, total_duration=10017.9, train/loss=0.126115, validation/loss=0.125824, validation/num_examples=83274637
I0306 15:23:08.726354 140185668916992 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.06769537180662155, loss=0.13263753056526184
I0306 15:24:36.832735 140339787351232 spec.py:321] Evaluating on the training split.
I0306 15:27:05.320263 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 15:27:13.079263 140339787351232 spec.py:349] Evaluating on the test split.
I0306 15:28:23.891161 140339787351232 submission_runner.py:469] Time since start: 10365.44s, 	Step: 1580, 	{'train/loss': 0.12541013189925337, 'validation/loss': 0.12603643333053496, 'validation/num_examples': 83274637, 'test/loss': 0.12846060021587172, 'test/num_examples': 95000000, 'score': 1462.0087404251099, 'total_duration': 10365.442111492157, 'accumulated_submission_time': 1462.0087404251099, 'accumulated_eval_time': 8903.066642522812, 'accumulated_logging_time': 0.27018141746520996}
I0306 15:28:23.899145 140185585055488 logging_writer.py:48] [1580] accumulated_eval_time=8903.07, accumulated_logging_time=0.270181, accumulated_submission_time=1462.01, global_step=1580, preemption_count=0, score=1462.01, test/loss=0.128461, test/num_examples=95000000, total_duration=10365.4, train/loss=0.12541, validation/loss=0.126036, validation/num_examples=83274637
I0306 15:28:26.108973 140185668916992 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.06150051951408386, loss=0.1309807002544403
I0306 15:30:07.886491 140185585055488 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.02796456217765808, loss=0.11773300170898438
I0306 15:30:24.572565 140339787351232 spec.py:321] Evaluating on the training split.
I0306 15:33:29.771278 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 15:33:37.438399 140339787351232 spec.py:349] Evaluating on the test split.
I0306 15:34:13.124795 140339787351232 submission_runner.py:469] Time since start: 10714.68s, 	Step: 1717, 	{'train/loss': 0.12271162473930503, 'validation/loss': 0.1254551975605861, 'validation/num_examples': 83274637, 'test/loss': 0.12783988479646383, 'test/num_examples': 95000000, 'score': 1582.66610455513, 'total_duration': 10714.675741910934, 'accumulated_submission_time': 1582.66610455513, 'accumulated_eval_time': 9131.618814468384, 'accumulated_logging_time': 0.28414154052734375}
I0306 15:34:13.205406 140185668916992 logging_writer.py:48] [1717] accumulated_eval_time=9131.62, accumulated_logging_time=0.284142, accumulated_submission_time=1582.67, global_step=1717, preemption_count=0, score=1582.67, test/loss=0.12784, test/num_examples=95000000, total_duration=10714.7, train/loss=0.122712, validation/loss=0.125455, validation/num_examples=83274637
I0306 15:35:13.611064 140185585055488 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.008351462893188, loss=0.11600361764431
I0306 15:36:13.187329 140339787351232 spec.py:321] Evaluating on the training split.
I0306 15:39:39.261079 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 15:39:46.716022 140339787351232 spec.py:349] Evaluating on the test split.
I0306 15:39:59.203170 140339787351232 submission_runner.py:469] Time since start: 11060.75s, 	Step: 1855, 	{'train/loss': 0.12487018109539395, 'validation/loss': 0.1257428938750395, 'validation/num_examples': 83274637, 'test/loss': 0.12826413875411183, 'test/num_examples': 95000000, 'score': 1702.6306369304657, 'total_duration': 11060.754112005234, 'accumulated_submission_time': 1702.6306369304657, 'accumulated_eval_time': 9357.63459444046, 'accumulated_logging_time': 0.37154173851013184}
I0306 15:39:59.211093 140185668916992 logging_writer.py:48] [1855] accumulated_eval_time=9357.63, accumulated_logging_time=0.371542, accumulated_submission_time=1702.63, global_step=1855, preemption_count=0, score=1702.63, test/loss=0.128264, test/num_examples=95000000, total_duration=11060.8, train/loss=0.12487, validation/loss=0.125743, validation/num_examples=83274637
I0306 15:40:23.768075 140185585055488 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.0061442977748811245, loss=0.11731269955635071
I0306 15:41:59.494682 140339787351232 spec.py:321] Evaluating on the training split.
I0306 15:46:00.046231 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 15:46:07.816554 140339787351232 spec.py:349] Evaluating on the test split.
I0306 15:46:16.668690 140339787351232 submission_runner.py:469] Time since start: 11438.22s, 	Step: 1983, 	{'train/loss': 0.1236365157407972, 'validation/loss': 0.12552868550194604, 'validation/num_examples': 83274637, 'test/loss': 0.12801613432360198, 'test/num_examples': 95000000, 'score': 1822.8981063365936, 'total_duration': 11438.21965932846, 'accumulated_submission_time': 1822.8981063365936, 'accumulated_eval_time': 9614.808578491211, 'accumulated_logging_time': 0.38559675216674805}
I0306 15:46:16.676876 140185668916992 logging_writer.py:48] [1983] accumulated_eval_time=9614.81, accumulated_logging_time=0.385597, accumulated_submission_time=1822.9, global_step=1983, preemption_count=0, score=1822.9, test/loss=0.128016, test/num_examples=95000000, total_duration=11438.2, train/loss=0.123637, validation/loss=0.125529, validation/num_examples=83274637
I0306 15:46:18.591142 140185585055488 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.0064538042061030865, loss=0.12236996740102768
I0306 15:48:02.615869 140185668916992 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.0065551623702049255, loss=0.11929626762866974
I0306 15:48:16.857321 140339787351232 spec.py:321] Evaluating on the training split.
I0306 15:52:16.670587 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 15:52:24.341712 140339787351232 spec.py:349] Evaluating on the test split.
I0306 15:52:33.184079 140339787351232 submission_runner.py:469] Time since start: 11814.73s, 	Step: 2114, 	{'train/loss': 0.12504178607754363, 'validation/loss': 0.1256199996360105, 'validation/num_examples': 83274637, 'test/loss': 0.12807082970805922, 'test/num_examples': 95000000, 'score': 1943.0422768592834, 'total_duration': 11814.73499917984, 'accumulated_submission_time': 1943.0422768592834, 'accumulated_eval_time': 9871.135347127914, 'accumulated_logging_time': 0.42000341415405273}
I0306 15:52:33.192554 140185585055488 logging_writer.py:48] [2114] accumulated_eval_time=9871.14, accumulated_logging_time=0.420003, accumulated_submission_time=1943.04, global_step=2114, preemption_count=0, score=1943.04, test/loss=0.128071, test/num_examples=95000000, total_duration=11814.7, train/loss=0.125042, validation/loss=0.12562, validation/num_examples=83274637
I0306 15:53:46.945594 140185668916992 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.04130517318844795, loss=0.12851263582706451
I0306 15:54:33.963606 140339787351232 spec.py:321] Evaluating on the training split.
I0306 15:58:27.431873 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 15:58:35.215854 140339787351232 spec.py:349] Evaluating on the test split.
I0306 15:58:43.855074 140339787351232 submission_runner.py:469] Time since start: 12185.41s, 	Step: 2242, 	{'train/loss': 0.12413560520599848, 'validation/loss': 0.12520900158065798, 'validation/num_examples': 83274637, 'test/loss': 0.12765085318667763, 'test/num_examples': 95000000, 'score': 2063.7976536750793, 'total_duration': 12185.406038761139, 'accumulated_submission_time': 2063.7976536750793, 'accumulated_eval_time': 10121.026782274246, 'accumulated_logging_time': 0.4348273277282715}
I0306 15:58:43.866556 140185585055488 logging_writer.py:48] [2242] accumulated_eval_time=10121, accumulated_logging_time=0.434827, accumulated_submission_time=2063.8, global_step=2242, preemption_count=0, score=2063.8, test/loss=0.127651, test/num_examples=95000000, total_duration=12185.4, train/loss=0.124136, validation/loss=0.125209, validation/num_examples=83274637
I0306 15:59:19.328380 140185668916992 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.09716968983411789, loss=0.1248578131198883
I0306 16:00:44.930416 140339787351232 spec.py:321] Evaluating on the training split.
I0306 16:04:35.858093 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 16:04:43.682259 140339787351232 spec.py:349] Evaluating on the test split.
I0306 16:04:52.672896 140339787351232 submission_runner.py:469] Time since start: 12554.22s, 	Step: 2377, 	{'train/loss': 0.12301755186943512, 'validation/loss': 0.1252236283108175, 'validation/num_examples': 83274637, 'test/loss': 0.1275730989925987, 'test/num_examples': 95000000, 'score': 2184.8439967632294, 'total_duration': 12554.223861932755, 'accumulated_submission_time': 2184.8439967632294, 'accumulated_eval_time': 10368.769230604172, 'accumulated_logging_time': 0.4524505138397217}
I0306 16:04:52.681222 140185585055488 logging_writer.py:48] [2377] accumulated_eval_time=10368.8, accumulated_logging_time=0.452451, accumulated_submission_time=2184.84, global_step=2377, preemption_count=0, score=2184.84, test/loss=0.127573, test/num_examples=95000000, total_duration=12554.2, train/loss=0.123018, validation/loss=0.125224, validation/num_examples=83274637
I0306 16:04:55.213649 140185668916992 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.04583301767706871, loss=0.13091009855270386
I0306 16:06:39.631536 140185585055488 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.011832751333713531, loss=0.12301333248615265
I0306 16:06:52.977101 140339787351232 spec.py:321] Evaluating on the training split.
I0306 16:10:45.303255 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 16:10:53.056969 140339787351232 spec.py:349] Evaluating on the test split.
I0306 16:11:01.920604 140339787351232 submission_runner.py:469] Time since start: 12923.47s, 	Step: 2515, 	{'train/loss': 0.12428706965215926, 'validation/loss': 0.12518441147140447, 'validation/num_examples': 83274637, 'test/loss': 0.12766349969161184, 'test/num_examples': 95000000, 'score': 2305.123528957367, 'total_duration': 12923.471545696259, 'accumulated_submission_time': 2305.123528957367, 'accumulated_eval_time': 10617.712666511536, 'accumulated_logging_time': 0.46770477294921875}
I0306 16:11:01.930508 140185668916992 logging_writer.py:48] [2515] accumulated_eval_time=10617.7, accumulated_logging_time=0.467705, accumulated_submission_time=2305.12, global_step=2515, preemption_count=0, score=2305.12, test/loss=0.127663, test/num_examples=95000000, total_duration=12923.5, train/loss=0.124287, validation/loss=0.125184, validation/num_examples=83274637
I0306 16:12:09.851113 140185585055488 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.030924301594495773, loss=0.1334117203950882
I0306 16:13:02.197842 140339787351232 spec.py:321] Evaluating on the training split.
I0306 16:16:45.862290 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 16:16:53.703239 140339787351232 spec.py:349] Evaluating on the test split.
I0306 16:17:02.623101 140339787351232 submission_runner.py:469] Time since start: 13284.17s, 	Step: 2648, 	{'train/loss': 0.12477573058890097, 'validation/loss': 0.12482437431066384, 'validation/num_examples': 83274637, 'test/loss': 0.12707150013363486, 'test/num_examples': 95000000, 'score': 2425.3730533123016, 'total_duration': 13284.174051046371, 'accumulated_submission_time': 2425.3730533123016, 'accumulated_eval_time': 10858.137867212296, 'accumulated_logging_time': 0.4847123622894287}
I0306 16:17:02.632008 140185668916992 logging_writer.py:48] [2648] accumulated_eval_time=10858.1, accumulated_logging_time=0.484712, accumulated_submission_time=2425.37, global_step=2648, preemption_count=0, score=2425.37, test/loss=0.127072, test/num_examples=95000000, total_duration=13284.2, train/loss=0.124776, validation/loss=0.124824, validation/num_examples=83274637
I0306 16:17:32.611934 140185585055488 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.010578584857285023, loss=0.11932766437530518
I0306 16:19:02.914143 140339787351232 spec.py:321] Evaluating on the training split.
I0306 16:22:40.238677 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 16:22:47.947288 140339787351232 spec.py:349] Evaluating on the test split.
I0306 16:22:56.674674 140339787351232 submission_runner.py:469] Time since start: 13638.23s, 	Step: 2780, 	{'train/loss': 0.12389525849629873, 'validation/loss': 0.1251506935676998, 'validation/num_examples': 83274637, 'test/loss': 0.12755006296258223, 'test/num_examples': 95000000, 'score': 2545.56321144104, 'total_duration': 13638.225637197495, 'accumulated_submission_time': 2545.56321144104, 'accumulated_eval_time': 11091.898374557495, 'accumulated_logging_time': 0.5755856037139893}
I0306 16:22:56.683015 140185668916992 logging_writer.py:48] [2780] accumulated_eval_time=11091.9, accumulated_logging_time=0.575586, accumulated_submission_time=2545.56, global_step=2780, preemption_count=0, score=2545.56, test/loss=0.12755, test/num_examples=95000000, total_duration=13638.2, train/loss=0.123895, validation/loss=0.125151, validation/num_examples=83274637
I0306 16:22:58.884519 140185585055488 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.006274113431572914, loss=0.11591200530529022
I0306 16:24:44.266906 140185668916992 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.03208058699965477, loss=0.13096317648887634
I0306 16:24:57.708856 140339787351232 spec.py:321] Evaluating on the training split.
I0306 16:28:41.651441 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 16:28:49.018149 140339787351232 spec.py:349] Evaluating on the test split.
I0306 16:28:57.791017 140339787351232 submission_runner.py:469] Time since start: 13999.34s, 	Step: 2915, 	{'train/loss': 0.12280079789178551, 'validation/loss': 0.1250706682111254, 'validation/num_examples': 83274637, 'test/loss': 0.12758728129111843, 'test/num_examples': 95000000, 'score': 2666.571323156357, 'total_duration': 13999.341974258423, 'accumulated_submission_time': 2666.571323156357, 'accumulated_eval_time': 11331.980484485626, 'accumulated_logging_time': 0.5911178588867188}
I0306 16:28:57.798876 140185585055488 logging_writer.py:48] [2915] accumulated_eval_time=11332, accumulated_logging_time=0.591118, accumulated_submission_time=2666.57, global_step=2915, preemption_count=0, score=2666.57, test/loss=0.127587, test/num_examples=95000000, total_duration=13999.3, train/loss=0.122801, validation/loss=0.125071, validation/num_examples=83274637
I0306 16:30:07.657761 140185668916992 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.013970001600682735, loss=0.1191016137599945
I0306 16:30:58.299989 140339787351232 spec.py:321] Evaluating on the training split.
I0306 16:34:37.750216 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 16:34:45.038589 140339787351232 spec.py:349] Evaluating on the test split.
I0306 16:34:53.828366 140339787351232 submission_runner.py:469] Time since start: 14355.38s, 	Step: 3045, 	{'train/loss': 0.12543551786656273, 'validation/loss': 0.1249610069178011, 'validation/num_examples': 83274637, 'test/loss': 0.1273094214740954, 'test/num_examples': 95000000, 'score': 2787.055482149124, 'total_duration': 14355.379331827164, 'accumulated_submission_time': 2787.055482149124, 'accumulated_eval_time': 11567.50882267952, 'accumulated_logging_time': 0.6059231758117676}
I0306 16:34:53.837126 140185585055488 logging_writer.py:48] [3045] accumulated_eval_time=11567.5, accumulated_logging_time=0.605923, accumulated_submission_time=2787.06, global_step=3045, preemption_count=0, score=2787.06, test/loss=0.127309, test/num_examples=95000000, total_duration=14355.4, train/loss=0.125436, validation/loss=0.124961, validation/num_examples=83274637
I0306 16:35:27.355125 140185668916992 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.012852808460593224, loss=0.12592771649360657
I0306 16:36:54.816907 140339787351232 spec.py:321] Evaluating on the training split.
I0306 16:40:43.793573 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 16:40:51.159241 140339787351232 spec.py:349] Evaluating on the test split.
I0306 16:40:59.917090 140339787351232 submission_runner.py:469] Time since start: 14721.47s, 	Step: 3174, 	{'train/loss': 0.12493689245772811, 'validation/loss': 0.12487605629911999, 'validation/num_examples': 83274637, 'test/loss': 0.12727106988075657, 'test/num_examples': 95000000, 'score': 2907.9970190525055, 'total_duration': 14721.468026161194, 'accumulated_submission_time': 2907.9970190525055, 'accumulated_eval_time': 11812.608943939209, 'accumulated_logging_time': 0.6433284282684326}
I0306 16:40:59.925988 140185585055488 logging_writer.py:48] [3174] accumulated_eval_time=11812.6, accumulated_logging_time=0.643328, accumulated_submission_time=2908, global_step=3174, preemption_count=0, score=2908, test/loss=0.127271, test/num_examples=95000000, total_duration=14721.5, train/loss=0.124937, validation/loss=0.124876, validation/num_examples=83274637
I0306 16:41:02.725904 140185668916992 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.06366101652383804, loss=0.12860818207263947
I0306 16:42:54.649686 140185585055488 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.007349240127950907, loss=0.12561427056789398
I0306 16:43:00.038006 140339787351232 spec.py:321] Evaluating on the training split.
I0306 16:46:37.588238 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 16:46:44.995092 140339787351232 spec.py:349] Evaluating on the test split.
I0306 16:46:53.789737 140339787351232 submission_runner.py:469] Time since start: 15075.34s, 	Step: 3306, 	{'train/loss': 0.12460863041990208, 'validation/loss': 0.12475219752524634, 'validation/num_examples': 83274637, 'test/loss': 0.12709369579564145, 'test/num_examples': 95000000, 'score': 3028.092873811722, 'total_duration': 15075.34069108963, 'accumulated_submission_time': 3028.092873811722, 'accumulated_eval_time': 12046.360619783401, 'accumulated_logging_time': 0.658679723739624}
I0306 16:46:53.799912 140185668916992 logging_writer.py:48] [3306] accumulated_eval_time=12046.4, accumulated_logging_time=0.65868, accumulated_submission_time=3028.09, global_step=3306, preemption_count=0, score=3028.09, test/loss=0.127094, test/num_examples=95000000, total_duration=15075.3, train/loss=0.124609, validation/loss=0.124752, validation/num_examples=83274637
I0306 16:48:16.240187 140185585055488 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.013329335488379002, loss=0.12615618109703064
I0306 16:48:54.916724 140339787351232 spec.py:321] Evaluating on the training split.
I0306 16:52:38.048448 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 16:52:45.348844 140339787351232 spec.py:349] Evaluating on the test split.
I0306 16:52:54.172845 140339787351232 submission_runner.py:469] Time since start: 15435.72s, 	Step: 3433, 	{'train/loss': 0.12631541237516222, 'validation/loss': 0.12495184056494109, 'validation/num_examples': 83274637, 'test/loss': 0.12721558587582238, 'test/num_examples': 95000000, 'score': 3149.1936831474304, 'total_duration': 15435.72381067276, 'accumulated_submission_time': 3149.1936831474304, 'accumulated_eval_time': 12285.616708517075, 'accumulated_logging_time': 0.6750872135162354}
I0306 16:52:54.181131 140185668916992 logging_writer.py:48] [3433] accumulated_eval_time=12285.6, accumulated_logging_time=0.675087, accumulated_submission_time=3149.19, global_step=3433, preemption_count=0, score=3149.19, test/loss=0.127216, test/num_examples=95000000, total_duration=15435.7, train/loss=0.126315, validation/loss=0.124952, validation/num_examples=83274637
I0306 16:53:41.632464 140185585055488 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.018262293189764023, loss=0.12270960211753845
I0306 16:54:54.739687 140339787351232 spec.py:321] Evaluating on the training split.
I0306 16:58:30.208812 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 16:58:37.639233 140339787351232 spec.py:349] Evaluating on the test split.
I0306 16:58:46.504246 140339787351232 submission_runner.py:469] Time since start: 15788.06s, 	Step: 3566, 	{'train/loss': 0.12478293293395883, 'validation/loss': 0.12475112921809028, 'validation/num_examples': 83274637, 'test/loss': 0.12707061570723685, 'test/num_examples': 95000000, 'score': 3269.730175971985, 'total_duration': 15788.055164337158, 'accumulated_submission_time': 3269.730175971985, 'accumulated_eval_time': 12517.381179332733, 'accumulated_logging_time': 0.6945619583129883}
I0306 16:58:46.512763 140185668916992 logging_writer.py:48] [3566] accumulated_eval_time=12517.4, accumulated_logging_time=0.694562, accumulated_submission_time=3269.73, global_step=3566, preemption_count=0, score=3269.73, test/loss=0.127071, test/num_examples=95000000, total_duration=15788.1, train/loss=0.124783, validation/loss=0.124751, validation/num_examples=83274637
I0306 16:58:57.869146 140185585055488 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.013018283061683178, loss=0.1239854171872139
I0306 17:00:48.002967 140339787351232 spec.py:321] Evaluating on the training split.
I0306 17:04:28.607851 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 17:04:35.976503 140339787351232 spec.py:349] Evaluating on the test split.
I0306 17:04:44.819513 140339787351232 submission_runner.py:469] Time since start: 16146.37s, 	Step: 3697, 	{'train/loss': 0.12334704024236907, 'validation/loss': 0.12496840360621858, 'validation/num_examples': 83274637, 'test/loss': 0.12743190731907894, 'test/num_examples': 95000000, 'score': 3391.203753709793, 'total_duration': 16146.370485305786, 'accumulated_submission_time': 3391.203753709793, 'accumulated_eval_time': 12754.197702169418, 'accumulated_logging_time': 0.7100903987884521}
I0306 17:04:44.828261 140185668916992 logging_writer.py:48] [3697] accumulated_eval_time=12754.2, accumulated_logging_time=0.71009, accumulated_submission_time=3391.2, global_step=3697, preemption_count=0, score=3391.2, test/loss=0.127432, test/num_examples=95000000, total_duration=16146.4, train/loss=0.123347, validation/loss=0.124968, validation/num_examples=83274637
I0306 17:04:45.301002 140185585055488 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.008109115064144135, loss=0.12968583405017853
I0306 17:06:13.637787 140185668916992 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.011732186190783978, loss=0.11775092780590057
I0306 17:06:46.095910 140339787351232 spec.py:321] Evaluating on the training split.
I0306 17:10:23.306617 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 17:10:30.764575 140339787351232 spec.py:349] Evaluating on the test split.
I0306 17:10:39.489704 140339787351232 submission_runner.py:469] Time since start: 16501.04s, 	Step: 3829, 	{'train/loss': 0.1261319908073301, 'validation/loss': 0.12491530240914996, 'validation/num_examples': 83274637, 'test/loss': 0.1273380443462171, 'test/num_examples': 95000000, 'score': 3512.4014904499054, 'total_duration': 16501.040668725967, 'accumulated_submission_time': 3512.4014904499054, 'accumulated_eval_time': 12987.591453313828, 'accumulated_logging_time': 0.7785751819610596}
I0306 17:10:39.498287 140185585055488 logging_writer.py:48] [3829] accumulated_eval_time=12987.6, accumulated_logging_time=0.778575, accumulated_submission_time=3512.4, global_step=3829, preemption_count=0, score=3512.4, test/loss=0.127338, test/num_examples=95000000, total_duration=16501, train/loss=0.126132, validation/loss=0.124915, validation/num_examples=83274637
I0306 17:11:32.271400 140185668916992 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.022363094612956047, loss=0.12475898861885071
I0306 17:12:40.098544 140339787351232 spec.py:321] Evaluating on the training split.
I0306 17:16:26.488323 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 17:16:33.775593 140339787351232 spec.py:349] Evaluating on the test split.
I0306 17:16:42.576621 140339787351232 submission_runner.py:469] Time since start: 16864.13s, 	Step: 3961, 	{'train/loss': 0.1232704305259874, 'validation/loss': 0.12455184107289886, 'validation/num_examples': 83274637, 'test/loss': 0.12692894565172697, 'test/num_examples': 95000000, 'score': 3632.9852254390717, 'total_duration': 16864.12758421898, 'accumulated_submission_time': 3632.9852254390717, 'accumulated_eval_time': 13230.069491624832, 'accumulated_logging_time': 0.7937722206115723}
I0306 17:16:42.586771 140185585055488 logging_writer.py:48] [3961] accumulated_eval_time=13230.1, accumulated_logging_time=0.793772, accumulated_submission_time=3632.99, global_step=3961, preemption_count=0, score=3632.99, test/loss=0.126929, test/num_examples=95000000, total_duration=16864.1, train/loss=0.12327, validation/loss=0.124552, validation/num_examples=83274637
I0306 17:16:59.821003 140185668916992 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.013042455539107323, loss=0.12552273273468018
I0306 17:18:42.749844 140339787351232 spec.py:321] Evaluating on the training split.
I0306 17:22:32.619671 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 17:22:39.979495 140339787351232 spec.py:349] Evaluating on the test split.
I0306 17:22:48.712804 140339787351232 submission_runner.py:469] Time since start: 17230.26s, 	Step: 4090, 	{'train/loss': 0.12174035877036224, 'validation/loss': 0.12475610241435028, 'validation/num_examples': 83274637, 'test/loss': 0.12710359581620065, 'test/num_examples': 95000000, 'score': 3753.117418527603, 'total_duration': 17230.263771533966, 'accumulated_submission_time': 3753.117418527603, 'accumulated_eval_time': 13476.032420873642, 'accumulated_logging_time': 0.8253259658813477}
I0306 17:22:48.721812 140185585055488 logging_writer.py:48] [4090] accumulated_eval_time=13476, accumulated_logging_time=0.825326, accumulated_submission_time=3753.12, global_step=4090, preemption_count=0, score=3753.12, test/loss=0.127104, test/num_examples=95000000, total_duration=17230.3, train/loss=0.12174, validation/loss=0.124756, validation/num_examples=83274637
I0306 17:22:49.903151 140185668916992 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.005570482928305864, loss=0.12491695582866669
I0306 17:24:26.013741 140185585055488 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.009115060791373253, loss=0.12349262833595276
I0306 17:24:49.261651 140339787351232 spec.py:321] Evaluating on the training split.
I0306 17:28:30.029636 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 17:28:37.268512 140339787351232 spec.py:349] Evaluating on the test split.
I0306 17:28:45.997511 140339787351232 submission_runner.py:469] Time since start: 17587.55s, 	Step: 4222, 	{'train/loss': 0.12575322786732665, 'validation/loss': 0.12491293677805974, 'validation/num_examples': 83274637, 'test/loss': 0.12724627936883223, 'test/num_examples': 95000000, 'score': 3873.6151247024536, 'total_duration': 17587.548482894897, 'accumulated_submission_time': 3873.6151247024536, 'accumulated_eval_time': 13712.76824593544, 'accumulated_logging_time': 0.8665564060211182}
I0306 17:28:46.006283 140185668916992 logging_writer.py:48] [4222] accumulated_eval_time=13712.8, accumulated_logging_time=0.866556, accumulated_submission_time=3873.62, global_step=4222, preemption_count=0, score=3873.62, test/loss=0.127246, test/num_examples=95000000, total_duration=17587.5, train/loss=0.125753, validation/loss=0.124913, validation/num_examples=83274637
I0306 17:29:41.755414 140185585055488 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.00712009659036994, loss=0.12733536958694458
I0306 17:30:46.283419 140339787351232 spec.py:321] Evaluating on the training split.
I0306 17:34:29.499660 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 17:34:36.865046 140339787351232 spec.py:349] Evaluating on the test split.
I0306 17:34:45.594573 140339787351232 submission_runner.py:469] Time since start: 17947.15s, 	Step: 4358, 	{'train/loss': 0.12388917960741985, 'validation/loss': 0.12497045716984595, 'validation/num_examples': 83274637, 'test/loss': 0.1273436292763158, 'test/num_examples': 95000000, 'score': 3993.864466190338, 'total_duration': 17947.145503997803, 'accumulated_submission_time': 3993.864466190338, 'accumulated_eval_time': 13952.079324483871, 'accumulated_logging_time': 0.893235445022583}
I0306 17:34:45.616209 140185668916992 logging_writer.py:48] [4358] accumulated_eval_time=13952.1, accumulated_logging_time=0.893235, accumulated_submission_time=3993.86, global_step=4358, preemption_count=0, score=3993.86, test/loss=0.127344, test/num_examples=95000000, total_duration=17947.1, train/loss=0.123889, validation/loss=0.12497, validation/num_examples=83274637
I0306 17:35:07.161004 140185585055488 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.008715718053281307, loss=0.11764313280582428
I0306 17:36:45.624829 140339787351232 spec.py:321] Evaluating on the training split.
I0306 17:40:31.377828 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 17:40:38.769011 140339787351232 spec.py:349] Evaluating on the test split.
I0306 17:40:47.570623 140339787351232 submission_runner.py:469] Time since start: 18309.12s, 	Step: 4487, 	{'train/loss': 0.12410039054054134, 'validation/loss': 0.1246292574570623, 'validation/num_examples': 83274637, 'test/loss': 0.12687943737664473, 'test/num_examples': 95000000, 'score': 4113.8525331020355, 'total_duration': 18309.12158060074, 'accumulated_submission_time': 4113.8525331020355, 'accumulated_eval_time': 14194.025070667267, 'accumulated_logging_time': 0.9209284782409668}
I0306 17:40:47.580829 140185668916992 logging_writer.py:48] [4487] accumulated_eval_time=14194, accumulated_logging_time=0.920928, accumulated_submission_time=4113.85, global_step=4487, preemption_count=0, score=4113.85, test/loss=0.126879, test/num_examples=95000000, total_duration=18309.1, train/loss=0.1241, validation/loss=0.124629, validation/num_examples=83274637
I0306 17:40:49.086086 140185585055488 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.006078728940337896, loss=0.1287568211555481
I0306 17:42:27.348610 140185668916992 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.02013065479695797, loss=0.12563921511173248
I0306 17:42:47.975258 140339787351232 spec.py:321] Evaluating on the training split.
I0306 17:46:28.475121 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 17:46:35.819392 140339787351232 spec.py:349] Evaluating on the test split.
I0306 17:46:44.575219 140339787351232 submission_runner.py:469] Time since start: 18666.13s, 	Step: 4619, 	{'train/loss': 0.12381547195075443, 'validation/loss': 0.12465405315252792, 'validation/num_examples': 83274637, 'test/loss': 0.12701043570106907, 'test/num_examples': 95000000, 'score': 4234.203807592392, 'total_duration': 18666.12617301941, 'accumulated_submission_time': 4234.203807592392, 'accumulated_eval_time': 14430.624977588654, 'accumulated_logging_time': 0.9640281200408936}
I0306 17:46:44.585032 140185585055488 logging_writer.py:48] [4619] accumulated_eval_time=14430.6, accumulated_logging_time=0.964028, accumulated_submission_time=4234.2, global_step=4619, preemption_count=0, score=4234.2, test/loss=0.12701, test/num_examples=95000000, total_duration=18666.1, train/loss=0.123815, validation/loss=0.124654, validation/num_examples=83274637
I0306 17:47:50.087534 140185668916992 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.01846178248524666, loss=0.12114477902650833
I0306 17:48:45.054004 140339787351232 spec.py:321] Evaluating on the training split.
I0306 17:52:24.984099 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 17:52:32.307477 140339787351232 spec.py:349] Evaluating on the test split.
I0306 17:52:41.152243 140339787351232 submission_runner.py:469] Time since start: 19022.70s, 	Step: 4749, 	{'train/loss': 0.12651506778579089, 'validation/loss': 0.12472218938492641, 'validation/num_examples': 83274637, 'test/loss': 0.1270062547080592, 'test/num_examples': 95000000, 'score': 4354.656206607819, 'total_duration': 19022.70318031311, 'accumulated_submission_time': 4354.656206607819, 'accumulated_eval_time': 14666.723143577576, 'accumulated_logging_time': 0.9803009033203125}
I0306 17:52:41.161859 140185585055488 logging_writer.py:48] [4749] accumulated_eval_time=14666.7, accumulated_logging_time=0.980301, accumulated_submission_time=4354.66, global_step=4749, preemption_count=0, score=4354.66, test/loss=0.127006, test/num_examples=95000000, total_duration=19022.7, train/loss=0.126515, validation/loss=0.124722, validation/num_examples=83274637
I0306 17:53:11.446627 140185668916992 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.0068024443462491035, loss=0.12206121534109116
I0306 17:54:42.191277 140339787351232 spec.py:321] Evaluating on the training split.
I0306 17:58:30.013699 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 17:58:37.322158 140339787351232 spec.py:349] Evaluating on the test split.
I0306 17:58:46.138254 140339787351232 submission_runner.py:469] Time since start: 19387.69s, 	Step: 4882, 	{'train/loss': 0.12270586894321367, 'validation/loss': 0.12454534681308113, 'validation/num_examples': 83274637, 'test/loss': 0.12688367181332236, 'test/num_examples': 95000000, 'score': 4475.668568611145, 'total_duration': 19387.689217567444, 'accumulated_submission_time': 4475.668568611145, 'accumulated_eval_time': 14910.670087099075, 'accumulated_logging_time': 0.9962403774261475}
I0306 17:58:46.147829 140185585055488 logging_writer.py:48] [4882] accumulated_eval_time=14910.7, accumulated_logging_time=0.99624, accumulated_submission_time=4475.67, global_step=4882, preemption_count=0, score=4475.67, test/loss=0.126884, test/num_examples=95000000, total_duration=19387.7, train/loss=0.122706, validation/loss=0.124545, validation/num_examples=83274637
I0306 17:58:48.152460 140185668916992 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.005605402868241072, loss=0.12356621026992798
I0306 18:00:33.522810 140185585055488 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.016103392466902733, loss=0.11815221607685089
I0306 18:00:47.661245 140339787351232 spec.py:321] Evaluating on the training split.
I0306 18:04:31.849248 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 18:04:39.064834 140339787351232 spec.py:349] Evaluating on the test split.
I0306 18:04:47.655227 140339787351232 submission_runner.py:469] Time since start: 19749.21s, 	Step: 5013, 	{'train/loss': 0.1221168984969457, 'validation/loss': 0.12428397004281598, 'validation/num_examples': 83274637, 'test/loss': 0.1266789323807566, 'test/num_examples': 95000000, 'score': 4597.155123233795, 'total_duration': 19749.206179142, 'accumulated_submission_time': 4597.155123233795, 'accumulated_eval_time': 15150.664023399353, 'accumulated_logging_time': 1.0229346752166748}
I0306 18:04:47.664157 140185668916992 logging_writer.py:48] [5013] accumulated_eval_time=15150.7, accumulated_logging_time=1.02293, accumulated_submission_time=4597.16, global_step=5013, preemption_count=0, score=4597.16, test/loss=0.126679, test/num_examples=95000000, total_duration=19749.2, train/loss=0.122117, validation/loss=0.124284, validation/num_examples=83274637
I0306 18:05:55.606886 140185585055488 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.010660636238753796, loss=0.11672641336917877
I0306 18:06:48.141444 140339787351232 spec.py:321] Evaluating on the training split.
I0306 18:10:29.836379 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 18:10:37.071310 140339787351232 spec.py:349] Evaluating on the test split.
I0306 18:10:45.641074 140339787351232 submission_runner.py:469] Time since start: 20107.19s, 	Step: 5149, 	{'train/loss': 0.12339046866920009, 'validation/loss': 0.12420010281222578, 'validation/num_examples': 83274637, 'test/loss': 0.12656989562088816, 'test/num_examples': 95000000, 'score': 4717.614072561264, 'total_duration': 20107.19204211235, 'accumulated_submission_time': 4717.614072561264, 'accumulated_eval_time': 15388.163626670837, 'accumulated_logging_time': 1.0392355918884277}
I0306 18:10:45.650123 140185668916992 logging_writer.py:48] [5149] accumulated_eval_time=15388.2, accumulated_logging_time=1.03924, accumulated_submission_time=4717.61, global_step=5149, preemption_count=0, score=4717.61, test/loss=0.12657, test/num_examples=95000000, total_duration=20107.2, train/loss=0.12339, validation/loss=0.1242, validation/num_examples=83274637
I0306 18:11:16.183297 140185585055488 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.005595913156867027, loss=0.12560983002185822
I0306 18:12:45.762155 140339787351232 spec.py:321] Evaluating on the training split.
I0306 18:16:29.181319 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 18:16:36.467793 140339787351232 spec.py:349] Evaluating on the test split.
I0306 18:16:45.237884 140339787351232 submission_runner.py:469] Time since start: 20466.79s, 	Step: 5279, 	{'train/loss': 0.12444068976449517, 'validation/loss': 0.12408207773915116, 'validation/num_examples': 83274637, 'test/loss': 0.12637831313733552, 'test/num_examples': 95000000, 'score': 4837.710016489029, 'total_duration': 20466.78885245323, 'accumulated_submission_time': 4837.710016489029, 'accumulated_eval_time': 15627.63933134079, 'accumulated_logging_time': 1.0544040203094482}
I0306 18:16:45.246875 140185668916992 logging_writer.py:48] [5279] accumulated_eval_time=15627.6, accumulated_logging_time=1.0544, accumulated_submission_time=4837.71, global_step=5279, preemption_count=0, score=4837.71, test/loss=0.126378, test/num_examples=95000000, total_duration=20466.8, train/loss=0.124441, validation/loss=0.124082, validation/num_examples=83274637
I0306 18:16:47.546821 140185585055488 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.006616567261517048, loss=0.12179958820343018
I0306 18:18:35.900053 140185668916992 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.010592048056423664, loss=0.11809172481298447
I0306 18:18:45.938884 140339787351232 spec.py:321] Evaluating on the training split.
I0306 18:22:32.306156 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 18:22:39.540617 140339787351232 spec.py:349] Evaluating on the test split.
I0306 18:22:48.160082 140339787351232 submission_runner.py:469] Time since start: 20829.71s, 	Step: 5410, 	{'train/loss': 0.12268208297637273, 'validation/loss': 0.12420915164285518, 'validation/num_examples': 83274637, 'test/loss': 0.12655876630345395, 'test/num_examples': 95000000, 'score': 4958.385294437408, 'total_duration': 20829.71104168892, 'accumulated_submission_time': 4958.385294437408, 'accumulated_eval_time': 15869.86048579216, 'accumulated_logging_time': 1.0695278644561768}
I0306 18:22:48.169475 140185585055488 logging_writer.py:48] [5410] accumulated_eval_time=15869.9, accumulated_logging_time=1.06953, accumulated_submission_time=4958.39, global_step=5410, preemption_count=0, score=4958.39, test/loss=0.126559, test/num_examples=95000000, total_duration=20829.7, train/loss=0.122682, validation/loss=0.124209, validation/num_examples=83274637
I0306 18:24:04.010713 140185668916992 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.008147478103637695, loss=0.12002746760845184
I0306 18:24:48.985543 140339787351232 spec.py:321] Evaluating on the training split.
I0306 18:28:25.124856 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 18:28:32.648274 140339787351232 spec.py:349] Evaluating on the test split.
I0306 18:28:41.466405 140339787351232 submission_runner.py:469] Time since start: 21183.02s, 	Step: 5541, 	{'train/loss': 0.12302071056416575, 'validation/loss': 0.12419396327100621, 'validation/num_examples': 83274637, 'test/loss': 0.1265852228412829, 'test/num_examples': 95000000, 'score': 5079.1681451797485, 'total_duration': 21183.01736354828, 'accumulated_submission_time': 5079.1681451797485, 'accumulated_eval_time': 16102.341301441193, 'accumulated_logging_time': 1.1017327308654785}
I0306 18:28:41.476207 140185585055488 logging_writer.py:48] [5541] accumulated_eval_time=16102.3, accumulated_logging_time=1.10173, accumulated_submission_time=5079.17, global_step=5541, preemption_count=0, score=5079.17, test/loss=0.126585, test/num_examples=95000000, total_duration=21183, train/loss=0.123021, validation/loss=0.124194, validation/num_examples=83274637
I0306 18:29:23.262383 140185668916992 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.005801833234727383, loss=0.1145118996500969
I0306 18:30:42.037720 140339787351232 spec.py:321] Evaluating on the training split.
I0306 18:34:18.575457 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 18:34:26.214894 140339787351232 spec.py:349] Evaluating on the test split.
I0306 18:34:35.208613 140339787351232 submission_runner.py:469] Time since start: 21536.76s, 	Step: 5672, 	{'train/loss': 0.11963155503683495, 'validation/loss': 0.1242517738359276, 'validation/num_examples': 83274637, 'test/loss': 0.12657328369654605, 'test/num_examples': 95000000, 'score': 5199.713940620422, 'total_duration': 21536.759580373764, 'accumulated_submission_time': 5199.713940620422, 'accumulated_eval_time': 16335.512162208557, 'accumulated_logging_time': 1.1177198886871338}
I0306 18:34:35.217544 140185585055488 logging_writer.py:48] [5672] accumulated_eval_time=16335.5, accumulated_logging_time=1.11772, accumulated_submission_time=5199.71, global_step=5672, preemption_count=0, score=5199.71, test/loss=0.126573, test/num_examples=95000000, total_duration=21536.8, train/loss=0.119632, validation/loss=0.124252, validation/num_examples=83274637
I0306 18:34:39.822086 140185668916992 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.0066094850189983845, loss=0.11965715885162354
I0306 18:36:33.645823 140185585055488 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.014361477456986904, loss=0.11996304988861084
I0306 18:36:35.980061 140339787351232 spec.py:321] Evaluating on the training split.
I0306 18:40:12.348491 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 18:40:19.606675 140339787351232 spec.py:349] Evaluating on the test split.
I0306 18:40:28.257044 140339787351232 submission_runner.py:469] Time since start: 21889.81s, 	Step: 5803, 	{'train/loss': 0.120853370957592, 'validation/loss': 0.12413421849410163, 'validation/num_examples': 83274637, 'test/loss': 0.12651912083675987, 'test/num_examples': 95000000, 'score': 5320.46044921875, 'total_duration': 21889.80800485611, 'accumulated_submission_time': 5320.46044921875, 'accumulated_eval_time': 16567.789128303528, 'accumulated_logging_time': 1.1326439380645752}
I0306 18:40:28.266587 140185668916992 logging_writer.py:48] [5803] accumulated_eval_time=16567.8, accumulated_logging_time=1.13264, accumulated_submission_time=5320.46, global_step=5803, preemption_count=0, score=5320.46, test/loss=0.126519, test/num_examples=95000000, total_duration=21889.8, train/loss=0.120853, validation/loss=0.124134, validation/num_examples=83274637
I0306 18:41:50.551064 140185585055488 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.014665174297988415, loss=0.12238375842571259
I0306 18:42:28.654091 140339787351232 spec.py:321] Evaluating on the training split.
I0306 18:46:02.091742 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 18:46:09.810946 140339787351232 spec.py:349] Evaluating on the test split.
I0306 18:46:18.502094 140339787351232 submission_runner.py:469] Time since start: 22240.05s, 	Step: 5931, 	{'train/loss': 0.12356366782958778, 'validation/loss': 0.12424719143641201, 'validation/num_examples': 83274637, 'test/loss': 0.12660915516036184, 'test/num_examples': 95000000, 'score': 5440.831295967102, 'total_duration': 22240.053060770035, 'accumulated_submission_time': 5440.831295967102, 'accumulated_eval_time': 16797.637093544006, 'accumulated_logging_time': 1.148430347442627}
I0306 18:46:18.535542 140185668916992 logging_writer.py:48] [5931] accumulated_eval_time=16797.6, accumulated_logging_time=1.14843, accumulated_submission_time=5440.83, global_step=5931, preemption_count=0, score=5440.83, test/loss=0.126609, test/num_examples=95000000, total_duration=22240.1, train/loss=0.123564, validation/loss=0.124247, validation/num_examples=83274637
I0306 18:47:09.853066 140185585055488 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.010099908336997032, loss=0.1253392994403839
I0306 18:48:20.956279 140339787351232 spec.py:321] Evaluating on the training split.
I0306 18:51:52.028292 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 18:51:59.677732 140339787351232 spec.py:349] Evaluating on the test split.
I0306 18:52:08.308889 140339787351232 submission_runner.py:469] Time since start: 22589.86s, 	Step: 6061, 	{'train/loss': 0.12428616384430877, 'validation/loss': 0.12441246350107926, 'validation/num_examples': 83274637, 'test/loss': 0.12679097071340462, 'test/num_examples': 95000000, 'score': 5563.223793745041, 'total_duration': 22589.859820842743, 'accumulated_submission_time': 5563.223793745041, 'accumulated_eval_time': 17024.989629030228, 'accumulated_logging_time': 1.2003881931304932}
I0306 18:52:08.320134 140185668916992 logging_writer.py:48] [6061] accumulated_eval_time=17025, accumulated_logging_time=1.20039, accumulated_submission_time=5563.22, global_step=6061, preemption_count=0, score=5563.22, test/loss=0.126791, test/num_examples=95000000, total_duration=22589.9, train/loss=0.124286, validation/loss=0.124412, validation/num_examples=83274637
I0306 18:52:23.693806 140185585055488 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.016038240864872932, loss=0.12583166360855103
I0306 18:54:08.746723 140339787351232 spec.py:321] Evaluating on the training split.
I0306 18:57:46.856850 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 18:57:54.298042 140339787351232 spec.py:349] Evaluating on the test split.
I0306 18:58:02.949349 140339787351232 submission_runner.py:469] Time since start: 22944.50s, 	Step: 6191, 	{'train/loss': 0.1257532609146346, 'validation/loss': 0.12432882500581892, 'validation/num_examples': 83274637, 'test/loss': 0.1265945744243421, 'test/num_examples': 95000000, 'score': 5683.633327007294, 'total_duration': 22944.50031208992, 'accumulated_submission_time': 5683.633327007294, 'accumulated_eval_time': 17259.192220926285, 'accumulated_logging_time': 1.2183516025543213}
I0306 18:58:02.959554 140185668916992 logging_writer.py:48] [6191] accumulated_eval_time=17259.2, accumulated_logging_time=1.21835, accumulated_submission_time=5683.63, global_step=6191, preemption_count=0, score=5683.63, test/loss=0.126595, test/num_examples=95000000, total_duration=22944.5, train/loss=0.125753, validation/loss=0.124329, validation/num_examples=83274637
I0306 18:58:04.002798 140185585055488 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.013403653167188168, loss=0.12312251329421997
I0306 18:59:38.737818 140185668916992 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.03024173714220524, loss=0.12095101177692413
I0306 19:00:03.070434 140339787351232 spec.py:321] Evaluating on the training split.
I0306 19:03:54.004917 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 19:04:01.318780 140339787351232 spec.py:349] Evaluating on the test split.
I0306 19:04:10.182114 140339787351232 submission_runner.py:469] Time since start: 23311.73s, 	Step: 6323, 	{'train/loss': 0.1226680363710009, 'validation/loss': 0.12417553719483265, 'validation/num_examples': 83274637, 'test/loss': 0.12654458884662828, 'test/num_examples': 95000000, 'score': 5803.726902246475, 'total_duration': 23311.733041763306, 'accumulated_submission_time': 5803.726902246475, 'accumulated_eval_time': 17506.303830385208, 'accumulated_logging_time': 1.2354815006256104}
I0306 19:04:10.193133 140185585055488 logging_writer.py:48] [6323] accumulated_eval_time=17506.3, accumulated_logging_time=1.23548, accumulated_submission_time=5803.73, global_step=6323, preemption_count=0, score=5803.73, test/loss=0.126545, test/num_examples=95000000, total_duration=23311.7, train/loss=0.122668, validation/loss=0.124176, validation/num_examples=83274637
I0306 19:05:10.370143 140185668916992 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.007689214777201414, loss=0.12215235829353333
I0306 19:06:10.829895 140339787351232 spec.py:321] Evaluating on the training split.
I0306 19:09:54.578505 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 19:10:01.939331 140339787351232 spec.py:349] Evaluating on the test split.
I0306 19:10:10.613220 140339787351232 submission_runner.py:469] Time since start: 23672.16s, 	Step: 6456, 	{'train/loss': 0.12213424829848157, 'validation/loss': 0.12415889030543373, 'validation/num_examples': 83274637, 'test/loss': 0.1265046060649671, 'test/num_examples': 95000000, 'score': 5924.346400499344, 'total_duration': 23672.164179563522, 'accumulated_submission_time': 5924.346400499344, 'accumulated_eval_time': 17746.0871052742, 'accumulated_logging_time': 1.2533743381500244}
I0306 19:10:10.622688 140185585055488 logging_writer.py:48] [6456] accumulated_eval_time=17746.1, accumulated_logging_time=1.25337, accumulated_submission_time=5924.35, global_step=6456, preemption_count=0, score=5924.35, test/loss=0.126505, test/num_examples=95000000, total_duration=23672.2, train/loss=0.122134, validation/loss=0.124159, validation/num_examples=83274637
I0306 19:10:32.497714 140185668916992 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.010423853993415833, loss=0.12868186831474304
I0306 19:12:11.334604 140339787351232 spec.py:321] Evaluating on the training split.
I0306 19:15:48.762865 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 19:15:56.070802 140339787351232 spec.py:349] Evaluating on the test split.
I0306 19:16:04.937116 140339787351232 submission_runner.py:469] Time since start: 24026.49s, 	Step: 6591, 	{'train/loss': 0.12430874941249688, 'validation/loss': 0.12427120661141024, 'validation/num_examples': 83274637, 'test/loss': 0.12665193784950657, 'test/num_examples': 95000000, 'score': 6045.04131269455, 'total_duration': 24026.488077878952, 'accumulated_submission_time': 6045.04131269455, 'accumulated_eval_time': 17979.689574480057, 'accumulated_logging_time': 1.2698581218719482}
I0306 19:16:04.946595 140185585055488 logging_writer.py:48] [6591] accumulated_eval_time=17979.7, accumulated_logging_time=1.26986, accumulated_submission_time=6045.04, global_step=6591, preemption_count=0, score=6045.04, test/loss=0.126652, test/num_examples=95000000, total_duration=24026.5, train/loss=0.124309, validation/loss=0.124271, validation/num_examples=83274637
I0306 19:16:05.982833 140185668916992 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.008112951181828976, loss=0.1136118695139885
I0306 19:17:38.246181 140185585055488 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.008739554323256016, loss=0.12617158889770508
I0306 19:18:06.268362 140339787351232 spec.py:321] Evaluating on the training split.
I0306 19:21:47.504174 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 19:21:54.806084 140339787351232 spec.py:349] Evaluating on the test split.
I0306 19:22:03.411825 140339787351232 submission_runner.py:469] Time since start: 24384.96s, 	Step: 6725, 	{'train/loss': 0.12232591637041208, 'validation/loss': 0.12407002392084691, 'validation/num_examples': 83274637, 'test/loss': 0.12633681567639804, 'test/num_examples': 95000000, 'score': 6166.339028596878, 'total_duration': 24384.962792873383, 'accumulated_submission_time': 6166.339028596878, 'accumulated_eval_time': 18216.832998991013, 'accumulated_logging_time': 1.293459177017212}
I0306 19:22:03.421178 140185668916992 logging_writer.py:48] [6725] accumulated_eval_time=18216.8, accumulated_logging_time=1.29346, accumulated_submission_time=6166.34, global_step=6725, preemption_count=0, score=6166.34, test/loss=0.126337, test/num_examples=95000000, total_duration=24385, train/loss=0.122326, validation/loss=0.12407, validation/num_examples=83274637
I0306 19:23:04.165956 140185585055488 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.012675121426582336, loss=0.12069591134786606
I0306 19:24:03.664188 140339787351232 spec.py:321] Evaluating on the training split.
I0306 19:27:37.725221 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 19:27:45.052936 140339787351232 spec.py:349] Evaluating on the test split.
I0306 19:27:53.611363 140339787351232 submission_runner.py:469] Time since start: 24735.16s, 	Step: 6851, 	{'train/loss': 0.1218055184087101, 'validation/loss': 0.1240427785585375, 'validation/num_examples': 83274637, 'test/loss': 0.12636871238692435, 'test/num_examples': 95000000, 'score': 6286.566481113434, 'total_duration': 24735.162326574326, 'accumulated_submission_time': 6286.566481113434, 'accumulated_eval_time': 18446.780131578445, 'accumulated_logging_time': 1.3088762760162354}
I0306 19:27:53.641944 140185668916992 logging_writer.py:48] [6851] accumulated_eval_time=18446.8, accumulated_logging_time=1.30888, accumulated_submission_time=6286.57, global_step=6851, preemption_count=0, score=6286.57, test/loss=0.126369, test/num_examples=95000000, total_duration=24735.2, train/loss=0.121806, validation/loss=0.124043, validation/num_examples=83274637
I0306 19:28:26.741586 140185585055488 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.007883635349571705, loss=0.12280906736850739
I0306 19:29:54.371095 140339787351232 spec.py:321] Evaluating on the training split.
I0306 19:33:38.850286 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 19:33:46.008056 140339787351232 spec.py:349] Evaluating on the test split.
I0306 19:33:54.511234 140339787351232 submission_runner.py:469] Time since start: 25096.06s, 	Step: 6979, 	{'train/loss': 0.12291293995419764, 'validation/loss': 0.12394246604344061, 'validation/num_examples': 83274637, 'test/loss': 0.1263249980160362, 'test/num_examples': 95000000, 'score': 6407.215991735458, 'total_duration': 25096.062175273895, 'accumulated_submission_time': 6407.215991735458, 'accumulated_eval_time': 18686.92020702362, 'accumulated_logging_time': 1.409529209136963}
I0306 19:33:54.521349 140185668916992 logging_writer.py:48] [6979] accumulated_eval_time=18686.9, accumulated_logging_time=1.40953, accumulated_submission_time=6407.22, global_step=6979, preemption_count=0, score=6407.22, test/loss=0.126325, test/num_examples=95000000, total_duration=25096.1, train/loss=0.122913, validation/loss=0.123942, validation/num_examples=83274637
I0306 19:33:56.805588 140185585055488 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.006069445051252842, loss=0.12302953004837036
I0306 19:35:39.402886 140185668916992 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.010285609401762486, loss=0.12504026293754578
I0306 19:35:55.331642 140339787351232 spec.py:321] Evaluating on the training split.
I0306 19:39:32.880871 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 19:39:40.400113 140339787351232 spec.py:349] Evaluating on the test split.
I0306 19:39:49.310032 140339787351232 submission_runner.py:469] Time since start: 25450.86s, 	Step: 7116, 	{'train/loss': 0.1232527189964206, 'validation/loss': 0.12406401024562556, 'validation/num_examples': 83274637, 'test/loss': 0.1262982859272204, 'test/num_examples': 95000000, 'score': 6528.00866150856, 'total_duration': 25450.86100101471, 'accumulated_submission_time': 6528.00866150856, 'accumulated_eval_time': 18920.89856529236, 'accumulated_logging_time': 1.4270086288452148}
I0306 19:39:49.321491 140185585055488 logging_writer.py:48] [7116] accumulated_eval_time=18920.9, accumulated_logging_time=1.42701, accumulated_submission_time=6528.01, global_step=7116, preemption_count=0, score=6528.01, test/loss=0.126298, test/num_examples=95000000, total_duration=25450.9, train/loss=0.123253, validation/loss=0.124064, validation/num_examples=83274637
I0306 19:40:57.525638 140185668916992 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.014685987494885921, loss=0.13482555747032166
I0306 19:41:49.640494 140339787351232 spec.py:321] Evaluating on the training split.
I0306 19:45:26.311946 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 19:45:33.598119 140339787351232 spec.py:349] Evaluating on the test split.
I0306 19:45:42.385303 140339787351232 submission_runner.py:469] Time since start: 25803.94s, 	Step: 7245, 	{'train/loss': 0.12336867531093787, 'validation/loss': 0.12385443354308016, 'validation/num_examples': 83274637, 'test/loss': 0.12615540984786183, 'test/num_examples': 95000000, 'score': 6648.310398101807, 'total_duration': 25803.936245918274, 'accumulated_submission_time': 6648.310398101807, 'accumulated_eval_time': 19153.643316984177, 'accumulated_logging_time': 1.4465827941894531}
I0306 19:45:42.396109 140185585055488 logging_writer.py:48] [7245] accumulated_eval_time=19153.6, accumulated_logging_time=1.44658, accumulated_submission_time=6648.31, global_step=7245, preemption_count=0, score=6648.31, test/loss=0.126155, test/num_examples=95000000, total_duration=25803.9, train/loss=0.123369, validation/loss=0.123854, validation/num_examples=83274637
I0306 19:46:17.863835 140185668916992 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.00801992230117321, loss=0.12083267420530319
I0306 19:47:42.752367 140339787351232 spec.py:321] Evaluating on the training split.
I0306 19:51:24.590994 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 19:51:32.064329 140339787351232 spec.py:349] Evaluating on the test split.
I0306 19:51:40.849577 140339787351232 submission_runner.py:469] Time since start: 26162.40s, 	Step: 7374, 	{'train/loss': 0.12202591430278695, 'validation/loss': 0.1239012324573481, 'validation/num_examples': 83274637, 'test/loss': 0.12617797489720395, 'test/num_examples': 95000000, 'score': 6768.63076710701, 'total_duration': 26162.40053510666, 'accumulated_submission_time': 6768.63076710701, 'accumulated_eval_time': 19391.740478515625, 'accumulated_logging_time': 1.4822049140930176}
I0306 19:51:40.859912 140185585055488 logging_writer.py:48] [7374] accumulated_eval_time=19391.7, accumulated_logging_time=1.4822, accumulated_submission_time=6768.63, global_step=7374, preemption_count=0, score=6768.63, test/loss=0.126178, test/num_examples=95000000, total_duration=26162.4, train/loss=0.122026, validation/loss=0.123901, validation/num_examples=83274637
I0306 19:51:43.700538 140185668916992 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.006520503666251898, loss=0.12848815321922302
I0306 19:53:37.319004 140185585055488 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.005622255615890026, loss=0.1264912188053131
I0306 19:53:41.582166 140339787351232 spec.py:321] Evaluating on the training split.
I0306 19:57:19.032459 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 19:57:26.389145 140339787351232 spec.py:349] Evaluating on the test split.
I0306 19:57:35.409075 140339787351232 submission_runner.py:469] Time since start: 26516.96s, 	Step: 7505, 	{'train/loss': 0.12064510217205908, 'validation/loss': 0.1239093264455066, 'validation/num_examples': 83274637, 'test/loss': 0.12623553109580593, 'test/num_examples': 95000000, 'score': 6889.336634159088, 'total_duration': 26516.960023880005, 'accumulated_submission_time': 6889.336634159088, 'accumulated_eval_time': 19625.567340135574, 'accumulated_logging_time': 1.498621940612793}
I0306 19:57:35.419021 140185668916992 logging_writer.py:48] [7505] accumulated_eval_time=19625.6, accumulated_logging_time=1.49862, accumulated_submission_time=6889.34, global_step=7505, preemption_count=0, score=6889.34, test/loss=0.126236, test/num_examples=95000000, total_duration=26517, train/loss=0.120645, validation/loss=0.123909, validation/num_examples=83274637
I0306 19:58:54.373354 140185585055488 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.013790090568363667, loss=0.12915877997875214
I0306 19:59:36.572329 140339787351232 spec.py:321] Evaluating on the training split.
I0306 20:03:26.702677 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 20:03:34.027350 140339787351232 spec.py:349] Evaluating on the test split.
I0306 20:03:42.746033 140339787351232 submission_runner.py:469] Time since start: 26884.30s, 	Step: 7637, 	{'train/loss': 0.12112517356169673, 'validation/loss': 0.12396345280606154, 'validation/num_examples': 83274637, 'test/loss': 0.12624936728001646, 'test/num_examples': 95000000, 'score': 7010.472729921341, 'total_duration': 26884.296994924545, 'accumulated_submission_time': 7010.472729921341, 'accumulated_eval_time': 19871.74100112915, 'accumulated_logging_time': 1.515608310699463}
I0306 20:03:42.756108 140185668916992 logging_writer.py:48] [7637] accumulated_eval_time=19871.7, accumulated_logging_time=1.51561, accumulated_submission_time=7010.47, global_step=7637, preemption_count=0, score=7010.47, test/loss=0.126249, test/num_examples=95000000, total_duration=26884.3, train/loss=0.121125, validation/loss=0.123963, validation/num_examples=83274637
I0306 20:04:26.581168 140185585055488 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.006109936628490686, loss=0.11868709325790405
I0306 20:05:44.122016 140339787351232 spec.py:321] Evaluating on the training split.
I0306 20:09:31.859746 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 20:09:39.208635 140339787351232 spec.py:349] Evaluating on the test split.
I0306 20:09:48.112123 140339787351232 submission_runner.py:469] Time since start: 27249.66s, 	Step: 7770, 	{'train/loss': 0.12231497772319137, 'validation/loss': 0.12386257724203402, 'validation/num_examples': 83274637, 'test/loss': 0.12620041381578948, 'test/num_examples': 95000000, 'score': 7131.822902202606, 'total_duration': 27249.663075208664, 'accumulated_submission_time': 7131.822902202606, 'accumulated_eval_time': 20115.731070041656, 'accumulated_logging_time': 1.5317189693450928}
I0306 20:09:48.124905 140185668916992 logging_writer.py:48] [7770] accumulated_eval_time=20115.7, accumulated_logging_time=1.53172, accumulated_submission_time=7131.82, global_step=7770, preemption_count=0, score=7131.82, test/loss=0.1262, test/num_examples=95000000, total_duration=27249.7, train/loss=0.122315, validation/loss=0.123863, validation/num_examples=83274637
I0306 20:09:54.648945 140185585055488 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.006310941185802221, loss=0.12352073937654495
I0306 20:11:48.146780 140339787351232 spec.py:321] Evaluating on the training split.
I0306 20:15:34.083025 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 20:15:41.430056 140339787351232 spec.py:349] Evaluating on the test split.
I0306 20:15:50.253593 140339787351232 submission_runner.py:469] Time since start: 27611.80s, 	Step: 7900, 	{'train/loss': 0.12197706113868165, 'validation/loss': 0.12398854645553348, 'validation/num_examples': 83274637, 'test/loss': 0.12636558840460527, 'test/num_examples': 95000000, 'score': 7251.794536352158, 'total_duration': 27611.804558753967, 'accumulated_submission_time': 7251.794536352158, 'accumulated_eval_time': 20357.838046312332, 'accumulated_logging_time': 1.5843541622161865}
I0306 20:15:50.264168 140185668916992 logging_writer.py:48] [7900] accumulated_eval_time=20357.8, accumulated_logging_time=1.58435, accumulated_submission_time=7251.79, global_step=7900, preemption_count=0, score=7251.79, test/loss=0.126366, test/num_examples=95000000, total_duration=27611.8, train/loss=0.121977, validation/loss=0.123989, validation/num_examples=83274637
I0306 20:15:50.424009 140185585055488 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.010256159119307995, loss=0.1273246705532074
I0306 20:17:18.923650 140185668916992 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.008029383607208729, loss=0.1305096596479416
I0306 20:17:51.131387 140339787351232 spec.py:321] Evaluating on the training split.
I0306 20:21:39.244572 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 20:21:46.476004 140339787351232 spec.py:349] Evaluating on the test split.
I0306 20:21:55.035144 140339787351232 submission_runner.py:469] Time since start: 27976.59s, 	Step: 8029, 	{'train/loss': 0.12054530166839279, 'validation/loss': 0.12387541944962936, 'validation/num_examples': 83274637, 'test/loss': 0.12622425652754934, 'test/num_examples': 95000000, 'score': 7372.6444709300995, 'total_duration': 27976.586094856262, 'accumulated_submission_time': 7372.6444709300995, 'accumulated_eval_time': 20601.741747140884, 'accumulated_logging_time': 1.6020512580871582}
I0306 20:21:55.047052 140185585055488 logging_writer.py:48] [8029] accumulated_eval_time=20601.7, accumulated_logging_time=1.60205, accumulated_submission_time=7372.64, global_step=8029, preemption_count=0, score=7372.64, test/loss=0.126224, test/num_examples=95000000, total_duration=27976.6, train/loss=0.120545, validation/loss=0.123875, validation/num_examples=83274637
I0306 20:22:47.733500 140185668916992 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.006879138294607401, loss=0.11950413882732391
I0306 20:23:55.968441 140339787351232 spec.py:321] Evaluating on the training split.
I0306 20:27:37.507145 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 20:27:44.940013 140339787351232 spec.py:349] Evaluating on the test split.
I0306 20:27:53.788323 140339787351232 submission_runner.py:469] Time since start: 28335.34s, 	Step: 8161, 	{'train/loss': 0.12345322467527299, 'validation/loss': 0.12392033408552264, 'validation/num_examples': 83274637, 'test/loss': 0.12623807544202303, 'test/num_examples': 95000000, 'score': 7493.548492670059, 'total_duration': 28335.339287757874, 'accumulated_submission_time': 7493.548492670059, 'accumulated_eval_time': 20839.561594724655, 'accumulated_logging_time': 1.620368242263794}
I0306 20:27:53.798451 140185585055488 logging_writer.py:48] [8161] accumulated_eval_time=20839.6, accumulated_logging_time=1.62037, accumulated_submission_time=7493.55, global_step=8161, preemption_count=0, score=7493.55, test/loss=0.126238, test/num_examples=95000000, total_duration=28335.3, train/loss=0.123453, validation/loss=0.12392, validation/num_examples=83274637
I0306 20:28:10.715831 140185668916992 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.009202147834002972, loss=0.12122278660535812
I0306 20:29:54.768989 140339787351232 spec.py:321] Evaluating on the training split.
I0306 20:33:31.547987 140339787351232 spec.py:333] Evaluating on the validation split.
I0306 20:33:39.019239 140339787351232 spec.py:349] Evaluating on the test split.
I0306 20:33:47.755742 140339787351232 submission_runner.py:469] Time since start: 28689.31s, 	Step: 8295, 	{'train/loss': 0.12245753569141873, 'validation/loss': 0.12384257117407751, 'validation/num_examples': 83274637, 'test/loss': 0.12609908645148027, 'test/num_examples': 95000000, 'score': 7614.475512504578, 'total_duration': 28689.30668568611, 'accumulated_submission_time': 7614.475512504578, 'accumulated_eval_time': 21072.54828619957, 'accumulated_logging_time': 1.663686990737915}
I0306 20:33:47.766236 140185585055488 logging_writer.py:48] [8295] accumulated_eval_time=21072.5, accumulated_logging_time=1.66369, accumulated_submission_time=7614.48, global_step=8295, preemption_count=0, score=7614.48, test/loss=0.126099, test/num_examples=95000000, total_duration=28689.3, train/loss=0.122458, validation/loss=0.123843, validation/num_examples=83274637
I0306 20:33:48.413720 140185668916992 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.00575224868953228, loss=0.12212531268596649
I0306 20:35:22.578970 140185585055488 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.007983769290149212, loss=0.12946778535842896
I0306 20:35:50.560530 140185668916992 logging_writer.py:48] [8423] global_step=8423, preemption_count=0, score=7737.23
I0306 20:35:55.405341 140339787351232 submission_runner.py:646] Tuning trial 2/5
I0306 20:35:55.425587 140339787351232 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.2, learning_rate=0.0008445074561975979, one_minus_beta1=0.11042418465, beta2=0.9978504782314613, weight_decay=0.08135402759553023, warmup_factor=0.05)
I0306 20:35:55.426818 140339787351232 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/loss': 0.6638776870831004, 'validation/loss': 0.6720217353851989, 'validation/num_examples': 83274637, 'test/loss': 0.6659842837171053, 'test/num_examples': 95000000, 'score': 12.939538955688477, 'total_duration': 1110.987648487091, 'accumulated_submission_time': 12.939538955688477, 'accumulated_eval_time': 1098.0480163097382, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (133, {'train/loss': 0.13226640463437675, 'validation/loss': 0.13193598768188342, 'validation/num_examples': 83274637, 'test/loss': 0.13511449777960527, 'test/num_examples': 95000000, 'score': 133.71610736846924, 'total_duration': 2195.314699411392, 'accumulated_submission_time': 133.71610736846924, 'accumulated_eval_time': 2061.574338912964, 'accumulated_logging_time': 0.016852855682373047, 'global_step': 133, 'preemption_count': 0}), (268, {'train/loss': 0.1280522385155255, 'validation/loss': 0.1288916950098241, 'validation/num_examples': 83274637, 'test/loss': 0.13150973726356907, 'test/num_examples': 95000000, 'score': 254.01084756851196, 'total_duration': 3306.6324026584625, 'accumulated_submission_time': 254.01084756851196, 'accumulated_eval_time': 3052.5762355327606, 'accumulated_logging_time': 0.030802011489868164, 'global_step': 268, 'preemption_count': 0}), (400, {'train/loss': 0.12667035487181735, 'validation/loss': 0.12827270590785494, 'validation/num_examples': 83274637, 'test/loss': 0.13079889851973683, 'test/num_examples': 95000000, 'score': 374.1688508987427, 'total_duration': 4390.592525482178, 'accumulated_submission_time': 374.1688508987427, 'accumulated_eval_time': 4016.355004787445, 'accumulated_logging_time': 0.04709219932556152, 'global_step': 400, 'preemption_count': 0}), (530, {'train/loss': 0.12712972105111717, 'validation/loss': 0.1269337720854554, 'validation/num_examples': 83274637, 'test/loss': 0.12950648403577303, 'test/num_examples': 95000000, 'score': 494.19627928733826, 'total_duration': 5448.820786476135, 'accumulated_submission_time': 494.19627928733826, 'accumulated_eval_time': 4954.534299135208, 'accumulated_logging_time': 0.0614016056060791, 'global_step': 530, 'preemption_count': 0}), (665, {'train/loss': 0.12759532422155329, 'validation/loss': 0.12700153259618083, 'validation/num_examples': 83274637, 'test/loss': 0.1296096310855263, 'test/num_examples': 95000000, 'score': 614.716376543045, 'total_duration': 6429.514367341995, 'accumulated_submission_time': 614.716376543045, 'accumulated_eval_time': 5814.685781002045, 'accumulated_logging_time': 0.07641434669494629, 'global_step': 665, 'preemption_count': 0}), (795, {'train/loss': 0.12442182039596, 'validation/loss': 0.12653519639901356, 'validation/num_examples': 83274637, 'test/loss': 0.12901377006578948, 'test/num_examples': 95000000, 'score': 736.322979927063, 'total_duration': 7407.854723453522, 'accumulated_submission_time': 736.322979927063, 'accumulated_eval_time': 6671.397732496262, 'accumulated_logging_time': 0.09142756462097168, 'global_step': 795, 'preemption_count': 0}), (925, {'train/loss': 0.12567190574072068, 'validation/loss': 0.12644808397640292, 'validation/num_examples': 83274637, 'test/loss': 0.12891937269736842, 'test/num_examples': 95000000, 'score': 857.528754234314, 'total_duration': 8292.312840223312, 'accumulated_submission_time': 857.528754234314, 'accumulated_eval_time': 7434.588493347168, 'accumulated_logging_time': 0.1459064483642578, 'global_step': 925, 'preemption_count': 0}), (1054, {'train/loss': 0.12718734387659802, 'validation/loss': 0.12646198999384597, 'validation/num_examples': 83274637, 'test/loss': 0.12904312219366776, 'test/num_examples': 95000000, 'score': 978.0316066741943, 'total_duration': 8980.565180301666, 'accumulated_submission_time': 978.0316066741943, 'accumulated_eval_time': 8002.282534360886, 'accumulated_logging_time': 0.1928858757019043, 'global_step': 1054, 'preemption_count': 0}), (1187, {'train/loss': 0.12726230020839838, 'validation/loss': 0.1270163713799985, 'validation/num_examples': 83274637, 'test/loss': 0.12952042274876643, 'test/num_examples': 95000000, 'score': 1099.5975060462952, 'total_duration': 9320.791712284088, 'accumulated_submission_time': 1099.5975060462952, 'accumulated_eval_time': 8220.920379161835, 'accumulated_logging_time': 0.20662689208984375, 'global_step': 1187, 'preemption_count': 0}), (1317, {'train/loss': 0.12280835854416748, 'validation/loss': 0.1256999730888387, 'validation/num_examples': 83274637, 'test/loss': 0.12811381315789475, 'test/num_examples': 95000000, 'score': 1219.8451099395752, 'total_duration': 9667.034027338028, 'accumulated_submission_time': 1219.8451099395752, 'accumulated_eval_time': 8446.89096403122, 'accumulated_logging_time': 0.22112822532653809, 'global_step': 1317, 'preemption_count': 0}), (1447, {'train/loss': 0.12611478691299757, 'validation/loss': 0.12582369590562206, 'validation/num_examples': 83274637, 'test/loss': 0.12824267183388158, 'test/num_examples': 95000000, 'score': 1341.5407948493958, 'total_duration': 10017.890672206879, 'accumulated_submission_time': 1341.5407948493958, 'accumulated_eval_time': 8676.008271932602, 'accumulated_logging_time': 0.2550997734069824, 'global_step': 1447, 'preemption_count': 0}), (1580, {'train/loss': 0.12541013189925337, 'validation/loss': 0.12603643333053496, 'validation/num_examples': 83274637, 'test/loss': 0.12846060021587172, 'test/num_examples': 95000000, 'score': 1462.0087404251099, 'total_duration': 10365.442111492157, 'accumulated_submission_time': 1462.0087404251099, 'accumulated_eval_time': 8903.066642522812, 'accumulated_logging_time': 0.27018141746520996, 'global_step': 1580, 'preemption_count': 0}), (1717, {'train/loss': 0.12271162473930503, 'validation/loss': 0.1254551975605861, 'validation/num_examples': 83274637, 'test/loss': 0.12783988479646383, 'test/num_examples': 95000000, 'score': 1582.66610455513, 'total_duration': 10714.675741910934, 'accumulated_submission_time': 1582.66610455513, 'accumulated_eval_time': 9131.618814468384, 'accumulated_logging_time': 0.28414154052734375, 'global_step': 1717, 'preemption_count': 0}), (1855, {'train/loss': 0.12487018109539395, 'validation/loss': 0.1257428938750395, 'validation/num_examples': 83274637, 'test/loss': 0.12826413875411183, 'test/num_examples': 95000000, 'score': 1702.6306369304657, 'total_duration': 11060.754112005234, 'accumulated_submission_time': 1702.6306369304657, 'accumulated_eval_time': 9357.63459444046, 'accumulated_logging_time': 0.37154173851013184, 'global_step': 1855, 'preemption_count': 0}), (1983, {'train/loss': 0.1236365157407972, 'validation/loss': 0.12552868550194604, 'validation/num_examples': 83274637, 'test/loss': 0.12801613432360198, 'test/num_examples': 95000000, 'score': 1822.8981063365936, 'total_duration': 11438.21965932846, 'accumulated_submission_time': 1822.8981063365936, 'accumulated_eval_time': 9614.808578491211, 'accumulated_logging_time': 0.38559675216674805, 'global_step': 1983, 'preemption_count': 0}), (2114, {'train/loss': 0.12504178607754363, 'validation/loss': 0.1256199996360105, 'validation/num_examples': 83274637, 'test/loss': 0.12807082970805922, 'test/num_examples': 95000000, 'score': 1943.0422768592834, 'total_duration': 11814.73499917984, 'accumulated_submission_time': 1943.0422768592834, 'accumulated_eval_time': 9871.135347127914, 'accumulated_logging_time': 0.42000341415405273, 'global_step': 2114, 'preemption_count': 0}), (2242, {'train/loss': 0.12413560520599848, 'validation/loss': 0.12520900158065798, 'validation/num_examples': 83274637, 'test/loss': 0.12765085318667763, 'test/num_examples': 95000000, 'score': 2063.7976536750793, 'total_duration': 12185.406038761139, 'accumulated_submission_time': 2063.7976536750793, 'accumulated_eval_time': 10121.026782274246, 'accumulated_logging_time': 0.4348273277282715, 'global_step': 2242, 'preemption_count': 0}), (2377, {'train/loss': 0.12301755186943512, 'validation/loss': 0.1252236283108175, 'validation/num_examples': 83274637, 'test/loss': 0.1275730989925987, 'test/num_examples': 95000000, 'score': 2184.8439967632294, 'total_duration': 12554.223861932755, 'accumulated_submission_time': 2184.8439967632294, 'accumulated_eval_time': 10368.769230604172, 'accumulated_logging_time': 0.4524505138397217, 'global_step': 2377, 'preemption_count': 0}), (2515, {'train/loss': 0.12428706965215926, 'validation/loss': 0.12518441147140447, 'validation/num_examples': 83274637, 'test/loss': 0.12766349969161184, 'test/num_examples': 95000000, 'score': 2305.123528957367, 'total_duration': 12923.471545696259, 'accumulated_submission_time': 2305.123528957367, 'accumulated_eval_time': 10617.712666511536, 'accumulated_logging_time': 0.46770477294921875, 'global_step': 2515, 'preemption_count': 0}), (2648, {'train/loss': 0.12477573058890097, 'validation/loss': 0.12482437431066384, 'validation/num_examples': 83274637, 'test/loss': 0.12707150013363486, 'test/num_examples': 95000000, 'score': 2425.3730533123016, 'total_duration': 13284.174051046371, 'accumulated_submission_time': 2425.3730533123016, 'accumulated_eval_time': 10858.137867212296, 'accumulated_logging_time': 0.4847123622894287, 'global_step': 2648, 'preemption_count': 0}), (2780, {'train/loss': 0.12389525849629873, 'validation/loss': 0.1251506935676998, 'validation/num_examples': 83274637, 'test/loss': 0.12755006296258223, 'test/num_examples': 95000000, 'score': 2545.56321144104, 'total_duration': 13638.225637197495, 'accumulated_submission_time': 2545.56321144104, 'accumulated_eval_time': 11091.898374557495, 'accumulated_logging_time': 0.5755856037139893, 'global_step': 2780, 'preemption_count': 0}), (2915, {'train/loss': 0.12280079789178551, 'validation/loss': 0.1250706682111254, 'validation/num_examples': 83274637, 'test/loss': 0.12758728129111843, 'test/num_examples': 95000000, 'score': 2666.571323156357, 'total_duration': 13999.341974258423, 'accumulated_submission_time': 2666.571323156357, 'accumulated_eval_time': 11331.980484485626, 'accumulated_logging_time': 0.5911178588867188, 'global_step': 2915, 'preemption_count': 0}), (3045, {'train/loss': 0.12543551786656273, 'validation/loss': 0.1249610069178011, 'validation/num_examples': 83274637, 'test/loss': 0.1273094214740954, 'test/num_examples': 95000000, 'score': 2787.055482149124, 'total_duration': 14355.379331827164, 'accumulated_submission_time': 2787.055482149124, 'accumulated_eval_time': 11567.50882267952, 'accumulated_logging_time': 0.6059231758117676, 'global_step': 3045, 'preemption_count': 0}), (3174, {'train/loss': 0.12493689245772811, 'validation/loss': 0.12487605629911999, 'validation/num_examples': 83274637, 'test/loss': 0.12727106988075657, 'test/num_examples': 95000000, 'score': 2907.9970190525055, 'total_duration': 14721.468026161194, 'accumulated_submission_time': 2907.9970190525055, 'accumulated_eval_time': 11812.608943939209, 'accumulated_logging_time': 0.6433284282684326, 'global_step': 3174, 'preemption_count': 0}), (3306, {'train/loss': 0.12460863041990208, 'validation/loss': 0.12475219752524634, 'validation/num_examples': 83274637, 'test/loss': 0.12709369579564145, 'test/num_examples': 95000000, 'score': 3028.092873811722, 'total_duration': 15075.34069108963, 'accumulated_submission_time': 3028.092873811722, 'accumulated_eval_time': 12046.360619783401, 'accumulated_logging_time': 0.658679723739624, 'global_step': 3306, 'preemption_count': 0}), (3433, {'train/loss': 0.12631541237516222, 'validation/loss': 0.12495184056494109, 'validation/num_examples': 83274637, 'test/loss': 0.12721558587582238, 'test/num_examples': 95000000, 'score': 3149.1936831474304, 'total_duration': 15435.72381067276, 'accumulated_submission_time': 3149.1936831474304, 'accumulated_eval_time': 12285.616708517075, 'accumulated_logging_time': 0.6750872135162354, 'global_step': 3433, 'preemption_count': 0}), (3566, {'train/loss': 0.12478293293395883, 'validation/loss': 0.12475112921809028, 'validation/num_examples': 83274637, 'test/loss': 0.12707061570723685, 'test/num_examples': 95000000, 'score': 3269.730175971985, 'total_duration': 15788.055164337158, 'accumulated_submission_time': 3269.730175971985, 'accumulated_eval_time': 12517.381179332733, 'accumulated_logging_time': 0.6945619583129883, 'global_step': 3566, 'preemption_count': 0}), (3697, {'train/loss': 0.12334704024236907, 'validation/loss': 0.12496840360621858, 'validation/num_examples': 83274637, 'test/loss': 0.12743190731907894, 'test/num_examples': 95000000, 'score': 3391.203753709793, 'total_duration': 16146.370485305786, 'accumulated_submission_time': 3391.203753709793, 'accumulated_eval_time': 12754.197702169418, 'accumulated_logging_time': 0.7100903987884521, 'global_step': 3697, 'preemption_count': 0}), (3829, {'train/loss': 0.1261319908073301, 'validation/loss': 0.12491530240914996, 'validation/num_examples': 83274637, 'test/loss': 0.1273380443462171, 'test/num_examples': 95000000, 'score': 3512.4014904499054, 'total_duration': 16501.040668725967, 'accumulated_submission_time': 3512.4014904499054, 'accumulated_eval_time': 12987.591453313828, 'accumulated_logging_time': 0.7785751819610596, 'global_step': 3829, 'preemption_count': 0}), (3961, {'train/loss': 0.1232704305259874, 'validation/loss': 0.12455184107289886, 'validation/num_examples': 83274637, 'test/loss': 0.12692894565172697, 'test/num_examples': 95000000, 'score': 3632.9852254390717, 'total_duration': 16864.12758421898, 'accumulated_submission_time': 3632.9852254390717, 'accumulated_eval_time': 13230.069491624832, 'accumulated_logging_time': 0.7937722206115723, 'global_step': 3961, 'preemption_count': 0}), (4090, {'train/loss': 0.12174035877036224, 'validation/loss': 0.12475610241435028, 'validation/num_examples': 83274637, 'test/loss': 0.12710359581620065, 'test/num_examples': 95000000, 'score': 3753.117418527603, 'total_duration': 17230.263771533966, 'accumulated_submission_time': 3753.117418527603, 'accumulated_eval_time': 13476.032420873642, 'accumulated_logging_time': 0.8253259658813477, 'global_step': 4090, 'preemption_count': 0}), (4222, {'train/loss': 0.12575322786732665, 'validation/loss': 0.12491293677805974, 'validation/num_examples': 83274637, 'test/loss': 0.12724627936883223, 'test/num_examples': 95000000, 'score': 3873.6151247024536, 'total_duration': 17587.548482894897, 'accumulated_submission_time': 3873.6151247024536, 'accumulated_eval_time': 13712.76824593544, 'accumulated_logging_time': 0.8665564060211182, 'global_step': 4222, 'preemption_count': 0}), (4358, {'train/loss': 0.12388917960741985, 'validation/loss': 0.12497045716984595, 'validation/num_examples': 83274637, 'test/loss': 0.1273436292763158, 'test/num_examples': 95000000, 'score': 3993.864466190338, 'total_duration': 17947.145503997803, 'accumulated_submission_time': 3993.864466190338, 'accumulated_eval_time': 13952.079324483871, 'accumulated_logging_time': 0.893235445022583, 'global_step': 4358, 'preemption_count': 0}), (4487, {'train/loss': 0.12410039054054134, 'validation/loss': 0.1246292574570623, 'validation/num_examples': 83274637, 'test/loss': 0.12687943737664473, 'test/num_examples': 95000000, 'score': 4113.8525331020355, 'total_duration': 18309.12158060074, 'accumulated_submission_time': 4113.8525331020355, 'accumulated_eval_time': 14194.025070667267, 'accumulated_logging_time': 0.9209284782409668, 'global_step': 4487, 'preemption_count': 0}), (4619, {'train/loss': 0.12381547195075443, 'validation/loss': 0.12465405315252792, 'validation/num_examples': 83274637, 'test/loss': 0.12701043570106907, 'test/num_examples': 95000000, 'score': 4234.203807592392, 'total_duration': 18666.12617301941, 'accumulated_submission_time': 4234.203807592392, 'accumulated_eval_time': 14430.624977588654, 'accumulated_logging_time': 0.9640281200408936, 'global_step': 4619, 'preemption_count': 0}), (4749, {'train/loss': 0.12651506778579089, 'validation/loss': 0.12472218938492641, 'validation/num_examples': 83274637, 'test/loss': 0.1270062547080592, 'test/num_examples': 95000000, 'score': 4354.656206607819, 'total_duration': 19022.70318031311, 'accumulated_submission_time': 4354.656206607819, 'accumulated_eval_time': 14666.723143577576, 'accumulated_logging_time': 0.9803009033203125, 'global_step': 4749, 'preemption_count': 0}), (4882, {'train/loss': 0.12270586894321367, 'validation/loss': 0.12454534681308113, 'validation/num_examples': 83274637, 'test/loss': 0.12688367181332236, 'test/num_examples': 95000000, 'score': 4475.668568611145, 'total_duration': 19387.689217567444, 'accumulated_submission_time': 4475.668568611145, 'accumulated_eval_time': 14910.670087099075, 'accumulated_logging_time': 0.9962403774261475, 'global_step': 4882, 'preemption_count': 0}), (5013, {'train/loss': 0.1221168984969457, 'validation/loss': 0.12428397004281598, 'validation/num_examples': 83274637, 'test/loss': 0.1266789323807566, 'test/num_examples': 95000000, 'score': 4597.155123233795, 'total_duration': 19749.206179142, 'accumulated_submission_time': 4597.155123233795, 'accumulated_eval_time': 15150.664023399353, 'accumulated_logging_time': 1.0229346752166748, 'global_step': 5013, 'preemption_count': 0}), (5149, {'train/loss': 0.12339046866920009, 'validation/loss': 0.12420010281222578, 'validation/num_examples': 83274637, 'test/loss': 0.12656989562088816, 'test/num_examples': 95000000, 'score': 4717.614072561264, 'total_duration': 20107.19204211235, 'accumulated_submission_time': 4717.614072561264, 'accumulated_eval_time': 15388.163626670837, 'accumulated_logging_time': 1.0392355918884277, 'global_step': 5149, 'preemption_count': 0}), (5279, {'train/loss': 0.12444068976449517, 'validation/loss': 0.12408207773915116, 'validation/num_examples': 83274637, 'test/loss': 0.12637831313733552, 'test/num_examples': 95000000, 'score': 4837.710016489029, 'total_duration': 20466.78885245323, 'accumulated_submission_time': 4837.710016489029, 'accumulated_eval_time': 15627.63933134079, 'accumulated_logging_time': 1.0544040203094482, 'global_step': 5279, 'preemption_count': 0}), (5410, {'train/loss': 0.12268208297637273, 'validation/loss': 0.12420915164285518, 'validation/num_examples': 83274637, 'test/loss': 0.12655876630345395, 'test/num_examples': 95000000, 'score': 4958.385294437408, 'total_duration': 20829.71104168892, 'accumulated_submission_time': 4958.385294437408, 'accumulated_eval_time': 15869.86048579216, 'accumulated_logging_time': 1.0695278644561768, 'global_step': 5410, 'preemption_count': 0}), (5541, {'train/loss': 0.12302071056416575, 'validation/loss': 0.12419396327100621, 'validation/num_examples': 83274637, 'test/loss': 0.1265852228412829, 'test/num_examples': 95000000, 'score': 5079.1681451797485, 'total_duration': 21183.01736354828, 'accumulated_submission_time': 5079.1681451797485, 'accumulated_eval_time': 16102.341301441193, 'accumulated_logging_time': 1.1017327308654785, 'global_step': 5541, 'preemption_count': 0}), (5672, {'train/loss': 0.11963155503683495, 'validation/loss': 0.1242517738359276, 'validation/num_examples': 83274637, 'test/loss': 0.12657328369654605, 'test/num_examples': 95000000, 'score': 5199.713940620422, 'total_duration': 21536.759580373764, 'accumulated_submission_time': 5199.713940620422, 'accumulated_eval_time': 16335.512162208557, 'accumulated_logging_time': 1.1177198886871338, 'global_step': 5672, 'preemption_count': 0}), (5803, {'train/loss': 0.120853370957592, 'validation/loss': 0.12413421849410163, 'validation/num_examples': 83274637, 'test/loss': 0.12651912083675987, 'test/num_examples': 95000000, 'score': 5320.46044921875, 'total_duration': 21889.80800485611, 'accumulated_submission_time': 5320.46044921875, 'accumulated_eval_time': 16567.789128303528, 'accumulated_logging_time': 1.1326439380645752, 'global_step': 5803, 'preemption_count': 0}), (5931, {'train/loss': 0.12356366782958778, 'validation/loss': 0.12424719143641201, 'validation/num_examples': 83274637, 'test/loss': 0.12660915516036184, 'test/num_examples': 95000000, 'score': 5440.831295967102, 'total_duration': 22240.053060770035, 'accumulated_submission_time': 5440.831295967102, 'accumulated_eval_time': 16797.637093544006, 'accumulated_logging_time': 1.148430347442627, 'global_step': 5931, 'preemption_count': 0}), (6061, {'train/loss': 0.12428616384430877, 'validation/loss': 0.12441246350107926, 'validation/num_examples': 83274637, 'test/loss': 0.12679097071340462, 'test/num_examples': 95000000, 'score': 5563.223793745041, 'total_duration': 22589.859820842743, 'accumulated_submission_time': 5563.223793745041, 'accumulated_eval_time': 17024.989629030228, 'accumulated_logging_time': 1.2003881931304932, 'global_step': 6061, 'preemption_count': 0}), (6191, {'train/loss': 0.1257532609146346, 'validation/loss': 0.12432882500581892, 'validation/num_examples': 83274637, 'test/loss': 0.1265945744243421, 'test/num_examples': 95000000, 'score': 5683.633327007294, 'total_duration': 22944.50031208992, 'accumulated_submission_time': 5683.633327007294, 'accumulated_eval_time': 17259.192220926285, 'accumulated_logging_time': 1.2183516025543213, 'global_step': 6191, 'preemption_count': 0}), (6323, {'train/loss': 0.1226680363710009, 'validation/loss': 0.12417553719483265, 'validation/num_examples': 83274637, 'test/loss': 0.12654458884662828, 'test/num_examples': 95000000, 'score': 5803.726902246475, 'total_duration': 23311.733041763306, 'accumulated_submission_time': 5803.726902246475, 'accumulated_eval_time': 17506.303830385208, 'accumulated_logging_time': 1.2354815006256104, 'global_step': 6323, 'preemption_count': 0}), (6456, {'train/loss': 0.12213424829848157, 'validation/loss': 0.12415889030543373, 'validation/num_examples': 83274637, 'test/loss': 0.1265046060649671, 'test/num_examples': 95000000, 'score': 5924.346400499344, 'total_duration': 23672.164179563522, 'accumulated_submission_time': 5924.346400499344, 'accumulated_eval_time': 17746.0871052742, 'accumulated_logging_time': 1.2533743381500244, 'global_step': 6456, 'preemption_count': 0}), (6591, {'train/loss': 0.12430874941249688, 'validation/loss': 0.12427120661141024, 'validation/num_examples': 83274637, 'test/loss': 0.12665193784950657, 'test/num_examples': 95000000, 'score': 6045.04131269455, 'total_duration': 24026.488077878952, 'accumulated_submission_time': 6045.04131269455, 'accumulated_eval_time': 17979.689574480057, 'accumulated_logging_time': 1.2698581218719482, 'global_step': 6591, 'preemption_count': 0}), (6725, {'train/loss': 0.12232591637041208, 'validation/loss': 0.12407002392084691, 'validation/num_examples': 83274637, 'test/loss': 0.12633681567639804, 'test/num_examples': 95000000, 'score': 6166.339028596878, 'total_duration': 24384.962792873383, 'accumulated_submission_time': 6166.339028596878, 'accumulated_eval_time': 18216.832998991013, 'accumulated_logging_time': 1.293459177017212, 'global_step': 6725, 'preemption_count': 0}), (6851, {'train/loss': 0.1218055184087101, 'validation/loss': 0.1240427785585375, 'validation/num_examples': 83274637, 'test/loss': 0.12636871238692435, 'test/num_examples': 95000000, 'score': 6286.566481113434, 'total_duration': 24735.162326574326, 'accumulated_submission_time': 6286.566481113434, 'accumulated_eval_time': 18446.780131578445, 'accumulated_logging_time': 1.3088762760162354, 'global_step': 6851, 'preemption_count': 0}), (6979, {'train/loss': 0.12291293995419764, 'validation/loss': 0.12394246604344061, 'validation/num_examples': 83274637, 'test/loss': 0.1263249980160362, 'test/num_examples': 95000000, 'score': 6407.215991735458, 'total_duration': 25096.062175273895, 'accumulated_submission_time': 6407.215991735458, 'accumulated_eval_time': 18686.92020702362, 'accumulated_logging_time': 1.409529209136963, 'global_step': 6979, 'preemption_count': 0}), (7116, {'train/loss': 0.1232527189964206, 'validation/loss': 0.12406401024562556, 'validation/num_examples': 83274637, 'test/loss': 0.1262982859272204, 'test/num_examples': 95000000, 'score': 6528.00866150856, 'total_duration': 25450.86100101471, 'accumulated_submission_time': 6528.00866150856, 'accumulated_eval_time': 18920.89856529236, 'accumulated_logging_time': 1.4270086288452148, 'global_step': 7116, 'preemption_count': 0}), (7245, {'train/loss': 0.12336867531093787, 'validation/loss': 0.12385443354308016, 'validation/num_examples': 83274637, 'test/loss': 0.12615540984786183, 'test/num_examples': 95000000, 'score': 6648.310398101807, 'total_duration': 25803.936245918274, 'accumulated_submission_time': 6648.310398101807, 'accumulated_eval_time': 19153.643316984177, 'accumulated_logging_time': 1.4465827941894531, 'global_step': 7245, 'preemption_count': 0}), (7374, {'train/loss': 0.12202591430278695, 'validation/loss': 0.1239012324573481, 'validation/num_examples': 83274637, 'test/loss': 0.12617797489720395, 'test/num_examples': 95000000, 'score': 6768.63076710701, 'total_duration': 26162.40053510666, 'accumulated_submission_time': 6768.63076710701, 'accumulated_eval_time': 19391.740478515625, 'accumulated_logging_time': 1.4822049140930176, 'global_step': 7374, 'preemption_count': 0}), (7505, {'train/loss': 0.12064510217205908, 'validation/loss': 0.1239093264455066, 'validation/num_examples': 83274637, 'test/loss': 0.12623553109580593, 'test/num_examples': 95000000, 'score': 6889.336634159088, 'total_duration': 26516.960023880005, 'accumulated_submission_time': 6889.336634159088, 'accumulated_eval_time': 19625.567340135574, 'accumulated_logging_time': 1.498621940612793, 'global_step': 7505, 'preemption_count': 0}), (7637, {'train/loss': 0.12112517356169673, 'validation/loss': 0.12396345280606154, 'validation/num_examples': 83274637, 'test/loss': 0.12624936728001646, 'test/num_examples': 95000000, 'score': 7010.472729921341, 'total_duration': 26884.296994924545, 'accumulated_submission_time': 7010.472729921341, 'accumulated_eval_time': 19871.74100112915, 'accumulated_logging_time': 1.515608310699463, 'global_step': 7637, 'preemption_count': 0}), (7770, {'train/loss': 0.12231497772319137, 'validation/loss': 0.12386257724203402, 'validation/num_examples': 83274637, 'test/loss': 0.12620041381578948, 'test/num_examples': 95000000, 'score': 7131.822902202606, 'total_duration': 27249.663075208664, 'accumulated_submission_time': 7131.822902202606, 'accumulated_eval_time': 20115.731070041656, 'accumulated_logging_time': 1.5317189693450928, 'global_step': 7770, 'preemption_count': 0}), (7900, {'train/loss': 0.12197706113868165, 'validation/loss': 0.12398854645553348, 'validation/num_examples': 83274637, 'test/loss': 0.12636558840460527, 'test/num_examples': 95000000, 'score': 7251.794536352158, 'total_duration': 27611.804558753967, 'accumulated_submission_time': 7251.794536352158, 'accumulated_eval_time': 20357.838046312332, 'accumulated_logging_time': 1.5843541622161865, 'global_step': 7900, 'preemption_count': 0}), (8029, {'train/loss': 0.12054530166839279, 'validation/loss': 0.12387541944962936, 'validation/num_examples': 83274637, 'test/loss': 0.12622425652754934, 'test/num_examples': 95000000, 'score': 7372.6444709300995, 'total_duration': 27976.586094856262, 'accumulated_submission_time': 7372.6444709300995, 'accumulated_eval_time': 20601.741747140884, 'accumulated_logging_time': 1.6020512580871582, 'global_step': 8029, 'preemption_count': 0}), (8161, {'train/loss': 0.12345322467527299, 'validation/loss': 0.12392033408552264, 'validation/num_examples': 83274637, 'test/loss': 0.12623807544202303, 'test/num_examples': 95000000, 'score': 7493.548492670059, 'total_duration': 28335.339287757874, 'accumulated_submission_time': 7493.548492670059, 'accumulated_eval_time': 20839.561594724655, 'accumulated_logging_time': 1.620368242263794, 'global_step': 8161, 'preemption_count': 0}), (8295, {'train/loss': 0.12245753569141873, 'validation/loss': 0.12384257117407751, 'validation/num_examples': 83274637, 'test/loss': 0.12609908645148027, 'test/num_examples': 95000000, 'score': 7614.475512504578, 'total_duration': 28689.30668568611, 'accumulated_submission_time': 7614.475512504578, 'accumulated_eval_time': 21072.54828619957, 'accumulated_logging_time': 1.663686990737915, 'global_step': 8295, 'preemption_count': 0})], 'global_step': 8423}
I0306 20:35:55.426942 140339787351232 submission_runner.py:649] Timing: 7737.23163151741
I0306 20:35:55.426995 140339787351232 submission_runner.py:651] Total number of evals: 64
I0306 20:35:55.427031 140339787351232 submission_runner.py:652] ====================
I0306 20:35:55.427211 140339787351232 submission_runner.py:750] Final criteo1tb score: 1
