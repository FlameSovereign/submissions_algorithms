python submission_runner.py --framework=jax --workload=criteo1tb --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_0 --overwrite=True --save_checkpoints=False --rng_seed=1644898432 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=2 --hparam_end_index=3 2>&1 | tee -a /logs/criteo1tb_jax_03-06-2025-12-49-30.log
2025-03-06 12:49:31.031693: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741265371.055026       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741265371.062082       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0306 12:49:36.838752 140171586897088 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax.
I0306 12:49:37.744247 140171586897088 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0306 12:49:37.746997 140171586897088 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0306 12:49:37.748622 140171586897088 submission_runner.py:606] Using RNG seed 1644898432
I0306 12:49:38.321717 140171586897088 submission_runner.py:615] --- Tuning run 3/5 ---
I0306 12:49:38.321928 140171586897088 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax/trial_3.
I0306 12:49:38.322126 140171586897088 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax/trial_3/hparams.json.
I0306 12:49:38.554405 140171586897088 submission_runner.py:218] Initializing dataset.
I0306 12:49:38.554587 140171586897088 submission_runner.py:229] Initializing model.
I0306 12:49:47.090466 140171586897088 submission_runner.py:272] Initializing optimizer.
I0306 12:49:47.575271 140171586897088 submission_runner.py:279] Initializing metrics bundle.
I0306 12:49:47.575488 140171586897088 submission_runner.py:301] Initializing checkpoint and logger.
I0306 12:49:47.576191 140171586897088 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax/trial_3 with prefix checkpoint_
I0306 12:49:47.576286 140171586897088 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax/trial_3/meta_data_0.json.
I0306 12:49:47.576450 140171586897088 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0306 12:49:47.576494 140171586897088 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0306 12:49:47.758665 140171586897088 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_0/criteo1tb_jax/trial_3/flags_0.json.
I0306 12:49:48.079298 140171586897088 submission_runner.py:337] Starting training loop.
I0306 12:50:00.943869 140028835088128 logging_writer.py:48] [0] global_step=0, grad_norm=9.659040451049805, loss=1.0983164310455322
I0306 12:50:00.986534 140171586897088 spec.py:321] Evaluating on the training split.
I0306 12:56:21.974038 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 13:02:14.174350 140171586897088 spec.py:349] Evaluating on the test split.
I0306 13:08:59.843549 140171586897088 submission_runner.py:469] Time since start: 1151.76s, 	Step: 1, 	{'train/loss': 1.097540407060827, 'validation/loss': 1.0978230088325842, 'validation/num_examples': 83274637, 'test/loss': 1.0966317264802632, 'test/num_examples': 95000000, 'score': 12.907138109207153, 'total_duration': 1151.7641592025757, 'accumulated_submission_time': 12.907138109207153, 'accumulated_eval_time': 1138.856914281845, 'accumulated_logging_time': 0}
I0306 13:08:59.852248 140019171825408 logging_writer.py:48] [1] accumulated_eval_time=1138.86, accumulated_logging_time=0, accumulated_submission_time=12.9071, global_step=1, preemption_count=0, score=12.9071, test/loss=1.09663, test/num_examples=95000000, total_duration=1151.76, train/loss=1.09754, validation/loss=1.09782, validation/num_examples=83274637
I0306 13:10:28.965087 140019087963904 logging_writer.py:48] [100] global_step=100, grad_norm=0.3612819015979767, loss=0.14397355914115906
I0306 13:11:01.117916 140171586897088 spec.py:321] Evaluating on the training split.
I0306 13:16:56.067209 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 13:22:13.071371 140171586897088 spec.py:349] Evaluating on the test split.
I0306 13:28:42.757840 140171586897088 submission_runner.py:469] Time since start: 2334.68s, 	Step: 127, 	{'train/loss': 0.13851618068585606, 'validation/loss': 0.1406375868050448, 'validation/num_examples': 83274637, 'test/loss': 0.14420327802220395, 'test/num_examples': 95000000, 'score': 134.1579625606537, 'total_duration': 2334.6784369945526, 'accumulated_submission_time': 134.1579625606537, 'accumulated_eval_time': 2200.4967563152313, 'accumulated_logging_time': 0.0169222354888916}
I0306 13:28:42.766346 140019171825408 logging_writer.py:48] [127] accumulated_eval_time=2200.5, accumulated_logging_time=0.0169222, accumulated_submission_time=134.158, global_step=127, preemption_count=0, score=134.158, test/loss=0.144203, test/num_examples=95000000, total_duration=2334.68, train/loss=0.138516, validation/loss=0.140638, validation/num_examples=83274637
I0306 13:29:37.157090 140019087963904 logging_writer.py:48] [200] global_step=200, grad_norm=0.011592859402298927, loss=0.1241675317287445
I0306 13:30:43.756793 140171586897088 spec.py:321] Evaluating on the training split.
I0306 13:36:46.915711 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 13:41:48.711376 140171586897088 spec.py:349] Evaluating on the test split.
I0306 13:48:03.564034 140171586897088 submission_runner.py:469] Time since start: 3495.48s, 	Step: 261, 	{'train/loss': 0.1294589923261284, 'validation/loss': 0.13039315266037274, 'validation/num_examples': 83274637, 'test/loss': 0.13289738861019737, 'test/num_examples': 95000000, 'score': 255.1340742111206, 'total_duration': 3495.484666109085, 'accumulated_submission_time': 255.1340742111206, 'accumulated_eval_time': 3240.3039350509644, 'accumulated_logging_time': 0.032485008239746094}
I0306 13:48:03.572489 140019171825408 logging_writer.py:48] [261] accumulated_eval_time=3240.3, accumulated_logging_time=0.032485, accumulated_submission_time=255.134, global_step=261, preemption_count=0, score=255.134, test/loss=0.132897, test/num_examples=95000000, total_duration=3495.48, train/loss=0.129459, validation/loss=0.130393, validation/num_examples=83274637
I0306 13:48:21.602555 140019087963904 logging_writer.py:48] [300] global_step=300, grad_norm=0.011644607409834862, loss=0.12469244003295898
I0306 13:50:03.999639 140171586897088 spec.py:321] Evaluating on the training split.
I0306 13:55:46.122222 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 14:00:54.855179 140171586897088 spec.py:349] Evaluating on the test split.
I0306 14:06:52.282932 140171586897088 submission_runner.py:469] Time since start: 4624.20s, 	Step: 392, 	{'train/loss': 0.1276890487064543, 'validation/loss': 0.12872954232395062, 'validation/num_examples': 83274637, 'test/loss': 0.1313001236533717, 'test/num_examples': 95000000, 'score': 375.5483627319336, 'total_duration': 4624.20357298851, 'accumulated_submission_time': 375.5483627319336, 'accumulated_eval_time': 4248.587181568146, 'accumulated_logging_time': 0.04717278480529785}
I0306 14:06:52.290974 140019171825408 logging_writer.py:48] [392] accumulated_eval_time=4248.59, accumulated_logging_time=0.0471728, accumulated_submission_time=375.548, global_step=392, preemption_count=0, score=375.548, test/loss=0.1313, test/num_examples=95000000, total_duration=4624.2, train/loss=0.127689, validation/loss=0.12873, validation/num_examples=83274637
I0306 14:06:53.256698 140019087963904 logging_writer.py:48] [400] global_step=400, grad_norm=0.008520822040736675, loss=0.12678058445453644
I0306 14:08:32.322338 140019171825408 logging_writer.py:48] [500] global_step=500, grad_norm=0.016948655247688293, loss=0.1252419650554657
I0306 14:08:53.154311 140171586897088 spec.py:321] Evaluating on the training split.
I0306 14:14:48.341892 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 14:19:31.587423 140171586897088 spec.py:349] Evaluating on the test split.
I0306 14:25:21.896112 140171586897088 submission_runner.py:469] Time since start: 5733.82s, 	Step: 517, 	{'train/loss': 0.127341563338941, 'validation/loss': 0.12764666610530753, 'validation/num_examples': 83274637, 'test/loss': 0.13020259854029606, 'test/num_examples': 95000000, 'score': 496.39841413497925, 'total_duration': 5733.816745758057, 'accumulated_submission_time': 496.39841413497925, 'accumulated_eval_time': 5237.32891869545, 'accumulated_logging_time': 0.0618133544921875}
I0306 14:25:21.903999 140019087963904 logging_writer.py:48] [517] accumulated_eval_time=5237.33, accumulated_logging_time=0.0618134, accumulated_submission_time=496.398, global_step=517, preemption_count=0, score=496.398, test/loss=0.130203, test/num_examples=95000000, total_duration=5733.82, train/loss=0.127342, validation/loss=0.127647, validation/num_examples=83274637
I0306 14:26:32.120117 140019171825408 logging_writer.py:48] [600] global_step=600, grad_norm=0.011714550666511059, loss=0.12879681587219238
I0306 14:27:22.151583 140171586897088 spec.py:321] Evaluating on the training split.
I0306 14:33:02.235616 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 14:38:08.525849 140171586897088 spec.py:349] Evaluating on the test split.
I0306 14:43:39.620592 140171586897088 submission_runner.py:469] Time since start: 6831.54s, 	Step: 648, 	{'train/loss': 0.1256158237913682, 'validation/loss': 0.12737351410358744, 'validation/num_examples': 83274637, 'test/loss': 0.12977979270148027, 'test/num_examples': 95000000, 'score': 616.6327495574951, 'total_duration': 6831.541186094284, 'accumulated_submission_time': 616.6327495574951, 'accumulated_eval_time': 6214.797825336456, 'accumulated_logging_time': 0.07611393928527832}
I0306 14:43:39.628726 140019087963904 logging_writer.py:48] [648] accumulated_eval_time=6214.8, accumulated_logging_time=0.0761139, accumulated_submission_time=616.633, global_step=648, preemption_count=0, score=616.633, test/loss=0.12978, test/num_examples=95000000, total_duration=6831.54, train/loss=0.125616, validation/loss=0.127374, validation/num_examples=83274637
I0306 14:44:12.278516 140019171825408 logging_writer.py:48] [700] global_step=700, grad_norm=0.017754193395376205, loss=0.1230115219950676
I0306 14:45:40.965582 140171586897088 spec.py:321] Evaluating on the training split.
I0306 14:50:51.202482 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 14:55:26.600569 140171586897088 spec.py:349] Evaluating on the test split.
I0306 15:00:37.102872 140171586897088 submission_runner.py:469] Time since start: 7849.02s, 	Step: 780, 	{'train/loss': 0.12793025807858263, 'validation/loss': 0.12712703321595162, 'validation/num_examples': 83274637, 'test/loss': 0.12950534886924342, 'test/num_examples': 95000000, 'score': 737.9544789791107, 'total_duration': 7849.023504495621, 'accumulated_submission_time': 737.9544789791107, 'accumulated_eval_time': 7110.935056447983, 'accumulated_logging_time': 0.09195971488952637}
I0306 15:00:37.135904 140019087963904 logging_writer.py:48] [780] accumulated_eval_time=7110.94, accumulated_logging_time=0.0919597, accumulated_submission_time=737.954, global_step=780, preemption_count=0, score=737.954, test/loss=0.129505, test/num_examples=95000000, total_duration=7849.02, train/loss=0.12793, validation/loss=0.127127, validation/num_examples=83274637
I0306 15:00:39.342782 140019171825408 logging_writer.py:48] [800] global_step=800, grad_norm=0.04018091782927513, loss=0.12000423669815063
I0306 15:02:30.908536 140019087963904 logging_writer.py:48] [900] global_step=900, grad_norm=0.009013930335640907, loss=0.12211637943983078
I0306 15:02:37.165520 140171586897088 spec.py:321] Evaluating on the training split.
I0306 15:07:20.624103 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 15:11:35.910085 140171586897088 spec.py:349] Evaluating on the test split.
I0306 15:16:30.973191 140171586897088 submission_runner.py:469] Time since start: 8802.89s, 	Step: 907, 	{'train/loss': 0.12725614269012175, 'validation/loss': 0.12682128021441233, 'validation/num_examples': 83274637, 'test/loss': 0.12915470270353618, 'test/num_examples': 95000000, 'score': 857.9698913097382, 'total_duration': 8802.893795490265, 'accumulated_submission_time': 857.9698913097382, 'accumulated_eval_time': 7944.742644309998, 'accumulated_logging_time': 0.1315314769744873}
I0306 15:16:30.981648 140019171825408 logging_writer.py:48] [907] accumulated_eval_time=7944.74, accumulated_logging_time=0.131531, accumulated_submission_time=857.97, global_step=907, preemption_count=0, score=857.97, test/loss=0.129155, test/num_examples=95000000, total_duration=8802.89, train/loss=0.127256, validation/loss=0.126821, validation/num_examples=83274637
I0306 15:17:51.734458 140019087963904 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.03496364876627922, loss=0.13287603855133057
I0306 15:18:31.817286 140171586897088 spec.py:321] Evaluating on the training split.
I0306 15:21:58.392982 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 15:25:03.651355 140171586897088 spec.py:349] Evaluating on the test split.
I0306 15:28:48.744624 140171586897088 submission_runner.py:469] Time since start: 9540.67s, 	Step: 1036, 	{'train/loss': 0.12556548006598306, 'validation/loss': 0.12673248344135682, 'validation/num_examples': 83274637, 'test/loss': 0.12926515476973685, 'test/num_examples': 95000000, 'score': 978.7902569770813, 'total_duration': 9540.665189504623, 'accumulated_submission_time': 978.7902569770813, 'accumulated_eval_time': 8561.669858694077, 'accumulated_logging_time': 0.1463632583618164}
I0306 15:28:48.770226 140019171825408 logging_writer.py:48] [1036] accumulated_eval_time=8561.67, accumulated_logging_time=0.146363, accumulated_submission_time=978.79, global_step=1036, preemption_count=0, score=978.79, test/loss=0.129265, test/num_examples=95000000, total_duration=9540.67, train/loss=0.125565, validation/loss=0.126732, validation/num_examples=83274637
I0306 15:29:36.383422 140019087963904 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.011739476583898067, loss=0.1272476315498352
I0306 15:30:48.810184 140171586897088 spec.py:321] Evaluating on the training split.
I0306 15:31:48.399062 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 15:32:40.494694 140171586897088 spec.py:349] Evaluating on the test split.
I0306 15:34:54.804003 140171586897088 submission_runner.py:469] Time since start: 9906.72s, 	Step: 1161, 	{'train/loss': 0.12525815270700544, 'validation/loss': 0.12647164132306762, 'validation/num_examples': 83274637, 'test/loss': 0.12889721312705593, 'test/num_examples': 95000000, 'score': 1098.813800573349, 'total_duration': 9906.724633216858, 'accumulated_submission_time': 1098.813800573349, 'accumulated_eval_time': 8807.663614749908, 'accumulated_logging_time': 0.17838263511657715}
I0306 15:34:54.813828 140019171825408 logging_writer.py:48] [1161] accumulated_eval_time=8807.66, accumulated_logging_time=0.178383, accumulated_submission_time=1098.81, global_step=1161, preemption_count=0, score=1098.81, test/loss=0.128897, test/num_examples=95000000, total_duration=9906.72, train/loss=0.125258, validation/loss=0.126472, validation/num_examples=83274637
I0306 15:35:13.473127 140019087963904 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.014531712047755718, loss=0.12738171219825745
I0306 15:36:55.112254 140171586897088 spec.py:321] Evaluating on the training split.
I0306 15:38:07.150310 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 15:38:28.801165 140171586897088 spec.py:349] Evaluating on the test split.
I0306 15:41:09.363586 140171586897088 submission_runner.py:469] Time since start: 10281.28s, 	Step: 1279, 	{'train/loss': 0.1277191495558001, 'validation/loss': 0.12600281114268586, 'validation/num_examples': 83274637, 'test/loss': 0.12857999910567433, 'test/num_examples': 95000000, 'score': 1219.0961878299713, 'total_duration': 10281.284190893173, 'accumulated_submission_time': 1219.0961878299713, 'accumulated_eval_time': 9061.914865016937, 'accumulated_logging_time': 0.19491815567016602}
I0306 15:41:09.372792 140019171825408 logging_writer.py:48] [1279] accumulated_eval_time=9061.91, accumulated_logging_time=0.194918, accumulated_submission_time=1219.1, global_step=1279, preemption_count=0, score=1219.1, test/loss=0.12858, test/num_examples=95000000, total_duration=10281.3, train/loss=0.127719, validation/loss=0.126003, validation/num_examples=83274637
I0306 15:41:11.852290 140019087963904 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.025003306567668915, loss=0.12699636816978455
I0306 15:43:08.783231 140019171825408 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.024315573275089264, loss=0.13056883215904236
I0306 15:43:10.098561 140171586897088 spec.py:321] Evaluating on the training split.
I0306 15:44:34.703062 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 15:44:42.178990 140171586897088 spec.py:349] Evaluating on the test split.
I0306 15:47:33.930687 140171586897088 submission_runner.py:469] Time since start: 10665.85s, 	Step: 1402, 	{'train/loss': 0.124531935888735, 'validation/loss': 0.12602079874009237, 'validation/num_examples': 83274637, 'test/loss': 0.1285766939658717, 'test/num_examples': 95000000, 'score': 1339.8050951957703, 'total_duration': 10665.851326227188, 'accumulated_submission_time': 1339.8050951957703, 'accumulated_eval_time': 9325.746924161911, 'accumulated_logging_time': 0.21086740493774414}
I0306 15:47:33.939095 140019087963904 logging_writer.py:48] [1402] accumulated_eval_time=9325.75, accumulated_logging_time=0.210867, accumulated_submission_time=1339.81, global_step=1402, preemption_count=0, score=1339.81, test/loss=0.128577, test/num_examples=95000000, total_duration=10665.9, train/loss=0.124532, validation/loss=0.126021, validation/num_examples=83274637
I0306 15:49:09.414370 140019171825408 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.012231206521391869, loss=0.12268203496932983
I0306 15:49:34.544288 140171586897088 spec.py:321] Evaluating on the training split.
I0306 15:50:58.098330 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 15:51:05.611434 140171586897088 spec.py:349] Evaluating on the test split.
I0306 15:53:51.656438 140171586897088 submission_runner.py:469] Time since start: 11043.58s, 	Step: 1521, 	{'train/loss': 0.12650610488962452, 'validation/loss': 0.12592389130307016, 'validation/num_examples': 83274637, 'test/loss': 0.1285931392783717, 'test/num_examples': 95000000, 'score': 1460.3932092189789, 'total_duration': 11043.57708120346, 'accumulated_submission_time': 1460.3932092189789, 'accumulated_eval_time': 9582.859015464783, 'accumulated_logging_time': 0.22658395767211914}
I0306 15:53:51.664595 140019087963904 logging_writer.py:48] [1521] accumulated_eval_time=9582.86, accumulated_logging_time=0.226584, accumulated_submission_time=1460.39, global_step=1521, preemption_count=0, score=1460.39, test/loss=0.128593, test/num_examples=95000000, total_duration=11043.6, train/loss=0.126506, validation/loss=0.125924, validation/num_examples=83274637
I0306 15:55:02.664054 140019171825408 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.010094397701323032, loss=0.12532606720924377
I0306 15:55:53.406049 140171586897088 spec.py:321] Evaluating on the training split.
I0306 15:57:22.151205 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 15:57:29.601441 140171586897088 spec.py:349] Evaluating on the test split.
I0306 16:00:08.071656 140171586897088 submission_runner.py:469] Time since start: 11419.99s, 	Step: 1643, 	{'train/loss': 0.1264668198642116, 'validation/loss': 0.12577630934502002, 'validation/num_examples': 83274637, 'test/loss': 0.1282472634971217, 'test/num_examples': 95000000, 'score': 1582.1186738014221, 'total_duration': 11419.992284297943, 'accumulated_submission_time': 1582.1186738014221, 'accumulated_eval_time': 9837.524570941925, 'accumulated_logging_time': 0.24126195907592773}
I0306 16:00:08.080466 140019087963904 logging_writer.py:48] [1643] accumulated_eval_time=9837.52, accumulated_logging_time=0.241262, accumulated_submission_time=1582.12, global_step=1643, preemption_count=0, score=1582.12, test/loss=0.128247, test/num_examples=95000000, total_duration=11420, train/loss=0.126467, validation/loss=0.125776, validation/num_examples=83274637
I0306 16:00:47.562011 140019171825408 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.037706729024648666, loss=0.12489379942417145
I0306 16:02:08.174251 140171586897088 spec.py:321] Evaluating on the training split.
I0306 16:03:52.816381 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 16:04:00.327372 140171586897088 spec.py:349] Evaluating on the test split.
I0306 16:06:29.053829 140171586897088 submission_runner.py:469] Time since start: 11800.97s, 	Step: 1763, 	{'train/loss': 0.1251748736198031, 'validation/loss': 0.12604747932960067, 'validation/num_examples': 83274637, 'test/loss': 0.12835338032483554, 'test/num_examples': 95000000, 'score': 1702.1954262256622, 'total_duration': 11800.974452733994, 'accumulated_submission_time': 1702.1954262256622, 'accumulated_eval_time': 10098.404072761536, 'accumulated_logging_time': 0.2571682929992676}
I0306 16:06:29.062503 140019087963904 logging_writer.py:48] [1763] accumulated_eval_time=10098.4, accumulated_logging_time=0.257168, accumulated_submission_time=1702.2, global_step=1763, preemption_count=0, score=1702.2, test/loss=0.128353, test/num_examples=95000000, total_duration=11801, train/loss=0.125175, validation/loss=0.126047, validation/num_examples=83274637
I0306 16:06:45.079999 140019171825408 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.027860771864652634, loss=0.12736926972866058
I0306 16:08:30.799634 140171586897088 spec.py:321] Evaluating on the training split.
I0306 16:10:10.031199 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 16:10:17.505329 140171586897088 spec.py:349] Evaluating on the test split.
I0306 16:12:50.063977 140171586897088 submission_runner.py:469] Time since start: 12181.98s, 	Step: 1884, 	{'train/loss': 0.12552697972962693, 'validation/loss': 0.12540024771179917, 'validation/num_examples': 83274637, 'test/loss': 0.1277124625, 'test/num_examples': 95000000, 'score': 1823.9036130905151, 'total_duration': 12181.984615325928, 'accumulated_submission_time': 1823.9036130905151, 'accumulated_eval_time': 10357.668365955353, 'accumulated_logging_time': 0.284895658493042}
I0306 16:12:50.079473 140019087963904 logging_writer.py:48] [1884] accumulated_eval_time=10357.7, accumulated_logging_time=0.284896, accumulated_submission_time=1823.9, global_step=1884, preemption_count=0, score=1823.9, test/loss=0.127712, test/num_examples=95000000, total_duration=12182, train/loss=0.125527, validation/loss=0.1254, validation/num_examples=83274637
I0306 16:12:51.854413 140019171825408 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.015064137987792492, loss=0.13006317615509033
I0306 16:14:47.413404 140019087963904 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.008868303149938583, loss=0.1211913526058197
I0306 16:14:50.338764 140171586897088 spec.py:321] Evaluating on the training split.
I0306 16:16:33.092741 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 16:16:40.525559 140171586897088 spec.py:349] Evaluating on the test split.
I0306 16:19:06.266379 140171586897088 submission_runner.py:469] Time since start: 12558.19s, 	Step: 2003, 	{'train/loss': 0.12230905879921508, 'validation/loss': 0.12543321003252317, 'validation/num_examples': 83274637, 'test/loss': 0.12808540560238488, 'test/num_examples': 95000000, 'score': 1944.14612865448, 'total_duration': 12558.186996459961, 'accumulated_submission_time': 1944.14612865448, 'accumulated_eval_time': 10613.595893144608, 'accumulated_logging_time': 0.3076164722442627}
I0306 16:19:06.274787 140019171825408 logging_writer.py:48] [2003] accumulated_eval_time=10613.6, accumulated_logging_time=0.307616, accumulated_submission_time=1944.15, global_step=2003, preemption_count=0, score=1944.15, test/loss=0.128085, test/num_examples=95000000, total_duration=12558.2, train/loss=0.122309, validation/loss=0.125433, validation/num_examples=83274637
I0306 16:20:39.517925 140019087963904 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.03318033367395401, loss=0.12202462553977966
I0306 16:21:07.346186 140171586897088 spec.py:321] Evaluating on the training split.
I0306 16:22:53.496291 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 16:23:01.036671 140171586897088 spec.py:349] Evaluating on the test split.
I0306 16:25:14.779624 140171586897088 submission_runner.py:469] Time since start: 12926.70s, 	Step: 2123, 	{'train/loss': 0.12188759496517526, 'validation/loss': 0.1254738043323931, 'validation/num_examples': 83274637, 'test/loss': 0.12793571976768092, 'test/num_examples': 95000000, 'score': 2065.2013726234436, 'total_duration': 12926.700229167938, 'accumulated_submission_time': 2065.2013726234436, 'accumulated_eval_time': 10861.029235839844, 'accumulated_logging_time': 0.3231971263885498}
I0306 16:25:14.788347 140019171825408 logging_writer.py:48] [2123] accumulated_eval_time=10861, accumulated_logging_time=0.323197, accumulated_submission_time=2065.2, global_step=2123, preemption_count=0, score=2065.2, test/loss=0.127936, test/num_examples=95000000, total_duration=12926.7, train/loss=0.121888, validation/loss=0.125474, validation/num_examples=83274637
I0306 16:26:23.050415 140019087963904 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.008800196461379528, loss=0.11640584468841553
I0306 16:27:14.794487 140171586897088 spec.py:321] Evaluating on the training split.
I0306 16:29:20.585530 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 16:29:28.265827 140171586897088 spec.py:349] Evaluating on the test split.
I0306 16:31:23.789559 140171586897088 submission_runner.py:469] Time since start: 13295.71s, 	Step: 2241, 	{'train/loss': 0.12484424119616079, 'validation/loss': 0.1253042430375965, 'validation/num_examples': 83274637, 'test/loss': 0.1277837732524671, 'test/num_examples': 95000000, 'score': 2185.1594557762146, 'total_duration': 13295.710200548172, 'accumulated_submission_time': 2185.1594557762146, 'accumulated_eval_time': 11110.024245977402, 'accumulated_logging_time': 0.37087273597717285}
I0306 16:31:23.798115 140019171825408 logging_writer.py:48] [2241] accumulated_eval_time=11110, accumulated_logging_time=0.370873, accumulated_submission_time=2185.16, global_step=2241, preemption_count=0, score=2185.16, test/loss=0.127784, test/num_examples=95000000, total_duration=13295.7, train/loss=0.124844, validation/loss=0.125304, validation/num_examples=83274637
I0306 16:32:06.541359 140019087963904 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.018531538546085358, loss=0.1288089007139206
I0306 16:33:25.376723 140171586897088 spec.py:321] Evaluating on the training split.
I0306 16:35:37.313559 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 16:35:45.195071 140171586897088 spec.py:349] Evaluating on the test split.
I0306 16:37:38.730397 140171586897088 submission_runner.py:469] Time since start: 13670.65s, 	Step: 2365, 	{'train/loss': 0.12442438846817182, 'validation/loss': 0.1251887019739144, 'validation/num_examples': 83274637, 'test/loss': 0.12754705320723683, 'test/num_examples': 95000000, 'score': 2306.7222244739532, 'total_duration': 13670.65102648735, 'accumulated_submission_time': 2306.7222244739532, 'accumulated_eval_time': 11363.37785744667, 'accumulated_logging_time': 0.3857142925262451}
I0306 16:37:38.740298 140019171825408 logging_writer.py:48] [2365] accumulated_eval_time=11363.4, accumulated_logging_time=0.385714, accumulated_submission_time=2306.72, global_step=2365, preemption_count=0, score=2306.72, test/loss=0.127547, test/num_examples=95000000, total_duration=13670.7, train/loss=0.124424, validation/loss=0.125189, validation/num_examples=83274637
I0306 16:37:51.318413 140019087963904 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.015680460259318352, loss=0.14106644690036774
I0306 16:39:38.899957 140171586897088 spec.py:321] Evaluating on the training split.
I0306 16:42:03.737655 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 16:42:11.283452 140171586897088 spec.py:349] Evaluating on the test split.
I0306 16:43:51.117724 140171586897088 submission_runner.py:469] Time since start: 14043.04s, 	Step: 2485, 	{'train/loss': 0.12563773058354855, 'validation/loss': 0.12514344367212987, 'validation/num_examples': 83274637, 'test/loss': 0.12747621431949013, 'test/num_examples': 95000000, 'score': 2426.865609407425, 'total_duration': 14043.038362979889, 'accumulated_submission_time': 2426.865609407425, 'accumulated_eval_time': 11615.5955722332, 'accumulated_logging_time': 0.4023456573486328}
I0306 16:43:51.126763 140019171825408 logging_writer.py:48] [2485] accumulated_eval_time=11615.6, accumulated_logging_time=0.402346, accumulated_submission_time=2426.87, global_step=2485, preemption_count=0, score=2426.87, test/loss=0.127476, test/num_examples=95000000, total_duration=14043, train/loss=0.125638, validation/loss=0.125143, validation/num_examples=83274637
I0306 16:43:52.841730 140019087963904 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.006816111970692873, loss=0.11940290033817291
I0306 16:45:44.924895 140019171825408 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.01154975313693285, loss=0.12019035965204239
I0306 16:45:52.229439 140171586897088 spec.py:321] Evaluating on the training split.
I0306 16:48:14.864994 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 16:48:22.762278 140171586897088 spec.py:349] Evaluating on the test split.
I0306 16:50:02.804346 140171586897088 submission_runner.py:469] Time since start: 14414.72s, 	Step: 2607, 	{'train/loss': 0.12497991015373161, 'validation/loss': 0.1253459540478562, 'validation/num_examples': 83274637, 'test/loss': 0.12785124714226972, 'test/num_examples': 95000000, 'score': 2547.922434568405, 'total_duration': 14414.724973201752, 'accumulated_submission_time': 2547.922434568405, 'accumulated_eval_time': 11866.170401573181, 'accumulated_logging_time': 0.4472486972808838}
I0306 16:50:02.823122 140019087963904 logging_writer.py:48] [2607] accumulated_eval_time=11866.2, accumulated_logging_time=0.447249, accumulated_submission_time=2547.92, global_step=2607, preemption_count=0, score=2547.92, test/loss=0.127851, test/num_examples=95000000, total_duration=14414.7, train/loss=0.12498, validation/loss=0.125346, validation/num_examples=83274637
I0306 16:51:33.499626 140019171825408 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.014394538477063179, loss=0.12459470331668854
I0306 16:52:03.126459 140171586897088 spec.py:321] Evaluating on the training split.
I0306 16:54:45.426264 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 16:54:53.198228 140171586897088 spec.py:349] Evaluating on the test split.
I0306 16:56:15.528794 140171586897088 submission_runner.py:469] Time since start: 14787.45s, 	Step: 2725, 	{'train/loss': 0.12384762901976798, 'validation/loss': 0.12507764985134182, 'validation/num_examples': 83274637, 'test/loss': 0.1272886120682566, 'test/num_examples': 95000000, 'score': 2668.2090606689453, 'total_duration': 14787.44944190979, 'accumulated_submission_time': 2668.2090606689453, 'accumulated_eval_time': 12118.572682619095, 'accumulated_logging_time': 0.4730703830718994}
I0306 16:56:15.555468 140019087963904 logging_writer.py:48] [2725] accumulated_eval_time=12118.6, accumulated_logging_time=0.47307, accumulated_submission_time=2668.21, global_step=2725, preemption_count=0, score=2668.21, test/loss=0.127289, test/num_examples=95000000, total_duration=14787.4, train/loss=0.123848, validation/loss=0.125078, validation/num_examples=83274637
I0306 16:57:19.492216 140019171825408 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.012365314178168774, loss=0.12912076711654663
I0306 16:58:17.886437 140171586897088 spec.py:321] Evaluating on the training split.
I0306 17:01:04.623435 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 17:01:12.244869 140171586897088 spec.py:349] Evaluating on the test split.
I0306 17:02:32.022861 140171586897088 submission_runner.py:469] Time since start: 15163.94s, 	Step: 2846, 	{'train/loss': 0.1228913426071218, 'validation/loss': 0.12501508352651616, 'validation/num_examples': 83274637, 'test/loss': 0.1274286460731908, 'test/num_examples': 95000000, 'score': 2790.5242536067963, 'total_duration': 15163.943510770798, 'accumulated_submission_time': 2790.5242536067963, 'accumulated_eval_time': 12372.709058046341, 'accumulated_logging_time': 0.506070613861084}
I0306 17:02:32.032020 140019087963904 logging_writer.py:48] [2846] accumulated_eval_time=12372.7, accumulated_logging_time=0.506071, accumulated_submission_time=2790.52, global_step=2846, preemption_count=0, score=2790.52, test/loss=0.127429, test/num_examples=95000000, total_duration=15163.9, train/loss=0.122891, validation/loss=0.125015, validation/num_examples=83274637
I0306 17:03:09.347813 140019171825408 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.012786749750375748, loss=0.12116629630327225
I0306 17:04:32.851332 140171586897088 spec.py:321] Evaluating on the training split.
I0306 17:07:24.250381 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 17:07:31.990394 140171586897088 spec.py:349] Evaluating on the test split.
I0306 17:08:44.338810 140171586897088 submission_runner.py:469] Time since start: 15536.26s, 	Step: 2967, 	{'train/loss': 0.12334638169773345, 'validation/loss': 0.12468248893534842, 'validation/num_examples': 83274637, 'test/loss': 0.1269826997944079, 'test/num_examples': 95000000, 'score': 2911.3264710903168, 'total_duration': 15536.259451389313, 'accumulated_submission_time': 2911.3264710903168, 'accumulated_eval_time': 12624.196480989456, 'accumulated_logging_time': 0.5218620300292969}
I0306 17:08:44.347536 140019087963904 logging_writer.py:48] [2967] accumulated_eval_time=12624.2, accumulated_logging_time=0.521862, accumulated_submission_time=2911.33, global_step=2967, preemption_count=0, score=2911.33, test/loss=0.126983, test/num_examples=95000000, total_duration=15536.3, train/loss=0.123346, validation/loss=0.124682, validation/num_examples=83274637
I0306 17:08:54.233741 140019171825408 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.010023473761975765, loss=0.12714749574661255
I0306 17:10:45.733438 140171586897088 spec.py:321] Evaluating on the training split.
I0306 17:13:48.785232 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 17:13:56.337552 140171586897088 spec.py:349] Evaluating on the test split.
I0306 17:15:02.398034 140171586897088 submission_runner.py:469] Time since start: 15914.32s, 	Step: 3093, 	{'train/loss': 0.12259700678804386, 'validation/loss': 0.12472432054031538, 'validation/num_examples': 83274637, 'test/loss': 0.12710161906866776, 'test/num_examples': 95000000, 'score': 3032.66086769104, 'total_duration': 15914.318681716919, 'accumulated_submission_time': 3032.66086769104, 'accumulated_eval_time': 12880.861028432846, 'accumulated_logging_time': 0.5726561546325684}
I0306 17:15:02.406708 140019087963904 logging_writer.py:48] [3093] accumulated_eval_time=12880.9, accumulated_logging_time=0.572656, accumulated_submission_time=3032.66, global_step=3093, preemption_count=0, score=3032.66, test/loss=0.127102, test/num_examples=95000000, total_duration=15914.3, train/loss=0.122597, validation/loss=0.124724, validation/num_examples=83274637
I0306 17:15:03.248307 140019171825408 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.012257236987352371, loss=0.12028226256370544
I0306 17:16:42.163414 140019087963904 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.00693966168910265, loss=0.1311064213514328
I0306 17:17:03.607851 140171586897088 spec.py:321] Evaluating on the training split.
I0306 17:20:19.028262 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 17:20:26.675839 140171586897088 spec.py:349] Evaluating on the test split.
I0306 17:21:20.271526 140171586897088 submission_runner.py:469] Time since start: 16292.19s, 	Step: 3218, 	{'train/loss': 0.12156629114874504, 'validation/loss': 0.12507036073478697, 'validation/num_examples': 83274637, 'test/loss': 0.1275661357010691, 'test/num_examples': 95000000, 'score': 3153.846284866333, 'total_duration': 16292.192174911499, 'accumulated_submission_time': 3153.846284866333, 'accumulated_eval_time': 13137.524651765823, 'accumulated_logging_time': 0.5879127979278564}
I0306 17:21:20.280608 140019171825408 logging_writer.py:48] [3218] accumulated_eval_time=13137.5, accumulated_logging_time=0.587913, accumulated_submission_time=3153.85, global_step=3218, preemption_count=0, score=3153.85, test/loss=0.127566, test/num_examples=95000000, total_duration=16292.2, train/loss=0.121566, validation/loss=0.12507, validation/num_examples=83274637
I0306 17:22:33.099517 140019087963904 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.006366730201989412, loss=0.12315760552883148
I0306 17:23:21.285223 140171586897088 spec.py:321] Evaluating on the training split.
I0306 17:26:40.929023 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 17:26:48.285408 140171586897088 spec.py:349] Evaluating on the test split.
I0306 17:27:33.636027 140171586897088 submission_runner.py:469] Time since start: 16665.56s, 	Step: 3338, 	{'train/loss': 0.1233620924418265, 'validation/loss': 0.1247260817671742, 'validation/num_examples': 83274637, 'test/loss': 0.12715302434210526, 'test/num_examples': 95000000, 'score': 3274.8349714279175, 'total_duration': 16665.556678771973, 'accumulated_submission_time': 3274.8349714279175, 'accumulated_eval_time': 13389.87541103363, 'accumulated_logging_time': 0.603417158126831}
I0306 17:27:33.645161 140019171825408 logging_writer.py:48] [3338] accumulated_eval_time=13389.9, accumulated_logging_time=0.603417, accumulated_submission_time=3274.83, global_step=3338, preemption_count=0, score=3274.83, test/loss=0.127153, test/num_examples=95000000, total_duration=16665.6, train/loss=0.123362, validation/loss=0.124726, validation/num_examples=83274637
I0306 17:28:18.849029 140019087963904 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.017327308654785156, loss=0.12433280795812607
I0306 17:29:35.006965 140171586897088 spec.py:321] Evaluating on the training split.
I0306 17:33:09.069494 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 17:33:16.774176 140171586897088 spec.py:349] Evaluating on the test split.
I0306 17:33:45.713069 140171586897088 submission_runner.py:469] Time since start: 17037.63s, 	Step: 3460, 	{'train/loss': 0.1249553577494134, 'validation/loss': 0.12473998062527768, 'validation/num_examples': 83274637, 'test/loss': 0.1270884769120066, 'test/num_examples': 95000000, 'score': 3396.181331396103, 'total_duration': 17037.63372373581, 'accumulated_submission_time': 3396.181331396103, 'accumulated_eval_time': 13640.58147406578, 'accumulated_logging_time': 0.618859052658081}
I0306 17:33:45.722766 140019171825408 logging_writer.py:48] [3460] accumulated_eval_time=13640.6, accumulated_logging_time=0.618859, accumulated_submission_time=3396.18, global_step=3460, preemption_count=0, score=3396.18, test/loss=0.127088, test/num_examples=95000000, total_duration=17037.6, train/loss=0.124955, validation/loss=0.12474, validation/num_examples=83274637
I0306 17:34:04.638223 140019087963904 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.007325625978410244, loss=0.12040328979492188
I0306 17:35:45.728853 140171586897088 spec.py:321] Evaluating on the training split.
I0306 17:39:40.399366 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 17:39:47.854473 140171586897088 spec.py:349] Evaluating on the test split.
I0306 17:39:59.241842 140171586897088 submission_runner.py:469] Time since start: 17411.16s, 	Step: 3579, 	{'train/loss': 0.1245589183655175, 'validation/loss': 0.12477572047659076, 'validation/num_examples': 83274637, 'test/loss': 0.12719209302014803, 'test/num_examples': 95000000, 'score': 3516.137008190155, 'total_duration': 17411.162484884262, 'accumulated_submission_time': 3516.137008190155, 'accumulated_eval_time': 13894.094406366348, 'accumulated_logging_time': 0.6686785221099854}
I0306 17:39:59.259882 140019171825408 logging_writer.py:48] [3579] accumulated_eval_time=13894.1, accumulated_logging_time=0.668679, accumulated_submission_time=3516.14, global_step=3579, preemption_count=0, score=3516.14, test/loss=0.127192, test/num_examples=95000000, total_duration=17411.2, train/loss=0.124559, validation/loss=0.124776, validation/num_examples=83274637
I0306 17:40:01.570791 140019087963904 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.024934859946370125, loss=0.11420229822397232
I0306 17:41:55.381291 140019171825408 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.008386422879993916, loss=0.13704288005828857
I0306 17:41:59.463635 140171586897088 spec.py:321] Evaluating on the training split.
I0306 17:46:02.853857 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 17:46:10.369579 140171586897088 spec.py:349] Evaluating on the test split.
I0306 17:46:18.945390 140171586897088 submission_runner.py:469] Time since start: 17790.87s, 	Step: 3703, 	{'train/loss': 0.1217703198627481, 'validation/loss': 0.12474762548068057, 'validation/num_examples': 83274637, 'test/loss': 0.12701612927631578, 'test/num_examples': 95000000, 'score': 3636.3246433734894, 'total_duration': 17790.866048574448, 'accumulated_submission_time': 3636.3246433734894, 'accumulated_eval_time': 14153.576115131378, 'accumulated_logging_time': 0.6928684711456299}
I0306 17:46:18.954852 140019087963904 logging_writer.py:48] [3703] accumulated_eval_time=14153.6, accumulated_logging_time=0.692868, accumulated_submission_time=3636.32, global_step=3703, preemption_count=0, score=3636.32, test/loss=0.127016, test/num_examples=95000000, total_duration=17790.9, train/loss=0.12177, validation/loss=0.124748, validation/num_examples=83274637
I0306 17:47:51.715186 140019171825408 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.012072339653968811, loss=0.12211492657661438
I0306 17:48:19.221092 140171586897088 spec.py:321] Evaluating on the training split.
I0306 17:52:37.508147 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 17:52:44.975587 140171586897088 spec.py:349] Evaluating on the test split.
I0306 17:52:53.499801 140171586897088 submission_runner.py:469] Time since start: 18185.42s, 	Step: 3822, 	{'train/loss': 0.12120544055254205, 'validation/loss': 0.1248157940444456, 'validation/num_examples': 83274637, 'test/loss': 0.12723486376439144, 'test/num_examples': 95000000, 'score': 3756.5744433403015, 'total_duration': 18185.420456647873, 'accumulated_submission_time': 3756.5744433403015, 'accumulated_eval_time': 14427.854778289795, 'accumulated_logging_time': 0.7094213962554932}
I0306 17:52:53.508773 140019087963904 logging_writer.py:48] [3822] accumulated_eval_time=14427.9, accumulated_logging_time=0.709421, accumulated_submission_time=3756.57, global_step=3822, preemption_count=0, score=3756.57, test/loss=0.127235, test/num_examples=95000000, total_duration=18185.4, train/loss=0.121205, validation/loss=0.124816, validation/num_examples=83274637
I0306 17:54:02.423053 140019171825408 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.012193847447633743, loss=0.12236864864826202
I0306 17:54:53.502281 140171586897088 spec.py:321] Evaluating on the training split.
I0306 17:59:12.233051 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 17:59:19.857290 140171586897088 spec.py:349] Evaluating on the test split.
I0306 17:59:28.627003 140171586897088 submission_runner.py:469] Time since start: 18580.55s, 	Step: 3940, 	{'train/loss': 0.12231062851705642, 'validation/loss': 0.12492781032073502, 'validation/num_examples': 83274637, 'test/loss': 0.12732437600740132, 'test/num_examples': 95000000, 'score': 3876.5299594402313, 'total_duration': 18580.54766225815, 'accumulated_submission_time': 3876.5299594402313, 'accumulated_eval_time': 14702.979464292526, 'accumulated_logging_time': 0.7467691898345947}
I0306 17:59:28.636920 140019087963904 logging_writer.py:48] [3940] accumulated_eval_time=14703, accumulated_logging_time=0.746769, accumulated_submission_time=3876.53, global_step=3940, preemption_count=0, score=3876.53, test/loss=0.127324, test/num_examples=95000000, total_duration=18580.5, train/loss=0.122311, validation/loss=0.124928, validation/num_examples=83274637
I0306 18:00:13.505305 140019171825408 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.022860480472445488, loss=0.12478682398796082
I0306 18:01:29.952246 140171586897088 spec.py:321] Evaluating on the training split.
I0306 18:05:42.422846 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 18:05:50.204726 140171586897088 spec.py:349] Evaluating on the test split.
I0306 18:05:58.985810 140171586897088 submission_runner.py:469] Time since start: 18970.91s, 	Step: 4061, 	{'train/loss': 0.1225739995240228, 'validation/loss': 0.12478219755047536, 'validation/num_examples': 83274637, 'test/loss': 0.1271267916118421, 'test/num_examples': 95000000, 'score': 3997.8293240070343, 'total_duration': 18970.906445980072, 'accumulated_submission_time': 3997.8293240070343, 'accumulated_eval_time': 14972.012969255447, 'accumulated_logging_time': 0.7633392810821533}
I0306 18:05:58.996854 140019087963904 logging_writer.py:48] [4061] accumulated_eval_time=14972, accumulated_logging_time=0.763339, accumulated_submission_time=3997.83, global_step=4061, preemption_count=0, score=3997.83, test/loss=0.127127, test/num_examples=95000000, total_duration=18970.9, train/loss=0.122574, validation/loss=0.124782, validation/num_examples=83274637
I0306 18:06:17.055100 140019171825408 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.00960148498415947, loss=0.1246713176369667
I0306 18:07:59.503817 140171586897088 spec.py:321] Evaluating on the training split.
I0306 18:12:11.548394 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 18:12:19.168671 140171586897088 spec.py:349] Evaluating on the test split.
I0306 18:12:28.018080 140171586897088 submission_runner.py:469] Time since start: 19359.94s, 	Step: 4180, 	{'train/loss': 0.1251415659281068, 'validation/loss': 0.1247370794978668, 'validation/num_examples': 83274637, 'test/loss': 0.12714903193873356, 'test/num_examples': 95000000, 'score': 4118.3199627399445, 'total_duration': 19359.938700914383, 'accumulated_submission_time': 4118.3199627399445, 'accumulated_eval_time': 15240.527163267136, 'accumulated_logging_time': 0.7810769081115723}
I0306 18:12:28.036382 140019087963904 logging_writer.py:48] [4180] accumulated_eval_time=15240.5, accumulated_logging_time=0.781077, accumulated_submission_time=4118.32, global_step=4180, preemption_count=0, score=4118.32, test/loss=0.127149, test/num_examples=95000000, total_duration=19359.9, train/loss=0.125142, validation/loss=0.124737, validation/num_examples=83274637
I0306 18:12:30.334499 140019171825408 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.006879108492285013, loss=0.13049693405628204
I0306 18:14:28.219160 140171586897088 spec.py:321] Evaluating on the training split.
I0306 18:18:35.660835 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 18:18:43.370368 140171586897088 spec.py:349] Evaluating on the test split.
I0306 18:18:52.135360 140171586897088 submission_runner.py:469] Time since start: 19744.06s, 	Step: 4299, 	{'train/loss': 0.12395218821863334, 'validation/loss': 0.12466469647538812, 'validation/num_examples': 83274637, 'test/loss': 0.1271118644839638, 'test/num_examples': 95000000, 'score': 4238.452558994293, 'total_duration': 19744.056017637253, 'accumulated_submission_time': 4238.452558994293, 'accumulated_eval_time': 15504.443326950073, 'accumulated_logging_time': 0.8402349948883057}
I0306 18:18:52.144589 140019087963904 logging_writer.py:48] [4299] accumulated_eval_time=15504.4, accumulated_logging_time=0.840235, accumulated_submission_time=4238.45, global_step=4299, preemption_count=0, score=4238.45, test/loss=0.127112, test/num_examples=95000000, total_duration=19744.1, train/loss=0.123952, validation/loss=0.124665, validation/num_examples=83274637
I0306 18:18:52.361997 140019171825408 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.009651637636125088, loss=0.12630583345890045
I0306 18:20:26.844449 140019087963904 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.00826753955334425, loss=0.12047650665044785
I0306 18:20:52.262309 140171586897088 spec.py:321] Evaluating on the training split.
I0306 18:25:04.857197 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 18:25:12.529002 140171586897088 spec.py:349] Evaluating on the test split.
I0306 18:25:21.216163 140171586897088 submission_runner.py:469] Time since start: 20133.14s, 	Step: 4421, 	{'train/loss': 0.12300120333924233, 'validation/loss': 0.12473076456748582, 'validation/num_examples': 83274637, 'test/loss': 0.1270501, 'test/num_examples': 95000000, 'score': 4358.5543076992035, 'total_duration': 20133.13681960106, 'accumulated_submission_time': 4358.5543076992035, 'accumulated_eval_time': 15773.39713382721, 'accumulated_logging_time': 0.8555290699005127}
I0306 18:25:21.225696 140019171825408 logging_writer.py:48] [4421] accumulated_eval_time=15773.4, accumulated_logging_time=0.855529, accumulated_submission_time=4358.55, global_step=4421, preemption_count=0, score=4358.55, test/loss=0.12705, test/num_examples=95000000, total_duration=20133.1, train/loss=0.123001, validation/loss=0.124731, validation/num_examples=83274637
I0306 18:26:28.667239 140019087963904 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.014430097304284573, loss=0.13506028056144714
I0306 18:27:22.645821 140171586897088 spec.py:321] Evaluating on the training split.
I0306 18:31:33.131896 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 18:31:40.763844 140171586897088 spec.py:349] Evaluating on the test split.
I0306 18:31:49.518026 140171586897088 submission_runner.py:469] Time since start: 20521.44s, 	Step: 4542, 	{'train/loss': 0.12383575936627088, 'validation/loss': 0.12468617647604921, 'validation/num_examples': 83274637, 'test/loss': 0.12710518601973683, 'test/num_examples': 95000000, 'score': 4479.9563064575195, 'total_duration': 20521.43867468834, 'accumulated_submission_time': 4479.9563064575195, 'accumulated_eval_time': 16040.26929140091, 'accumulated_logging_time': 0.8735275268554688}
I0306 18:31:49.527870 140019171825408 logging_writer.py:48] [4542] accumulated_eval_time=16040.3, accumulated_logging_time=0.873528, accumulated_submission_time=4479.96, global_step=4542, preemption_count=0, score=4479.96, test/loss=0.127105, test/num_examples=95000000, total_duration=20521.4, train/loss=0.123836, validation/loss=0.124686, validation/num_examples=83274637
I0306 18:32:33.237244 140019087963904 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.011320932768285275, loss=0.1200919970870018
I0306 18:33:50.637522 140171586897088 spec.py:321] Evaluating on the training split.
I0306 18:38:01.188176 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 18:38:08.840835 140171586897088 spec.py:349] Evaluating on the test split.
I0306 18:38:17.613419 140171586897088 submission_runner.py:469] Time since start: 20909.53s, 	Step: 4663, 	{'train/loss': 0.12257937529364472, 'validation/loss': 0.12478880271262657, 'validation/num_examples': 83274637, 'test/loss': 0.1270858423828125, 'test/num_examples': 95000000, 'score': 4601.049095869064, 'total_duration': 20909.534068346024, 'accumulated_submission_time': 4601.049095869064, 'accumulated_eval_time': 16307.245141267776, 'accumulated_logging_time': 0.8910069465637207}
I0306 18:38:17.623726 140019171825408 logging_writer.py:48] [4663] accumulated_eval_time=16307.2, accumulated_logging_time=0.891007, accumulated_submission_time=4601.05, global_step=4663, preemption_count=0, score=4601.05, test/loss=0.127086, test/num_examples=95000000, total_duration=20909.5, train/loss=0.122579, validation/loss=0.124789, validation/num_examples=83274637
I0306 18:38:32.550470 140019087963904 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.011375727131962776, loss=0.1223229318857193
I0306 18:40:17.729036 140171586897088 spec.py:321] Evaluating on the training split.
I0306 18:44:32.520720 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 18:44:40.253512 140171586897088 spec.py:349] Evaluating on the test split.
I0306 18:44:49.042743 140171586897088 submission_runner.py:469] Time since start: 21300.96s, 	Step: 4784, 	{'train/loss': 0.1254976549238529, 'validation/loss': 0.12486772263433132, 'validation/num_examples': 83274637, 'test/loss': 0.12735609599095396, 'test/num_examples': 95000000, 'score': 4721.118688583374, 'total_duration': 21300.96338891983, 'accumulated_submission_time': 4721.118688583374, 'accumulated_eval_time': 16578.558802366257, 'accumulated_logging_time': 0.9272923469543457}
I0306 18:44:49.052547 140019171825408 logging_writer.py:48] [4784] accumulated_eval_time=16578.6, accumulated_logging_time=0.927292, accumulated_submission_time=4721.12, global_step=4784, preemption_count=0, score=4721.12, test/loss=0.127356, test/num_examples=95000000, total_duration=21301, train/loss=0.125498, validation/loss=0.124868, validation/num_examples=83274637
I0306 18:44:50.858302 140019087963904 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.024097584187984467, loss=0.12123756110668182
I0306 18:46:41.479698 140019171825408 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.01709628850221634, loss=0.1208922415971756
I0306 18:46:49.111731 140171586897088 spec.py:321] Evaluating on the training split.
I0306 18:50:57.506134 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 18:51:05.153174 140171586897088 spec.py:349] Evaluating on the test split.
I0306 18:51:14.100644 140171586897088 submission_runner.py:469] Time since start: 21686.02s, 	Step: 4907, 	{'train/loss': 0.12394796257967469, 'validation/loss': 0.12466837949532655, 'validation/num_examples': 83274637, 'test/loss': 0.12700366087582238, 'test/num_examples': 95000000, 'score': 4841.161161661148, 'total_duration': 21686.02130484581, 'accumulated_submission_time': 4841.161161661148, 'accumulated_eval_time': 16843.54767346382, 'accumulated_logging_time': 0.9445006847381592}
I0306 18:51:14.110055 140019087963904 logging_writer.py:48] [4907] accumulated_eval_time=16843.5, accumulated_logging_time=0.944501, accumulated_submission_time=4841.16, global_step=4907, preemption_count=0, score=4841.16, test/loss=0.127004, test/num_examples=95000000, total_duration=21686, train/loss=0.123948, validation/loss=0.124668, validation/num_examples=83274637
I0306 18:52:37.768046 140019171825408 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.007730613928288221, loss=0.135294571518898
I0306 18:53:14.733745 140171586897088 spec.py:321] Evaluating on the training split.
I0306 18:57:25.348742 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 18:57:32.824411 140171586897088 spec.py:349] Evaluating on the test split.
I0306 18:57:41.643988 140171586897088 submission_runner.py:469] Time since start: 22073.56s, 	Step: 5029, 	{'train/loss': 0.12484328041099152, 'validation/loss': 0.12461495304963585, 'validation/num_examples': 83274637, 'test/loss': 0.12735960069901317, 'test/num_examples': 95000000, 'score': 4961.768985033035, 'total_duration': 22073.56462931633, 'accumulated_submission_time': 4961.768985033035, 'accumulated_eval_time': 17110.45785689354, 'accumulated_logging_time': 0.9603605270385742}
I0306 18:57:41.654555 140019087963904 logging_writer.py:48] [5029] accumulated_eval_time=17110.5, accumulated_logging_time=0.960361, accumulated_submission_time=4961.77, global_step=5029, preemption_count=0, score=4961.77, test/loss=0.12736, test/num_examples=95000000, total_duration=22073.6, train/loss=0.124843, validation/loss=0.124615, validation/num_examples=83274637
I0306 18:58:39.342949 140019171825408 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.006209638435393572, loss=0.12274715304374695
I0306 18:59:42.079615 140171586897088 spec.py:321] Evaluating on the training split.
I0306 19:03:54.859364 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 19:04:02.205998 140171586897088 spec.py:349] Evaluating on the test split.
I0306 19:04:11.088314 140171586897088 submission_runner.py:469] Time since start: 22463.01s, 	Step: 5153, 	{'train/loss': 0.12306639241675536, 'validation/loss': 0.12440256343024873, 'validation/num_examples': 83274637, 'test/loss': 0.12680705363898026, 'test/num_examples': 95000000, 'score': 5082.169224500656, 'total_duration': 22463.008970737457, 'accumulated_submission_time': 5082.169224500656, 'accumulated_eval_time': 17379.46651148796, 'accumulated_logging_time': 0.9857747554779053}
I0306 19:04:11.097989 140019087963904 logging_writer.py:48] [5153] accumulated_eval_time=17379.5, accumulated_logging_time=0.985775, accumulated_submission_time=5082.17, global_step=5153, preemption_count=0, score=5082.17, test/loss=0.126807, test/num_examples=95000000, total_duration=22463, train/loss=0.123066, validation/loss=0.124403, validation/num_examples=83274637
I0306 19:04:39.571624 140019171825408 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.015663880854845047, loss=0.12005209177732468
I0306 19:06:12.234414 140171586897088 spec.py:321] Evaluating on the training split.
I0306 19:10:17.709820 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 19:10:25.118572 140171586897088 spec.py:349] Evaluating on the test split.
I0306 19:10:34.062471 140171586897088 submission_runner.py:469] Time since start: 22845.98s, 	Step: 5273, 	{'train/loss': 0.12249337528018081, 'validation/loss': 0.12455678502199595, 'validation/num_examples': 83274637, 'test/loss': 0.12689530626027962, 'test/num_examples': 95000000, 'score': 5203.2736258506775, 'total_duration': 22845.98309469223, 'accumulated_submission_time': 5203.2736258506775, 'accumulated_eval_time': 17641.29449915886, 'accumulated_logging_time': 1.0182573795318604}
I0306 19:10:34.072142 140019087963904 logging_writer.py:48] [5273] accumulated_eval_time=17641.3, accumulated_logging_time=1.01826, accumulated_submission_time=5203.27, global_step=5273, preemption_count=0, score=5203.27, test/loss=0.126895, test/num_examples=95000000, total_duration=22846, train/loss=0.122493, validation/loss=0.124557, validation/num_examples=83274637
I0306 19:10:37.281449 140019171825408 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.01705985516309738, loss=0.11740736663341522
I0306 19:12:34.711326 140171586897088 spec.py:321] Evaluating on the training split.
I0306 19:16:38.770495 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 19:16:46.257426 140171586897088 spec.py:349] Evaluating on the test split.
I0306 19:16:54.994085 140171586897088 submission_runner.py:469] Time since start: 23226.91s, 	Step: 5393, 	{'train/loss': 0.12466076344439068, 'validation/loss': 0.12422599376937993, 'validation/num_examples': 83274637, 'test/loss': 0.12651245366981909, 'test/num_examples': 95000000, 'score': 5323.897226333618, 'total_duration': 23226.914736270905, 'accumulated_submission_time': 5323.897226333618, 'accumulated_eval_time': 17901.57721376419, 'accumulated_logging_time': 1.0341253280639648}
I0306 19:16:55.004575 140019087963904 logging_writer.py:48] [5393] accumulated_eval_time=17901.6, accumulated_logging_time=1.03413, accumulated_submission_time=5323.9, global_step=5393, preemption_count=0, score=5323.9, test/loss=0.126512, test/num_examples=95000000, total_duration=23226.9, train/loss=0.124661, validation/loss=0.124226, validation/num_examples=83274637
I0306 19:16:55.862942 140019171825408 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.006393721327185631, loss=0.1322275549173355
I0306 19:18:41.509958 140019087963904 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.017490534111857414, loss=0.11926087737083435
I0306 19:18:56.283517 140171586897088 spec.py:321] Evaluating on the training split.
I0306 19:23:08.191494 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 19:23:15.452360 140171586897088 spec.py:349] Evaluating on the test split.
I0306 19:23:24.141810 140171586897088 submission_runner.py:469] Time since start: 23616.06s, 	Step: 5512, 	{'train/loss': 0.12270390026786793, 'validation/loss': 0.1242280859617782, 'validation/num_examples': 83274637, 'test/loss': 0.12659068251439146, 'test/num_examples': 95000000, 'score': 5445.1599678993225, 'total_duration': 23616.06245279312, 'accumulated_submission_time': 5445.1599678993225, 'accumulated_eval_time': 18169.435449123383, 'accumulated_logging_time': 1.0515897274017334}
I0306 19:23:24.152431 140019171825408 logging_writer.py:48] [5512] accumulated_eval_time=18169.4, accumulated_logging_time=1.05159, accumulated_submission_time=5445.16, global_step=5512, preemption_count=0, score=5445.16, test/loss=0.126591, test/num_examples=95000000, total_duration=23616.1, train/loss=0.122704, validation/loss=0.124228, validation/num_examples=83274637
I0306 19:24:43.544065 140019087963904 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.009298192337155342, loss=0.12667015194892883
I0306 19:25:24.776419 140171586897088 spec.py:321] Evaluating on the training split.
I0306 19:29:34.350358 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 19:29:41.751322 140171586897088 spec.py:349] Evaluating on the test split.
I0306 19:29:50.616541 140171586897088 submission_runner.py:469] Time since start: 24002.54s, 	Step: 5633, 	{'train/loss': 0.12169308894835178, 'validation/loss': 0.12460264759315125, 'validation/num_examples': 83274637, 'test/loss': 0.12703433987458881, 'test/num_examples': 95000000, 'score': 5565.751047611237, 'total_duration': 24002.53719806671, 'accumulated_submission_time': 5565.751047611237, 'accumulated_eval_time': 18435.275528907776, 'accumulated_logging_time': 1.0850191116333008}
I0306 19:29:50.626027 140019171825408 logging_writer.py:48] [5633] accumulated_eval_time=18435.3, accumulated_logging_time=1.08502, accumulated_submission_time=5565.75, global_step=5633, preemption_count=0, score=5565.75, test/loss=0.127034, test/num_examples=95000000, total_duration=24002.5, train/loss=0.121693, validation/loss=0.124603, validation/num_examples=83274637
I0306 19:30:44.710613 140019087963904 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.008346364833414555, loss=0.11553964763879776
I0306 19:31:51.718320 140171586897088 spec.py:321] Evaluating on the training split.
I0306 19:35:59.857066 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 19:36:07.332575 140171586897088 spec.py:349] Evaluating on the test split.
I0306 19:36:16.063963 140171586897088 submission_runner.py:469] Time since start: 24387.98s, 	Step: 5753, 	{'train/loss': 0.123904851271109, 'validation/loss': 0.12440839716036528, 'validation/num_examples': 83274637, 'test/loss': 0.12686846106085525, 'test/num_examples': 95000000, 'score': 5686.826882123947, 'total_duration': 24387.984611034393, 'accumulated_submission_time': 5686.826882123947, 'accumulated_eval_time': 18699.621121406555, 'accumulated_logging_time': 1.1016483306884766}
I0306 19:36:16.074378 140019171825408 logging_writer.py:48] [5753] accumulated_eval_time=18699.6, accumulated_logging_time=1.10165, accumulated_submission_time=5686.83, global_step=5753, preemption_count=0, score=5686.83, test/loss=0.126868, test/num_examples=95000000, total_duration=24388, train/loss=0.123905, validation/loss=0.124408, validation/num_examples=83274637
I0306 19:36:45.892244 140019087963904 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.06890197843313217, loss=0.13539227843284607
I0306 19:38:16.333372 140171586897088 spec.py:321] Evaluating on the training split.
I0306 19:42:23.160258 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 19:42:30.584197 140171586897088 spec.py:349] Evaluating on the test split.
I0306 19:42:39.200510 140171586897088 submission_runner.py:469] Time since start: 24771.12s, 	Step: 5873, 	{'train/loss': 0.12059460886103927, 'validation/loss': 0.12431196120191622, 'validation/num_examples': 83274637, 'test/loss': 0.12671084272203947, 'test/num_examples': 95000000, 'score': 5807.069628953934, 'total_duration': 24771.121168375015, 'accumulated_submission_time': 5807.069628953934, 'accumulated_eval_time': 18962.48823738098, 'accumulated_logging_time': 1.1190123558044434}
I0306 19:42:39.210445 140019171825408 logging_writer.py:48] [5873] accumulated_eval_time=18962.5, accumulated_logging_time=1.11901, accumulated_submission_time=5807.07, global_step=5873, preemption_count=0, score=5807.07, test/loss=0.126711, test/num_examples=95000000, total_duration=24771.1, train/loss=0.120595, validation/loss=0.124312, validation/num_examples=83274637
I0306 19:42:42.288856 140019087963904 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.009555618278682232, loss=0.13441656529903412
I0306 19:44:39.649451 140171586897088 spec.py:321] Evaluating on the training split.
I0306 19:48:54.529100 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 19:49:01.738112 140171586897088 spec.py:349] Evaluating on the test split.
I0306 19:49:10.199472 140171586897088 submission_runner.py:469] Time since start: 25162.12s, 	Step: 5992, 	{'train/loss': 0.12287216702675295, 'validation/loss': 0.12444130787638183, 'validation/num_examples': 83274637, 'test/loss': 0.1269075531455592, 'test/num_examples': 95000000, 'score': 5927.491410970688, 'total_duration': 25162.12011241913, 'accumulated_submission_time': 5927.491410970688, 'accumulated_eval_time': 19233.03820514679, 'accumulated_logging_time': 1.136143445968628}
I0306 19:49:10.209102 140019171825408 logging_writer.py:48] [5992] accumulated_eval_time=19233, accumulated_logging_time=1.13614, accumulated_submission_time=5927.49, global_step=5992, preemption_count=0, score=5927.49, test/loss=0.126908, test/num_examples=95000000, total_duration=25162.1, train/loss=0.122872, validation/loss=0.124441, validation/num_examples=83274637
I0306 19:49:11.163595 140019087963904 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.007425444666296244, loss=0.12121991068124771
I0306 19:51:02.523956 140019171825408 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.006911621894687414, loss=0.11802782118320465
I0306 19:51:10.340961 140171586897088 spec.py:321] Evaluating on the training split.
I0306 19:55:17.673989 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 19:55:24.948951 140171586897088 spec.py:349] Evaluating on the test split.
I0306 19:55:33.411998 140171586897088 submission_runner.py:469] Time since start: 25545.33s, 	Step: 6107, 	{'train/loss': 0.1216156375389429, 'validation/loss': 0.12433620024553514, 'validation/num_examples': 83274637, 'test/loss': 0.1267765425986842, 'test/num_examples': 95000000, 'score': 6047.58939909935, 'total_duration': 25545.332653284073, 'accumulated_submission_time': 6047.58939909935, 'accumulated_eval_time': 19496.10919237137, 'accumulated_logging_time': 1.170776128768921}
I0306 19:55:33.434817 140019087963904 logging_writer.py:48] [6107] accumulated_eval_time=19496.1, accumulated_logging_time=1.17078, accumulated_submission_time=6047.59, global_step=6107, preemption_count=0, score=6047.59, test/loss=0.126777, test/num_examples=95000000, total_duration=25545.3, train/loss=0.121616, validation/loss=0.124336, validation/num_examples=83274637
I0306 19:56:58.476783 140019171825408 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.011075166054069996, loss=0.1283361315727234
I0306 19:57:34.563276 140171586897088 spec.py:321] Evaluating on the training split.
I0306 20:01:53.183181 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 20:02:00.356121 140171586897088 spec.py:349] Evaluating on the test split.
I0306 20:02:08.884577 140171586897088 submission_runner.py:469] Time since start: 25940.81s, 	Step: 6228, 	{'train/loss': 0.12339324075377213, 'validation/loss': 0.12427524328278894, 'validation/num_examples': 83274637, 'test/loss': 0.12654429330797698, 'test/num_examples': 95000000, 'score': 6168.69278049469, 'total_duration': 25940.805236577988, 'accumulated_submission_time': 6168.69278049469, 'accumulated_eval_time': 19770.43045067787, 'accumulated_logging_time': 1.200709342956543}
I0306 20:02:08.895098 140019087963904 logging_writer.py:48] [6228] accumulated_eval_time=19770.4, accumulated_logging_time=1.20071, accumulated_submission_time=6168.69, global_step=6228, preemption_count=0, score=6168.69, test/loss=0.126544, test/num_examples=95000000, total_duration=25940.8, train/loss=0.123393, validation/loss=0.124275, validation/num_examples=83274637
I0306 20:03:08.793118 140019171825408 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.00958472304046154, loss=0.12602266669273376
I0306 20:04:09.708829 140171586897088 spec.py:321] Evaluating on the training split.
I0306 20:08:19.003220 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 20:08:26.177659 140171586897088 spec.py:349] Evaluating on the test split.
I0306 20:08:34.680234 140171586897088 submission_runner.py:469] Time since start: 26326.60s, 	Step: 6348, 	{'train/loss': 0.12219167489019579, 'validation/loss': 0.12438986587532161, 'validation/num_examples': 83274637, 'test/loss': 0.12669156044407895, 'test/num_examples': 95000000, 'score': 6289.490707159042, 'total_duration': 26326.600895404816, 'accumulated_submission_time': 6289.490707159042, 'accumulated_eval_time': 20035.401827573776, 'accumulated_logging_time': 1.2173614501953125}
I0306 20:08:34.690032 140019087963904 logging_writer.py:48] [6348] accumulated_eval_time=20035.4, accumulated_logging_time=1.21736, accumulated_submission_time=6289.49, global_step=6348, preemption_count=0, score=6289.49, test/loss=0.126692, test/num_examples=95000000, total_duration=26326.6, train/loss=0.122192, validation/loss=0.12439, validation/num_examples=83274637
I0306 20:09:10.655719 140019171825408 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.008437025360763073, loss=0.1224881261587143
I0306 20:10:35.136333 140171586897088 spec.py:321] Evaluating on the training split.
I0306 20:14:51.632854 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 20:14:58.809399 140171586897088 spec.py:349] Evaluating on the test split.
I0306 20:15:07.272783 140171586897088 submission_runner.py:469] Time since start: 26719.19s, 	Step: 6466, 	{'train/loss': 0.12346401236623337, 'validation/loss': 0.12427912674078213, 'validation/num_examples': 83274637, 'test/loss': 0.12670367321134868, 'test/num_examples': 95000000, 'score': 6409.896944761276, 'total_duration': 26719.19340777397, 'accumulated_submission_time': 6409.896944761276, 'accumulated_eval_time': 20307.538204669952, 'accumulated_logging_time': 1.2569687366485596}
I0306 20:15:07.284657 140019087963904 logging_writer.py:48] [6466] accumulated_eval_time=20307.5, accumulated_logging_time=1.25697, accumulated_submission_time=6409.9, global_step=6466, preemption_count=0, score=6409.9, test/loss=0.126704, test/num_examples=95000000, total_duration=26719.2, train/loss=0.123464, validation/loss=0.124279, validation/num_examples=83274637
I0306 20:15:20.045284 140019171825408 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.006864809896796942, loss=0.12287633866071701
I0306 20:17:07.328761 140171586897088 spec.py:321] Evaluating on the training split.
I0306 20:21:25.937994 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 20:21:33.043085 140171586897088 spec.py:349] Evaluating on the test split.
I0306 20:21:41.552551 140171586897088 submission_runner.py:469] Time since start: 27113.47s, 	Step: 6587, 	{'train/loss': 0.12202850115374199, 'validation/loss': 0.12397880359113536, 'validation/num_examples': 83274637, 'test/loss': 0.1262945986225329, 'test/num_examples': 95000000, 'score': 6529.92381477356, 'total_duration': 27113.473199367523, 'accumulated_submission_time': 6529.92381477356, 'accumulated_eval_time': 20581.761965990067, 'accumulated_logging_time': 1.2757446765899658}
I0306 20:21:41.563210 140019087963904 logging_writer.py:48] [6587] accumulated_eval_time=20581.8, accumulated_logging_time=1.27574, accumulated_submission_time=6529.92, global_step=6587, preemption_count=0, score=6529.92, test/loss=0.126295, test/num_examples=95000000, total_duration=27113.5, train/loss=0.122029, validation/loss=0.123979, validation/num_examples=83274637
I0306 20:21:43.036914 140019171825408 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.00987121369689703, loss=0.1151433065533638
I0306 20:23:32.679865 140019087963904 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.008711195550858974, loss=0.11827707290649414
I0306 20:23:41.816955 140171586897088 spec.py:321] Evaluating on the training split.
I0306 20:27:57.767353 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 20:28:04.893026 140171586897088 spec.py:349] Evaluating on the test split.
I0306 20:28:13.466776 140171586897088 submission_runner.py:469] Time since start: 27505.39s, 	Step: 6708, 	{'train/loss': 0.12209938316600127, 'validation/loss': 0.12402709709523599, 'validation/num_examples': 83274637, 'test/loss': 0.12645075347450657, 'test/num_examples': 95000000, 'score': 6650.1604771614075, 'total_duration': 27505.387426137924, 'accumulated_submission_time': 6650.1604771614075, 'accumulated_eval_time': 20853.411732912064, 'accumulated_logging_time': 1.293532371520996}
I0306 20:28:13.477259 140019171825408 logging_writer.py:48] [6708] accumulated_eval_time=20853.4, accumulated_logging_time=1.29353, accumulated_submission_time=6650.16, global_step=6708, preemption_count=0, score=6650.16, test/loss=0.126451, test/num_examples=95000000, total_duration=27505.4, train/loss=0.122099, validation/loss=0.124027, validation/num_examples=83274637
I0306 20:29:37.853163 140019087963904 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.01661495491862297, loss=0.12094186991453171
I0306 20:30:13.624940 140171586897088 spec.py:321] Evaluating on the training split.
I0306 20:34:16.583473 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 20:34:24.179267 140171586897088 spec.py:349] Evaluating on the test split.
I0306 20:34:33.128246 140171586897088 submission_runner.py:469] Time since start: 27885.05s, 	Step: 6828, 	{'train/loss': 0.1227060299624437, 'validation/loss': 0.12401109288702904, 'validation/num_examples': 83274637, 'test/loss': 0.12638994853001645, 'test/num_examples': 95000000, 'score': 6770.291089057922, 'total_duration': 27885.048901081085, 'accumulated_submission_time': 6770.291089057922, 'accumulated_eval_time': 21112.914993286133, 'accumulated_logging_time': 1.3112225532531738}
I0306 20:34:33.139854 140019171825408 logging_writer.py:48] [6828] accumulated_eval_time=21112.9, accumulated_logging_time=1.31122, accumulated_submission_time=6770.29, global_step=6828, preemption_count=0, score=6770.29, test/loss=0.12639, test/num_examples=95000000, total_duration=27885, train/loss=0.122706, validation/loss=0.124011, validation/num_examples=83274637
I0306 20:35:32.104051 140019087963904 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.009477847255766392, loss=0.12883199751377106
I0306 20:36:33.231734 140171586897088 spec.py:321] Evaluating on the training split.
I0306 20:40:44.073142 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 20:40:51.373938 140171586897088 spec.py:349] Evaluating on the test split.
I0306 20:41:00.183599 140171586897088 submission_runner.py:469] Time since start: 28272.10s, 	Step: 6951, 	{'train/loss': 0.12068564930942448, 'validation/loss': 0.12405960022729332, 'validation/num_examples': 83274637, 'test/loss': 0.1264138845703125, 'test/num_examples': 95000000, 'score': 6890.353255987167, 'total_duration': 28272.10425400734, 'accumulated_submission_time': 6890.353255987167, 'accumulated_eval_time': 21379.866821050644, 'accumulated_logging_time': 1.3433582782745361}
I0306 20:41:00.194467 140019171825408 logging_writer.py:48] [6951] accumulated_eval_time=21379.9, accumulated_logging_time=1.34336, accumulated_submission_time=6890.35, global_step=6951, preemption_count=0, score=6890.35, test/loss=0.126414, test/num_examples=95000000, total_duration=28272.1, train/loss=0.120686, validation/loss=0.12406, validation/num_examples=83274637
I0306 20:41:30.110371 140019087963904 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.015208892524242401, loss=0.12211069464683533
I0306 20:43:01.311847 140171586897088 spec.py:321] Evaluating on the training split.
I0306 20:47:12.516703 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 20:47:19.895305 140171586897088 spec.py:349] Evaluating on the test split.
I0306 20:47:28.716507 140171586897088 submission_runner.py:469] Time since start: 28660.64s, 	Step: 7072, 	{'train/loss': 0.12185720025134161, 'validation/loss': 0.123973406193743, 'validation/num_examples': 83274637, 'test/loss': 0.12632695460526316, 'test/num_examples': 95000000, 'score': 7011.454977989197, 'total_duration': 28660.63714313507, 'accumulated_submission_time': 7011.454977989197, 'accumulated_eval_time': 21647.271420955658, 'accumulated_logging_time': 1.360609531402588}
I0306 20:47:28.727025 140019171825408 logging_writer.py:48] [7072] accumulated_eval_time=21647.3, accumulated_logging_time=1.36061, accumulated_submission_time=7011.45, global_step=7072, preemption_count=0, score=7011.45, test/loss=0.126327, test/num_examples=95000000, total_duration=28660.6, train/loss=0.121857, validation/loss=0.123973, validation/num_examples=83274637
I0306 20:47:33.431161 140019087963904 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.011257839389145374, loss=0.12878729403018951
I0306 20:49:28.786681 140171586897088 spec.py:321] Evaluating on the training split.
I0306 20:53:48.298545 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 20:53:55.458364 140171586897088 spec.py:349] Evaluating on the test split.
I0306 20:54:03.990755 140171586897088 submission_runner.py:469] Time since start: 29055.91s, 	Step: 7190, 	{'train/loss': 0.12367577576693499, 'validation/loss': 0.12410696539782913, 'validation/num_examples': 83274637, 'test/loss': 0.1264183210834704, 'test/num_examples': 95000000, 'score': 7131.4991846084595, 'total_duration': 29055.911410808563, 'accumulated_submission_time': 7131.4991846084595, 'accumulated_eval_time': 21922.475452184677, 'accumulated_logging_time': 1.3776171207427979}
I0306 20:54:04.001079 140019171825408 logging_writer.py:48] [7190] accumulated_eval_time=21922.5, accumulated_logging_time=1.37762, accumulated_submission_time=7131.5, global_step=7190, preemption_count=0, score=7131.5, test/loss=0.126418, test/num_examples=95000000, total_duration=29055.9, train/loss=0.123676, validation/loss=0.124107, validation/num_examples=83274637
I0306 20:54:05.156008 140019087963904 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.014410813339054585, loss=0.1409836858510971
I0306 20:55:56.261870 140019171825408 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.006513140629976988, loss=0.1241709515452385
I0306 20:56:04.146547 140171586897088 spec.py:321] Evaluating on the training split.
I0306 21:00:16.001413 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 21:00:23.197311 140171586897088 spec.py:349] Evaluating on the test split.
I0306 21:00:31.693107 140171586897088 submission_runner.py:469] Time since start: 29443.61s, 	Step: 7307, 	{'train/loss': 0.12122896647537654, 'validation/loss': 0.12396937756122964, 'validation/num_examples': 83274637, 'test/loss': 0.1262845745682566, 'test/num_examples': 95000000, 'score': 7251.62829875946, 'total_duration': 29443.613761901855, 'accumulated_submission_time': 7251.62829875946, 'accumulated_eval_time': 22190.02196574211, 'accumulated_logging_time': 1.394381046295166}
I0306 21:00:31.703068 140019087963904 logging_writer.py:48] [7307] accumulated_eval_time=22190, accumulated_logging_time=1.39438, accumulated_submission_time=7251.63, global_step=7307, preemption_count=0, score=7251.63, test/loss=0.126285, test/num_examples=95000000, total_duration=29443.6, train/loss=0.121229, validation/loss=0.123969, validation/num_examples=83274637
I0306 21:02:03.555794 140019171825408 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.013736899010837078, loss=0.1263875961303711
I0306 21:02:32.493517 140171586897088 spec.py:321] Evaluating on the training split.
I0306 21:06:49.287210 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 21:06:56.562055 140171586897088 spec.py:349] Evaluating on the test split.
I0306 21:07:05.189269 140171586897088 submission_runner.py:469] Time since start: 29837.11s, 	Step: 7425, 	{'train/loss': 0.12387934993694788, 'validation/loss': 0.12408543504725064, 'validation/num_examples': 83274637, 'test/loss': 0.12641437200863487, 'test/num_examples': 95000000, 'score': 7372.382732391357, 'total_duration': 29837.109925746918, 'accumulated_submission_time': 7372.382732391357, 'accumulated_eval_time': 22462.717671871185, 'accumulated_logging_time': 1.4302856922149658}
I0306 21:07:05.200010 140019087963904 logging_writer.py:48] [7425] accumulated_eval_time=22462.7, accumulated_logging_time=1.43029, accumulated_submission_time=7372.38, global_step=7425, preemption_count=0, score=7372.38, test/loss=0.126414, test/num_examples=95000000, total_duration=29837.1, train/loss=0.123879, validation/loss=0.124085, validation/num_examples=83274637
I0306 21:08:10.201216 140019171825408 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.008998985402286053, loss=0.11873524636030197
I0306 21:09:05.759409 140171586897088 spec.py:321] Evaluating on the training split.
I0306 21:13:14.144071 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 21:13:21.416405 140171586897088 spec.py:349] Evaluating on the test split.
I0306 21:13:30.174272 140171586897088 submission_runner.py:469] Time since start: 30222.09s, 	Step: 7544, 	{'train/loss': 0.12313362307049944, 'validation/loss': 0.12401531731370119, 'validation/num_examples': 83274637, 'test/loss': 0.1262967347964638, 'test/num_examples': 95000000, 'score': 7492.926265001297, 'total_duration': 30222.09490418434, 'accumulated_submission_time': 7492.926265001297, 'accumulated_eval_time': 22727.132464647293, 'accumulated_logging_time': 1.4476747512817383}
I0306 21:13:30.185946 140019087963904 logging_writer.py:48] [7544] accumulated_eval_time=22727.1, accumulated_logging_time=1.44767, accumulated_submission_time=7492.93, global_step=7544, preemption_count=0, score=7492.93, test/loss=0.126297, test/num_examples=95000000, total_duration=30222.1, train/loss=0.123134, validation/loss=0.124015, validation/num_examples=83274637
I0306 21:14:12.895967 140019171825408 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.007025678176432848, loss=0.12943513691425323
I0306 21:15:30.772177 140171586897088 spec.py:321] Evaluating on the training split.
I0306 21:19:42.237747 140171586897088 spec.py:333] Evaluating on the validation split.
I0306 21:19:49.439836 140171586897088 spec.py:349] Evaluating on the test split.
I0306 21:19:58.190039 140171586897088 submission_runner.py:469] Time since start: 30610.11s, 	Step: 7660, 	{'train/loss': 0.12256479457770504, 'validation/loss': 0.1239104029029346, 'validation/num_examples': 83274637, 'test/loss': 0.12622660940583882, 'test/num_examples': 95000000, 'score': 7613.495776414871, 'total_duration': 30610.110697984695, 'accumulated_submission_time': 7613.495776414871, 'accumulated_eval_time': 22994.550292253494, 'accumulated_logging_time': 1.4660871028900146}
I0306 21:19:58.217048 140019087963904 logging_writer.py:48] [7660] accumulated_eval_time=22994.6, accumulated_logging_time=1.46609, accumulated_submission_time=7613.5, global_step=7660, preemption_count=0, score=7613.5, test/loss=0.126227, test/num_examples=95000000, total_duration=30610.1, train/loss=0.122565, validation/loss=0.12391, validation/num_examples=83274637
I0306 21:20:18.225155 140019171825408 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.008433387614786625, loss=0.12956534326076508
I0306 21:21:58.797525 140019087963904 logging_writer.py:48] [7779] global_step=7779, preemption_count=0, score=7734.03
I0306 21:22:00.516816 140171586897088 submission_runner.py:646] Tuning trial 3/5
I0306 21:22:00.532648 140171586897088 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.0, learning_rate=0.001308209823469072, one_minus_beta1=0.02686663061, beta2=0.9981232922116359, weight_decay=0.16375311233774334, warmup_factor=0.1)
I0306 21:22:00.533751 140171586897088 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/loss': 1.097540407060827, 'validation/loss': 1.0978230088325842, 'validation/num_examples': 83274637, 'test/loss': 1.0966317264802632, 'test/num_examples': 95000000, 'score': 12.907138109207153, 'total_duration': 1151.7641592025757, 'accumulated_submission_time': 12.907138109207153, 'accumulated_eval_time': 1138.856914281845, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (127, {'train/loss': 0.13851618068585606, 'validation/loss': 0.1406375868050448, 'validation/num_examples': 83274637, 'test/loss': 0.14420327802220395, 'test/num_examples': 95000000, 'score': 134.1579625606537, 'total_duration': 2334.6784369945526, 'accumulated_submission_time': 134.1579625606537, 'accumulated_eval_time': 2200.4967563152313, 'accumulated_logging_time': 0.0169222354888916, 'global_step': 127, 'preemption_count': 0}), (261, {'train/loss': 0.1294589923261284, 'validation/loss': 0.13039315266037274, 'validation/num_examples': 83274637, 'test/loss': 0.13289738861019737, 'test/num_examples': 95000000, 'score': 255.1340742111206, 'total_duration': 3495.484666109085, 'accumulated_submission_time': 255.1340742111206, 'accumulated_eval_time': 3240.3039350509644, 'accumulated_logging_time': 0.032485008239746094, 'global_step': 261, 'preemption_count': 0}), (392, {'train/loss': 0.1276890487064543, 'validation/loss': 0.12872954232395062, 'validation/num_examples': 83274637, 'test/loss': 0.1313001236533717, 'test/num_examples': 95000000, 'score': 375.5483627319336, 'total_duration': 4624.20357298851, 'accumulated_submission_time': 375.5483627319336, 'accumulated_eval_time': 4248.587181568146, 'accumulated_logging_time': 0.04717278480529785, 'global_step': 392, 'preemption_count': 0}), (517, {'train/loss': 0.127341563338941, 'validation/loss': 0.12764666610530753, 'validation/num_examples': 83274637, 'test/loss': 0.13020259854029606, 'test/num_examples': 95000000, 'score': 496.39841413497925, 'total_duration': 5733.816745758057, 'accumulated_submission_time': 496.39841413497925, 'accumulated_eval_time': 5237.32891869545, 'accumulated_logging_time': 0.0618133544921875, 'global_step': 517, 'preemption_count': 0}), (648, {'train/loss': 0.1256158237913682, 'validation/loss': 0.12737351410358744, 'validation/num_examples': 83274637, 'test/loss': 0.12977979270148027, 'test/num_examples': 95000000, 'score': 616.6327495574951, 'total_duration': 6831.541186094284, 'accumulated_submission_time': 616.6327495574951, 'accumulated_eval_time': 6214.797825336456, 'accumulated_logging_time': 0.07611393928527832, 'global_step': 648, 'preemption_count': 0}), (780, {'train/loss': 0.12793025807858263, 'validation/loss': 0.12712703321595162, 'validation/num_examples': 83274637, 'test/loss': 0.12950534886924342, 'test/num_examples': 95000000, 'score': 737.9544789791107, 'total_duration': 7849.023504495621, 'accumulated_submission_time': 737.9544789791107, 'accumulated_eval_time': 7110.935056447983, 'accumulated_logging_time': 0.09195971488952637, 'global_step': 780, 'preemption_count': 0}), (907, {'train/loss': 0.12725614269012175, 'validation/loss': 0.12682128021441233, 'validation/num_examples': 83274637, 'test/loss': 0.12915470270353618, 'test/num_examples': 95000000, 'score': 857.9698913097382, 'total_duration': 8802.893795490265, 'accumulated_submission_time': 857.9698913097382, 'accumulated_eval_time': 7944.742644309998, 'accumulated_logging_time': 0.1315314769744873, 'global_step': 907, 'preemption_count': 0}), (1036, {'train/loss': 0.12556548006598306, 'validation/loss': 0.12673248344135682, 'validation/num_examples': 83274637, 'test/loss': 0.12926515476973685, 'test/num_examples': 95000000, 'score': 978.7902569770813, 'total_duration': 9540.665189504623, 'accumulated_submission_time': 978.7902569770813, 'accumulated_eval_time': 8561.669858694077, 'accumulated_logging_time': 0.1463632583618164, 'global_step': 1036, 'preemption_count': 0}), (1161, {'train/loss': 0.12525815270700544, 'validation/loss': 0.12647164132306762, 'validation/num_examples': 83274637, 'test/loss': 0.12889721312705593, 'test/num_examples': 95000000, 'score': 1098.813800573349, 'total_duration': 9906.724633216858, 'accumulated_submission_time': 1098.813800573349, 'accumulated_eval_time': 8807.663614749908, 'accumulated_logging_time': 0.17838263511657715, 'global_step': 1161, 'preemption_count': 0}), (1279, {'train/loss': 0.1277191495558001, 'validation/loss': 0.12600281114268586, 'validation/num_examples': 83274637, 'test/loss': 0.12857999910567433, 'test/num_examples': 95000000, 'score': 1219.0961878299713, 'total_duration': 10281.284190893173, 'accumulated_submission_time': 1219.0961878299713, 'accumulated_eval_time': 9061.914865016937, 'accumulated_logging_time': 0.19491815567016602, 'global_step': 1279, 'preemption_count': 0}), (1402, {'train/loss': 0.124531935888735, 'validation/loss': 0.12602079874009237, 'validation/num_examples': 83274637, 'test/loss': 0.1285766939658717, 'test/num_examples': 95000000, 'score': 1339.8050951957703, 'total_duration': 10665.851326227188, 'accumulated_submission_time': 1339.8050951957703, 'accumulated_eval_time': 9325.746924161911, 'accumulated_logging_time': 0.21086740493774414, 'global_step': 1402, 'preemption_count': 0}), (1521, {'train/loss': 0.12650610488962452, 'validation/loss': 0.12592389130307016, 'validation/num_examples': 83274637, 'test/loss': 0.1285931392783717, 'test/num_examples': 95000000, 'score': 1460.3932092189789, 'total_duration': 11043.57708120346, 'accumulated_submission_time': 1460.3932092189789, 'accumulated_eval_time': 9582.859015464783, 'accumulated_logging_time': 0.22658395767211914, 'global_step': 1521, 'preemption_count': 0}), (1643, {'train/loss': 0.1264668198642116, 'validation/loss': 0.12577630934502002, 'validation/num_examples': 83274637, 'test/loss': 0.1282472634971217, 'test/num_examples': 95000000, 'score': 1582.1186738014221, 'total_duration': 11419.992284297943, 'accumulated_submission_time': 1582.1186738014221, 'accumulated_eval_time': 9837.524570941925, 'accumulated_logging_time': 0.24126195907592773, 'global_step': 1643, 'preemption_count': 0}), (1763, {'train/loss': 0.1251748736198031, 'validation/loss': 0.12604747932960067, 'validation/num_examples': 83274637, 'test/loss': 0.12835338032483554, 'test/num_examples': 95000000, 'score': 1702.1954262256622, 'total_duration': 11800.974452733994, 'accumulated_submission_time': 1702.1954262256622, 'accumulated_eval_time': 10098.404072761536, 'accumulated_logging_time': 0.2571682929992676, 'global_step': 1763, 'preemption_count': 0}), (1884, {'train/loss': 0.12552697972962693, 'validation/loss': 0.12540024771179917, 'validation/num_examples': 83274637, 'test/loss': 0.1277124625, 'test/num_examples': 95000000, 'score': 1823.9036130905151, 'total_duration': 12181.984615325928, 'accumulated_submission_time': 1823.9036130905151, 'accumulated_eval_time': 10357.668365955353, 'accumulated_logging_time': 0.284895658493042, 'global_step': 1884, 'preemption_count': 0}), (2003, {'train/loss': 0.12230905879921508, 'validation/loss': 0.12543321003252317, 'validation/num_examples': 83274637, 'test/loss': 0.12808540560238488, 'test/num_examples': 95000000, 'score': 1944.14612865448, 'total_duration': 12558.186996459961, 'accumulated_submission_time': 1944.14612865448, 'accumulated_eval_time': 10613.595893144608, 'accumulated_logging_time': 0.3076164722442627, 'global_step': 2003, 'preemption_count': 0}), (2123, {'train/loss': 0.12188759496517526, 'validation/loss': 0.1254738043323931, 'validation/num_examples': 83274637, 'test/loss': 0.12793571976768092, 'test/num_examples': 95000000, 'score': 2065.2013726234436, 'total_duration': 12926.700229167938, 'accumulated_submission_time': 2065.2013726234436, 'accumulated_eval_time': 10861.029235839844, 'accumulated_logging_time': 0.3231971263885498, 'global_step': 2123, 'preemption_count': 0}), (2241, {'train/loss': 0.12484424119616079, 'validation/loss': 0.1253042430375965, 'validation/num_examples': 83274637, 'test/loss': 0.1277837732524671, 'test/num_examples': 95000000, 'score': 2185.1594557762146, 'total_duration': 13295.710200548172, 'accumulated_submission_time': 2185.1594557762146, 'accumulated_eval_time': 11110.024245977402, 'accumulated_logging_time': 0.37087273597717285, 'global_step': 2241, 'preemption_count': 0}), (2365, {'train/loss': 0.12442438846817182, 'validation/loss': 0.1251887019739144, 'validation/num_examples': 83274637, 'test/loss': 0.12754705320723683, 'test/num_examples': 95000000, 'score': 2306.7222244739532, 'total_duration': 13670.65102648735, 'accumulated_submission_time': 2306.7222244739532, 'accumulated_eval_time': 11363.37785744667, 'accumulated_logging_time': 0.3857142925262451, 'global_step': 2365, 'preemption_count': 0}), (2485, {'train/loss': 0.12563773058354855, 'validation/loss': 0.12514344367212987, 'validation/num_examples': 83274637, 'test/loss': 0.12747621431949013, 'test/num_examples': 95000000, 'score': 2426.865609407425, 'total_duration': 14043.038362979889, 'accumulated_submission_time': 2426.865609407425, 'accumulated_eval_time': 11615.5955722332, 'accumulated_logging_time': 0.4023456573486328, 'global_step': 2485, 'preemption_count': 0}), (2607, {'train/loss': 0.12497991015373161, 'validation/loss': 0.1253459540478562, 'validation/num_examples': 83274637, 'test/loss': 0.12785124714226972, 'test/num_examples': 95000000, 'score': 2547.922434568405, 'total_duration': 14414.724973201752, 'accumulated_submission_time': 2547.922434568405, 'accumulated_eval_time': 11866.170401573181, 'accumulated_logging_time': 0.4472486972808838, 'global_step': 2607, 'preemption_count': 0}), (2725, {'train/loss': 0.12384762901976798, 'validation/loss': 0.12507764985134182, 'validation/num_examples': 83274637, 'test/loss': 0.1272886120682566, 'test/num_examples': 95000000, 'score': 2668.2090606689453, 'total_duration': 14787.44944190979, 'accumulated_submission_time': 2668.2090606689453, 'accumulated_eval_time': 12118.572682619095, 'accumulated_logging_time': 0.4730703830718994, 'global_step': 2725, 'preemption_count': 0}), (2846, {'train/loss': 0.1228913426071218, 'validation/loss': 0.12501508352651616, 'validation/num_examples': 83274637, 'test/loss': 0.1274286460731908, 'test/num_examples': 95000000, 'score': 2790.5242536067963, 'total_duration': 15163.943510770798, 'accumulated_submission_time': 2790.5242536067963, 'accumulated_eval_time': 12372.709058046341, 'accumulated_logging_time': 0.506070613861084, 'global_step': 2846, 'preemption_count': 0}), (2967, {'train/loss': 0.12334638169773345, 'validation/loss': 0.12468248893534842, 'validation/num_examples': 83274637, 'test/loss': 0.1269826997944079, 'test/num_examples': 95000000, 'score': 2911.3264710903168, 'total_duration': 15536.259451389313, 'accumulated_submission_time': 2911.3264710903168, 'accumulated_eval_time': 12624.196480989456, 'accumulated_logging_time': 0.5218620300292969, 'global_step': 2967, 'preemption_count': 0}), (3093, {'train/loss': 0.12259700678804386, 'validation/loss': 0.12472432054031538, 'validation/num_examples': 83274637, 'test/loss': 0.12710161906866776, 'test/num_examples': 95000000, 'score': 3032.66086769104, 'total_duration': 15914.318681716919, 'accumulated_submission_time': 3032.66086769104, 'accumulated_eval_time': 12880.861028432846, 'accumulated_logging_time': 0.5726561546325684, 'global_step': 3093, 'preemption_count': 0}), (3218, {'train/loss': 0.12156629114874504, 'validation/loss': 0.12507036073478697, 'validation/num_examples': 83274637, 'test/loss': 0.1275661357010691, 'test/num_examples': 95000000, 'score': 3153.846284866333, 'total_duration': 16292.192174911499, 'accumulated_submission_time': 3153.846284866333, 'accumulated_eval_time': 13137.524651765823, 'accumulated_logging_time': 0.5879127979278564, 'global_step': 3218, 'preemption_count': 0}), (3338, {'train/loss': 0.1233620924418265, 'validation/loss': 0.1247260817671742, 'validation/num_examples': 83274637, 'test/loss': 0.12715302434210526, 'test/num_examples': 95000000, 'score': 3274.8349714279175, 'total_duration': 16665.556678771973, 'accumulated_submission_time': 3274.8349714279175, 'accumulated_eval_time': 13389.87541103363, 'accumulated_logging_time': 0.603417158126831, 'global_step': 3338, 'preemption_count': 0}), (3460, {'train/loss': 0.1249553577494134, 'validation/loss': 0.12473998062527768, 'validation/num_examples': 83274637, 'test/loss': 0.1270884769120066, 'test/num_examples': 95000000, 'score': 3396.181331396103, 'total_duration': 17037.63372373581, 'accumulated_submission_time': 3396.181331396103, 'accumulated_eval_time': 13640.58147406578, 'accumulated_logging_time': 0.618859052658081, 'global_step': 3460, 'preemption_count': 0}), (3579, {'train/loss': 0.1245589183655175, 'validation/loss': 0.12477572047659076, 'validation/num_examples': 83274637, 'test/loss': 0.12719209302014803, 'test/num_examples': 95000000, 'score': 3516.137008190155, 'total_duration': 17411.162484884262, 'accumulated_submission_time': 3516.137008190155, 'accumulated_eval_time': 13894.094406366348, 'accumulated_logging_time': 0.6686785221099854, 'global_step': 3579, 'preemption_count': 0}), (3703, {'train/loss': 0.1217703198627481, 'validation/loss': 0.12474762548068057, 'validation/num_examples': 83274637, 'test/loss': 0.12701612927631578, 'test/num_examples': 95000000, 'score': 3636.3246433734894, 'total_duration': 17790.866048574448, 'accumulated_submission_time': 3636.3246433734894, 'accumulated_eval_time': 14153.576115131378, 'accumulated_logging_time': 0.6928684711456299, 'global_step': 3703, 'preemption_count': 0}), (3822, {'train/loss': 0.12120544055254205, 'validation/loss': 0.1248157940444456, 'validation/num_examples': 83274637, 'test/loss': 0.12723486376439144, 'test/num_examples': 95000000, 'score': 3756.5744433403015, 'total_duration': 18185.420456647873, 'accumulated_submission_time': 3756.5744433403015, 'accumulated_eval_time': 14427.854778289795, 'accumulated_logging_time': 0.7094213962554932, 'global_step': 3822, 'preemption_count': 0}), (3940, {'train/loss': 0.12231062851705642, 'validation/loss': 0.12492781032073502, 'validation/num_examples': 83274637, 'test/loss': 0.12732437600740132, 'test/num_examples': 95000000, 'score': 3876.5299594402313, 'total_duration': 18580.54766225815, 'accumulated_submission_time': 3876.5299594402313, 'accumulated_eval_time': 14702.979464292526, 'accumulated_logging_time': 0.7467691898345947, 'global_step': 3940, 'preemption_count': 0}), (4061, {'train/loss': 0.1225739995240228, 'validation/loss': 0.12478219755047536, 'validation/num_examples': 83274637, 'test/loss': 0.1271267916118421, 'test/num_examples': 95000000, 'score': 3997.8293240070343, 'total_duration': 18970.906445980072, 'accumulated_submission_time': 3997.8293240070343, 'accumulated_eval_time': 14972.012969255447, 'accumulated_logging_time': 0.7633392810821533, 'global_step': 4061, 'preemption_count': 0}), (4180, {'train/loss': 0.1251415659281068, 'validation/loss': 0.1247370794978668, 'validation/num_examples': 83274637, 'test/loss': 0.12714903193873356, 'test/num_examples': 95000000, 'score': 4118.3199627399445, 'total_duration': 19359.938700914383, 'accumulated_submission_time': 4118.3199627399445, 'accumulated_eval_time': 15240.527163267136, 'accumulated_logging_time': 0.7810769081115723, 'global_step': 4180, 'preemption_count': 0}), (4299, {'train/loss': 0.12395218821863334, 'validation/loss': 0.12466469647538812, 'validation/num_examples': 83274637, 'test/loss': 0.1271118644839638, 'test/num_examples': 95000000, 'score': 4238.452558994293, 'total_duration': 19744.056017637253, 'accumulated_submission_time': 4238.452558994293, 'accumulated_eval_time': 15504.443326950073, 'accumulated_logging_time': 0.8402349948883057, 'global_step': 4299, 'preemption_count': 0}), (4421, {'train/loss': 0.12300120333924233, 'validation/loss': 0.12473076456748582, 'validation/num_examples': 83274637, 'test/loss': 0.1270501, 'test/num_examples': 95000000, 'score': 4358.5543076992035, 'total_duration': 20133.13681960106, 'accumulated_submission_time': 4358.5543076992035, 'accumulated_eval_time': 15773.39713382721, 'accumulated_logging_time': 0.8555290699005127, 'global_step': 4421, 'preemption_count': 0}), (4542, {'train/loss': 0.12383575936627088, 'validation/loss': 0.12468617647604921, 'validation/num_examples': 83274637, 'test/loss': 0.12710518601973683, 'test/num_examples': 95000000, 'score': 4479.9563064575195, 'total_duration': 20521.43867468834, 'accumulated_submission_time': 4479.9563064575195, 'accumulated_eval_time': 16040.26929140091, 'accumulated_logging_time': 0.8735275268554688, 'global_step': 4542, 'preemption_count': 0}), (4663, {'train/loss': 0.12257937529364472, 'validation/loss': 0.12478880271262657, 'validation/num_examples': 83274637, 'test/loss': 0.1270858423828125, 'test/num_examples': 95000000, 'score': 4601.049095869064, 'total_duration': 20909.534068346024, 'accumulated_submission_time': 4601.049095869064, 'accumulated_eval_time': 16307.245141267776, 'accumulated_logging_time': 0.8910069465637207, 'global_step': 4663, 'preemption_count': 0}), (4784, {'train/loss': 0.1254976549238529, 'validation/loss': 0.12486772263433132, 'validation/num_examples': 83274637, 'test/loss': 0.12735609599095396, 'test/num_examples': 95000000, 'score': 4721.118688583374, 'total_duration': 21300.96338891983, 'accumulated_submission_time': 4721.118688583374, 'accumulated_eval_time': 16578.558802366257, 'accumulated_logging_time': 0.9272923469543457, 'global_step': 4784, 'preemption_count': 0}), (4907, {'train/loss': 0.12394796257967469, 'validation/loss': 0.12466837949532655, 'validation/num_examples': 83274637, 'test/loss': 0.12700366087582238, 'test/num_examples': 95000000, 'score': 4841.161161661148, 'total_duration': 21686.02130484581, 'accumulated_submission_time': 4841.161161661148, 'accumulated_eval_time': 16843.54767346382, 'accumulated_logging_time': 0.9445006847381592, 'global_step': 4907, 'preemption_count': 0}), (5029, {'train/loss': 0.12484328041099152, 'validation/loss': 0.12461495304963585, 'validation/num_examples': 83274637, 'test/loss': 0.12735960069901317, 'test/num_examples': 95000000, 'score': 4961.768985033035, 'total_duration': 22073.56462931633, 'accumulated_submission_time': 4961.768985033035, 'accumulated_eval_time': 17110.45785689354, 'accumulated_logging_time': 0.9603605270385742, 'global_step': 5029, 'preemption_count': 0}), (5153, {'train/loss': 0.12306639241675536, 'validation/loss': 0.12440256343024873, 'validation/num_examples': 83274637, 'test/loss': 0.12680705363898026, 'test/num_examples': 95000000, 'score': 5082.169224500656, 'total_duration': 22463.008970737457, 'accumulated_submission_time': 5082.169224500656, 'accumulated_eval_time': 17379.46651148796, 'accumulated_logging_time': 0.9857747554779053, 'global_step': 5153, 'preemption_count': 0}), (5273, {'train/loss': 0.12249337528018081, 'validation/loss': 0.12455678502199595, 'validation/num_examples': 83274637, 'test/loss': 0.12689530626027962, 'test/num_examples': 95000000, 'score': 5203.2736258506775, 'total_duration': 22845.98309469223, 'accumulated_submission_time': 5203.2736258506775, 'accumulated_eval_time': 17641.29449915886, 'accumulated_logging_time': 1.0182573795318604, 'global_step': 5273, 'preemption_count': 0}), (5393, {'train/loss': 0.12466076344439068, 'validation/loss': 0.12422599376937993, 'validation/num_examples': 83274637, 'test/loss': 0.12651245366981909, 'test/num_examples': 95000000, 'score': 5323.897226333618, 'total_duration': 23226.914736270905, 'accumulated_submission_time': 5323.897226333618, 'accumulated_eval_time': 17901.57721376419, 'accumulated_logging_time': 1.0341253280639648, 'global_step': 5393, 'preemption_count': 0}), (5512, {'train/loss': 0.12270390026786793, 'validation/loss': 0.1242280859617782, 'validation/num_examples': 83274637, 'test/loss': 0.12659068251439146, 'test/num_examples': 95000000, 'score': 5445.1599678993225, 'total_duration': 23616.06245279312, 'accumulated_submission_time': 5445.1599678993225, 'accumulated_eval_time': 18169.435449123383, 'accumulated_logging_time': 1.0515897274017334, 'global_step': 5512, 'preemption_count': 0}), (5633, {'train/loss': 0.12169308894835178, 'validation/loss': 0.12460264759315125, 'validation/num_examples': 83274637, 'test/loss': 0.12703433987458881, 'test/num_examples': 95000000, 'score': 5565.751047611237, 'total_duration': 24002.53719806671, 'accumulated_submission_time': 5565.751047611237, 'accumulated_eval_time': 18435.275528907776, 'accumulated_logging_time': 1.0850191116333008, 'global_step': 5633, 'preemption_count': 0}), (5753, {'train/loss': 0.123904851271109, 'validation/loss': 0.12440839716036528, 'validation/num_examples': 83274637, 'test/loss': 0.12686846106085525, 'test/num_examples': 95000000, 'score': 5686.826882123947, 'total_duration': 24387.984611034393, 'accumulated_submission_time': 5686.826882123947, 'accumulated_eval_time': 18699.621121406555, 'accumulated_logging_time': 1.1016483306884766, 'global_step': 5753, 'preemption_count': 0}), (5873, {'train/loss': 0.12059460886103927, 'validation/loss': 0.12431196120191622, 'validation/num_examples': 83274637, 'test/loss': 0.12671084272203947, 'test/num_examples': 95000000, 'score': 5807.069628953934, 'total_duration': 24771.121168375015, 'accumulated_submission_time': 5807.069628953934, 'accumulated_eval_time': 18962.48823738098, 'accumulated_logging_time': 1.1190123558044434, 'global_step': 5873, 'preemption_count': 0}), (5992, {'train/loss': 0.12287216702675295, 'validation/loss': 0.12444130787638183, 'validation/num_examples': 83274637, 'test/loss': 0.1269075531455592, 'test/num_examples': 95000000, 'score': 5927.491410970688, 'total_duration': 25162.12011241913, 'accumulated_submission_time': 5927.491410970688, 'accumulated_eval_time': 19233.03820514679, 'accumulated_logging_time': 1.136143445968628, 'global_step': 5992, 'preemption_count': 0}), (6107, {'train/loss': 0.1216156375389429, 'validation/loss': 0.12433620024553514, 'validation/num_examples': 83274637, 'test/loss': 0.1267765425986842, 'test/num_examples': 95000000, 'score': 6047.58939909935, 'total_duration': 25545.332653284073, 'accumulated_submission_time': 6047.58939909935, 'accumulated_eval_time': 19496.10919237137, 'accumulated_logging_time': 1.170776128768921, 'global_step': 6107, 'preemption_count': 0}), (6228, {'train/loss': 0.12339324075377213, 'validation/loss': 0.12427524328278894, 'validation/num_examples': 83274637, 'test/loss': 0.12654429330797698, 'test/num_examples': 95000000, 'score': 6168.69278049469, 'total_duration': 25940.805236577988, 'accumulated_submission_time': 6168.69278049469, 'accumulated_eval_time': 19770.43045067787, 'accumulated_logging_time': 1.200709342956543, 'global_step': 6228, 'preemption_count': 0}), (6348, {'train/loss': 0.12219167489019579, 'validation/loss': 0.12438986587532161, 'validation/num_examples': 83274637, 'test/loss': 0.12669156044407895, 'test/num_examples': 95000000, 'score': 6289.490707159042, 'total_duration': 26326.600895404816, 'accumulated_submission_time': 6289.490707159042, 'accumulated_eval_time': 20035.401827573776, 'accumulated_logging_time': 1.2173614501953125, 'global_step': 6348, 'preemption_count': 0}), (6466, {'train/loss': 0.12346401236623337, 'validation/loss': 0.12427912674078213, 'validation/num_examples': 83274637, 'test/loss': 0.12670367321134868, 'test/num_examples': 95000000, 'score': 6409.896944761276, 'total_duration': 26719.19340777397, 'accumulated_submission_time': 6409.896944761276, 'accumulated_eval_time': 20307.538204669952, 'accumulated_logging_time': 1.2569687366485596, 'global_step': 6466, 'preemption_count': 0}), (6587, {'train/loss': 0.12202850115374199, 'validation/loss': 0.12397880359113536, 'validation/num_examples': 83274637, 'test/loss': 0.1262945986225329, 'test/num_examples': 95000000, 'score': 6529.92381477356, 'total_duration': 27113.473199367523, 'accumulated_submission_time': 6529.92381477356, 'accumulated_eval_time': 20581.761965990067, 'accumulated_logging_time': 1.2757446765899658, 'global_step': 6587, 'preemption_count': 0}), (6708, {'train/loss': 0.12209938316600127, 'validation/loss': 0.12402709709523599, 'validation/num_examples': 83274637, 'test/loss': 0.12645075347450657, 'test/num_examples': 95000000, 'score': 6650.1604771614075, 'total_duration': 27505.387426137924, 'accumulated_submission_time': 6650.1604771614075, 'accumulated_eval_time': 20853.411732912064, 'accumulated_logging_time': 1.293532371520996, 'global_step': 6708, 'preemption_count': 0}), (6828, {'train/loss': 0.1227060299624437, 'validation/loss': 0.12401109288702904, 'validation/num_examples': 83274637, 'test/loss': 0.12638994853001645, 'test/num_examples': 95000000, 'score': 6770.291089057922, 'total_duration': 27885.048901081085, 'accumulated_submission_time': 6770.291089057922, 'accumulated_eval_time': 21112.914993286133, 'accumulated_logging_time': 1.3112225532531738, 'global_step': 6828, 'preemption_count': 0}), (6951, {'train/loss': 0.12068564930942448, 'validation/loss': 0.12405960022729332, 'validation/num_examples': 83274637, 'test/loss': 0.1264138845703125, 'test/num_examples': 95000000, 'score': 6890.353255987167, 'total_duration': 28272.10425400734, 'accumulated_submission_time': 6890.353255987167, 'accumulated_eval_time': 21379.866821050644, 'accumulated_logging_time': 1.3433582782745361, 'global_step': 6951, 'preemption_count': 0}), (7072, {'train/loss': 0.12185720025134161, 'validation/loss': 0.123973406193743, 'validation/num_examples': 83274637, 'test/loss': 0.12632695460526316, 'test/num_examples': 95000000, 'score': 7011.454977989197, 'total_duration': 28660.63714313507, 'accumulated_submission_time': 7011.454977989197, 'accumulated_eval_time': 21647.271420955658, 'accumulated_logging_time': 1.360609531402588, 'global_step': 7072, 'preemption_count': 0}), (7190, {'train/loss': 0.12367577576693499, 'validation/loss': 0.12410696539782913, 'validation/num_examples': 83274637, 'test/loss': 0.1264183210834704, 'test/num_examples': 95000000, 'score': 7131.4991846084595, 'total_duration': 29055.911410808563, 'accumulated_submission_time': 7131.4991846084595, 'accumulated_eval_time': 21922.475452184677, 'accumulated_logging_time': 1.3776171207427979, 'global_step': 7190, 'preemption_count': 0}), (7307, {'train/loss': 0.12122896647537654, 'validation/loss': 0.12396937756122964, 'validation/num_examples': 83274637, 'test/loss': 0.1262845745682566, 'test/num_examples': 95000000, 'score': 7251.62829875946, 'total_duration': 29443.613761901855, 'accumulated_submission_time': 7251.62829875946, 'accumulated_eval_time': 22190.02196574211, 'accumulated_logging_time': 1.394381046295166, 'global_step': 7307, 'preemption_count': 0}), (7425, {'train/loss': 0.12387934993694788, 'validation/loss': 0.12408543504725064, 'validation/num_examples': 83274637, 'test/loss': 0.12641437200863487, 'test/num_examples': 95000000, 'score': 7372.382732391357, 'total_duration': 29837.109925746918, 'accumulated_submission_time': 7372.382732391357, 'accumulated_eval_time': 22462.717671871185, 'accumulated_logging_time': 1.4302856922149658, 'global_step': 7425, 'preemption_count': 0}), (7544, {'train/loss': 0.12313362307049944, 'validation/loss': 0.12401531731370119, 'validation/num_examples': 83274637, 'test/loss': 0.1262967347964638, 'test/num_examples': 95000000, 'score': 7492.926265001297, 'total_duration': 30222.09490418434, 'accumulated_submission_time': 7492.926265001297, 'accumulated_eval_time': 22727.132464647293, 'accumulated_logging_time': 1.4476747512817383, 'global_step': 7544, 'preemption_count': 0}), (7660, {'train/loss': 0.12256479457770504, 'validation/loss': 0.1239104029029346, 'validation/num_examples': 83274637, 'test/loss': 0.12622660940583882, 'test/num_examples': 95000000, 'score': 7613.495776414871, 'total_duration': 30610.110697984695, 'accumulated_submission_time': 7613.495776414871, 'accumulated_eval_time': 22994.550292253494, 'accumulated_logging_time': 1.4660871028900146, 'global_step': 7660, 'preemption_count': 0})], 'global_step': 7779}
I0306 21:22:00.533899 140171586897088 submission_runner.py:649] Timing: 7734.025271177292
I0306 21:22:00.533944 140171586897088 submission_runner.py:651] Total number of evals: 64
I0306 21:22:00.533978 140171586897088 submission_runner.py:652] ====================
I0306 21:22:00.534153 140171586897088 submission_runner.py:750] Final criteo1tb score: 2
