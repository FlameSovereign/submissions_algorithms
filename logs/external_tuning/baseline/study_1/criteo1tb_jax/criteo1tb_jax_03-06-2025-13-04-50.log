python submission_runner.py --framework=jax --workload=criteo1tb --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_1 --overwrite=True --save_checkpoints=False --rng_seed=-983464499 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=1 --hparam_end_index=2 2>&1 | tee -a /logs/criteo1tb_jax_03-06-2025-13-04-50.log
2025-03-06 13:05:07.775613: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741266308.336939       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741266308.610311       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0306 13:05:55.141885 140651857294528 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax.
I0306 13:05:58.206302 140651857294528 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0306 13:05:58.209259 140651857294528 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0306 13:05:58.251952 140651857294528 submission_runner.py:606] Using RNG seed -983464499
I0306 13:06:01.644281 140651857294528 submission_runner.py:615] --- Tuning run 2/5 ---
I0306 13:06:01.644464 140651857294528 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_2.
I0306 13:06:01.644649 140651857294528 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_2/hparams.json.
I0306 13:06:01.877965 140651857294528 submission_runner.py:218] Initializing dataset.
I0306 13:06:01.878144 140651857294528 submission_runner.py:229] Initializing model.
I0306 13:06:11.684697 140651857294528 submission_runner.py:272] Initializing optimizer.
I0306 13:06:12.387459 140651857294528 submission_runner.py:279] Initializing metrics bundle.
I0306 13:06:12.387696 140651857294528 submission_runner.py:301] Initializing checkpoint and logger.
I0306 13:06:12.388400 140651857294528 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_2 with prefix checkpoint_
I0306 13:06:12.388511 140651857294528 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_2/meta_data_0.json.
I0306 13:06:12.388668 140651857294528 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0306 13:06:12.388714 140651857294528 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0306 13:06:12.942183 140651857294528 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_2/flags_0.json.
I0306 13:06:13.562050 140651857294528 submission_runner.py:337] Starting training loop.
I0306 13:06:30.631276 140510282884864 logging_writer.py:48] [0] global_step=0, grad_norm=8.132284164428711, loss=0.8488404750823975
I0306 13:06:31.072738 140651857294528 spec.py:321] Evaluating on the training split.
I0306 13:12:55.737629 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 13:18:59.329639 140651857294528 spec.py:349] Evaluating on the test split.
I0306 13:26:11.669870 140651857294528 submission_runner.py:469] Time since start: 1198.11s, 	Step: 1, 	{'train/loss': 0.8468768641633807, 'validation/loss': 0.8396444041051478, 'validation/num_examples': 83274637, 'test/loss': 0.8447341442434211, 'test/num_examples': 95000000, 'score': 17.51051688194275, 'total_duration': 1198.1077556610107, 'accumulated_submission_time': 17.51051688194275, 'accumulated_eval_time': 1180.5970673561096, 'accumulated_logging_time': 0}
I0306 13:26:11.751653 140498421401344 logging_writer.py:48] [1] accumulated_eval_time=1180.6, accumulated_logging_time=0, accumulated_submission_time=17.5105, global_step=1, preemption_count=0, score=17.5105, test/loss=0.844734, test/num_examples=95000000, total_duration=1198.11, train/loss=0.846877, validation/loss=0.839644, validation/num_examples=83274637
I0306 13:27:42.221258 140498413008640 logging_writer.py:48] [100] global_step=100, grad_norm=0.10898148268461227, loss=0.1346130222082138
I0306 13:28:12.565298 140651857294528 spec.py:321] Evaluating on the training split.
I0306 13:34:07.105203 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 13:39:32.618467 140651857294528 spec.py:349] Evaluating on the test split.
I0306 13:45:16.964789 140651857294528 submission_runner.py:469] Time since start: 2343.40s, 	Step: 124, 	{'train/loss': 0.13165923094365206, 'validation/loss': 0.13287403623013166, 'validation/num_examples': 83274637, 'test/loss': 0.1361750539165296, 'test/num_examples': 95000000, 'score': 138.28577494621277, 'total_duration': 2343.402681827545, 'accumulated_submission_time': 138.28577494621277, 'accumulated_eval_time': 2204.996488571167, 'accumulated_logging_time': 0.11409664154052734}
I0306 13:45:16.975084 140498421401344 logging_writer.py:48] [124] accumulated_eval_time=2205, accumulated_logging_time=0.114097, accumulated_submission_time=138.286, global_step=124, preemption_count=0, score=138.286, test/loss=0.136175, test/num_examples=95000000, total_duration=2343.4, train/loss=0.131659, validation/loss=0.132874, validation/num_examples=83274637
I0306 13:46:25.825365 140498413008640 logging_writer.py:48] [200] global_step=200, grad_norm=0.2502041459083557, loss=0.13144874572753906
I0306 13:47:17.647815 140651857294528 spec.py:321] Evaluating on the training split.
I0306 13:53:19.840100 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 13:58:47.428883 140651857294528 spec.py:349] Evaluating on the test split.
I0306 14:04:39.929019 140651857294528 submission_runner.py:469] Time since start: 3506.37s, 	Step: 242, 	{'train/loss': 0.13078994080190015, 'validation/loss': 0.13014530611551556, 'validation/num_examples': 83274637, 'test/loss': 0.13300973092105264, 'test/num_examples': 95000000, 'score': 258.94517993927, 'total_duration': 3506.366910457611, 'accumulated_submission_time': 258.94517993927, 'accumulated_eval_time': 3247.277646303177, 'accumulated_logging_time': 0.131760835647583}
I0306 14:04:39.938715 140498421401344 logging_writer.py:48] [242] accumulated_eval_time=3247.28, accumulated_logging_time=0.131761, accumulated_submission_time=258.945, global_step=242, preemption_count=0, score=258.945, test/loss=0.13301, test/num_examples=95000000, total_duration=3506.37, train/loss=0.13079, validation/loss=0.130145, validation/num_examples=83274637
I0306 14:05:21.606681 140498413008640 logging_writer.py:48] [300] global_step=300, grad_norm=0.13152863085269928, loss=0.13068044185638428
I0306 14:06:40.012907 140651857294528 spec.py:321] Evaluating on the training split.
I0306 14:12:37.001072 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 14:18:06.724729 140651857294528 spec.py:349] Evaluating on the test split.
I0306 14:24:42.822227 140651857294528 submission_runner.py:469] Time since start: 4709.26s, 	Step: 366, 	{'train/loss': 0.1292647971250351, 'validation/loss': 0.1285554359215302, 'validation/num_examples': 83274637, 'test/loss': 0.13098443510485197, 'test/num_examples': 95000000, 'score': 378.9810049533844, 'total_duration': 4709.2601227760315, 'accumulated_submission_time': 378.9810049533844, 'accumulated_eval_time': 4330.086905956268, 'accumulated_logging_time': 0.17319011688232422}
I0306 14:24:42.831540 140498421401344 logging_writer.py:48] [366] accumulated_eval_time=4330.09, accumulated_logging_time=0.17319, accumulated_submission_time=378.981, global_step=366, preemption_count=0, score=378.981, test/loss=0.130984, test/num_examples=95000000, total_duration=4709.26, train/loss=0.129265, validation/loss=0.128555, validation/num_examples=83274637
I0306 14:24:54.711858 140498413008640 logging_writer.py:48] [400] global_step=400, grad_norm=0.07717198133468628, loss=0.12212655693292618
I0306 14:26:43.120216 140651857294528 spec.py:321] Evaluating on the training split.
I0306 14:32:18.461306 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 14:37:25.057144 140651857294528 spec.py:349] Evaluating on the test split.
I0306 14:43:12.209628 140651857294528 submission_runner.py:469] Time since start: 5818.65s, 	Step: 489, 	{'train/loss': 0.1278986215661719, 'validation/loss': 0.12790689983218195, 'validation/num_examples': 83274637, 'test/loss': 0.13022834760485197, 'test/num_examples': 95000000, 'score': 499.2554967403412, 'total_duration': 5818.647523880005, 'accumulated_submission_time': 499.2554967403412, 'accumulated_eval_time': 5319.176256895065, 'accumulated_logging_time': 0.1897106170654297}
I0306 14:43:12.218329 140498421401344 logging_writer.py:48] [489] accumulated_eval_time=5319.18, accumulated_logging_time=0.189711, accumulated_submission_time=499.255, global_step=489, preemption_count=0, score=499.255, test/loss=0.130228, test/num_examples=95000000, total_duration=5818.65, train/loss=0.127899, validation/loss=0.127907, validation/num_examples=83274637
I0306 14:43:13.508538 140498413008640 logging_writer.py:48] [500] global_step=500, grad_norm=0.038140442222356796, loss=0.1258316934108734
I0306 14:45:01.256938 140498421401344 logging_writer.py:48] [600] global_step=600, grad_norm=0.010437401942908764, loss=0.1330939084291458
I0306 14:45:12.645382 140651857294528 spec.py:321] Evaluating on the training split.
I0306 14:50:44.979656 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 14:55:54.847229 140651857294528 spec.py:349] Evaluating on the test split.
I0306 15:02:13.326354 140651857294528 submission_runner.py:469] Time since start: 6959.76s, 	Step: 611, 	{'train/loss': 0.12756432148879804, 'validation/loss': 0.1273053841392758, 'validation/num_examples': 83274637, 'test/loss': 0.1294932509765625, 'test/num_examples': 95000000, 'score': 619.6694910526276, 'total_duration': 6959.764257669449, 'accumulated_submission_time': 619.6694910526276, 'accumulated_eval_time': 6339.8571672439575, 'accumulated_logging_time': 0.20522022247314453}
I0306 15:02:13.335523 140498413008640 logging_writer.py:48] [611] accumulated_eval_time=6339.86, accumulated_logging_time=0.20522, accumulated_submission_time=619.669, global_step=611, preemption_count=0, score=619.669, test/loss=0.129493, test/num_examples=95000000, total_duration=6959.76, train/loss=0.127564, validation/loss=0.127305, validation/num_examples=83274637
I0306 15:03:36.909965 140498421401344 logging_writer.py:48] [700] global_step=700, grad_norm=0.014379969798028469, loss=0.1268027275800705
I0306 15:04:13.756981 140651857294528 spec.py:321] Evaluating on the training split.
I0306 15:09:39.912686 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 15:14:28.018344 140651857294528 spec.py:349] Evaluating on the test split.
I0306 15:20:27.773512 140651857294528 submission_runner.py:469] Time since start: 8054.21s, 	Step: 733, 	{'train/loss': 0.12411739952487391, 'validation/loss': 0.12661876283179752, 'validation/num_examples': 83274637, 'test/loss': 0.1288775078125, 'test/num_examples': 95000000, 'score': 740.0739302635193, 'total_duration': 8054.211392402649, 'accumulated_submission_time': 740.0739302635193, 'accumulated_eval_time': 7313.873615264893, 'accumulated_logging_time': 0.2211766242980957}
I0306 15:20:27.782064 140498413008640 logging_writer.py:48] [733] accumulated_eval_time=7313.87, accumulated_logging_time=0.221177, accumulated_submission_time=740.074, global_step=733, preemption_count=0, score=740.074, test/loss=0.128878, test/num_examples=95000000, total_duration=8054.21, train/loss=0.124117, validation/loss=0.126619, validation/num_examples=83274637
I0306 15:21:18.542570 140498421401344 logging_writer.py:48] [800] global_step=800, grad_norm=0.08557510375976562, loss=0.12633439898490906
I0306 15:22:27.870903 140651857294528 spec.py:321] Evaluating on the training split.
I0306 15:27:20.643677 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 15:31:30.751049 140651857294528 spec.py:349] Evaluating on the test split.
I0306 15:37:12.820413 140651857294528 submission_runner.py:469] Time since start: 9059.26s, 	Step: 856, 	{'train/loss': 0.12427519876861347, 'validation/loss': 0.1265790096106746, 'validation/num_examples': 83274637, 'test/loss': 0.1289225959189967, 'test/num_examples': 95000000, 'score': 860.1493990421295, 'total_duration': 9059.25832104683, 'accumulated_submission_time': 860.1493990421295, 'accumulated_eval_time': 8198.823070526123, 'accumulated_logging_time': 0.23624038696289062}
I0306 15:37:12.828605 140498413008640 logging_writer.py:48] [856] accumulated_eval_time=8198.82, accumulated_logging_time=0.23624, accumulated_submission_time=860.149, global_step=856, preemption_count=0, score=860.149, test/loss=0.128923, test/num_examples=95000000, total_duration=9059.26, train/loss=0.124275, validation/loss=0.126579, validation/num_examples=83274637
I0306 15:37:35.790388 140498421401344 logging_writer.py:48] [900] global_step=900, grad_norm=0.0072257942520082, loss=0.1180480420589447
I0306 15:39:13.419644 140651857294528 spec.py:321] Evaluating on the training split.
I0306 15:42:36.732607 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 15:45:49.416678 140651857294528 spec.py:349] Evaluating on the test split.
I0306 15:51:47.531814 140651857294528 submission_runner.py:469] Time since start: 9933.97s, 	Step: 980, 	{'train/loss': 0.12491215023932592, 'validation/loss': 0.12656091942538467, 'validation/num_examples': 83274637, 'test/loss': 0.12903860786389804, 'test/num_examples': 95000000, 'score': 980.7276062965393, 'total_duration': 9933.969725370407, 'accumulated_submission_time': 980.7276062965393, 'accumulated_eval_time': 8952.935188055038, 'accumulated_logging_time': 0.2505645751953125}
I0306 15:51:47.539770 140498413008640 logging_writer.py:48] [980] accumulated_eval_time=8952.94, accumulated_logging_time=0.250565, accumulated_submission_time=980.728, global_step=980, preemption_count=0, score=980.728, test/loss=0.129039, test/num_examples=95000000, total_duration=9933.97, train/loss=0.124912, validation/loss=0.126561, validation/num_examples=83274637
I0306 15:51:49.771622 140498421401344 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.008217294700443745, loss=0.12628236413002014
I0306 15:53:41.249940 140498413008640 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.019320737570524216, loss=0.12437164783477783
I0306 15:53:48.684248 140651857294528 spec.py:321] Evaluating on the training split.
I0306 15:54:46.359190 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 15:57:58.838557 140651857294528 spec.py:349] Evaluating on the test split.
I0306 16:03:35.014711 140651857294528 submission_runner.py:469] Time since start: 10641.45s, 	Step: 1107, 	{'train/loss': 0.12233184648197402, 'validation/loss': 0.1262564442457619, 'validation/num_examples': 83274637, 'test/loss': 0.1284572827919408, 'test/num_examples': 95000000, 'score': 1101.8586184978485, 'total_duration': 10641.452624082565, 'accumulated_submission_time': 1101.8586184978485, 'accumulated_eval_time': 9539.265597343445, 'accumulated_logging_time': 0.26516008377075195}
I0306 16:03:35.023152 140498421401344 logging_writer.py:48] [1107] accumulated_eval_time=9539.27, accumulated_logging_time=0.26516, accumulated_submission_time=1101.86, global_step=1107, preemption_count=0, score=1101.86, test/loss=0.128457, test/num_examples=95000000, total_duration=10641.5, train/loss=0.122332, validation/loss=0.126256, validation/num_examples=83274637
I0306 16:04:53.395769 140498413008640 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.03654659911990166, loss=0.12793001532554626
I0306 16:05:35.892474 140651857294528 spec.py:321] Evaluating on the training split.
I0306 16:06:34.365841 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 16:09:45.209862 140651857294528 spec.py:349] Evaluating on the test split.
I0306 16:15:24.500216 140651857294528 submission_runner.py:469] Time since start: 11350.94s, 	Step: 1238, 	{'train/loss': 0.12496927833922629, 'validation/loss': 0.12598165055645935, 'validation/num_examples': 83274637, 'test/loss': 0.12829339068667764, 'test/num_examples': 95000000, 'score': 1222.7141873836517, 'total_duration': 11350.938090801239, 'accumulated_submission_time': 1222.7141873836517, 'accumulated_eval_time': 10127.873252391815, 'accumulated_logging_time': 0.28087806701660156}
I0306 16:15:24.509512 140498421401344 logging_writer.py:48] [1238] accumulated_eval_time=10127.9, accumulated_logging_time=0.280878, accumulated_submission_time=1222.71, global_step=1238, preemption_count=0, score=1222.71, test/loss=0.128293, test/num_examples=95000000, total_duration=11350.9, train/loss=0.124969, validation/loss=0.125982, validation/num_examples=83274637
I0306 16:16:06.501582 140498413008640 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.012279108166694641, loss=0.12185302376747131
I0306 16:17:26.037502 140651857294528 spec.py:321] Evaluating on the training split.
I0306 16:18:17.506850 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 16:21:26.046888 140651857294528 spec.py:349] Evaluating on the test split.
I0306 16:27:04.187929 140651857294528 submission_runner.py:469] Time since start: 12050.63s, 	Step: 1367, 	{'train/loss': 0.12573112720775903, 'validation/loss': 0.12666109016679428, 'validation/num_examples': 83274637, 'test/loss': 0.12908541226356907, 'test/num_examples': 95000000, 'score': 1344.2285900115967, 'total_duration': 12050.625841617584, 'accumulated_submission_time': 1344.2285900115967, 'accumulated_eval_time': 10706.02362704277, 'accumulated_logging_time': 0.2967653274536133}
I0306 16:27:04.195873 140498421401344 logging_writer.py:48] [1367] accumulated_eval_time=10706, accumulated_logging_time=0.296765, accumulated_submission_time=1344.23, global_step=1367, preemption_count=0, score=1344.23, test/loss=0.129085, test/num_examples=95000000, total_duration=12050.6, train/loss=0.125731, validation/loss=0.126661, validation/num_examples=83274637
I0306 16:27:14.537339 140498413008640 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.0654807835817337, loss=0.12240064144134521
I0306 16:29:04.843721 140651857294528 spec.py:321] Evaluating on the training split.
I0306 16:30:01.800359 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 16:33:13.461654 140651857294528 spec.py:349] Evaluating on the test split.
I0306 16:38:50.123108 140651857294528 submission_runner.py:469] Time since start: 12756.56s, 	Step: 1492, 	{'train/loss': 0.12507833654072675, 'validation/loss': 0.12683979877565016, 'validation/num_examples': 83274637, 'test/loss': 0.12954369391447368, 'test/num_examples': 95000000, 'score': 1464.8628129959106, 'total_duration': 12756.56100654602, 'accumulated_submission_time': 1464.8628129959106, 'accumulated_eval_time': 11291.302953243256, 'accumulated_logging_time': 0.31174278259277344}
I0306 16:38:50.131316 140498421401344 logging_writer.py:48] [1492] accumulated_eval_time=11291.3, accumulated_logging_time=0.311743, accumulated_submission_time=1464.86, global_step=1492, preemption_count=0, score=1464.86, test/loss=0.129544, test/num_examples=95000000, total_duration=12756.6, train/loss=0.125078, validation/loss=0.12684, validation/num_examples=83274637
I0306 16:38:51.080439 140498413008640 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.020040297880768776, loss=0.12841108441352844
I0306 16:40:32.175665 140498421401344 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.01563466526567936, loss=0.11964859813451767
I0306 16:40:50.382287 140651857294528 spec.py:321] Evaluating on the training split.
I0306 16:41:46.112028 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 16:44:58.551848 140651857294528 spec.py:349] Evaluating on the test split.
I0306 16:50:25.284720 140651857294528 submission_runner.py:469] Time since start: 13451.72s, 	Step: 1618, 	{'train/loss': 0.1241400532143296, 'validation/loss': 0.12558066604834953, 'validation/num_examples': 83274637, 'test/loss': 0.12804377916324014, 'test/num_examples': 95000000, 'score': 1585.1013505458832, 'total_duration': 13451.722628116608, 'accumulated_submission_time': 1585.1013505458832, 'accumulated_eval_time': 11866.205326795578, 'accumulated_logging_time': 0.32619214057922363}
I0306 16:50:25.294289 140498413008640 logging_writer.py:48] [1618] accumulated_eval_time=11866.2, accumulated_logging_time=0.326192, accumulated_submission_time=1585.1, global_step=1618, preemption_count=0, score=1585.1, test/loss=0.128044, test/num_examples=95000000, total_duration=13451.7, train/loss=0.12414, validation/loss=0.125581, validation/num_examples=83274637
I0306 16:51:33.063865 140498421401344 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.010409144684672356, loss=0.12166991829872131
I0306 16:52:25.816781 140651857294528 spec.py:321] Evaluating on the training split.
I0306 16:53:22.067358 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 16:56:32.976679 140651857294528 spec.py:349] Evaluating on the test split.
I0306 17:02:24.958921 140651857294528 submission_runner.py:469] Time since start: 14171.40s, 	Step: 1753, 	{'train/loss': 0.12363109089809018, 'validation/loss': 0.12557747522274737, 'validation/num_examples': 83274637, 'test/loss': 0.12796457404399672, 'test/num_examples': 95000000, 'score': 1705.6104550361633, 'total_duration': 14171.39682841301, 'accumulated_submission_time': 1705.6104550361633, 'accumulated_eval_time': 12465.34740614891, 'accumulated_logging_time': 0.3426346778869629}
I0306 17:02:24.967404 140498413008640 logging_writer.py:48] [1753] accumulated_eval_time=12465.3, accumulated_logging_time=0.342635, accumulated_submission_time=1705.61, global_step=1753, preemption_count=0, score=1705.61, test/loss=0.127965, test/num_examples=95000000, total_duration=14171.4, train/loss=0.123631, validation/loss=0.125577, validation/num_examples=83274637
I0306 17:02:51.289001 140498421401344 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.007633838336914778, loss=0.12151120603084564
I0306 17:04:26.046063 140651857294528 spec.py:321] Evaluating on the training split.
I0306 17:05:17.995672 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 17:08:32.946321 140651857294528 spec.py:349] Evaluating on the test split.
I0306 17:14:20.320200 140651857294528 submission_runner.py:469] Time since start: 14886.76s, 	Step: 1883, 	{'train/loss': 0.1239848710338837, 'validation/loss': 0.1256544372028642, 'validation/num_examples': 83274637, 'test/loss': 0.12813866979851973, 'test/num_examples': 95000000, 'score': 1826.676770210266, 'total_duration': 14886.758071899414, 'accumulated_submission_time': 1826.676770210266, 'accumulated_eval_time': 13059.621452093124, 'accumulated_logging_time': 0.3574647903442383}
I0306 17:14:20.328871 140498413008640 logging_writer.py:48] [1883] accumulated_eval_time=13059.6, accumulated_logging_time=0.357465, accumulated_submission_time=1826.68, global_step=1883, preemption_count=0, score=1826.68, test/loss=0.128139, test/num_examples=95000000, total_duration=14886.8, train/loss=0.123985, validation/loss=0.125654, validation/num_examples=83274637
I0306 17:14:22.222111 140498421401344 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.018925292417407036, loss=0.11808694154024124
I0306 17:16:08.423625 140498413008640 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.008328286930918694, loss=0.12250293046236038
I0306 17:16:21.238415 140651857294528 spec.py:321] Evaluating on the training split.
I0306 17:17:17.461565 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 17:20:25.158151 140651857294528 spec.py:349] Evaluating on the test split.
I0306 17:26:19.920235 140651857294528 submission_runner.py:469] Time since start: 15606.36s, 	Step: 2011, 	{'train/loss': 0.12495644775998292, 'validation/loss': 0.12576343708696158, 'validation/num_examples': 83274637, 'test/loss': 0.12811256052631578, 'test/num_examples': 95000000, 'score': 1947.5722000598907, 'total_duration': 15606.35813832283, 'accumulated_submission_time': 1947.5722000598907, 'accumulated_eval_time': 13658.303216457367, 'accumulated_logging_time': 0.37312936782836914}
I0306 17:26:19.929451 140498421401344 logging_writer.py:48] [2011] accumulated_eval_time=13658.3, accumulated_logging_time=0.373129, accumulated_submission_time=1947.57, global_step=2011, preemption_count=0, score=1947.57, test/loss=0.128113, test/num_examples=95000000, total_duration=15606.4, train/loss=0.124956, validation/loss=0.125763, validation/num_examples=83274637
I0306 17:27:37.029945 140498413008640 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.07587393373250961, loss=0.12243712693452835
I0306 17:28:20.410714 140651857294528 spec.py:321] Evaluating on the training split.
I0306 17:29:19.085485 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 17:32:16.703015 140651857294528 spec.py:349] Evaluating on the test split.
I0306 17:37:53.460192 140651857294528 submission_runner.py:469] Time since start: 16299.90s, 	Step: 2136, 	{'train/loss': 0.1216379342799854, 'validation/loss': 0.12542165951403367, 'validation/num_examples': 83274637, 'test/loss': 0.12778497641858552, 'test/num_examples': 95000000, 'score': 2068.0396132469177, 'total_duration': 16299.89810681343, 'accumulated_submission_time': 2068.0396132469177, 'accumulated_eval_time': 14231.352643728256, 'accumulated_logging_time': 0.38913941383361816}
I0306 17:37:53.468774 140498421401344 logging_writer.py:48] [2136] accumulated_eval_time=14231.4, accumulated_logging_time=0.389139, accumulated_submission_time=2068.04, global_step=2136, preemption_count=0, score=2068.04, test/loss=0.127785, test/num_examples=95000000, total_duration=16299.9, train/loss=0.121638, validation/loss=0.125422, validation/num_examples=83274637
I0306 17:38:42.371482 140498413008640 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.058614324778318405, loss=0.13012930750846863
I0306 17:39:54.281859 140651857294528 spec.py:321] Evaluating on the training split.
I0306 17:40:52.542985 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 17:43:52.465935 140651857294528 spec.py:349] Evaluating on the test split.
I0306 17:49:35.979429 140651857294528 submission_runner.py:469] Time since start: 17002.42s, 	Step: 2257, 	{'train/loss': 0.12376725453438249, 'validation/loss': 0.1253308979156354, 'validation/num_examples': 83274637, 'test/loss': 0.12776037979029606, 'test/num_examples': 95000000, 'score': 2188.8399634361267, 'total_duration': 17002.417342424393, 'accumulated_submission_time': 2188.8399634361267, 'accumulated_eval_time': 14813.050162553787, 'accumulated_logging_time': 0.40425777435302734}
I0306 17:49:35.988248 140498421401344 logging_writer.py:48] [2257] accumulated_eval_time=14813.1, accumulated_logging_time=0.404258, accumulated_submission_time=2188.84, global_step=2257, preemption_count=0, score=2188.84, test/loss=0.12776, test/num_examples=95000000, total_duration=17002.4, train/loss=0.123767, validation/loss=0.125331, validation/num_examples=83274637
I0306 17:49:58.270766 140498413008640 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.04870519042015076, loss=0.12088225036859512
I0306 17:51:36.295304 140651857294528 spec.py:321] Evaluating on the training split.
I0306 17:52:35.192214 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 17:55:36.098008 140651857294528 spec.py:349] Evaluating on the test split.
I0306 18:01:14.800604 140651857294528 submission_runner.py:469] Time since start: 17701.24s, 	Step: 2381, 	{'train/loss': 0.12348817355649651, 'validation/loss': 0.12538711490889626, 'validation/num_examples': 83274637, 'test/loss': 0.1278966222861842, 'test/num_examples': 95000000, 'score': 2309.1336331367493, 'total_duration': 17701.238498210907, 'accumulated_submission_time': 2309.1336331367493, 'accumulated_eval_time': 15391.55540060997, 'accumulated_logging_time': 0.41968607902526855}
I0306 18:01:14.810523 140498421401344 logging_writer.py:48] [2381] accumulated_eval_time=15391.6, accumulated_logging_time=0.419686, accumulated_submission_time=2309.13, global_step=2381, preemption_count=0, score=2309.13, test/loss=0.127897, test/num_examples=95000000, total_duration=17701.2, train/loss=0.123488, validation/loss=0.125387, validation/num_examples=83274637
I0306 18:01:16.957567 140498413008640 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.025372739881277084, loss=0.12490014731884003
I0306 18:03:10.588346 140498421401344 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.025725314393639565, loss=0.13103613257408142
I0306 18:03:15.349827 140651857294528 spec.py:321] Evaluating on the training split.
I0306 18:04:11.435040 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 18:07:12.306993 140651857294528 spec.py:349] Evaluating on the test split.
I0306 18:12:51.280286 140651857294528 submission_runner.py:469] Time since start: 18397.72s, 	Step: 2505, 	{'train/loss': 0.12531994881823003, 'validation/loss': 0.12523072736772145, 'validation/num_examples': 83274637, 'test/loss': 0.12755082786800986, 'test/num_examples': 95000000, 'score': 2429.659361600876, 'total_duration': 18397.718171834946, 'accumulated_submission_time': 2429.659361600876, 'accumulated_eval_time': 15967.485778570175, 'accumulated_logging_time': 0.43640565872192383}
I0306 18:12:51.289386 140498413008640 logging_writer.py:48] [2505] accumulated_eval_time=15967.5, accumulated_logging_time=0.436406, accumulated_submission_time=2429.66, global_step=2505, preemption_count=0, score=2429.66, test/loss=0.127551, test/num_examples=95000000, total_duration=18397.7, train/loss=0.12532, validation/loss=0.125231, validation/num_examples=83274637
I0306 18:14:18.495497 140498421401344 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.04762158542871475, loss=0.1260521560907364
I0306 18:14:51.420697 140651857294528 spec.py:321] Evaluating on the training split.
I0306 18:15:44.797810 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 18:18:46.671863 140651857294528 spec.py:349] Evaluating on the test split.
I0306 18:24:16.916139 140651857294528 submission_runner.py:469] Time since start: 19083.35s, 	Step: 2627, 	{'train/loss': 0.12285201941505543, 'validation/loss': 0.1251606670496129, 'validation/num_examples': 83274637, 'test/loss': 0.1275215230777138, 'test/num_examples': 95000000, 'score': 2549.778029680252, 'total_duration': 19083.35404109955, 'accumulated_submission_time': 2549.778029680252, 'accumulated_eval_time': 16532.981155395508, 'accumulated_logging_time': 0.45175623893737793}
I0306 18:24:16.924745 140498413008640 logging_writer.py:48] [2627] accumulated_eval_time=16533, accumulated_logging_time=0.451756, accumulated_submission_time=2549.78, global_step=2627, preemption_count=0, score=2549.78, test/loss=0.127522, test/num_examples=95000000, total_duration=19083.4, train/loss=0.122852, validation/loss=0.125161, validation/num_examples=83274637
I0306 18:25:13.031831 140498421401344 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.05128467455506325, loss=0.12315987795591354
I0306 18:26:17.306083 140651857294528 spec.py:321] Evaluating on the training split.
I0306 18:27:14.562535 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 18:30:15.821247 140651857294528 spec.py:349] Evaluating on the test split.
I0306 18:36:02.954772 140651857294528 submission_runner.py:469] Time since start: 19789.39s, 	Step: 2756, 	{'train/loss': 0.1250271589594817, 'validation/loss': 0.12481046580123115, 'validation/num_examples': 83274637, 'test/loss': 0.12729003046875, 'test/num_examples': 95000000, 'score': 2670.1203801631927, 'total_duration': 19789.39267730713, 'accumulated_submission_time': 2670.1203801631927, 'accumulated_eval_time': 17118.629784584045, 'accumulated_logging_time': 0.49337029457092285}
I0306 18:36:02.964568 140498413008640 logging_writer.py:48] [2756] accumulated_eval_time=17118.6, accumulated_logging_time=0.49337, accumulated_submission_time=2670.12, global_step=2756, preemption_count=0, score=2670.12, test/loss=0.12729, test/num_examples=95000000, total_duration=19789.4, train/loss=0.125027, validation/loss=0.12481, validation/num_examples=83274637
I0306 18:36:25.934082 140498421401344 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.04081237316131592, loss=0.12401872128248215
I0306 18:38:03.301602 140651857294528 spec.py:321] Evaluating on the training split.
I0306 18:38:55.609611 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 18:41:58.151810 140651857294528 spec.py:349] Evaluating on the test split.
I0306 18:47:33.935056 140651857294528 submission_runner.py:469] Time since start: 20480.37s, 	Step: 2885, 	{'train/loss': 0.12385352055466026, 'validation/loss': 0.1255128686796317, 'validation/num_examples': 83274637, 'test/loss': 0.1281385216796875, 'test/num_examples': 95000000, 'score': 2790.4438214302063, 'total_duration': 20480.372973442078, 'accumulated_submission_time': 2790.4438214302063, 'accumulated_eval_time': 17689.26319551468, 'accumulated_logging_time': 0.5100991725921631}
I0306 18:47:33.944208 140498413008640 logging_writer.py:48] [2885] accumulated_eval_time=17689.3, accumulated_logging_time=0.510099, accumulated_submission_time=2790.44, global_step=2885, preemption_count=0, score=2790.44, test/loss=0.128139, test/num_examples=95000000, total_duration=20480.4, train/loss=0.123854, validation/loss=0.125513, validation/num_examples=83274637
I0306 18:47:35.642299 140498421401344 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.03327644243836403, loss=0.11804444342851639
I0306 18:49:27.970587 140498413008640 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.009010504931211472, loss=0.11420153081417084
I0306 18:49:33.943664 140651857294528 spec.py:321] Evaluating on the training split.
I0306 18:50:23.302447 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 18:53:27.090987 140651857294528 spec.py:349] Evaluating on the test split.
I0306 18:58:56.895784 140651857294528 submission_runner.py:469] Time since start: 21163.33s, 	Step: 3006, 	{'train/loss': 0.12408096931359303, 'validation/loss': 0.12505477251294186, 'validation/num_examples': 83274637, 'test/loss': 0.12747361478207236, 'test/num_examples': 95000000, 'score': 2910.429848909378, 'total_duration': 21163.33367061615, 'accumulated_submission_time': 2910.429848909378, 'accumulated_eval_time': 18252.215242147446, 'accumulated_logging_time': 0.5264132022857666}
I0306 18:58:56.904691 140498421401344 logging_writer.py:48] [3006] accumulated_eval_time=18252.2, accumulated_logging_time=0.526413, accumulated_submission_time=2910.43, global_step=3006, preemption_count=0, score=2910.43, test/loss=0.127474, test/num_examples=95000000, total_duration=21163.3, train/loss=0.124081, validation/loss=0.125055, validation/num_examples=83274637
I0306 19:00:18.880854 140498413008640 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.015189196914434433, loss=0.1220887079834938
I0306 19:00:57.322129 140651857294528 spec.py:321] Evaluating on the training split.
I0306 19:01:51.407970 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 19:04:49.372532 140651857294528 spec.py:349] Evaluating on the test split.
I0306 19:10:28.554955 140651857294528 submission_runner.py:469] Time since start: 21854.99s, 	Step: 3134, 	{'train/loss': 0.12396142040174338, 'validation/loss': 0.12497159212746328, 'validation/num_examples': 83274637, 'test/loss': 0.1273595798519737, 'test/num_examples': 95000000, 'score': 3030.8343048095703, 'total_duration': 21854.992869377136, 'accumulated_submission_time': 3030.8343048095703, 'accumulated_eval_time': 18823.448016881943, 'accumulated_logging_time': 0.5419425964355469}
I0306 19:10:28.564144 140498421401344 logging_writer.py:48] [3134] accumulated_eval_time=18823.4, accumulated_logging_time=0.541943, accumulated_submission_time=3030.83, global_step=3134, preemption_count=0, score=3030.83, test/loss=0.12736, test/num_examples=95000000, total_duration=21855, train/loss=0.123961, validation/loss=0.124972, validation/num_examples=83274637
I0306 19:11:20.973501 140498413008640 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.036181870847940445, loss=0.11631734669208527
I0306 19:12:29.050544 140651857294528 spec.py:321] Evaluating on the training split.
I0306 19:13:26.253453 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 19:16:29.923679 140651857294528 spec.py:349] Evaluating on the test split.
I0306 19:22:23.601642 140651857294528 submission_runner.py:469] Time since start: 22570.04s, 	Step: 3256, 	{'train/loss': 0.12352669748635788, 'validation/loss': 0.12494236270751471, 'validation/num_examples': 83274637, 'test/loss': 0.1272778615131579, 'test/num_examples': 95000000, 'score': 3151.307098388672, 'total_duration': 22570.039531946182, 'accumulated_submission_time': 3151.307098388672, 'accumulated_eval_time': 19417.999048948288, 'accumulated_logging_time': 0.5577719211578369}
I0306 19:22:23.611756 140498421401344 logging_writer.py:48] [3256] accumulated_eval_time=19418, accumulated_logging_time=0.557772, accumulated_submission_time=3151.31, global_step=3256, preemption_count=0, score=3151.31, test/loss=0.127278, test/num_examples=95000000, total_duration=22570, train/loss=0.123527, validation/loss=0.124942, validation/num_examples=83274637
I0306 19:22:46.066247 140498413008640 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.04538290202617645, loss=0.12858803570270538
I0306 19:24:24.640433 140651857294528 spec.py:321] Evaluating on the training split.
I0306 19:25:23.286664 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 19:28:27.706128 140651857294528 spec.py:349] Evaluating on the test split.
I0306 19:34:20.720340 140651857294528 submission_runner.py:469] Time since start: 23287.16s, 	Step: 3386, 	{'train/loss': 0.1231222698734429, 'validation/loss': 0.12491472282513522, 'validation/num_examples': 83274637, 'test/loss': 0.12727893550575659, 'test/num_examples': 95000000, 'score': 3272.3222374916077, 'total_duration': 23287.158255577087, 'accumulated_submission_time': 3272.3222374916077, 'accumulated_eval_time': 20014.078914880753, 'accumulated_logging_time': 0.5746197700500488}
I0306 19:34:20.729244 140498421401344 logging_writer.py:48] [3386] accumulated_eval_time=20014.1, accumulated_logging_time=0.57462, accumulated_submission_time=3272.32, global_step=3386, preemption_count=0, score=3272.32, test/loss=0.127279, test/num_examples=95000000, total_duration=23287.2, train/loss=0.123122, validation/loss=0.124915, validation/num_examples=83274637
I0306 19:34:22.310505 140498413008640 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.012274293228983879, loss=0.12001161277294159
I0306 19:36:05.603504 140498421401344 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.02804642915725708, loss=0.12730011343955994
I0306 19:36:21.120566 140651857294528 spec.py:321] Evaluating on the training split.
I0306 19:37:12.655149 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 19:40:14.054635 140651857294528 spec.py:349] Evaluating on the test split.
I0306 19:46:11.614426 140651857294528 submission_runner.py:469] Time since start: 23998.05s, 	Step: 3516, 	{'train/loss': 0.12209073148386658, 'validation/loss': 0.12494745615839865, 'validation/num_examples': 83274637, 'test/loss': 0.12726066474095396, 'test/num_examples': 95000000, 'score': 3392.7003223896027, 'total_duration': 23998.05234026909, 'accumulated_submission_time': 3392.7003223896027, 'accumulated_eval_time': 20604.572757720947, 'accumulated_logging_time': 0.5902433395385742}
I0306 19:46:11.687951 140498413008640 logging_writer.py:48] [3516] accumulated_eval_time=20604.6, accumulated_logging_time=0.590243, accumulated_submission_time=3392.7, global_step=3516, preemption_count=0, score=3392.7, test/loss=0.127261, test/num_examples=95000000, total_duration=23998.1, train/loss=0.122091, validation/loss=0.124947, validation/num_examples=83274637
I0306 19:47:18.788720 140498421401344 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.00922481995075941, loss=0.12313659489154816
I0306 19:48:12.451832 140651857294528 spec.py:321] Evaluating on the training split.
I0306 19:49:09.709743 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 19:52:16.125180 140651857294528 spec.py:349] Evaluating on the test split.
I0306 19:57:53.470258 140651857294528 submission_runner.py:469] Time since start: 24699.91s, 	Step: 3645, 	{'train/loss': 0.12221984725750093, 'validation/loss': 0.12478758184293406, 'validation/num_examples': 83274637, 'test/loss': 0.1271138253700658, 'test/num_examples': 95000000, 'score': 3513.433576822281, 'total_duration': 24699.90816259384, 'accumulated_submission_time': 3513.433576822281, 'accumulated_eval_time': 21185.591124534607, 'accumulated_logging_time': 0.6867139339447021}
I0306 19:57:53.479622 140498413008640 logging_writer.py:48] [3645] accumulated_eval_time=21185.6, accumulated_logging_time=0.686714, accumulated_submission_time=3513.43, global_step=3645, preemption_count=0, score=3513.43, test/loss=0.127114, test/num_examples=95000000, total_duration=24699.9, train/loss=0.12222, validation/loss=0.124788, validation/num_examples=83274637
I0306 19:58:29.691884 140498421401344 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.024678364396095276, loss=0.12621724605560303
I0306 19:59:54.461483 140651857294528 spec.py:321] Evaluating on the training split.
I0306 20:00:48.581508 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 20:03:51.099353 140651857294528 spec.py:349] Evaluating on the test split.
I0306 20:09:44.449483 140651857294528 submission_runner.py:469] Time since start: 25410.89s, 	Step: 3770, 	{'train/loss': 0.12321369170720847, 'validation/loss': 0.12475728011691903, 'validation/num_examples': 83274637, 'test/loss': 0.12719411322985197, 'test/num_examples': 95000000, 'score': 3634.402688026428, 'total_duration': 25410.887385368347, 'accumulated_submission_time': 3634.402688026428, 'accumulated_eval_time': 21775.579063892365, 'accumulated_logging_time': 0.7025368213653564}
I0306 20:09:44.460260 140498413008640 logging_writer.py:48] [3770] accumulated_eval_time=21775.6, accumulated_logging_time=0.702537, accumulated_submission_time=3634.4, global_step=3770, preemption_count=0, score=3634.4, test/loss=0.127194, test/num_examples=95000000, total_duration=25410.9, train/loss=0.123214, validation/loss=0.124757, validation/num_examples=83274637
I0306 20:09:50.616851 140498421401344 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.03263269364833832, loss=0.12581737339496613
I0306 20:11:45.623469 140651857294528 spec.py:321] Evaluating on the training split.
I0306 20:12:41.367533 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 20:15:44.728400 140651857294528 spec.py:349] Evaluating on the test split.
I0306 20:21:35.403110 140651857294528 submission_runner.py:469] Time since start: 26121.84s, 	Step: 3896, 	{'train/loss': 0.1251876589566844, 'validation/loss': 0.12562481553788551, 'validation/num_examples': 83274637, 'test/loss': 0.12804074818050987, 'test/num_examples': 95000000, 'score': 3755.552521467209, 'total_duration': 26121.84099292755, 'accumulated_submission_time': 3755.552521467209, 'accumulated_eval_time': 22365.3586230278, 'accumulated_logging_time': 0.7202227115631104}
I0306 20:21:35.412012 140498413008640 logging_writer.py:48] [3896] accumulated_eval_time=22365.4, accumulated_logging_time=0.720223, accumulated_submission_time=3755.55, global_step=3896, preemption_count=0, score=3755.55, test/loss=0.128041, test/num_examples=95000000, total_duration=26121.8, train/loss=0.125188, validation/loss=0.125625, validation/num_examples=83274637
I0306 20:21:35.947368 140498421401344 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.006141140125691891, loss=0.12537826597690582
I0306 20:23:09.539107 140498413008640 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.010825210250914097, loss=0.12424286454916
I0306 20:23:35.652689 140651857294528 spec.py:321] Evaluating on the training split.
I0306 20:24:30.225545 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 20:27:32.639241 140651857294528 spec.py:349] Evaluating on the test split.
I0306 20:33:24.745980 140651857294528 submission_runner.py:469] Time since start: 26831.18s, 	Step: 4024, 	{'train/loss': 0.12291745084730334, 'validation/loss': 0.12491091624941952, 'validation/num_examples': 83274637, 'test/loss': 0.12740046923314144, 'test/num_examples': 95000000, 'score': 3875.780742406845, 'total_duration': 26831.183886051178, 'accumulated_submission_time': 3875.780742406845, 'accumulated_eval_time': 22954.451852798462, 'accumulated_logging_time': 0.7354459762573242}
I0306 20:33:24.756464 140498421401344 logging_writer.py:48] [4024] accumulated_eval_time=22954.5, accumulated_logging_time=0.735446, accumulated_submission_time=3875.78, global_step=4024, preemption_count=0, score=3875.78, test/loss=0.1274, test/num_examples=95000000, total_duration=26831.2, train/loss=0.122917, validation/loss=0.124911, validation/num_examples=83274637
I0306 20:34:29.330191 140498413008640 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.009782985784113407, loss=0.12103778123855591
I0306 20:35:25.007158 140651857294528 spec.py:321] Evaluating on the training split.
I0306 20:36:24.430379 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 20:39:25.787373 140651857294528 spec.py:349] Evaluating on the test split.
I0306 20:45:01.822170 140651857294528 submission_runner.py:469] Time since start: 27528.26s, 	Step: 4146, 	{'train/loss': 0.12231111452686337, 'validation/loss': 0.12473896355342827, 'validation/num_examples': 83274637, 'test/loss': 0.1272196835629112, 'test/num_examples': 95000000, 'score': 3996.0177767276764, 'total_duration': 27528.260083913803, 'accumulated_submission_time': 3996.0177767276764, 'accumulated_eval_time': 23531.266834259033, 'accumulated_logging_time': 0.7528486251831055}
I0306 20:45:01.831543 140498421401344 logging_writer.py:48] [4146] accumulated_eval_time=23531.3, accumulated_logging_time=0.752849, accumulated_submission_time=3996.02, global_step=4146, preemption_count=0, score=3996.02, test/loss=0.12722, test/num_examples=95000000, total_duration=27528.3, train/loss=0.122311, validation/loss=0.124739, validation/num_examples=83274637
I0306 20:45:37.010418 140498413008640 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.027542250230908394, loss=0.12043105065822601
I0306 20:47:02.518722 140651857294528 spec.py:321] Evaluating on the training split.
I0306 20:48:04.217585 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 20:51:05.919116 140651857294528 spec.py:349] Evaluating on the test split.
I0306 20:56:45.678163 140651857294528 submission_runner.py:469] Time since start: 28232.12s, 	Step: 4271, 	{'train/loss': 0.12310923730849095, 'validation/loss': 0.12457783793668023, 'validation/num_examples': 83274637, 'test/loss': 0.12692073269942433, 'test/num_examples': 95000000, 'score': 4116.691578388214, 'total_duration': 28232.116079568863, 'accumulated_submission_time': 4116.691578388214, 'accumulated_eval_time': 24114.426236867905, 'accumulated_logging_time': 0.7685575485229492}
I0306 20:56:45.687238 140498421401344 logging_writer.py:48] [4271] accumulated_eval_time=24114.4, accumulated_logging_time=0.768558, accumulated_submission_time=4116.69, global_step=4271, preemption_count=0, score=4116.69, test/loss=0.126921, test/num_examples=95000000, total_duration=28232.1, train/loss=0.123109, validation/loss=0.124578, validation/num_examples=83274637
I0306 20:56:50.844378 140498413008640 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.012408208101987839, loss=0.12514059245586395
I0306 20:58:46.178836 140651857294528 spec.py:321] Evaluating on the training split.
I0306 20:59:42.705071 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 21:02:46.766151 140651857294528 spec.py:349] Evaluating on the test split.
I0306 21:08:20.905352 140651857294528 submission_runner.py:469] Time since start: 28927.34s, 	Step: 4397, 	{'train/loss': 0.12432889319347136, 'validation/loss': 0.12451053270952715, 'validation/num_examples': 83274637, 'test/loss': 0.12681708634868422, 'test/num_examples': 95000000, 'score': 4237.170535326004, 'total_duration': 28927.34323644638, 'accumulated_submission_time': 4237.170535326004, 'accumulated_eval_time': 24689.152673959732, 'accumulated_logging_time': 0.7838764190673828}
I0306 21:08:20.914606 140498421401344 logging_writer.py:48] [4397] accumulated_eval_time=24689.2, accumulated_logging_time=0.783876, accumulated_submission_time=4237.17, global_step=4397, preemption_count=0, score=4237.17, test/loss=0.126817, test/num_examples=95000000, total_duration=28927.3, train/loss=0.124329, validation/loss=0.124511, validation/num_examples=83274637
I0306 21:08:21.396408 140498413008640 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.010127086192369461, loss=0.12439626455307007
I0306 21:09:52.634565 140498421401344 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.021629609167575836, loss=0.13157512247562408
I0306 21:10:21.703017 140651857294528 spec.py:321] Evaluating on the training split.
I0306 21:11:16.063279 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 21:14:17.946415 140651857294528 spec.py:349] Evaluating on the test split.
I0306 21:20:07.902373 140651857294528 submission_runner.py:469] Time since start: 29634.34s, 	Step: 4526, 	{'train/loss': 0.12176572287794929, 'validation/loss': 0.1243412987742144, 'validation/num_examples': 83274637, 'test/loss': 0.12662408999794408, 'test/num_examples': 95000000, 'score': 4357.899606704712, 'total_duration': 29634.340282201767, 'accumulated_submission_time': 4357.899606704712, 'accumulated_eval_time': 25275.35197854042, 'accumulated_logging_time': 0.8461194038391113}
I0306 21:20:07.911529 140498413008640 logging_writer.py:48] [4526] accumulated_eval_time=25275.4, accumulated_logging_time=0.846119, accumulated_submission_time=4357.9, global_step=4526, preemption_count=0, score=4357.9, test/loss=0.126624, test/num_examples=95000000, total_duration=29634.3, train/loss=0.121766, validation/loss=0.124341, validation/num_examples=83274637
I0306 21:21:08.437052 140498421401344 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.014979339204728603, loss=0.12072470039129257
I0306 21:22:08.756665 140651857294528 spec.py:321] Evaluating on the training split.
I0306 21:23:03.581355 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 21:26:06.429506 140651857294528 spec.py:349] Evaluating on the test split.
I0306 21:31:50.604549 140651857294528 submission_runner.py:469] Time since start: 30337.04s, 	Step: 4652, 	{'train/loss': 0.12156340814892601, 'validation/loss': 0.12452679966139292, 'validation/num_examples': 83274637, 'test/loss': 0.1268375433696546, 'test/num_examples': 95000000, 'score': 4478.731933355331, 'total_duration': 30337.042452335358, 'accumulated_submission_time': 4478.731933355331, 'accumulated_eval_time': 25857.19980120659, 'accumulated_logging_time': 0.8615744113922119}
I0306 21:31:50.613851 140498413008640 logging_writer.py:48] [4652] accumulated_eval_time=25857.2, accumulated_logging_time=0.861574, accumulated_submission_time=4478.73, global_step=4652, preemption_count=0, score=4478.73, test/loss=0.126838, test/num_examples=95000000, total_duration=30337, train/loss=0.121563, validation/loss=0.124527, validation/num_examples=83274637
I0306 21:32:18.973803 140498421401344 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.007704101502895355, loss=0.1167677715420723
I0306 21:33:50.810725 140651857294528 spec.py:321] Evaluating on the training split.
I0306 21:34:42.833901 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 21:37:43.441566 140651857294528 spec.py:349] Evaluating on the test split.
I0306 21:43:36.158025 140651857294528 submission_runner.py:469] Time since start: 31042.60s, 	Step: 4775, 	{'train/loss': 0.12208045169757972, 'validation/loss': 0.12465389623927076, 'validation/num_examples': 83274637, 'test/loss': 0.127100912890625, 'test/num_examples': 95000000, 'score': 4598.916563272476, 'total_duration': 31042.595942497253, 'accumulated_submission_time': 4598.916563272476, 'accumulated_eval_time': 26442.547056674957, 'accumulated_logging_time': 0.8772487640380859}
I0306 21:43:36.167576 140498413008640 logging_writer.py:48] [4775] accumulated_eval_time=26442.5, accumulated_logging_time=0.877249, accumulated_submission_time=4598.92, global_step=4775, preemption_count=0, score=4598.92, test/loss=0.127101, test/num_examples=95000000, total_duration=31042.6, train/loss=0.12208, validation/loss=0.124654, validation/num_examples=83274637
I0306 21:43:38.952356 140498421401344 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.007042713928967714, loss=0.12725690007209778
I0306 21:45:33.423612 140498413008640 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.005833893083035946, loss=0.12122100591659546
I0306 21:45:36.371916 140651857294528 spec.py:321] Evaluating on the training split.
I0306 21:46:31.895887 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 21:49:33.161819 140651857294528 spec.py:349] Evaluating on the test split.
I0306 21:55:20.870267 140651857294528 submission_runner.py:469] Time since start: 31747.31s, 	Step: 4904, 	{'train/loss': 0.12000434517672977, 'validation/loss': 0.12438560094355695, 'validation/num_examples': 83274637, 'test/loss': 0.1268504113075658, 'test/num_examples': 95000000, 'score': 4719.107129096985, 'total_duration': 31747.308179616928, 'accumulated_submission_time': 4719.107129096985, 'accumulated_eval_time': 27027.045350313187, 'accumulated_logging_time': 0.8935179710388184}
I0306 21:55:20.879840 140498421401344 logging_writer.py:48] [4904] accumulated_eval_time=27027, accumulated_logging_time=0.893518, accumulated_submission_time=4719.11, global_step=4904, preemption_count=0, score=4719.11, test/loss=0.12685, test/num_examples=95000000, total_duration=31747.3, train/loss=0.120004, validation/loss=0.124386, validation/num_examples=83274637
I0306 21:56:44.687990 140498413008640 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.005890275817364454, loss=0.11773498356342316
I0306 21:57:22.469035 140651857294528 spec.py:321] Evaluating on the training split.
I0306 21:58:20.985569 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 22:01:29.091174 140651857294528 spec.py:349] Evaluating on the test split.
I0306 22:07:10.678990 140651857294528 submission_runner.py:469] Time since start: 32457.12s, 	Step: 5034, 	{'train/loss': 0.12385366548953941, 'validation/loss': 0.12494566977710339, 'validation/num_examples': 83274637, 'test/loss': 0.12738404704975329, 'test/num_examples': 95000000, 'score': 4840.683376789093, 'total_duration': 32457.116898059845, 'accumulated_submission_time': 4840.683376789093, 'accumulated_eval_time': 27615.25526356697, 'accumulated_logging_time': 0.9099223613739014}
I0306 22:07:10.688601 140498421401344 logging_writer.py:48] [5034] accumulated_eval_time=27615.3, accumulated_logging_time=0.909922, accumulated_submission_time=4840.68, global_step=5034, preemption_count=0, score=4840.68, test/loss=0.127384, test/num_examples=95000000, total_duration=32457.1, train/loss=0.123854, validation/loss=0.124946, validation/num_examples=83274637
I0306 22:08:02.712736 140498413008640 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.03600422665476799, loss=0.11874322593212128
I0306 22:09:10.732690 140651857294528 spec.py:321] Evaluating on the training split.
I0306 22:10:03.210762 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 22:13:03.115029 140651857294528 spec.py:349] Evaluating on the test split.
I0306 22:18:39.601841 140651857294528 submission_runner.py:469] Time since start: 33146.04s, 	Step: 5157, 	{'train/loss': 0.1233628557046067, 'validation/loss': 0.12440482533593557, 'validation/num_examples': 83274637, 'test/loss': 0.12674451749588816, 'test/num_examples': 95000000, 'score': 4960.714819908142, 'total_duration': 33146.03971242905, 'accumulated_submission_time': 4960.714819908142, 'accumulated_eval_time': 28184.124321699142, 'accumulated_logging_time': 0.9261705875396729}
I0306 22:18:39.613072 140498421401344 logging_writer.py:48] [5157] accumulated_eval_time=28184.1, accumulated_logging_time=0.926171, accumulated_submission_time=4960.71, global_step=5157, preemption_count=0, score=4960.71, test/loss=0.126745, test/num_examples=95000000, total_duration=33146, train/loss=0.123363, validation/loss=0.124405, validation/num_examples=83274637
I0306 22:19:00.786744 140498413008640 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.008591260761022568, loss=0.13336938619613647
I0306 22:20:40.424870 140651857294528 spec.py:321] Evaluating on the training split.
I0306 22:21:32.020111 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 22:24:31.563827 140651857294528 spec.py:349] Evaluating on the test split.
I0306 22:30:27.718938 140651857294528 submission_runner.py:469] Time since start: 33854.16s, 	Step: 5287, 	{'train/loss': 0.1246023823114686, 'validation/loss': 0.12435700032588404, 'validation/num_examples': 83274637, 'test/loss': 0.12675276105057565, 'test/num_examples': 95000000, 'score': 5081.51232790947, 'total_duration': 33854.15684604645, 'accumulated_submission_time': 5081.51232790947, 'accumulated_eval_time': 28771.418333292007, 'accumulated_logging_time': 0.9441499710083008}
I0306 22:30:27.728466 140498421401344 logging_writer.py:48] [5287] accumulated_eval_time=28771.4, accumulated_logging_time=0.94415, accumulated_submission_time=5081.51, global_step=5287, preemption_count=0, score=5081.51, test/loss=0.126753, test/num_examples=95000000, total_duration=33854.2, train/loss=0.124602, validation/loss=0.124357, validation/num_examples=83274637
I0306 22:30:29.220970 140498413008640 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.009664498269557953, loss=0.11971911042928696
I0306 22:32:07.345825 140498421401344 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.007340881507843733, loss=0.1265212893486023
I0306 22:32:28.702148 140651857294528 spec.py:321] Evaluating on the training split.
I0306 22:33:23.625130 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 22:36:31.517972 140651857294528 spec.py:349] Evaluating on the test split.
I0306 22:42:03.007307 140651857294528 submission_runner.py:469] Time since start: 34549.45s, 	Step: 5420, 	{'train/loss': 0.12340945704787407, 'validation/loss': 0.12458771131683603, 'validation/num_examples': 83274637, 'test/loss': 0.12708953586554275, 'test/num_examples': 95000000, 'score': 5202.472890853882, 'total_duration': 34549.44522380829, 'accumulated_submission_time': 5202.472890853882, 'accumulated_eval_time': 29345.723439216614, 'accumulated_logging_time': 0.9602022171020508}
I0306 22:42:03.016579 140498413008640 logging_writer.py:48] [5420] accumulated_eval_time=29345.7, accumulated_logging_time=0.960202, accumulated_submission_time=5202.47, global_step=5420, preemption_count=0, score=5202.47, test/loss=0.12709, test/num_examples=95000000, total_duration=34549.4, train/loss=0.123409, validation/loss=0.124588, validation/num_examples=83274637
I0306 22:43:06.967188 140498421401344 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.020900174975395203, loss=0.11626841127872467
I0306 22:44:03.550855 140651857294528 spec.py:321] Evaluating on the training split.
I0306 22:44:58.365544 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 22:47:56.791520 140651857294528 spec.py:349] Evaluating on the test split.
I0306 22:53:28.066059 140651857294528 submission_runner.py:469] Time since start: 35234.50s, 	Step: 5547, 	{'train/loss': 0.12128476369774567, 'validation/loss': 0.12423953548725766, 'validation/num_examples': 83274637, 'test/loss': 0.12667096429893093, 'test/num_examples': 95000000, 'score': 5322.994548797607, 'total_duration': 35234.50396442413, 'accumulated_submission_time': 5322.994548797607, 'accumulated_eval_time': 29910.23858356476, 'accumulated_logging_time': 0.9759297370910645}
I0306 22:53:28.075586 140498413008640 logging_writer.py:48] [5547] accumulated_eval_time=29910.2, accumulated_logging_time=0.97593, accumulated_submission_time=5322.99, global_step=5547, preemption_count=0, score=5322.99, test/loss=0.126671, test/num_examples=95000000, total_duration=35234.5, train/loss=0.121285, validation/loss=0.12424, validation/num_examples=83274637
I0306 22:54:02.707857 140498421401344 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.018704941496253014, loss=0.11994284391403198
I0306 22:55:28.145950 140651857294528 spec.py:321] Evaluating on the training split.
I0306 22:56:23.628420 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 22:59:26.409399 140651857294528 spec.py:349] Evaluating on the test split.
I0306 23:04:58.155992 140651857294528 submission_runner.py:469] Time since start: 35924.59s, 	Step: 5671, 	{'train/loss': 0.12324503911131958, 'validation/loss': 0.12435478768536616, 'validation/num_examples': 83274637, 'test/loss': 0.12676753462171053, 'test/num_examples': 95000000, 'score': 5443.052620649338, 'total_duration': 35924.59390425682, 'accumulated_submission_time': 5443.052620649338, 'accumulated_eval_time': 30480.248576641083, 'accumulated_logging_time': 0.9920907020568848}
I0306 23:04:58.165504 140498413008640 logging_writer.py:48] [5671] accumulated_eval_time=30480.2, accumulated_logging_time=0.992091, accumulated_submission_time=5443.05, global_step=5671, preemption_count=0, score=5443.05, test/loss=0.126768, test/num_examples=95000000, total_duration=35924.6, train/loss=0.123245, validation/loss=0.124355, validation/num_examples=83274637
I0306 23:05:03.968224 140498421401344 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.007186350878328085, loss=0.1175876259803772
I0306 23:06:54.827078 140498413008640 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.01880999654531479, loss=0.11883460730314255
I0306 23:06:59.198922 140651857294528 spec.py:321] Evaluating on the training split.
I0306 23:07:53.429138 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 23:11:01.096453 140651857294528 spec.py:349] Evaluating on the test split.
I0306 23:16:39.968662 140651857294528 submission_runner.py:469] Time since start: 36626.41s, 	Step: 5805, 	{'train/loss': 0.12218669832408803, 'validation/loss': 0.12421460785706614, 'validation/num_examples': 83274637, 'test/loss': 0.1267118974917763, 'test/num_examples': 95000000, 'score': 5564.073139667511, 'total_duration': 36626.4065387249, 'accumulated_submission_time': 5564.073139667511, 'accumulated_eval_time': 31061.01822423935, 'accumulated_logging_time': 1.0081450939178467}
I0306 23:16:39.978640 140498421401344 logging_writer.py:48] [5805] accumulated_eval_time=31061, accumulated_logging_time=1.00815, accumulated_submission_time=5564.07, global_step=5805, preemption_count=0, score=5564.07, test/loss=0.126712, test/num_examples=95000000, total_duration=36626.4, train/loss=0.122187, validation/loss=0.124215, validation/num_examples=83274637
I0306 23:17:57.322333 140498413008640 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.007274916861206293, loss=0.11636044830083847
I0306 23:18:40.185053 140651857294528 spec.py:321] Evaluating on the training split.
I0306 23:19:35.412816 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 23:22:37.737984 140651857294528 spec.py:349] Evaluating on the test split.
I0306 23:28:22.529331 140651857294528 submission_runner.py:469] Time since start: 37328.97s, 	Step: 5938, 	{'train/loss': 0.12455099655912732, 'validation/loss': 0.12408408587820532, 'validation/num_examples': 83274637, 'test/loss': 0.12654902644942434, 'test/num_examples': 95000000, 'score': 5684.264944076538, 'total_duration': 37328.96723628044, 'accumulated_submission_time': 5684.264944076538, 'accumulated_eval_time': 31643.36244249344, 'accumulated_logging_time': 1.025517463684082}
I0306 23:28:22.538800 140498421401344 logging_writer.py:48] [5938] accumulated_eval_time=31643.4, accumulated_logging_time=1.02552, accumulated_submission_time=5684.26, global_step=5938, preemption_count=0, score=5684.26, test/loss=0.126549, test/num_examples=95000000, total_duration=37329, train/loss=0.124551, validation/loss=0.124084, validation/num_examples=83274637
I0306 23:29:05.002264 140498413008640 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.024642201140522957, loss=0.12854227423667908
I0306 23:30:23.186332 140651857294528 spec.py:321] Evaluating on the training split.
I0306 23:31:18.304109 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 23:34:21.176181 140651857294528 spec.py:349] Evaluating on the test split.
I0306 23:40:02.771399 140651857294528 submission_runner.py:469] Time since start: 38029.21s, 	Step: 6073, 	{'train/loss': 0.12230221209051849, 'validation/loss': 0.12417118031744617, 'validation/num_examples': 83274637, 'test/loss': 0.12654970531455592, 'test/num_examples': 95000000, 'score': 5804.89813375473, 'total_duration': 38029.20930528641, 'accumulated_submission_time': 5804.89813375473, 'accumulated_eval_time': 32222.947456598282, 'accumulated_logging_time': 1.042325496673584}
I0306 23:40:02.782728 140498421401344 logging_writer.py:48] [6073] accumulated_eval_time=32222.9, accumulated_logging_time=1.04233, accumulated_submission_time=5804.9, global_step=6073, preemption_count=0, score=5804.9, test/loss=0.12655, test/num_examples=95000000, total_duration=38029.2, train/loss=0.122302, validation/loss=0.124171, validation/num_examples=83274637
I0306 23:40:06.313569 140498413008640 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.009709467180073261, loss=0.12406188249588013
I0306 23:42:01.831845 140498421401344 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.011083791963756084, loss=0.12268801778554916
I0306 23:42:03.387236 140651857294528 spec.py:321] Evaluating on the training split.
I0306 23:42:58.990341 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 23:46:01.990761 140651857294528 spec.py:349] Evaluating on the test split.
I0306 23:51:33.620039 140651857294528 submission_runner.py:469] Time since start: 38720.06s, 	Step: 6202, 	{'train/loss': 0.1224644680349332, 'validation/loss': 0.12417826883176815, 'validation/num_examples': 83274637, 'test/loss': 0.12660570711348684, 'test/num_examples': 95000000, 'score': 5925.489762544632, 'total_duration': 38720.05794811249, 'accumulated_submission_time': 5925.489762544632, 'accumulated_eval_time': 32793.18019986153, 'accumulated_logging_time': 1.060392141342163}
I0306 23:51:33.631111 140498413008640 logging_writer.py:48] [6202] accumulated_eval_time=32793.2, accumulated_logging_time=1.06039, accumulated_submission_time=5925.49, global_step=6202, preemption_count=0, score=5925.49, test/loss=0.126606, test/num_examples=95000000, total_duration=38720.1, train/loss=0.122464, validation/loss=0.124178, validation/num_examples=83274637
I0306 23:53:02.773553 140498421401344 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.00833235401660204, loss=0.11751338839530945
I0306 23:53:33.792404 140651857294528 spec.py:321] Evaluating on the training split.
I0306 23:54:27.552817 140651857294528 spec.py:333] Evaluating on the validation split.
I0306 23:57:32.466518 140651857294528 spec.py:349] Evaluating on the test split.
I0307 00:03:15.977013 140651857294528 submission_runner.py:469] Time since start: 39422.41s, 	Step: 6327, 	{'train/loss': 0.12255117690788125, 'validation/loss': 0.12410471574100422, 'validation/num_examples': 83274637, 'test/loss': 0.12651501328125, 'test/num_examples': 95000000, 'score': 6045.625273942947, 'total_duration': 39422.41489505768, 'accumulated_submission_time': 6045.625273942947, 'accumulated_eval_time': 33375.36472725868, 'accumulated_logging_time': 1.0909276008605957}
I0307 00:03:15.988435 140498413008640 logging_writer.py:48] [6327] accumulated_eval_time=33375.4, accumulated_logging_time=1.09093, accumulated_submission_time=6045.63, global_step=6327, preemption_count=0, score=6045.63, test/loss=0.126515, test/num_examples=95000000, total_duration=39422.4, train/loss=0.122551, validation/loss=0.124105, validation/num_examples=83274637
I0307 00:04:13.066370 140498421401344 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.00742520485073328, loss=0.12360157072544098
I0307 00:05:16.471723 140651857294528 spec.py:321] Evaluating on the training split.
I0307 00:06:07.956098 140651857294528 spec.py:333] Evaluating on the validation split.
I0307 00:09:11.721159 140651857294528 spec.py:349] Evaluating on the test split.
I0307 00:14:45.088354 140651857294528 submission_runner.py:469] Time since start: 40111.53s, 	Step: 6451, 	{'train/loss': 0.12201038202118573, 'validation/loss': 0.12403908312555899, 'validation/num_examples': 83274637, 'test/loss': 0.1263898390625, 'test/num_examples': 95000000, 'score': 6166.0940907001495, 'total_duration': 40111.52622318268, 'accumulated_submission_time': 6166.0940907001495, 'accumulated_eval_time': 33943.98127603531, 'accumulated_logging_time': 1.109558343887329}
I0307 00:14:45.098411 140498413008640 logging_writer.py:48] [6451] accumulated_eval_time=33944, accumulated_logging_time=1.10956, accumulated_submission_time=6166.09, global_step=6451, preemption_count=0, score=6166.09, test/loss=0.12639, test/num_examples=95000000, total_duration=40111.5, train/loss=0.12201, validation/loss=0.124039, validation/num_examples=83274637
I0307 00:15:12.680338 140498421401344 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.006651837378740311, loss=0.12105172872543335
I0307 00:16:45.951433 140651857294528 spec.py:321] Evaluating on the training split.
I0307 00:17:43.692666 140651857294528 spec.py:333] Evaluating on the validation split.
I0307 00:20:49.157387 140651857294528 spec.py:349] Evaluating on the test split.
I0307 00:26:38.100526 140651857294528 submission_runner.py:469] Time since start: 40824.54s, 	Step: 6583, 	{'train/loss': 0.12320003856512361, 'validation/loss': 0.12399068405491444, 'validation/num_examples': 83274637, 'test/loss': 0.1264061351665296, 'test/num_examples': 95000000, 'score': 6286.93448638916, 'total_duration': 40824.538427591324, 'accumulated_submission_time': 6286.93448638916, 'accumulated_eval_time': 34536.13030791283, 'accumulated_logging_time': 1.1261589527130127}
I0307 00:26:38.110333 140498413008640 logging_writer.py:48] [6583] accumulated_eval_time=34536.1, accumulated_logging_time=1.12616, accumulated_submission_time=6286.93, global_step=6583, preemption_count=0, score=6286.93, test/loss=0.126406, test/num_examples=95000000, total_duration=40824.5, train/loss=0.1232, validation/loss=0.123991, validation/num_examples=83274637
I0307 00:26:40.049207 140498421401344 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.01465507410466671, loss=0.12294254451990128
I0307 00:28:30.340049 140498413008640 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.0069816503673791885, loss=0.1194990947842598
I0307 00:28:38.493011 140651857294528 spec.py:321] Evaluating on the training split.
I0307 00:29:38.448716 140651857294528 spec.py:333] Evaluating on the validation split.
I0307 00:32:40.917408 140651857294528 spec.py:349] Evaluating on the test split.
I0307 00:38:28.258015 140651857294528 submission_runner.py:469] Time since start: 41534.70s, 	Step: 6708, 	{'train/loss': 0.12476014646953382, 'validation/loss': 0.1240272384526144, 'validation/num_examples': 83274637, 'test/loss': 0.1264680996196546, 'test/num_examples': 95000000, 'score': 6407.303883552551, 'total_duration': 41534.695927381516, 'accumulated_submission_time': 6407.303883552551, 'accumulated_eval_time': 35125.895265340805, 'accumulated_logging_time': 1.1421468257904053}
I0307 00:38:28.268332 140498421401344 logging_writer.py:48] [6708] accumulated_eval_time=35125.9, accumulated_logging_time=1.14215, accumulated_submission_time=6407.3, global_step=6708, preemption_count=0, score=6407.3, test/loss=0.126468, test/num_examples=95000000, total_duration=41534.7, train/loss=0.12476, validation/loss=0.124027, validation/num_examples=83274637
I0307 00:39:45.532021 140498413008640 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.00718818511813879, loss=0.12106934189796448
I0307 00:40:28.627478 140651857294528 spec.py:321] Evaluating on the training split.
I0307 00:41:23.293956 140651857294528 spec.py:333] Evaluating on the validation split.
I0307 00:44:28.111824 140651857294528 spec.py:349] Evaluating on the test split.
I0307 00:50:01.841013 140651857294528 submission_runner.py:469] Time since start: 42228.28s, 	Step: 6837, 	{'train/loss': 0.12178169053821068, 'validation/loss': 0.12390307626581128, 'validation/num_examples': 83274637, 'test/loss': 0.1262296876850329, 'test/num_examples': 95000000, 'score': 6527.605560064316, 'total_duration': 42228.278921842575, 'accumulated_submission_time': 6527.605560064316, 'accumulated_eval_time': 35699.10874414444, 'accumulated_logging_time': 1.203906774520874}
I0307 00:50:01.850907 140498421401344 logging_writer.py:48] [6837] accumulated_eval_time=35699.1, accumulated_logging_time=1.20391, accumulated_submission_time=6527.61, global_step=6837, preemption_count=0, score=6527.61, test/loss=0.12623, test/num_examples=95000000, total_duration=42228.3, train/loss=0.121782, validation/loss=0.123903, validation/num_examples=83274637
I0307 00:50:46.061466 140498413008640 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.006928132846951485, loss=0.12994477152824402
I0307 00:52:02.171003 140651857294528 spec.py:321] Evaluating on the training split.
I0307 00:52:54.163834 140651857294528 spec.py:333] Evaluating on the validation split.
I0307 00:55:55.717960 140651857294528 spec.py:349] Evaluating on the test split.
I0307 01:01:46.216707 140651857294528 submission_runner.py:469] Time since start: 42932.65s, 	Step: 6963, 	{'train/loss': 0.12346816857187252, 'validation/loss': 0.12391625068200912, 'validation/num_examples': 83274637, 'test/loss': 0.12627774678248355, 'test/num_examples': 95000000, 'score': 6647.912091732025, 'total_duration': 42932.65462064743, 'accumulated_submission_time': 6647.912091732025, 'accumulated_eval_time': 36283.15440273285, 'accumulated_logging_time': 1.2201542854309082}
I0307 01:01:46.227013 140498421401344 logging_writer.py:48] [6963] accumulated_eval_time=36283.2, accumulated_logging_time=1.22015, accumulated_submission_time=6647.91, global_step=6963, preemption_count=0, score=6647.91, test/loss=0.126278, test/num_examples=95000000, total_duration=42932.7, train/loss=0.123468, validation/loss=0.123916, validation/num_examples=83274637
I0307 01:02:00.975386 140498413008640 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.009126984514296055, loss=0.1286616325378418
I0307 01:03:46.819957 140651857294528 spec.py:321] Evaluating on the training split.
I0307 01:04:41.020370 140651857294528 spec.py:333] Evaluating on the validation split.
I0307 01:07:46.276672 140651857294528 spec.py:349] Evaluating on the test split.
I0307 01:13:28.873569 140651857294528 submission_runner.py:469] Time since start: 43635.31s, 	Step: 7086, 	{'train/loss': 0.12243157830206478, 'validation/loss': 0.12391387402166602, 'validation/num_examples': 83274637, 'test/loss': 0.12629450929276315, 'test/num_examples': 95000000, 'score': 6768.491855382919, 'total_duration': 43635.31145477295, 'accumulated_submission_time': 6768.491855382919, 'accumulated_eval_time': 36865.20793938637, 'accumulated_logging_time': 1.2369575500488281}
I0307 01:13:28.884227 140498421401344 logging_writer.py:48] [7086] accumulated_eval_time=36865.2, accumulated_logging_time=1.23696, accumulated_submission_time=6768.49, global_step=7086, preemption_count=0, score=6768.49, test/loss=0.126295, test/num_examples=95000000, total_duration=43635.3, train/loss=0.122432, validation/loss=0.123914, validation/num_examples=83274637
I0307 01:13:30.492447 140498413008640 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.009425719268620014, loss=0.12147025763988495
I0307 01:15:20.199360 140498421401344 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.0090143708512187, loss=0.126352459192276
I0307 01:15:29.317724 140651857294528 spec.py:321] Evaluating on the training split.
I0307 01:16:23.606047 140651857294528 spec.py:333] Evaluating on the validation split.
I0307 01:19:28.644349 140651857294528 spec.py:349] Evaluating on the test split.
I0307 01:25:07.197769 140651857294528 submission_runner.py:469] Time since start: 44333.64s, 	Step: 7209, 	{'train/loss': 0.12258229566351422, 'validation/loss': 0.1243209392424498, 'validation/num_examples': 83274637, 'test/loss': 0.12679388120888158, 'test/num_examples': 95000000, 'score': 6888.912811279297, 'total_duration': 44333.63565540314, 'accumulated_submission_time': 6888.912811279297, 'accumulated_eval_time': 37443.08790707588, 'accumulated_logging_time': 1.254134178161621}
I0307 01:25:07.208111 140498413008640 logging_writer.py:48] [7209] accumulated_eval_time=37443.1, accumulated_logging_time=1.25413, accumulated_submission_time=6888.91, global_step=7209, preemption_count=0, score=6888.91, test/loss=0.126794, test/num_examples=95000000, total_duration=44333.6, train/loss=0.122582, validation/loss=0.124321, validation/num_examples=83274637
I0307 01:26:25.644991 140498421401344 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.010180833749473095, loss=0.1158265620470047
I0307 01:27:07.295294 140651857294528 spec.py:321] Evaluating on the training split.
I0307 01:28:00.288044 140651857294528 spec.py:333] Evaluating on the validation split.
I0307 01:31:02.806087 140651857294528 spec.py:349] Evaluating on the test split.
I0307 01:37:00.554463 140651857294528 submission_runner.py:469] Time since start: 45046.99s, 	Step: 7337, 	{'train/loss': 0.12194953284829667, 'validation/loss': 0.12377321982408492, 'validation/num_examples': 83274637, 'test/loss': 0.12615572486636514, 'test/num_examples': 95000000, 'score': 7008.98715877533, 'total_duration': 45046.99235343933, 'accumulated_submission_time': 7008.98715877533, 'accumulated_eval_time': 38036.34699702263, 'accumulated_logging_time': 1.2710177898406982}
I0307 01:37:00.566361 140498413008640 logging_writer.py:48] [7337] accumulated_eval_time=38036.3, accumulated_logging_time=1.27102, accumulated_submission_time=7008.99, global_step=7337, preemption_count=0, score=7008.99, test/loss=0.126156, test/num_examples=95000000, total_duration=45047, train/loss=0.12195, validation/loss=0.123773, validation/num_examples=83274637
I0307 01:37:54.170848 140498421401344 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.013308877125382423, loss=0.12373384088277817
I0307 01:39:00.714898 140651857294528 spec.py:321] Evaluating on the training split.
I0307 01:39:55.993308 140651857294528 spec.py:333] Evaluating on the validation split.
I0307 01:43:01.533454 140651857294528 spec.py:349] Evaluating on the test split.
I0307 01:48:39.619714 140651857294528 submission_runner.py:469] Time since start: 45746.06s, 	Step: 7454, 	{'train/loss': 0.12174597466891666, 'validation/loss': 0.12390359814120985, 'validation/num_examples': 83274637, 'test/loss': 0.12628656729029605, 'test/num_examples': 95000000, 'score': 7129.122438192368, 'total_duration': 45746.057626485825, 'accumulated_submission_time': 7129.122438192368, 'accumulated_eval_time': 38615.25175905228, 'accumulated_logging_time': 1.2898931503295898}
I0307 01:48:39.630072 140498413008640 logging_writer.py:48] [7454] accumulated_eval_time=38615.3, accumulated_logging_time=1.28989, accumulated_submission_time=7129.12, global_step=7454, preemption_count=0, score=7129.12, test/loss=0.126287, test/num_examples=95000000, total_duration=45746.1, train/loss=0.121746, validation/loss=0.123904, validation/num_examples=83274637
I0307 01:49:03.483067 140498421401344 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.006375959143042564, loss=0.1199653372168541
I0307 01:50:40.193469 140651857294528 spec.py:321] Evaluating on the training split.
I0307 01:51:38.662066 140651857294528 spec.py:333] Evaluating on the validation split.
I0307 01:54:43.142880 140651857294528 spec.py:349] Evaluating on the test split.
I0307 02:00:25.710657 140651857294528 submission_runner.py:469] Time since start: 46452.15s, 	Step: 7573, 	{'train/loss': 0.12348200596353542, 'validation/loss': 0.12386847376442557, 'validation/num_examples': 83274637, 'test/loss': 0.1261723084087171, 'test/num_examples': 95000000, 'score': 7249.673212528229, 'total_duration': 46452.14857292175, 'accumulated_submission_time': 7249.673212528229, 'accumulated_eval_time': 39200.76890826225, 'accumulated_logging_time': 1.3066761493682861}
I0307 02:00:25.780908 140498413008640 logging_writer.py:48] [7573] accumulated_eval_time=39200.8, accumulated_logging_time=1.30668, accumulated_submission_time=7249.67, global_step=7573, preemption_count=0, score=7249.67, test/loss=0.126172, test/num_examples=95000000, total_duration=46452.1, train/loss=0.123482, validation/loss=0.123868, validation/num_examples=83274637
I0307 02:00:29.643532 140498421401344 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.005962262395769358, loss=0.124036505818367
I0307 02:02:26.192192 140651857294528 spec.py:321] Evaluating on the training split.
I0307 02:03:18.243978 140651857294528 spec.py:333] Evaluating on the validation split.
I0307 02:06:20.679097 140651857294528 spec.py:349] Evaluating on the test split.
I0307 02:12:06.107424 140651857294528 submission_runner.py:469] Time since start: 47152.55s, 	Step: 7700, 	{'train/loss': 0.12098765547779745, 'validation/loss': 0.1239316353346878, 'validation/num_examples': 83274637, 'test/loss': 0.12626669283511513, 'test/num_examples': 95000000, 'score': 7369.999773025513, 'total_duration': 47152.545298576355, 'accumulated_submission_time': 7369.999773025513, 'accumulated_eval_time': 39780.68405175209, 'accumulated_logging_time': 1.4552488327026367}
I0307 02:12:06.119556 140498413008640 logging_writer.py:48] [7700] accumulated_eval_time=39780.7, accumulated_logging_time=1.45525, accumulated_submission_time=7370, global_step=7700, preemption_count=0, score=7370, test/loss=0.126267, test/num_examples=95000000, total_duration=47152.5, train/loss=0.120988, validation/loss=0.123932, validation/num_examples=83274637
I0307 02:12:06.237089 140498421401344 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.0075162420980632305, loss=0.12802767753601074
I0307 02:13:41.413526 140498413008640 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.008405277505517006, loss=0.1313064843416214
I0307 02:14:06.974246 140651857294528 spec.py:321] Evaluating on the training split.
I0307 02:15:04.889370 140651857294528 spec.py:333] Evaluating on the validation split.
I0307 02:18:04.116600 140651857294528 spec.py:349] Evaluating on the test split.
I0307 02:23:55.104944 140651857294528 submission_runner.py:469] Time since start: 47861.54s, 	Step: 7822, 	{'train/loss': 0.12094193994530342, 'validation/loss': 0.12373132413100837, 'validation/num_examples': 83274637, 'test/loss': 0.12598943702713816, 'test/num_examples': 95000000, 'score': 7490.840028762817, 'total_duration': 47861.542850494385, 'accumulated_submission_time': 7490.840028762817, 'accumulated_eval_time': 40368.814693927765, 'accumulated_logging_time': 1.4743711948394775}
I0307 02:23:55.115045 140498421401344 logging_writer.py:48] [7822] accumulated_eval_time=40368.8, accumulated_logging_time=1.47437, accumulated_submission_time=7490.84, global_step=7822, preemption_count=0, score=7490.84, test/loss=0.125989, test/num_examples=95000000, total_duration=47861.5, train/loss=0.120942, validation/loss=0.123731, validation/num_examples=83274637
I0307 02:23:55.126007 140498413008640 logging_writer.py:48] [7822] global_step=7822, preemption_count=0, score=7490.84
I0307 02:23:55.967190 140651857294528 submission_runner.py:646] Tuning trial 2/5
I0307 02:23:55.992665 140651857294528 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.2, learning_rate=0.0008445074561975979, one_minus_beta1=0.11042418465, beta2=0.9978504782314613, weight_decay=0.08135402759553023, warmup_factor=0.05)
I0307 02:23:55.993767 140651857294528 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/loss': 0.8468768641633807, 'validation/loss': 0.8396444041051478, 'validation/num_examples': 83274637, 'test/loss': 0.8447341442434211, 'test/num_examples': 95000000, 'score': 17.51051688194275, 'total_duration': 1198.1077556610107, 'accumulated_submission_time': 17.51051688194275, 'accumulated_eval_time': 1180.5970673561096, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (124, {'train/loss': 0.13165923094365206, 'validation/loss': 0.13287403623013166, 'validation/num_examples': 83274637, 'test/loss': 0.1361750539165296, 'test/num_examples': 95000000, 'score': 138.28577494621277, 'total_duration': 2343.402681827545, 'accumulated_submission_time': 138.28577494621277, 'accumulated_eval_time': 2204.996488571167, 'accumulated_logging_time': 0.11409664154052734, 'global_step': 124, 'preemption_count': 0}), (242, {'train/loss': 0.13078994080190015, 'validation/loss': 0.13014530611551556, 'validation/num_examples': 83274637, 'test/loss': 0.13300973092105264, 'test/num_examples': 95000000, 'score': 258.94517993927, 'total_duration': 3506.366910457611, 'accumulated_submission_time': 258.94517993927, 'accumulated_eval_time': 3247.277646303177, 'accumulated_logging_time': 0.131760835647583, 'global_step': 242, 'preemption_count': 0}), (366, {'train/loss': 0.1292647971250351, 'validation/loss': 0.1285554359215302, 'validation/num_examples': 83274637, 'test/loss': 0.13098443510485197, 'test/num_examples': 95000000, 'score': 378.9810049533844, 'total_duration': 4709.2601227760315, 'accumulated_submission_time': 378.9810049533844, 'accumulated_eval_time': 4330.086905956268, 'accumulated_logging_time': 0.17319011688232422, 'global_step': 366, 'preemption_count': 0}), (489, {'train/loss': 0.1278986215661719, 'validation/loss': 0.12790689983218195, 'validation/num_examples': 83274637, 'test/loss': 0.13022834760485197, 'test/num_examples': 95000000, 'score': 499.2554967403412, 'total_duration': 5818.647523880005, 'accumulated_submission_time': 499.2554967403412, 'accumulated_eval_time': 5319.176256895065, 'accumulated_logging_time': 0.1897106170654297, 'global_step': 489, 'preemption_count': 0}), (611, {'train/loss': 0.12756432148879804, 'validation/loss': 0.1273053841392758, 'validation/num_examples': 83274637, 'test/loss': 0.1294932509765625, 'test/num_examples': 95000000, 'score': 619.6694910526276, 'total_duration': 6959.764257669449, 'accumulated_submission_time': 619.6694910526276, 'accumulated_eval_time': 6339.8571672439575, 'accumulated_logging_time': 0.20522022247314453, 'global_step': 611, 'preemption_count': 0}), (733, {'train/loss': 0.12411739952487391, 'validation/loss': 0.12661876283179752, 'validation/num_examples': 83274637, 'test/loss': 0.1288775078125, 'test/num_examples': 95000000, 'score': 740.0739302635193, 'total_duration': 8054.211392402649, 'accumulated_submission_time': 740.0739302635193, 'accumulated_eval_time': 7313.873615264893, 'accumulated_logging_time': 0.2211766242980957, 'global_step': 733, 'preemption_count': 0}), (856, {'train/loss': 0.12427519876861347, 'validation/loss': 0.1265790096106746, 'validation/num_examples': 83274637, 'test/loss': 0.1289225959189967, 'test/num_examples': 95000000, 'score': 860.1493990421295, 'total_duration': 9059.25832104683, 'accumulated_submission_time': 860.1493990421295, 'accumulated_eval_time': 8198.823070526123, 'accumulated_logging_time': 0.23624038696289062, 'global_step': 856, 'preemption_count': 0}), (980, {'train/loss': 0.12491215023932592, 'validation/loss': 0.12656091942538467, 'validation/num_examples': 83274637, 'test/loss': 0.12903860786389804, 'test/num_examples': 95000000, 'score': 980.7276062965393, 'total_duration': 9933.969725370407, 'accumulated_submission_time': 980.7276062965393, 'accumulated_eval_time': 8952.935188055038, 'accumulated_logging_time': 0.2505645751953125, 'global_step': 980, 'preemption_count': 0}), (1107, {'train/loss': 0.12233184648197402, 'validation/loss': 0.1262564442457619, 'validation/num_examples': 83274637, 'test/loss': 0.1284572827919408, 'test/num_examples': 95000000, 'score': 1101.8586184978485, 'total_duration': 10641.452624082565, 'accumulated_submission_time': 1101.8586184978485, 'accumulated_eval_time': 9539.265597343445, 'accumulated_logging_time': 0.26516008377075195, 'global_step': 1107, 'preemption_count': 0}), (1238, {'train/loss': 0.12496927833922629, 'validation/loss': 0.12598165055645935, 'validation/num_examples': 83274637, 'test/loss': 0.12829339068667764, 'test/num_examples': 95000000, 'score': 1222.7141873836517, 'total_duration': 11350.938090801239, 'accumulated_submission_time': 1222.7141873836517, 'accumulated_eval_time': 10127.873252391815, 'accumulated_logging_time': 0.28087806701660156, 'global_step': 1238, 'preemption_count': 0}), (1367, {'train/loss': 0.12573112720775903, 'validation/loss': 0.12666109016679428, 'validation/num_examples': 83274637, 'test/loss': 0.12908541226356907, 'test/num_examples': 95000000, 'score': 1344.2285900115967, 'total_duration': 12050.625841617584, 'accumulated_submission_time': 1344.2285900115967, 'accumulated_eval_time': 10706.02362704277, 'accumulated_logging_time': 0.2967653274536133, 'global_step': 1367, 'preemption_count': 0}), (1492, {'train/loss': 0.12507833654072675, 'validation/loss': 0.12683979877565016, 'validation/num_examples': 83274637, 'test/loss': 0.12954369391447368, 'test/num_examples': 95000000, 'score': 1464.8628129959106, 'total_duration': 12756.56100654602, 'accumulated_submission_time': 1464.8628129959106, 'accumulated_eval_time': 11291.302953243256, 'accumulated_logging_time': 0.31174278259277344, 'global_step': 1492, 'preemption_count': 0}), (1618, {'train/loss': 0.1241400532143296, 'validation/loss': 0.12558066604834953, 'validation/num_examples': 83274637, 'test/loss': 0.12804377916324014, 'test/num_examples': 95000000, 'score': 1585.1013505458832, 'total_duration': 13451.722628116608, 'accumulated_submission_time': 1585.1013505458832, 'accumulated_eval_time': 11866.205326795578, 'accumulated_logging_time': 0.32619214057922363, 'global_step': 1618, 'preemption_count': 0}), (1753, {'train/loss': 0.12363109089809018, 'validation/loss': 0.12557747522274737, 'validation/num_examples': 83274637, 'test/loss': 0.12796457404399672, 'test/num_examples': 95000000, 'score': 1705.6104550361633, 'total_duration': 14171.39682841301, 'accumulated_submission_time': 1705.6104550361633, 'accumulated_eval_time': 12465.34740614891, 'accumulated_logging_time': 0.3426346778869629, 'global_step': 1753, 'preemption_count': 0}), (1883, {'train/loss': 0.1239848710338837, 'validation/loss': 0.1256544372028642, 'validation/num_examples': 83274637, 'test/loss': 0.12813866979851973, 'test/num_examples': 95000000, 'score': 1826.676770210266, 'total_duration': 14886.758071899414, 'accumulated_submission_time': 1826.676770210266, 'accumulated_eval_time': 13059.621452093124, 'accumulated_logging_time': 0.3574647903442383, 'global_step': 1883, 'preemption_count': 0}), (2011, {'train/loss': 0.12495644775998292, 'validation/loss': 0.12576343708696158, 'validation/num_examples': 83274637, 'test/loss': 0.12811256052631578, 'test/num_examples': 95000000, 'score': 1947.5722000598907, 'total_duration': 15606.35813832283, 'accumulated_submission_time': 1947.5722000598907, 'accumulated_eval_time': 13658.303216457367, 'accumulated_logging_time': 0.37312936782836914, 'global_step': 2011, 'preemption_count': 0}), (2136, {'train/loss': 0.1216379342799854, 'validation/loss': 0.12542165951403367, 'validation/num_examples': 83274637, 'test/loss': 0.12778497641858552, 'test/num_examples': 95000000, 'score': 2068.0396132469177, 'total_duration': 16299.89810681343, 'accumulated_submission_time': 2068.0396132469177, 'accumulated_eval_time': 14231.352643728256, 'accumulated_logging_time': 0.38913941383361816, 'global_step': 2136, 'preemption_count': 0}), (2257, {'train/loss': 0.12376725453438249, 'validation/loss': 0.1253308979156354, 'validation/num_examples': 83274637, 'test/loss': 0.12776037979029606, 'test/num_examples': 95000000, 'score': 2188.8399634361267, 'total_duration': 17002.417342424393, 'accumulated_submission_time': 2188.8399634361267, 'accumulated_eval_time': 14813.050162553787, 'accumulated_logging_time': 0.40425777435302734, 'global_step': 2257, 'preemption_count': 0}), (2381, {'train/loss': 0.12348817355649651, 'validation/loss': 0.12538711490889626, 'validation/num_examples': 83274637, 'test/loss': 0.1278966222861842, 'test/num_examples': 95000000, 'score': 2309.1336331367493, 'total_duration': 17701.238498210907, 'accumulated_submission_time': 2309.1336331367493, 'accumulated_eval_time': 15391.55540060997, 'accumulated_logging_time': 0.41968607902526855, 'global_step': 2381, 'preemption_count': 0}), (2505, {'train/loss': 0.12531994881823003, 'validation/loss': 0.12523072736772145, 'validation/num_examples': 83274637, 'test/loss': 0.12755082786800986, 'test/num_examples': 95000000, 'score': 2429.659361600876, 'total_duration': 18397.718171834946, 'accumulated_submission_time': 2429.659361600876, 'accumulated_eval_time': 15967.485778570175, 'accumulated_logging_time': 0.43640565872192383, 'global_step': 2505, 'preemption_count': 0}), (2627, {'train/loss': 0.12285201941505543, 'validation/loss': 0.1251606670496129, 'validation/num_examples': 83274637, 'test/loss': 0.1275215230777138, 'test/num_examples': 95000000, 'score': 2549.778029680252, 'total_duration': 19083.35404109955, 'accumulated_submission_time': 2549.778029680252, 'accumulated_eval_time': 16532.981155395508, 'accumulated_logging_time': 0.45175623893737793, 'global_step': 2627, 'preemption_count': 0}), (2756, {'train/loss': 0.1250271589594817, 'validation/loss': 0.12481046580123115, 'validation/num_examples': 83274637, 'test/loss': 0.12729003046875, 'test/num_examples': 95000000, 'score': 2670.1203801631927, 'total_duration': 19789.39267730713, 'accumulated_submission_time': 2670.1203801631927, 'accumulated_eval_time': 17118.629784584045, 'accumulated_logging_time': 0.49337029457092285, 'global_step': 2756, 'preemption_count': 0}), (2885, {'train/loss': 0.12385352055466026, 'validation/loss': 0.1255128686796317, 'validation/num_examples': 83274637, 'test/loss': 0.1281385216796875, 'test/num_examples': 95000000, 'score': 2790.4438214302063, 'total_duration': 20480.372973442078, 'accumulated_submission_time': 2790.4438214302063, 'accumulated_eval_time': 17689.26319551468, 'accumulated_logging_time': 0.5100991725921631, 'global_step': 2885, 'preemption_count': 0}), (3006, {'train/loss': 0.12408096931359303, 'validation/loss': 0.12505477251294186, 'validation/num_examples': 83274637, 'test/loss': 0.12747361478207236, 'test/num_examples': 95000000, 'score': 2910.429848909378, 'total_duration': 21163.33367061615, 'accumulated_submission_time': 2910.429848909378, 'accumulated_eval_time': 18252.215242147446, 'accumulated_logging_time': 0.5264132022857666, 'global_step': 3006, 'preemption_count': 0}), (3134, {'train/loss': 0.12396142040174338, 'validation/loss': 0.12497159212746328, 'validation/num_examples': 83274637, 'test/loss': 0.1273595798519737, 'test/num_examples': 95000000, 'score': 3030.8343048095703, 'total_duration': 21854.992869377136, 'accumulated_submission_time': 3030.8343048095703, 'accumulated_eval_time': 18823.448016881943, 'accumulated_logging_time': 0.5419425964355469, 'global_step': 3134, 'preemption_count': 0}), (3256, {'train/loss': 0.12352669748635788, 'validation/loss': 0.12494236270751471, 'validation/num_examples': 83274637, 'test/loss': 0.1272778615131579, 'test/num_examples': 95000000, 'score': 3151.307098388672, 'total_duration': 22570.039531946182, 'accumulated_submission_time': 3151.307098388672, 'accumulated_eval_time': 19417.999048948288, 'accumulated_logging_time': 0.5577719211578369, 'global_step': 3256, 'preemption_count': 0}), (3386, {'train/loss': 0.1231222698734429, 'validation/loss': 0.12491472282513522, 'validation/num_examples': 83274637, 'test/loss': 0.12727893550575659, 'test/num_examples': 95000000, 'score': 3272.3222374916077, 'total_duration': 23287.158255577087, 'accumulated_submission_time': 3272.3222374916077, 'accumulated_eval_time': 20014.078914880753, 'accumulated_logging_time': 0.5746197700500488, 'global_step': 3386, 'preemption_count': 0}), (3516, {'train/loss': 0.12209073148386658, 'validation/loss': 0.12494745615839865, 'validation/num_examples': 83274637, 'test/loss': 0.12726066474095396, 'test/num_examples': 95000000, 'score': 3392.7003223896027, 'total_duration': 23998.05234026909, 'accumulated_submission_time': 3392.7003223896027, 'accumulated_eval_time': 20604.572757720947, 'accumulated_logging_time': 0.5902433395385742, 'global_step': 3516, 'preemption_count': 0}), (3645, {'train/loss': 0.12221984725750093, 'validation/loss': 0.12478758184293406, 'validation/num_examples': 83274637, 'test/loss': 0.1271138253700658, 'test/num_examples': 95000000, 'score': 3513.433576822281, 'total_duration': 24699.90816259384, 'accumulated_submission_time': 3513.433576822281, 'accumulated_eval_time': 21185.591124534607, 'accumulated_logging_time': 0.6867139339447021, 'global_step': 3645, 'preemption_count': 0}), (3770, {'train/loss': 0.12321369170720847, 'validation/loss': 0.12475728011691903, 'validation/num_examples': 83274637, 'test/loss': 0.12719411322985197, 'test/num_examples': 95000000, 'score': 3634.402688026428, 'total_duration': 25410.887385368347, 'accumulated_submission_time': 3634.402688026428, 'accumulated_eval_time': 21775.579063892365, 'accumulated_logging_time': 0.7025368213653564, 'global_step': 3770, 'preemption_count': 0}), (3896, {'train/loss': 0.1251876589566844, 'validation/loss': 0.12562481553788551, 'validation/num_examples': 83274637, 'test/loss': 0.12804074818050987, 'test/num_examples': 95000000, 'score': 3755.552521467209, 'total_duration': 26121.84099292755, 'accumulated_submission_time': 3755.552521467209, 'accumulated_eval_time': 22365.3586230278, 'accumulated_logging_time': 0.7202227115631104, 'global_step': 3896, 'preemption_count': 0}), (4024, {'train/loss': 0.12291745084730334, 'validation/loss': 0.12491091624941952, 'validation/num_examples': 83274637, 'test/loss': 0.12740046923314144, 'test/num_examples': 95000000, 'score': 3875.780742406845, 'total_duration': 26831.183886051178, 'accumulated_submission_time': 3875.780742406845, 'accumulated_eval_time': 22954.451852798462, 'accumulated_logging_time': 0.7354459762573242, 'global_step': 4024, 'preemption_count': 0}), (4146, {'train/loss': 0.12231111452686337, 'validation/loss': 0.12473896355342827, 'validation/num_examples': 83274637, 'test/loss': 0.1272196835629112, 'test/num_examples': 95000000, 'score': 3996.0177767276764, 'total_duration': 27528.260083913803, 'accumulated_submission_time': 3996.0177767276764, 'accumulated_eval_time': 23531.266834259033, 'accumulated_logging_time': 0.7528486251831055, 'global_step': 4146, 'preemption_count': 0}), (4271, {'train/loss': 0.12310923730849095, 'validation/loss': 0.12457783793668023, 'validation/num_examples': 83274637, 'test/loss': 0.12692073269942433, 'test/num_examples': 95000000, 'score': 4116.691578388214, 'total_duration': 28232.116079568863, 'accumulated_submission_time': 4116.691578388214, 'accumulated_eval_time': 24114.426236867905, 'accumulated_logging_time': 0.7685575485229492, 'global_step': 4271, 'preemption_count': 0}), (4397, {'train/loss': 0.12432889319347136, 'validation/loss': 0.12451053270952715, 'validation/num_examples': 83274637, 'test/loss': 0.12681708634868422, 'test/num_examples': 95000000, 'score': 4237.170535326004, 'total_duration': 28927.34323644638, 'accumulated_submission_time': 4237.170535326004, 'accumulated_eval_time': 24689.152673959732, 'accumulated_logging_time': 0.7838764190673828, 'global_step': 4397, 'preemption_count': 0}), (4526, {'train/loss': 0.12176572287794929, 'validation/loss': 0.1243412987742144, 'validation/num_examples': 83274637, 'test/loss': 0.12662408999794408, 'test/num_examples': 95000000, 'score': 4357.899606704712, 'total_duration': 29634.340282201767, 'accumulated_submission_time': 4357.899606704712, 'accumulated_eval_time': 25275.35197854042, 'accumulated_logging_time': 0.8461194038391113, 'global_step': 4526, 'preemption_count': 0}), (4652, {'train/loss': 0.12156340814892601, 'validation/loss': 0.12452679966139292, 'validation/num_examples': 83274637, 'test/loss': 0.1268375433696546, 'test/num_examples': 95000000, 'score': 4478.731933355331, 'total_duration': 30337.042452335358, 'accumulated_submission_time': 4478.731933355331, 'accumulated_eval_time': 25857.19980120659, 'accumulated_logging_time': 0.8615744113922119, 'global_step': 4652, 'preemption_count': 0}), (4775, {'train/loss': 0.12208045169757972, 'validation/loss': 0.12465389623927076, 'validation/num_examples': 83274637, 'test/loss': 0.127100912890625, 'test/num_examples': 95000000, 'score': 4598.916563272476, 'total_duration': 31042.595942497253, 'accumulated_submission_time': 4598.916563272476, 'accumulated_eval_time': 26442.547056674957, 'accumulated_logging_time': 0.8772487640380859, 'global_step': 4775, 'preemption_count': 0}), (4904, {'train/loss': 0.12000434517672977, 'validation/loss': 0.12438560094355695, 'validation/num_examples': 83274637, 'test/loss': 0.1268504113075658, 'test/num_examples': 95000000, 'score': 4719.107129096985, 'total_duration': 31747.308179616928, 'accumulated_submission_time': 4719.107129096985, 'accumulated_eval_time': 27027.045350313187, 'accumulated_logging_time': 0.8935179710388184, 'global_step': 4904, 'preemption_count': 0}), (5034, {'train/loss': 0.12385366548953941, 'validation/loss': 0.12494566977710339, 'validation/num_examples': 83274637, 'test/loss': 0.12738404704975329, 'test/num_examples': 95000000, 'score': 4840.683376789093, 'total_duration': 32457.116898059845, 'accumulated_submission_time': 4840.683376789093, 'accumulated_eval_time': 27615.25526356697, 'accumulated_logging_time': 0.9099223613739014, 'global_step': 5034, 'preemption_count': 0}), (5157, {'train/loss': 0.1233628557046067, 'validation/loss': 0.12440482533593557, 'validation/num_examples': 83274637, 'test/loss': 0.12674451749588816, 'test/num_examples': 95000000, 'score': 4960.714819908142, 'total_duration': 33146.03971242905, 'accumulated_submission_time': 4960.714819908142, 'accumulated_eval_time': 28184.124321699142, 'accumulated_logging_time': 0.9261705875396729, 'global_step': 5157, 'preemption_count': 0}), (5287, {'train/loss': 0.1246023823114686, 'validation/loss': 0.12435700032588404, 'validation/num_examples': 83274637, 'test/loss': 0.12675276105057565, 'test/num_examples': 95000000, 'score': 5081.51232790947, 'total_duration': 33854.15684604645, 'accumulated_submission_time': 5081.51232790947, 'accumulated_eval_time': 28771.418333292007, 'accumulated_logging_time': 0.9441499710083008, 'global_step': 5287, 'preemption_count': 0}), (5420, {'train/loss': 0.12340945704787407, 'validation/loss': 0.12458771131683603, 'validation/num_examples': 83274637, 'test/loss': 0.12708953586554275, 'test/num_examples': 95000000, 'score': 5202.472890853882, 'total_duration': 34549.44522380829, 'accumulated_submission_time': 5202.472890853882, 'accumulated_eval_time': 29345.723439216614, 'accumulated_logging_time': 0.9602022171020508, 'global_step': 5420, 'preemption_count': 0}), (5547, {'train/loss': 0.12128476369774567, 'validation/loss': 0.12423953548725766, 'validation/num_examples': 83274637, 'test/loss': 0.12667096429893093, 'test/num_examples': 95000000, 'score': 5322.994548797607, 'total_duration': 35234.50396442413, 'accumulated_submission_time': 5322.994548797607, 'accumulated_eval_time': 29910.23858356476, 'accumulated_logging_time': 0.9759297370910645, 'global_step': 5547, 'preemption_count': 0}), (5671, {'train/loss': 0.12324503911131958, 'validation/loss': 0.12435478768536616, 'validation/num_examples': 83274637, 'test/loss': 0.12676753462171053, 'test/num_examples': 95000000, 'score': 5443.052620649338, 'total_duration': 35924.59390425682, 'accumulated_submission_time': 5443.052620649338, 'accumulated_eval_time': 30480.248576641083, 'accumulated_logging_time': 0.9920907020568848, 'global_step': 5671, 'preemption_count': 0}), (5805, {'train/loss': 0.12218669832408803, 'validation/loss': 0.12421460785706614, 'validation/num_examples': 83274637, 'test/loss': 0.1267118974917763, 'test/num_examples': 95000000, 'score': 5564.073139667511, 'total_duration': 36626.4065387249, 'accumulated_submission_time': 5564.073139667511, 'accumulated_eval_time': 31061.01822423935, 'accumulated_logging_time': 1.0081450939178467, 'global_step': 5805, 'preemption_count': 0}), (5938, {'train/loss': 0.12455099655912732, 'validation/loss': 0.12408408587820532, 'validation/num_examples': 83274637, 'test/loss': 0.12654902644942434, 'test/num_examples': 95000000, 'score': 5684.264944076538, 'total_duration': 37328.96723628044, 'accumulated_submission_time': 5684.264944076538, 'accumulated_eval_time': 31643.36244249344, 'accumulated_logging_time': 1.025517463684082, 'global_step': 5938, 'preemption_count': 0}), (6073, {'train/loss': 0.12230221209051849, 'validation/loss': 0.12417118031744617, 'validation/num_examples': 83274637, 'test/loss': 0.12654970531455592, 'test/num_examples': 95000000, 'score': 5804.89813375473, 'total_duration': 38029.20930528641, 'accumulated_submission_time': 5804.89813375473, 'accumulated_eval_time': 32222.947456598282, 'accumulated_logging_time': 1.042325496673584, 'global_step': 6073, 'preemption_count': 0}), (6202, {'train/loss': 0.1224644680349332, 'validation/loss': 0.12417826883176815, 'validation/num_examples': 83274637, 'test/loss': 0.12660570711348684, 'test/num_examples': 95000000, 'score': 5925.489762544632, 'total_duration': 38720.05794811249, 'accumulated_submission_time': 5925.489762544632, 'accumulated_eval_time': 32793.18019986153, 'accumulated_logging_time': 1.060392141342163, 'global_step': 6202, 'preemption_count': 0}), (6327, {'train/loss': 0.12255117690788125, 'validation/loss': 0.12410471574100422, 'validation/num_examples': 83274637, 'test/loss': 0.12651501328125, 'test/num_examples': 95000000, 'score': 6045.625273942947, 'total_duration': 39422.41489505768, 'accumulated_submission_time': 6045.625273942947, 'accumulated_eval_time': 33375.36472725868, 'accumulated_logging_time': 1.0909276008605957, 'global_step': 6327, 'preemption_count': 0}), (6451, {'train/loss': 0.12201038202118573, 'validation/loss': 0.12403908312555899, 'validation/num_examples': 83274637, 'test/loss': 0.1263898390625, 'test/num_examples': 95000000, 'score': 6166.0940907001495, 'total_duration': 40111.52622318268, 'accumulated_submission_time': 6166.0940907001495, 'accumulated_eval_time': 33943.98127603531, 'accumulated_logging_time': 1.109558343887329, 'global_step': 6451, 'preemption_count': 0}), (6583, {'train/loss': 0.12320003856512361, 'validation/loss': 0.12399068405491444, 'validation/num_examples': 83274637, 'test/loss': 0.1264061351665296, 'test/num_examples': 95000000, 'score': 6286.93448638916, 'total_duration': 40824.538427591324, 'accumulated_submission_time': 6286.93448638916, 'accumulated_eval_time': 34536.13030791283, 'accumulated_logging_time': 1.1261589527130127, 'global_step': 6583, 'preemption_count': 0}), (6708, {'train/loss': 0.12476014646953382, 'validation/loss': 0.1240272384526144, 'validation/num_examples': 83274637, 'test/loss': 0.1264680996196546, 'test/num_examples': 95000000, 'score': 6407.303883552551, 'total_duration': 41534.695927381516, 'accumulated_submission_time': 6407.303883552551, 'accumulated_eval_time': 35125.895265340805, 'accumulated_logging_time': 1.1421468257904053, 'global_step': 6708, 'preemption_count': 0}), (6837, {'train/loss': 0.12178169053821068, 'validation/loss': 0.12390307626581128, 'validation/num_examples': 83274637, 'test/loss': 0.1262296876850329, 'test/num_examples': 95000000, 'score': 6527.605560064316, 'total_duration': 42228.278921842575, 'accumulated_submission_time': 6527.605560064316, 'accumulated_eval_time': 35699.10874414444, 'accumulated_logging_time': 1.203906774520874, 'global_step': 6837, 'preemption_count': 0}), (6963, {'train/loss': 0.12346816857187252, 'validation/loss': 0.12391625068200912, 'validation/num_examples': 83274637, 'test/loss': 0.12627774678248355, 'test/num_examples': 95000000, 'score': 6647.912091732025, 'total_duration': 42932.65462064743, 'accumulated_submission_time': 6647.912091732025, 'accumulated_eval_time': 36283.15440273285, 'accumulated_logging_time': 1.2201542854309082, 'global_step': 6963, 'preemption_count': 0}), (7086, {'train/loss': 0.12243157830206478, 'validation/loss': 0.12391387402166602, 'validation/num_examples': 83274637, 'test/loss': 0.12629450929276315, 'test/num_examples': 95000000, 'score': 6768.491855382919, 'total_duration': 43635.31145477295, 'accumulated_submission_time': 6768.491855382919, 'accumulated_eval_time': 36865.20793938637, 'accumulated_logging_time': 1.2369575500488281, 'global_step': 7086, 'preemption_count': 0}), (7209, {'train/loss': 0.12258229566351422, 'validation/loss': 0.1243209392424498, 'validation/num_examples': 83274637, 'test/loss': 0.12679388120888158, 'test/num_examples': 95000000, 'score': 6888.912811279297, 'total_duration': 44333.63565540314, 'accumulated_submission_time': 6888.912811279297, 'accumulated_eval_time': 37443.08790707588, 'accumulated_logging_time': 1.254134178161621, 'global_step': 7209, 'preemption_count': 0}), (7337, {'train/loss': 0.12194953284829667, 'validation/loss': 0.12377321982408492, 'validation/num_examples': 83274637, 'test/loss': 0.12615572486636514, 'test/num_examples': 95000000, 'score': 7008.98715877533, 'total_duration': 45046.99235343933, 'accumulated_submission_time': 7008.98715877533, 'accumulated_eval_time': 38036.34699702263, 'accumulated_logging_time': 1.2710177898406982, 'global_step': 7337, 'preemption_count': 0}), (7454, {'train/loss': 0.12174597466891666, 'validation/loss': 0.12390359814120985, 'validation/num_examples': 83274637, 'test/loss': 0.12628656729029605, 'test/num_examples': 95000000, 'score': 7129.122438192368, 'total_duration': 45746.057626485825, 'accumulated_submission_time': 7129.122438192368, 'accumulated_eval_time': 38615.25175905228, 'accumulated_logging_time': 1.2898931503295898, 'global_step': 7454, 'preemption_count': 0}), (7573, {'train/loss': 0.12348200596353542, 'validation/loss': 0.12386847376442557, 'validation/num_examples': 83274637, 'test/loss': 0.1261723084087171, 'test/num_examples': 95000000, 'score': 7249.673212528229, 'total_duration': 46452.14857292175, 'accumulated_submission_time': 7249.673212528229, 'accumulated_eval_time': 39200.76890826225, 'accumulated_logging_time': 1.3066761493682861, 'global_step': 7573, 'preemption_count': 0}), (7700, {'train/loss': 0.12098765547779745, 'validation/loss': 0.1239316353346878, 'validation/num_examples': 83274637, 'test/loss': 0.12626669283511513, 'test/num_examples': 95000000, 'score': 7369.999773025513, 'total_duration': 47152.545298576355, 'accumulated_submission_time': 7369.999773025513, 'accumulated_eval_time': 39780.68405175209, 'accumulated_logging_time': 1.4552488327026367, 'global_step': 7700, 'preemption_count': 0}), (7822, {'train/loss': 0.12094193994530342, 'validation/loss': 0.12373132413100837, 'validation/num_examples': 83274637, 'test/loss': 0.12598943702713816, 'test/num_examples': 95000000, 'score': 7490.840028762817, 'total_duration': 47861.542850494385, 'accumulated_submission_time': 7490.840028762817, 'accumulated_eval_time': 40368.814693927765, 'accumulated_logging_time': 1.4743711948394775, 'global_step': 7822, 'preemption_count': 0})], 'global_step': 7822}
I0307 02:23:55.993869 140651857294528 submission_runner.py:649] Timing: 7490.840028762817
I0307 02:23:55.993906 140651857294528 submission_runner.py:651] Total number of evals: 63
I0307 02:23:55.993933 140651857294528 submission_runner.py:652] ====================
I0307 02:23:55.994059 140651857294528 submission_runner.py:750] Final criteo1tb score: 1
