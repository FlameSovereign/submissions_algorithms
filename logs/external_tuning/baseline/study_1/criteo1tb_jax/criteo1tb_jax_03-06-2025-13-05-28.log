python submission_runner.py --framework=jax --workload=criteo1tb --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_1 --overwrite=True --save_checkpoints=False --rng_seed=1337895170 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=2 --hparam_end_index=3 2>&1 | tee -a /logs/criteo1tb_jax_03-06-2025-13-05-28.log
2025-03-06 13:05:46.393307: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741266347.113028       8 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741266347.315330       8 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0306 13:06:35.247165 140478046332096 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax.
I0306 13:06:38.198934 140478046332096 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0306 13:06:38.202827 140478046332096 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0306 13:06:38.212419 140478046332096 submission_runner.py:606] Using RNG seed 1337895170
I0306 13:06:41.828904 140478046332096 submission_runner.py:615] --- Tuning run 3/5 ---
I0306 13:06:41.829111 140478046332096 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_3.
I0306 13:06:41.829313 140478046332096 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_3/hparams.json.
I0306 13:06:42.070343 140478046332096 submission_runner.py:218] Initializing dataset.
I0306 13:06:42.070552 140478046332096 submission_runner.py:229] Initializing model.
I0306 13:06:52.402105 140478046332096 submission_runner.py:272] Initializing optimizer.
I0306 13:06:53.014297 140478046332096 submission_runner.py:279] Initializing metrics bundle.
I0306 13:06:53.014550 140478046332096 submission_runner.py:301] Initializing checkpoint and logger.
I0306 13:06:53.015287 140478046332096 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_3 with prefix checkpoint_
I0306 13:06:53.015393 140478046332096 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_3/meta_data_0.json.
I0306 13:06:53.015590 140478046332096 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0306 13:06:53.015645 140478046332096 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0306 13:06:53.562851 140478046332096 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_3/flags_0.json.
I0306 13:06:54.175370 140478046332096 submission_runner.py:337] Starting training loop.
I0306 13:07:11.299164 140336403834624 logging_writer.py:48] [0] global_step=0, grad_norm=8.441930770874023, loss=1.564972162246704
I0306 13:07:11.730268 140478046332096 spec.py:321] Evaluating on the training split.
I0306 13:13:23.031659 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 13:19:43.173286 140478046332096 spec.py:349] Evaluating on the test split.
I0306 13:26:50.558672 140478046332096 submission_runner.py:469] Time since start: 1196.38s, 	Step: 1, 	{'train/loss': 1.5643279462490443, 'validation/loss': 1.554338093362088, 'validation/num_examples': 83274637, 'test/loss': 1.558430137006579, 'test/num_examples': 95000000, 'score': 17.554768323898315, 'total_duration': 1196.383222579956, 'accumulated_submission_time': 17.554768323898315, 'accumulated_eval_time': 1178.8283214569092, 'accumulated_logging_time': 0}
I0306 13:26:50.585868 140325129529088 logging_writer.py:48] [1] accumulated_eval_time=1178.83, accumulated_logging_time=0, accumulated_submission_time=17.5548, global_step=1, preemption_count=0, score=17.5548, test/loss=1.55843, test/num_examples=95000000, total_duration=1196.38, train/loss=1.56433, validation/loss=1.55434, validation/num_examples=83274637
I0306 13:28:19.938519 140325121136384 logging_writer.py:48] [100] global_step=100, grad_norm=0.5260789394378662, loss=0.15561580657958984
I0306 13:28:51.518773 140478046332096 spec.py:321] Evaluating on the training split.
I0306 13:34:59.579388 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 13:40:05.111498 140478046332096 spec.py:349] Evaluating on the test split.
I0306 13:46:22.831325 140478046332096 submission_runner.py:469] Time since start: 2368.66s, 	Step: 124, 	{'train/loss': 0.14676508773703995, 'validation/loss': 0.1469547006204227, 'validation/num_examples': 83274637, 'test/loss': 0.15087009793379935, 'test/num_examples': 95000000, 'score': 138.4368302822113, 'total_duration': 2368.6558921337128, 'accumulated_submission_time': 138.4368302822113, 'accumulated_eval_time': 2230.14080953598, 'accumulated_logging_time': 0.0710759162902832}
I0306 13:46:22.841200 140325129529088 logging_writer.py:48] [124] accumulated_eval_time=2230.14, accumulated_logging_time=0.0710759, accumulated_submission_time=138.437, global_step=124, preemption_count=0, score=138.437, test/loss=0.15087, test/num_examples=95000000, total_duration=2368.66, train/loss=0.146765, validation/loss=0.146955, validation/num_examples=83274637
I0306 13:47:23.025082 140325121136384 logging_writer.py:48] [200] global_step=200, grad_norm=0.011423141695559025, loss=0.13670797646045685
I0306 13:48:23.812436 140478046332096 spec.py:321] Evaluating on the training split.
I0306 13:54:13.734631 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 13:59:45.935255 140478046332096 spec.py:349] Evaluating on the test split.
I0306 14:06:19.869219 140478046332096 submission_runner.py:469] Time since start: 3565.69s, 	Step: 251, 	{'train/loss': 0.13063181601699042, 'validation/loss': 0.1298651045800547, 'validation/num_examples': 83274637, 'test/loss': 0.13298397574013157, 'test/num_examples': 95000000, 'score': 259.3906283378601, 'total_duration': 3565.693806409836, 'accumulated_submission_time': 259.3906283378601, 'accumulated_eval_time': 3306.1975412368774, 'accumulated_logging_time': 0.09196019172668457}
I0306 14:06:19.877283 140325129529088 logging_writer.py:48] [251] accumulated_eval_time=3306.2, accumulated_logging_time=0.0919602, accumulated_submission_time=259.391, global_step=251, preemption_count=0, score=259.391, test/loss=0.132984, test/num_examples=95000000, total_duration=3565.69, train/loss=0.130632, validation/loss=0.129865, validation/num_examples=83274637
I0306 14:06:49.051115 140325121136384 logging_writer.py:48] [300] global_step=300, grad_norm=0.007710420526564121, loss=0.125542551279068
I0306 14:08:20.212797 140478046332096 spec.py:321] Evaluating on the training split.
I0306 14:14:24.891399 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 14:20:00.698513 140478046332096 spec.py:349] Evaluating on the test split.
I0306 14:26:11.639955 140478046332096 submission_runner.py:469] Time since start: 4757.46s, 	Step: 377, 	{'train/loss': 0.12744358409219567, 'validation/loss': 0.12830548942099412, 'validation/num_examples': 83274637, 'test/loss': 0.13087449351356908, 'test/num_examples': 95000000, 'score': 379.6320559978485, 'total_duration': 4757.464533805847, 'accumulated_submission_time': 379.6320559978485, 'accumulated_eval_time': 4377.624646663666, 'accumulated_logging_time': 0.18748736381530762}
I0306 14:26:11.649149 140325129529088 logging_writer.py:48] [377] accumulated_eval_time=4377.62, accumulated_logging_time=0.187487, accumulated_submission_time=379.632, global_step=377, preemption_count=0, score=379.632, test/loss=0.130874, test/num_examples=95000000, total_duration=4757.46, train/loss=0.127444, validation/loss=0.128305, validation/num_examples=83274637
I0306 14:26:14.186072 140325121136384 logging_writer.py:48] [400] global_step=400, grad_norm=0.012430598959326744, loss=0.12053520977497101
I0306 14:28:06.812923 140325129529088 logging_writer.py:48] [500] global_step=500, grad_norm=0.015056638047099113, loss=0.1226276159286499
I0306 14:28:12.774078 140478046332096 spec.py:321] Evaluating on the training split.
I0306 14:34:04.737035 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 14:39:34.433043 140478046332096 spec.py:349] Evaluating on the test split.
I0306 14:45:31.472944 140478046332096 submission_runner.py:469] Time since start: 5917.30s, 	Step: 506, 	{'train/loss': 0.12841418257814907, 'validation/loss': 0.12750278034249155, 'validation/num_examples': 83274637, 'test/loss': 0.1302071578433388, 'test/num_examples': 95000000, 'score': 500.7431161403656, 'total_duration': 5917.297533988953, 'accumulated_submission_time': 500.7431161403656, 'accumulated_eval_time': 5416.323463439941, 'accumulated_logging_time': 0.2034609317779541}
I0306 14:45:31.480753 140325121136384 logging_writer.py:48] [506] accumulated_eval_time=5416.32, accumulated_logging_time=0.203461, accumulated_submission_time=500.743, global_step=506, preemption_count=0, score=500.743, test/loss=0.130207, test/num_examples=95000000, total_duration=5917.3, train/loss=0.128414, validation/loss=0.127503, validation/num_examples=83274637
I0306 14:46:57.492763 140325129529088 logging_writer.py:48] [600] global_step=600, grad_norm=0.0290362648665905, loss=0.1273391842842102
I0306 14:47:31.647115 140478046332096 spec.py:321] Evaluating on the training split.
I0306 14:53:31.609551 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 14:58:25.110458 140478046332096 spec.py:349] Evaluating on the test split.
I0306 15:04:06.536350 140478046332096 submission_runner.py:469] Time since start: 7032.36s, 	Step: 630, 	{'train/loss': 0.1266249223910975, 'validation/loss': 0.12703634700463703, 'validation/num_examples': 83274637, 'test/loss': 0.12957333250411185, 'test/num_examples': 95000000, 'score': 620.8961129188538, 'total_duration': 7032.36092209816, 'accumulated_submission_time': 620.8961129188538, 'accumulated_eval_time': 6411.21263384819, 'accumulated_logging_time': 0.2177901268005371}
I0306 15:04:06.544344 140325121136384 logging_writer.py:48] [630] accumulated_eval_time=6411.21, accumulated_logging_time=0.21779, accumulated_submission_time=620.896, global_step=630, preemption_count=0, score=620.896, test/loss=0.129573, test/num_examples=95000000, total_duration=7032.36, train/loss=0.126625, validation/loss=0.127036, validation/num_examples=83274637
I0306 15:04:59.699675 140325129529088 logging_writer.py:48] [700] global_step=700, grad_norm=0.022958479821681976, loss=0.12462387979030609
I0306 15:06:06.565629 140478046332096 spec.py:321] Evaluating on the training split.
I0306 15:11:36.831053 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 15:16:11.320405 140478046332096 spec.py:349] Evaluating on the test split.
I0306 15:22:34.788563 140478046332096 submission_runner.py:469] Time since start: 8140.61s, 	Step: 754, 	{'train/loss': 0.1254932541259617, 'validation/loss': 0.12704325561489876, 'validation/num_examples': 83274637, 'test/loss': 0.12945047961554276, 'test/num_examples': 95000000, 'score': 740.9032416343689, 'total_duration': 8140.613120794296, 'accumulated_submission_time': 740.9032416343689, 'accumulated_eval_time': 7399.435496330261, 'accumulated_logging_time': 0.23218345642089844}
I0306 15:22:34.798114 140325121136384 logging_writer.py:48] [754] accumulated_eval_time=7399.44, accumulated_logging_time=0.232183, accumulated_submission_time=740.903, global_step=754, preemption_count=0, score=740.903, test/loss=0.12945, test/num_examples=95000000, total_duration=8140.61, train/loss=0.125493, validation/loss=0.127043, validation/num_examples=83274637
I0306 15:23:01.652226 140325129529088 logging_writer.py:48] [800] global_step=800, grad_norm=0.017797591164708138, loss=0.12650948762893677
I0306 15:24:35.224148 140478046332096 spec.py:321] Evaluating on the training split.
I0306 15:29:29.173202 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 15:33:49.124879 140478046332096 spec.py:349] Evaluating on the test split.
I0306 15:39:45.001107 140478046332096 submission_runner.py:469] Time since start: 9170.83s, 	Step: 881, 	{'train/loss': 0.12575014156974712, 'validation/loss': 0.12629015590483375, 'validation/num_examples': 83274637, 'test/loss': 0.1288488301089638, 'test/num_examples': 95000000, 'score': 861.3150129318237, 'total_duration': 9170.825680017471, 'accumulated_submission_time': 861.3150129318237, 'accumulated_eval_time': 8309.212390422821, 'accumulated_logging_time': 0.24882149696350098}
I0306 15:39:45.009279 140325121136384 logging_writer.py:48] [881] accumulated_eval_time=8309.21, accumulated_logging_time=0.248821, accumulated_submission_time=861.315, global_step=881, preemption_count=0, score=861.315, test/loss=0.128849, test/num_examples=95000000, total_duration=9170.83, train/loss=0.12575, validation/loss=0.12629, validation/num_examples=83274637
I0306 15:39:47.096831 140325129529088 logging_writer.py:48] [900] global_step=900, grad_norm=0.010697262361645699, loss=0.12599226832389832
I0306 15:41:34.708063 140325121136384 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.035723235458135605, loss=0.12104909121990204
I0306 15:41:45.774374 140478046332096 spec.py:321] Evaluating on the training split.
I0306 15:45:11.400495 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 15:48:24.365192 140478046332096 spec.py:349] Evaluating on the test split.
I0306 15:54:39.667675 140478046332096 submission_runner.py:469] Time since start: 10065.49s, 	Step: 1011, 	{'train/loss': 0.12976076452752705, 'validation/loss': 0.12623448636944373, 'validation/num_examples': 83274637, 'test/loss': 0.12875196859580593, 'test/num_examples': 95000000, 'score': 982.06720495224, 'total_duration': 10065.492263555527, 'accumulated_submission_time': 982.06720495224, 'accumulated_eval_time': 9083.105635643005, 'accumulated_logging_time': 0.26323938369750977}
I0306 15:54:39.675655 140325129529088 logging_writer.py:48] [1011] accumulated_eval_time=9083.11, accumulated_logging_time=0.263239, accumulated_submission_time=982.067, global_step=1011, preemption_count=0, score=982.067, test/loss=0.128752, test/num_examples=95000000, total_duration=10065.5, train/loss=0.129761, validation/loss=0.126234, validation/num_examples=83274637
I0306 15:55:54.641716 140325121136384 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.01464373990893364, loss=0.13122853636741638
I0306 15:56:39.850503 140478046332096 spec.py:321] Evaluating on the training split.
I0306 15:57:35.272777 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 16:00:46.796977 140478046332096 spec.py:349] Evaluating on the test split.
I0306 16:07:02.604453 140478046332096 submission_runner.py:469] Time since start: 10808.43s, 	Step: 1141, 	{'train/loss': 0.1261857660639586, 'validation/loss': 0.12606750919166046, 'validation/num_examples': 83274637, 'test/loss': 0.12861445922080592, 'test/num_examples': 95000000, 'score': 1102.2286915779114, 'total_duration': 10808.429029464722, 'accumulated_submission_time': 1102.2286915779114, 'accumulated_eval_time': 9705.8595225811, 'accumulated_logging_time': 0.27788281440734863}
I0306 16:07:02.612706 140325129529088 logging_writer.py:48] [1141] accumulated_eval_time=9705.86, accumulated_logging_time=0.277883, accumulated_submission_time=1102.23, global_step=1141, preemption_count=0, score=1102.23, test/loss=0.128614, test/num_examples=95000000, total_duration=10808.4, train/loss=0.126186, validation/loss=0.126068, validation/num_examples=83274637
I0306 16:07:44.384535 140325121136384 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.013970009051263332, loss=0.12264702469110489
I0306 16:09:03.422739 140478046332096 spec.py:321] Evaluating on the training split.
I0306 16:09:10.785626 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 16:12:19.845538 140478046332096 spec.py:349] Evaluating on the test split.
I0306 16:18:24.629532 140478046332096 submission_runner.py:469] Time since start: 11490.45s, 	Step: 1273, 	{'train/loss': 0.12435483262411454, 'validation/loss': 0.1257960795769421, 'validation/num_examples': 83274637, 'test/loss': 0.12814976915090462, 'test/num_examples': 95000000, 'score': 1223.0243318080902, 'total_duration': 11490.45410823822, 'accumulated_submission_time': 1223.0243318080902, 'accumulated_eval_time': 10267.066249608994, 'accumulated_logging_time': 0.2926304340362549}
I0306 16:18:24.637534 140325129529088 logging_writer.py:48] [1273] accumulated_eval_time=10267.1, accumulated_logging_time=0.29263, accumulated_submission_time=1223.02, global_step=1273, preemption_count=0, score=1223.02, test/loss=0.12815, test/num_examples=95000000, total_duration=11490.5, train/loss=0.124355, validation/loss=0.125796, validation/num_examples=83274637
I0306 16:18:28.219812 140325121136384 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.021696945652365685, loss=0.1271064430475235
I0306 16:20:24.796347 140478046332096 spec.py:321] Evaluating on the training split.
I0306 16:20:32.161574 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 16:23:40.477756 140478046332096 spec.py:349] Evaluating on the test split.
I0306 16:29:52.518648 140478046332096 submission_runner.py:469] Time since start: 12178.34s, 	Step: 1399, 	{'train/loss': 0.1246185830483834, 'validation/loss': 0.12581940183810109, 'validation/num_examples': 83274637, 'test/loss': 0.12824688838404605, 'test/num_examples': 95000000, 'score': 1343.1694192886353, 'total_duration': 12178.343220472336, 'accumulated_submission_time': 1343.1694192886353, 'accumulated_eval_time': 10834.788488149643, 'accumulated_logging_time': 0.30718183517456055}
I0306 16:29:52.527214 140325129529088 logging_writer.py:48] [1399] accumulated_eval_time=10834.8, accumulated_logging_time=0.307182, accumulated_submission_time=1343.17, global_step=1399, preemption_count=0, score=1343.17, test/loss=0.128247, test/num_examples=95000000, total_duration=12178.3, train/loss=0.124619, validation/loss=0.125819, validation/num_examples=83274637
I0306 16:29:52.765924 140325121136384 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.023017259314656258, loss=0.12995490431785583
I0306 16:31:20.156341 140325129529088 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.021357083693146706, loss=0.12802454829216003
I0306 16:31:52.549558 140478046332096 spec.py:321] Evaluating on the training split.
I0306 16:31:59.907518 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 16:35:10.286411 140478046332096 spec.py:349] Evaluating on the test split.
I0306 16:41:23.829070 140478046332096 submission_runner.py:469] Time since start: 12869.65s, 	Step: 1528, 	{'train/loss': 0.12407894063530103, 'validation/loss': 0.12569256951080285, 'validation/num_examples': 83274637, 'test/loss': 0.1279889480571546, 'test/num_examples': 95000000, 'score': 1463.177746295929, 'total_duration': 12869.653655290604, 'accumulated_submission_time': 1463.177746295929, 'accumulated_eval_time': 11406.067941188812, 'accumulated_logging_time': 0.3225138187408447}
I0306 16:41:23.838251 140325121136384 logging_writer.py:48] [1528] accumulated_eval_time=11406.1, accumulated_logging_time=0.322514, accumulated_submission_time=1463.18, global_step=1528, preemption_count=0, score=1463.18, test/loss=0.127989, test/num_examples=95000000, total_duration=12869.7, train/loss=0.124079, validation/loss=0.125693, validation/num_examples=83274637
I0306 16:42:17.883731 140325129529088 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.020673876628279686, loss=0.11990991234779358
I0306 16:43:24.636164 140478046332096 spec.py:321] Evaluating on the training split.
I0306 16:43:31.970932 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 16:46:42.502634 140478046332096 spec.py:349] Evaluating on the test split.
I0306 16:52:49.110266 140478046332096 submission_runner.py:469] Time since start: 13554.93s, 	Step: 1663, 	{'train/loss': 0.12587155346647375, 'validation/loss': 0.12572233399903623, 'validation/num_examples': 83274637, 'test/loss': 0.12817866753700657, 'test/num_examples': 95000000, 'score': 1583.961757183075, 'total_duration': 13554.934842586517, 'accumulated_submission_time': 1583.961757183075, 'accumulated_eval_time': 11970.541976690292, 'accumulated_logging_time': 0.3386857509613037}
I0306 16:52:49.118748 140325121136384 logging_writer.py:48] [1663] accumulated_eval_time=11970.5, accumulated_logging_time=0.338686, accumulated_submission_time=1583.96, global_step=1663, preemption_count=0, score=1583.96, test/loss=0.128179, test/num_examples=95000000, total_duration=13554.9, train/loss=0.125872, validation/loss=0.125722, validation/num_examples=83274637
I0306 16:53:03.912246 140325129529088 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.007418584078550339, loss=0.11789324134588242
I0306 16:54:49.658630 140478046332096 spec.py:321] Evaluating on the training split.
I0306 16:54:57.066653 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 16:58:07.774647 140478046332096 spec.py:349] Evaluating on the test split.
I0306 17:04:09.764212 140478046332096 submission_runner.py:469] Time since start: 14235.59s, 	Step: 1793, 	{'train/loss': 0.12390250415078499, 'validation/loss': 0.1259307169447362, 'validation/num_examples': 83274637, 'test/loss': 0.12837540990953947, 'test/num_examples': 95000000, 'score': 1704.4877960681915, 'total_duration': 14235.588782787323, 'accumulated_submission_time': 1704.4877960681915, 'accumulated_eval_time': 12530.647500038147, 'accumulated_logging_time': 0.3540196418762207}
I0306 17:04:09.772251 140325121136384 logging_writer.py:48] [1793] accumulated_eval_time=12530.6, accumulated_logging_time=0.35402, accumulated_submission_time=1704.49, global_step=1793, preemption_count=0, score=1704.49, test/loss=0.128375, test/num_examples=95000000, total_duration=14235.6, train/loss=0.123903, validation/loss=0.125931, validation/num_examples=83274637
I0306 17:04:10.631563 140325129529088 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.03440968692302704, loss=0.1285175383090973
I0306 17:05:45.069570 140325121136384 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.044966381043195724, loss=0.13280019164085388
I0306 17:06:10.127201 140478046332096 spec.py:321] Evaluating on the training split.
I0306 17:06:17.517776 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 17:09:29.605295 140478046332096 spec.py:349] Evaluating on the test split.
I0306 17:15:43.632814 140478046332096 submission_runner.py:469] Time since start: 14929.46s, 	Step: 1921, 	{'train/loss': 0.12448471761162176, 'validation/loss': 0.1255535986375532, 'validation/num_examples': 83274637, 'test/loss': 0.12805319506578947, 'test/num_examples': 95000000, 'score': 1824.8284029960632, 'total_duration': 14929.457396507263, 'accumulated_submission_time': 1824.8284029960632, 'accumulated_eval_time': 13104.153054714203, 'accumulated_logging_time': 0.36905360221862793}
I0306 17:15:43.642235 140325129529088 logging_writer.py:48] [1921] accumulated_eval_time=13104.2, accumulated_logging_time=0.369054, accumulated_submission_time=1824.83, global_step=1921, preemption_count=0, score=1824.83, test/loss=0.128053, test/num_examples=95000000, total_duration=14929.5, train/loss=0.124485, validation/loss=0.125554, validation/num_examples=83274637
I0306 17:16:48.866245 140325121136384 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.009611777029931545, loss=0.11980350315570831
I0306 17:17:44.208350 140478046332096 spec.py:321] Evaluating on the training split.
I0306 17:17:51.644293 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 17:21:04.758302 140478046332096 spec.py:349] Evaluating on the test split.
I0306 17:27:31.734396 140478046332096 submission_runner.py:469] Time since start: 15637.56s, 	Step: 2047, 	{'train/loss': 0.12460140702343962, 'validation/loss': 0.12541039834192516, 'validation/num_examples': 83274637, 'test/loss': 0.12787072002467106, 'test/num_examples': 95000000, 'score': 1945.380578994751, 'total_duration': 15637.5589864254, 'accumulated_submission_time': 1945.380578994751, 'accumulated_eval_time': 13691.679047584534, 'accumulated_logging_time': 0.38525819778442383}
I0306 17:27:31.743114 140325129529088 logging_writer.py:48] [2047] accumulated_eval_time=13691.7, accumulated_logging_time=0.385258, accumulated_submission_time=1945.38, global_step=2047, preemption_count=0, score=1945.38, test/loss=0.127871, test/num_examples=95000000, total_duration=15637.6, train/loss=0.124601, validation/loss=0.12541, validation/num_examples=83274637
I0306 17:28:03.545050 140325121136384 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.05611184984445572, loss=0.1297949254512787
I0306 17:29:32.249381 140478046332096 spec.py:321] Evaluating on the training split.
I0306 17:29:39.732908 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 17:32:51.010886 140478046332096 spec.py:349] Evaluating on the test split.
I0306 17:38:51.582532 140478046332096 submission_runner.py:469] Time since start: 16317.41s, 	Step: 2179, 	{'train/loss': 0.12478902863350304, 'validation/loss': 0.1255483392494779, 'validation/num_examples': 83274637, 'test/loss': 0.12806700280633224, 'test/num_examples': 95000000, 'score': 2065.8742623329163, 'total_duration': 16317.40709900856, 'accumulated_submission_time': 2065.8742623329163, 'accumulated_eval_time': 14251.01211977005, 'accumulated_logging_time': 0.40017032623291016}
I0306 17:38:51.617098 140325129529088 logging_writer.py:48] [2179] accumulated_eval_time=14251, accumulated_logging_time=0.40017, accumulated_submission_time=2065.87, global_step=2179, preemption_count=0, score=2065.87, test/loss=0.128067, test/num_examples=95000000, total_duration=16317.4, train/loss=0.124789, validation/loss=0.125548, validation/num_examples=83274637
I0306 17:38:53.956279 140325121136384 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.006324077025055885, loss=0.12121690809726715
I0306 17:40:48.102525 140325129529088 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.01711786724627018, loss=0.12133990228176117
I0306 17:40:52.271889 140478046332096 spec.py:321] Evaluating on the training split.
I0306 17:40:59.756470 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 17:44:07.596526 140478046332096 spec.py:349] Evaluating on the test split.
I0306 17:50:28.580111 140478046332096 submission_runner.py:469] Time since start: 17014.40s, 	Step: 2305, 	{'train/loss': 0.12417204009146436, 'validation/loss': 0.12546434597698433, 'validation/num_examples': 83274637, 'test/loss': 0.12786355264185856, 'test/num_examples': 95000000, 'score': 2186.51450920105, 'total_duration': 17014.404703378677, 'accumulated_submission_time': 2186.51450920105, 'accumulated_eval_time': 14827.320286273956, 'accumulated_logging_time': 0.4418661594390869}
I0306 17:50:28.588737 140325121136384 logging_writer.py:48] [2305] accumulated_eval_time=14827.3, accumulated_logging_time=0.441866, accumulated_submission_time=2186.51, global_step=2305, preemption_count=0, score=2186.51, test/loss=0.127864, test/num_examples=95000000, total_duration=17014.4, train/loss=0.124172, validation/loss=0.125464, validation/num_examples=83274637
I0306 17:51:52.804000 140325129529088 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.01232105027884245, loss=0.11788270622491837
I0306 17:52:29.957031 140478046332096 spec.py:321] Evaluating on the training split.
I0306 17:52:37.336279 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 17:55:47.868010 140478046332096 spec.py:349] Evaluating on the test split.
I0306 18:01:53.315829 140478046332096 submission_runner.py:469] Time since start: 17699.14s, 	Step: 2432, 	{'train/loss': 0.1256449488020918, 'validation/loss': 0.12549165574989612, 'validation/num_examples': 83274637, 'test/loss': 0.1277846369449013, 'test/num_examples': 95000000, 'score': 2307.8695497512817, 'total_duration': 17699.1404004097, 'accumulated_submission_time': 2307.8695497512817, 'accumulated_eval_time': 15390.679008960724, 'accumulated_logging_time': 0.4575679302215576}
I0306 18:01:53.324327 140325121136384 logging_writer.py:48] [2432] accumulated_eval_time=15390.7, accumulated_logging_time=0.457568, accumulated_submission_time=2307.87, global_step=2432, preemption_count=0, score=2307.87, test/loss=0.127785, test/num_examples=95000000, total_duration=17699.1, train/loss=0.125645, validation/loss=0.125492, validation/num_examples=83274637
I0306 18:02:46.610432 140325129529088 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.017966125160455704, loss=0.13073837757110596
I0306 18:03:54.087616 140478046332096 spec.py:321] Evaluating on the training split.
I0306 18:04:01.501328 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 18:07:10.298096 140478046332096 spec.py:349] Evaluating on the test split.
I0306 18:13:10.008494 140478046332096 submission_runner.py:469] Time since start: 18375.83s, 	Step: 2559, 	{'train/loss': 0.12484655393369543, 'validation/loss': 0.12536965207173276, 'validation/num_examples': 83274637, 'test/loss': 0.1277759156455592, 'test/num_examples': 95000000, 'score': 2428.619769334793, 'total_duration': 18375.833077430725, 'accumulated_submission_time': 2428.619769334793, 'accumulated_eval_time': 15946.599844932556, 'accumulated_logging_time': 0.4726545810699463}
I0306 18:13:10.016914 140325121136384 logging_writer.py:48] [2559] accumulated_eval_time=15946.6, accumulated_logging_time=0.472655, accumulated_submission_time=2428.62, global_step=2559, preemption_count=0, score=2428.62, test/loss=0.127776, test/num_examples=95000000, total_duration=18375.8, train/loss=0.124847, validation/loss=0.12537, validation/num_examples=83274637
I0306 18:13:29.057917 140325129529088 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.005926900543272495, loss=0.13348975777626038
I0306 18:15:11.347442 140478046332096 spec.py:321] Evaluating on the training split.
I0306 18:15:18.729720 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 18:18:29.159972 140478046332096 spec.py:349] Evaluating on the test split.
I0306 18:24:46.734583 140478046332096 submission_runner.py:469] Time since start: 19072.56s, 	Step: 2688, 	{'train/loss': 0.12509728698704228, 'validation/loss': 0.12530836832998968, 'validation/num_examples': 83274637, 'test/loss': 0.127854564453125, 'test/num_examples': 95000000, 'score': 2549.931867837906, 'total_duration': 19072.559165477753, 'accumulated_submission_time': 2549.931867837906, 'accumulated_eval_time': 16521.986930131912, 'accumulated_logging_time': 0.49251866340637207}
I0306 18:24:46.743810 140325121136384 logging_writer.py:48] [2688] accumulated_eval_time=16522, accumulated_logging_time=0.492519, accumulated_submission_time=2549.93, global_step=2688, preemption_count=0, score=2549.93, test/loss=0.127855, test/num_examples=95000000, total_duration=19072.6, train/loss=0.125097, validation/loss=0.125308, validation/num_examples=83274637
I0306 18:24:48.104057 140325129529088 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.021226517856121063, loss=0.12523432075977325
I0306 18:26:22.537122 140325121136384 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.029385266825556755, loss=0.12630879878997803
I0306 18:26:48.172003 140478046332096 spec.py:321] Evaluating on the training split.
I0306 18:26:55.556471 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 18:30:05.390643 140478046332096 spec.py:349] Evaluating on the test split.
I0306 18:36:26.240291 140478046332096 submission_runner.py:469] Time since start: 19772.06s, 	Step: 2822, 	{'train/loss': 0.12225597497052366, 'validation/loss': 0.1255851622836592, 'validation/num_examples': 83274637, 'test/loss': 0.12811425926192435, 'test/num_examples': 95000000, 'score': 2671.3471899032593, 'total_duration': 19772.064861297607, 'accumulated_submission_time': 2671.3471899032593, 'accumulated_eval_time': 17100.055140018463, 'accumulated_logging_time': 0.5082402229309082}
I0306 18:36:26.273475 140325129529088 logging_writer.py:48] [2822] accumulated_eval_time=17100.1, accumulated_logging_time=0.50824, accumulated_submission_time=2671.35, global_step=2822, preemption_count=0, score=2671.35, test/loss=0.128114, test/num_examples=95000000, total_duration=19772.1, train/loss=0.122256, validation/loss=0.125585, validation/num_examples=83274637
I0306 18:37:30.989118 140325121136384 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.032740216702222824, loss=0.12575122714042664
I0306 18:38:27.288971 140478046332096 spec.py:321] Evaluating on the training split.
I0306 18:38:34.673305 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 18:41:44.869187 140478046332096 spec.py:349] Evaluating on the test split.
I0306 18:47:53.248547 140478046332096 submission_runner.py:469] Time since start: 20459.07s, 	Step: 2948, 	{'train/loss': 0.12546463493468626, 'validation/loss': 0.12507515874710823, 'validation/num_examples': 83274637, 'test/loss': 0.1273711386821546, 'test/num_examples': 95000000, 'score': 2792.3495619297028, 'total_duration': 20459.07313323021, 'accumulated_submission_time': 2792.3495619297028, 'accumulated_eval_time': 17666.014655590057, 'accumulated_logging_time': 0.5479557514190674}
I0306 18:47:53.257371 140325129529088 logging_writer.py:48] [2948] accumulated_eval_time=17666, accumulated_logging_time=0.547956, accumulated_submission_time=2792.35, global_step=2948, preemption_count=0, score=2792.35, test/loss=0.127371, test/num_examples=95000000, total_duration=20459.1, train/loss=0.125465, validation/loss=0.125075, validation/num_examples=83274637
I0306 18:48:26.401170 140325121136384 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.02631295472383499, loss=0.13775065541267395
I0306 18:49:55.062952 140478046332096 spec.py:321] Evaluating on the training split.
I0306 18:50:02.501060 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 18:53:12.329931 140478046332096 spec.py:349] Evaluating on the test split.
I0306 18:59:13.264852 140478046332096 submission_runner.py:469] Time since start: 21139.09s, 	Step: 3071, 	{'train/loss': 0.12355792243619385, 'validation/loss': 0.12503744198576858, 'validation/num_examples': 83274637, 'test/loss': 0.12734697806332237, 'test/num_examples': 95000000, 'score': 2914.1416778564453, 'total_duration': 21139.089408636093, 'accumulated_submission_time': 2914.1416778564453, 'accumulated_eval_time': 18224.216467142105, 'accumulated_logging_time': 0.5634949207305908}
I0306 18:59:13.273313 140325129529088 logging_writer.py:48] [3071] accumulated_eval_time=18224.2, accumulated_logging_time=0.563495, accumulated_submission_time=2914.14, global_step=3071, preemption_count=0, score=2914.14, test/loss=0.127347, test/num_examples=95000000, total_duration=21139.1, train/loss=0.123558, validation/loss=0.125037, validation/num_examples=83274637
I0306 18:59:19.152647 140325121136384 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.0073255798779428005, loss=0.13170433044433594
I0306 19:01:13.786468 140478046332096 spec.py:321] Evaluating on the training split.
I0306 19:01:21.165215 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 19:04:29.780703 140478046332096 spec.py:349] Evaluating on the test split.
I0306 19:10:43.992123 140478046332096 submission_runner.py:469] Time since start: 21829.82s, 	Step: 3195, 	{'train/loss': 0.12356853861150877, 'validation/loss': 0.12507293460825705, 'validation/num_examples': 83274637, 'test/loss': 0.12743322465049342, 'test/num_examples': 95000000, 'score': 3034.6326928138733, 'total_duration': 21829.816714525223, 'accumulated_submission_time': 3034.6326928138733, 'accumulated_eval_time': 18794.422073602676, 'accumulated_logging_time': 0.5880229473114014}
I0306 19:10:44.000882 140325129529088 logging_writer.py:48] [3195] accumulated_eval_time=18794.4, accumulated_logging_time=0.588023, accumulated_submission_time=3034.63, global_step=3195, preemption_count=0, score=3034.63, test/loss=0.127433, test/num_examples=95000000, total_duration=21829.8, train/loss=0.123569, validation/loss=0.125073, validation/num_examples=83274637
I0306 19:10:44.643109 140325121136384 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.020787091925740242, loss=0.12097195535898209
I0306 19:12:20.775827 140325129529088 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.006110737100243568, loss=0.12711714208126068
I0306 19:12:44.115633 140478046332096 spec.py:321] Evaluating on the training split.
I0306 19:12:51.601044 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 19:16:01.930510 140478046332096 spec.py:349] Evaluating on the test split.
I0306 19:22:18.045367 140478046332096 submission_runner.py:469] Time since start: 22523.87s, 	Step: 3319, 	{'train/loss': 0.1251623838460483, 'validation/loss': 0.125159601855978, 'validation/num_examples': 83274637, 'test/loss': 0.12743895261101973, 'test/num_examples': 95000000, 'score': 3154.732905626297, 'total_duration': 22523.8699259758, 'accumulated_submission_time': 3154.732905626297, 'accumulated_eval_time': 19368.351719856262, 'accumulated_logging_time': 0.6046538352966309}
I0306 19:22:18.055131 140325121136384 logging_writer.py:48] [3319] accumulated_eval_time=19368.4, accumulated_logging_time=0.604654, accumulated_submission_time=3154.73, global_step=3319, preemption_count=0, score=3154.73, test/loss=0.127439, test/num_examples=95000000, total_duration=22523.9, train/loss=0.125162, validation/loss=0.12516, validation/num_examples=83274637
I0306 19:23:29.869516 140325129529088 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.008624550886452198, loss=0.11943056434392929
I0306 19:24:18.533576 140478046332096 spec.py:321] Evaluating on the training split.
I0306 19:24:25.904064 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 19:27:37.115544 140478046332096 spec.py:349] Evaluating on the test split.
I0306 19:33:50.560478 140478046332096 submission_runner.py:469] Time since start: 23216.39s, 	Step: 3441, 	{'train/loss': 0.12427752511868687, 'validation/loss': 0.12514792980462047, 'validation/num_examples': 83274637, 'test/loss': 0.12753883857935855, 'test/num_examples': 95000000, 'score': 3275.197326898575, 'total_duration': 23216.38505935669, 'accumulated_submission_time': 3275.197326898575, 'accumulated_eval_time': 19940.378561735153, 'accumulated_logging_time': 0.6212949752807617}
I0306 19:33:50.569178 140325121136384 logging_writer.py:48] [3441] accumulated_eval_time=19940.4, accumulated_logging_time=0.621295, accumulated_submission_time=3275.2, global_step=3441, preemption_count=0, score=3275.2, test/loss=0.127539, test/num_examples=95000000, total_duration=23216.4, train/loss=0.124278, validation/loss=0.125148, validation/num_examples=83274637
I0306 19:34:30.030256 140325129529088 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.010586797259747982, loss=0.11833041906356812
I0306 19:35:50.913812 140478046332096 spec.py:321] Evaluating on the training split.
I0306 19:35:58.348504 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 19:39:06.928235 140478046332096 spec.py:349] Evaluating on the test split.
I0306 19:45:16.354368 140478046332096 submission_runner.py:469] Time since start: 23902.18s, 	Step: 3562, 	{'train/loss': 0.12295111234786, 'validation/loss': 0.12510137096570104, 'validation/num_examples': 83274637, 'test/loss': 0.127446999609375, 'test/num_examples': 95000000, 'score': 3395.5289919376373, 'total_duration': 23902.17893576622, 'accumulated_submission_time': 3395.5289919376373, 'accumulated_eval_time': 20505.819056272507, 'accumulated_logging_time': 0.6364827156066895}
I0306 19:45:16.363351 140325121136384 logging_writer.py:48] [3562] accumulated_eval_time=20505.8, accumulated_logging_time=0.636483, accumulated_submission_time=3395.53, global_step=3562, preemption_count=0, score=3395.53, test/loss=0.127447, test/num_examples=95000000, total_duration=23902.2, train/loss=0.122951, validation/loss=0.125101, validation/num_examples=83274637
I0306 19:45:31.906993 140325129529088 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.008494961075484753, loss=0.12229252606630325
I0306 19:47:17.098811 140478046332096 spec.py:321] Evaluating on the training split.
I0306 19:47:24.520744 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 19:50:35.126499 140478046332096 spec.py:349] Evaluating on the test split.
I0306 19:56:24.439994 140478046332096 submission_runner.py:469] Time since start: 24570.26s, 	Step: 3693, 	{'train/loss': 0.124784325231921, 'validation/loss': 0.1251223912206625, 'validation/num_examples': 83274637, 'test/loss': 0.12740889857113488, 'test/num_examples': 95000000, 'score': 3516.2516479492188, 'total_duration': 24570.264561653137, 'accumulated_submission_time': 3516.2516479492188, 'accumulated_eval_time': 21053.160164117813, 'accumulated_logging_time': 0.6517095565795898}
I0306 19:56:24.448807 140325121136384 logging_writer.py:48] [3693] accumulated_eval_time=21053.2, accumulated_logging_time=0.65171, accumulated_submission_time=3516.25, global_step=3693, preemption_count=0, score=3516.25, test/loss=0.127409, test/num_examples=95000000, total_duration=24570.3, train/loss=0.124784, validation/loss=0.125122, validation/num_examples=83274637
I0306 19:56:25.324965 140325129529088 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.02147279866039753, loss=0.1203758493065834
I0306 19:58:06.772920 140325121136384 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.015337496064603329, loss=0.1317756026983261
I0306 19:58:25.324125 140478046332096 spec.py:321] Evaluating on the training split.
I0306 19:58:32.780279 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 20:01:40.258986 140478046332096 spec.py:349] Evaluating on the test split.
I0306 20:07:34.929129 140478046332096 submission_runner.py:469] Time since start: 25240.75s, 	Step: 3816, 	{'train/loss': 0.12479039511215761, 'validation/loss': 0.12499024841656996, 'validation/num_examples': 83274637, 'test/loss': 0.12726430571546052, 'test/num_examples': 95000000, 'score': 3637.113730430603, 'total_duration': 25240.753722906113, 'accumulated_submission_time': 3637.113730430603, 'accumulated_eval_time': 21602.765113830566, 'accumulated_logging_time': 0.6670820713043213}
I0306 20:07:34.938660 140325129529088 logging_writer.py:48] [3816] accumulated_eval_time=21602.8, accumulated_logging_time=0.667082, accumulated_submission_time=3637.11, global_step=3816, preemption_count=0, score=3637.11, test/loss=0.127264, test/num_examples=95000000, total_duration=25240.8, train/loss=0.12479, validation/loss=0.12499, validation/num_examples=83274637
I0306 20:08:43.902213 140325121136384 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.0068497140891849995, loss=0.13170114159584045
I0306 20:09:35.828711 140478046332096 spec.py:321] Evaluating on the training split.
I0306 20:09:43.241243 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 20:12:54.065537 140478046332096 spec.py:349] Evaluating on the test split.
I0306 20:19:07.450371 140478046332096 submission_runner.py:469] Time since start: 25933.27s, 	Step: 3945, 	{'train/loss': 0.12263125864168008, 'validation/loss': 0.12509838908023588, 'validation/num_examples': 83274637, 'test/loss': 0.12736087434210527, 'test/num_examples': 95000000, 'score': 3757.9903812408447, 'total_duration': 25933.274955511093, 'accumulated_submission_time': 3757.9903812408447, 'accumulated_eval_time': 22174.386714696884, 'accumulated_logging_time': 0.6830539703369141}
I0306 20:19:07.459443 140325129529088 logging_writer.py:48] [3945] accumulated_eval_time=22174.4, accumulated_logging_time=0.683054, accumulated_submission_time=3757.99, global_step=3945, preemption_count=0, score=3757.99, test/loss=0.127361, test/num_examples=95000000, total_duration=25933.3, train/loss=0.122631, validation/loss=0.125098, validation/num_examples=83274637
I0306 20:19:43.915836 140325121136384 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.008673780597746372, loss=0.11890250444412231
I0306 20:21:08.507551 140478046332096 spec.py:321] Evaluating on the training split.
I0306 20:21:15.928111 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 20:24:24.920198 140478046332096 spec.py:349] Evaluating on the test split.
I0306 20:30:16.365794 140478046332096 submission_runner.py:469] Time since start: 26602.19s, 	Step: 4072, 	{'train/loss': 0.1237830160736288, 'validation/loss': 0.12494631665656496, 'validation/num_examples': 83274637, 'test/loss': 0.1272601976459704, 'test/num_examples': 95000000, 'score': 3879.001822948456, 'total_duration': 26602.1903860569, 'accumulated_submission_time': 3879.001822948456, 'accumulated_eval_time': 22722.244903087616, 'accumulated_logging_time': 0.7213518619537354}
I0306 20:30:16.374733 140325129529088 logging_writer.py:48] [4072] accumulated_eval_time=22722.2, accumulated_logging_time=0.721352, accumulated_submission_time=3879, global_step=4072, preemption_count=0, score=3879, test/loss=0.12726, test/num_examples=95000000, total_duration=26602.2, train/loss=0.123783, validation/loss=0.124946, validation/num_examples=83274637
I0306 20:30:21.004562 140325121136384 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.013582353480160236, loss=0.11984959244728088
I0306 20:32:17.432135 140478046332096 spec.py:321] Evaluating on the training split.
I0306 20:32:24.767432 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 20:35:32.055424 140478046332096 spec.py:349] Evaluating on the test split.
I0306 20:41:34.275063 140478046332096 submission_runner.py:469] Time since start: 27280.10s, 	Step: 4195, 	{'train/loss': 0.12372184517857789, 'validation/loss': 0.1249731570617654, 'validation/num_examples': 83274637, 'test/loss': 0.12739083367598683, 'test/num_examples': 95000000, 'score': 4000.045855283737, 'total_duration': 27280.09962797165, 'accumulated_submission_time': 4000.045855283737, 'accumulated_eval_time': 23279.087752580643, 'accumulated_logging_time': 0.7364778518676758}
I0306 20:41:34.285608 140325129529088 logging_writer.py:48] [4195] accumulated_eval_time=23279.1, accumulated_logging_time=0.736478, accumulated_submission_time=4000.05, global_step=4195, preemption_count=0, score=4000.05, test/loss=0.127391, test/num_examples=95000000, total_duration=27280.1, train/loss=0.123722, validation/loss=0.124973, validation/num_examples=83274637
I0306 20:41:34.926371 140325121136384 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.008222075179219246, loss=0.12342382967472076
I0306 20:43:09.669939 140325129529088 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.011626766994595528, loss=0.1269184798002243
I0306 20:43:34.332750 140478046332096 spec.py:321] Evaluating on the training split.
I0306 20:43:41.708887 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 20:46:52.505419 140478046332096 spec.py:349] Evaluating on the test split.
I0306 20:52:59.644185 140478046332096 submission_runner.py:469] Time since start: 27965.47s, 	Step: 4320, 	{'train/loss': 0.12372396534906244, 'validation/loss': 0.12509821552048803, 'validation/num_examples': 83274637, 'test/loss': 0.12745343686266447, 'test/num_examples': 95000000, 'score': 4120.079644441605, 'total_duration': 27965.468767642975, 'accumulated_submission_time': 4120.079644441605, 'accumulated_eval_time': 23844.39912223816, 'accumulated_logging_time': 0.7537472248077393}
I0306 20:52:59.653867 140325121136384 logging_writer.py:48] [4320] accumulated_eval_time=23844.4, accumulated_logging_time=0.753747, accumulated_submission_time=4120.08, global_step=4320, preemption_count=0, score=4120.08, test/loss=0.127453, test/num_examples=95000000, total_duration=27965.5, train/loss=0.123724, validation/loss=0.125098, validation/num_examples=83274637
I0306 20:54:04.119967 140325129529088 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.01611994579434395, loss=0.125681534409523
I0306 20:55:00.811369 140478046332096 spec.py:321] Evaluating on the training split.
I0306 20:55:08.276486 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 20:58:17.608984 140478046332096 spec.py:349] Evaluating on the test split.
I0306 21:04:15.599881 140478046332096 submission_runner.py:469] Time since start: 28641.42s, 	Step: 4452, 	{'train/loss': 0.12582913360927464, 'validation/loss': 0.12492268979218502, 'validation/num_examples': 83274637, 'test/loss': 0.12723401062911185, 'test/num_examples': 95000000, 'score': 4241.191298484802, 'total_duration': 28641.424456834793, 'accumulated_submission_time': 4241.191298484802, 'accumulated_eval_time': 24399.18756389618, 'accumulated_logging_time': 0.8021435737609863}
I0306 21:04:15.629233 140325121136384 logging_writer.py:48] [4452] accumulated_eval_time=24399.2, accumulated_logging_time=0.802144, accumulated_submission_time=4241.19, global_step=4452, preemption_count=0, score=4241.19, test/loss=0.127234, test/num_examples=95000000, total_duration=28641.4, train/loss=0.125829, validation/loss=0.124923, validation/num_examples=83274637
I0306 21:04:43.240876 140325129529088 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.008026477880775928, loss=0.127144455909729
I0306 21:06:16.003529 140478046332096 spec.py:321] Evaluating on the training split.
I0306 21:06:23.324507 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 21:09:34.587480 140478046332096 spec.py:349] Evaluating on the test split.
I0306 21:15:37.309667 140478046332096 submission_runner.py:469] Time since start: 29323.13s, 	Step: 4581, 	{'train/loss': 0.1247426931213283, 'validation/loss': 0.12481299998463592, 'validation/num_examples': 83274637, 'test/loss': 0.12724466645764804, 'test/num_examples': 95000000, 'score': 4361.552614688873, 'total_duration': 29323.13425898552, 'accumulated_submission_time': 4361.552614688873, 'accumulated_eval_time': 24960.49365758896, 'accumulated_logging_time': 0.8378274440765381}
I0306 21:15:37.318860 140325121136384 logging_writer.py:48] [4581] accumulated_eval_time=24960.5, accumulated_logging_time=0.837827, accumulated_submission_time=4361.55, global_step=4581, preemption_count=0, score=4361.55, test/loss=0.127245, test/num_examples=95000000, total_duration=29323.1, train/loss=0.124743, validation/loss=0.124813, validation/num_examples=83274637
I0306 21:15:39.451901 140325129529088 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.014851962216198444, loss=0.12200295925140381
I0306 21:17:29.782061 140325121136384 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.007919375784695148, loss=0.11748071759939194
I0306 21:17:37.988999 140478046332096 spec.py:321] Evaluating on the training split.
I0306 21:17:45.288278 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 21:20:52.789715 140478046332096 spec.py:349] Evaluating on the test split.
I0306 21:26:51.137263 140478046332096 submission_runner.py:469] Time since start: 29996.96s, 	Step: 4708, 	{'train/loss': 0.12230284909173003, 'validation/loss': 0.1246844894635731, 'validation/num_examples': 83274637, 'test/loss': 0.12702142392064145, 'test/num_examples': 95000000, 'score': 4482.209956645966, 'total_duration': 29996.961845874786, 'accumulated_submission_time': 4482.209956645966, 'accumulated_eval_time': 25513.64185810089, 'accumulated_logging_time': 0.8537154197692871}
I0306 21:26:51.146591 140325129529088 logging_writer.py:48] [4708] accumulated_eval_time=25513.6, accumulated_logging_time=0.853715, accumulated_submission_time=4482.21, global_step=4708, preemption_count=0, score=4482.21, test/loss=0.127021, test/num_examples=95000000, total_duration=29997, train/loss=0.122303, validation/loss=0.124684, validation/num_examples=83274637
I0306 21:28:14.462538 140325121136384 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.01666838862001896, loss=0.13449393212795258
I0306 21:28:51.451797 140478046332096 spec.py:321] Evaluating on the training split.
I0306 21:28:58.837913 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 21:32:07.108889 140478046332096 spec.py:349] Evaluating on the test split.
I0306 21:38:04.571767 140478046332096 submission_runner.py:469] Time since start: 30670.40s, 	Step: 4833, 	{'train/loss': 0.12358026265067125, 'validation/loss': 0.1248654430091324, 'validation/num_examples': 83274637, 'test/loss': 0.12727901067023026, 'test/num_examples': 95000000, 'score': 4602.503079891205, 'total_duration': 30670.396349191666, 'accumulated_submission_time': 4602.503079891205, 'accumulated_eval_time': 26066.76176381111, 'accumulated_logging_time': 0.8691861629486084}
I0306 21:38:04.580773 140325129529088 logging_writer.py:48] [4833] accumulated_eval_time=26066.8, accumulated_logging_time=0.869186, accumulated_submission_time=4602.5, global_step=4833, preemption_count=0, score=4602.5, test/loss=0.127279, test/num_examples=95000000, total_duration=30670.4, train/loss=0.12358, validation/loss=0.124865, validation/num_examples=83274637
I0306 21:39:02.797510 140325121136384 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.011984176933765411, loss=0.1292303204536438
I0306 21:40:04.952994 140478046332096 spec.py:321] Evaluating on the training split.
I0306 21:40:12.232911 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 21:43:19.847890 140478046332096 spec.py:349] Evaluating on the test split.
I0306 21:49:15.272973 140478046332096 submission_runner.py:469] Time since start: 31341.10s, 	Step: 4950, 	{'train/loss': 0.12218069735000718, 'validation/loss': 0.12477362345852788, 'validation/num_examples': 83274637, 'test/loss': 0.12730673182565788, 'test/num_examples': 95000000, 'score': 4722.854833602905, 'total_duration': 31341.097544193268, 'accumulated_submission_time': 4722.854833602905, 'accumulated_eval_time': 26617.08167076111, 'accumulated_logging_time': 0.8915328979492188}
I0306 21:49:15.282437 140325129529088 logging_writer.py:48] [4950] accumulated_eval_time=26617.1, accumulated_logging_time=0.891533, accumulated_submission_time=4722.85, global_step=4950, preemption_count=0, score=4722.85, test/loss=0.127307, test/num_examples=95000000, total_duration=31341.1, train/loss=0.122181, validation/loss=0.124774, validation/num_examples=83274637
I0306 21:49:45.902650 140325121136384 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.010506629943847656, loss=0.12482252717018127
I0306 21:51:16.037572 140478046332096 spec.py:321] Evaluating on the training split.
I0306 21:51:23.398872 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 21:54:33.748890 140478046332096 spec.py:349] Evaluating on the test split.
I0306 22:00:27.073209 140478046332096 submission_runner.py:469] Time since start: 32012.90s, 	Step: 5076, 	{'train/loss': 0.12343536292747506, 'validation/loss': 0.12463917394570682, 'validation/num_examples': 83274637, 'test/loss': 0.12701670238486842, 'test/num_examples': 95000000, 'score': 4843.595588445663, 'total_duration': 32012.897755622864, 'accumulated_submission_time': 4843.595588445663, 'accumulated_eval_time': 27168.117213249207, 'accumulated_logging_time': 0.9082489013671875}
I0306 22:00:27.083821 140325129529088 logging_writer.py:48] [5076] accumulated_eval_time=27168.1, accumulated_logging_time=0.908249, accumulated_submission_time=4843.6, global_step=5076, preemption_count=0, score=4843.6, test/loss=0.127017, test/num_examples=95000000, total_duration=32012.9, train/loss=0.123435, validation/loss=0.124639, validation/num_examples=83274637
I0306 22:00:29.701343 140325121136384 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.0085549745708704, loss=0.11964022368192673
I0306 22:02:27.678334 140478046332096 spec.py:321] Evaluating on the training split.
I0306 22:02:35.125043 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 22:05:47.640788 140478046332096 spec.py:349] Evaluating on the test split.
I0306 22:11:58.248460 140478046332096 submission_runner.py:469] Time since start: 32704.07s, 	Step: 5196, 	{'train/loss': 0.1246374396126975, 'validation/loss': 0.12452992669792425, 'validation/num_examples': 83274637, 'test/loss': 0.12683617874177633, 'test/num_examples': 95000000, 'score': 4964.177098751068, 'total_duration': 32704.073038816452, 'accumulated_submission_time': 4964.177098751068, 'accumulated_eval_time': 27738.687275648117, 'accumulated_logging_time': 0.9254529476165771}
I0306 22:11:58.259095 140325129529088 logging_writer.py:48] [5196] accumulated_eval_time=27738.7, accumulated_logging_time=0.925453, accumulated_submission_time=4964.18, global_step=5196, preemption_count=0, score=4964.18, test/loss=0.126836, test/num_examples=95000000, total_duration=32704.1, train/loss=0.124637, validation/loss=0.12453, validation/num_examples=83274637
I0306 22:11:58.808738 140325121136384 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.011601977981626987, loss=0.1195128783583641
I0306 22:13:30.269283 140325129529088 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.022517506033182144, loss=0.13223984837532043
I0306 22:13:58.250910 140478046332096 spec.py:321] Evaluating on the training split.
I0306 22:14:05.647226 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 22:17:14.588819 140478046332096 spec.py:349] Evaluating on the test split.
I0306 22:23:13.136570 140478046332096 submission_runner.py:469] Time since start: 33378.96s, 	Step: 5323, 	{'train/loss': 0.12161061971348787, 'validation/loss': 0.12455201786930148, 'validation/num_examples': 83274637, 'test/loss': 0.12700974284539474, 'test/num_examples': 95000000, 'score': 5084.154655694962, 'total_duration': 33378.96115016937, 'accumulated_submission_time': 5084.154655694962, 'accumulated_eval_time': 28293.572871923447, 'accumulated_logging_time': 0.9430966377258301}
I0306 22:23:13.146342 140325121136384 logging_writer.py:48] [5323] accumulated_eval_time=28293.6, accumulated_logging_time=0.943097, accumulated_submission_time=5084.15, global_step=5323, preemption_count=0, score=5084.15, test/loss=0.12701, test/num_examples=95000000, total_duration=33379, train/loss=0.121611, validation/loss=0.124552, validation/num_examples=83274637
I0306 22:24:13.719338 140325129529088 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.0076740942895412445, loss=0.12459467351436615
I0306 22:25:13.421041 140478046332096 spec.py:321] Evaluating on the training split.
I0306 22:25:20.819000 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 22:28:27.678441 140478046332096 spec.py:349] Evaluating on the test split.
I0306 22:34:25.571277 140478046332096 submission_runner.py:469] Time since start: 34051.40s, 	Step: 5451, 	{'train/loss': 0.12193303583365567, 'validation/loss': 0.12460708516409347, 'validation/num_examples': 83274637, 'test/loss': 0.12702956279810856, 'test/num_examples': 95000000, 'score': 5204.415857791901, 'total_duration': 34051.39586830139, 'accumulated_submission_time': 5204.415857791901, 'accumulated_eval_time': 28845.72306203842, 'accumulated_logging_time': 0.9593415260314941}
I0306 22:34:25.581163 140325121136384 logging_writer.py:48] [5451] accumulated_eval_time=28845.7, accumulated_logging_time=0.959342, accumulated_submission_time=5204.42, global_step=5451, preemption_count=0, score=5204.42, test/loss=0.12703, test/num_examples=95000000, total_duration=34051.4, train/loss=0.121933, validation/loss=0.124607, validation/num_examples=83274637
I0306 22:34:56.634910 140325129529088 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.010745379142463207, loss=0.11370786279439926
I0306 22:36:26.729781 140478046332096 spec.py:321] Evaluating on the training split.
I0306 22:36:34.143631 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 22:39:39.994374 140478046332096 spec.py:349] Evaluating on the test split.
I0306 22:45:41.168641 140478046332096 submission_runner.py:469] Time since start: 34726.99s, 	Step: 5576, 	{'train/loss': 0.12207660556964155, 'validation/loss': 0.12421180242205679, 'validation/num_examples': 83274637, 'test/loss': 0.1266040540604441, 'test/num_examples': 95000000, 'score': 5325.550531387329, 'total_duration': 34726.99320721626, 'accumulated_submission_time': 5325.550531387329, 'accumulated_eval_time': 29400.161841869354, 'accumulated_logging_time': 0.9761569499969482}
I0306 22:45:41.178101 140325121136384 logging_writer.py:48] [5576] accumulated_eval_time=29400.2, accumulated_logging_time=0.976157, accumulated_submission_time=5325.55, global_step=5576, preemption_count=0, score=5325.55, test/loss=0.126604, test/num_examples=95000000, total_duration=34727, train/loss=0.122077, validation/loss=0.124212, validation/num_examples=83274637
I0306 22:45:43.851962 140325129529088 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.01108456775546074, loss=0.1259969174861908
I0306 22:47:39.673920 140325121136384 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.01050268579274416, loss=0.12760835886001587
I0306 22:47:41.846734 140478046332096 spec.py:321] Evaluating on the training split.
I0306 22:47:49.205210 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 22:50:53.537188 140478046332096 spec.py:349] Evaluating on the test split.
I0306 22:56:58.869704 140478046332096 submission_runner.py:469] Time since start: 35404.69s, 	Step: 5703, 	{'train/loss': 0.12074117238322894, 'validation/loss': 0.12442536233254235, 'validation/num_examples': 83274637, 'test/loss': 0.12677003684210528, 'test/num_examples': 95000000, 'score': 5446.205047607422, 'total_duration': 35404.694294929504, 'accumulated_submission_time': 5446.205047607422, 'accumulated_eval_time': 29957.184755325317, 'accumulated_logging_time': 0.9923720359802246}
I0306 22:56:58.879529 140325129529088 logging_writer.py:48] [5703] accumulated_eval_time=29957.2, accumulated_logging_time=0.992372, accumulated_submission_time=5446.21, global_step=5703, preemption_count=0, score=5446.21, test/loss=0.12677, test/num_examples=95000000, total_duration=35404.7, train/loss=0.120741, validation/loss=0.124425, validation/num_examples=83274637
I0306 22:58:27.655567 140325121136384 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.018520884215831757, loss=0.12067445367574692
I0306 22:58:58.931856 140478046332096 spec.py:321] Evaluating on the training split.
I0306 22:59:06.314134 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 23:02:05.800071 140478046332096 spec.py:349] Evaluating on the test split.
I0306 23:07:53.526860 140478046332096 submission_runner.py:469] Time since start: 36059.35s, 	Step: 5828, 	{'train/loss': 0.12107502301252863, 'validation/loss': 0.12445772843448795, 'validation/num_examples': 83274637, 'test/loss': 0.12686341712582236, 'test/num_examples': 95000000, 'score': 5566.244394779205, 'total_duration': 36059.35145139694, 'accumulated_submission_time': 5566.244394779205, 'accumulated_eval_time': 30491.779702425003, 'accumulated_logging_time': 1.00844144821167}
I0306 23:07:53.536657 140325129529088 logging_writer.py:48] [5828] accumulated_eval_time=30491.8, accumulated_logging_time=1.00844, accumulated_submission_time=5566.24, global_step=5828, preemption_count=0, score=5566.24, test/loss=0.126863, test/num_examples=95000000, total_duration=36059.4, train/loss=0.121075, validation/loss=0.124458, validation/num_examples=83274637
I0306 23:08:50.791381 140325121136384 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.006804456003010273, loss=0.11382089555263519
I0306 23:09:53.778696 140478046332096 spec.py:321] Evaluating on the training split.
I0306 23:10:01.203148 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 23:13:02.786565 140478046332096 spec.py:349] Evaluating on the test split.
I0306 23:18:58.440676 140478046332096 submission_runner.py:469] Time since start: 36724.27s, 	Step: 5956, 	{'train/loss': 0.12125630059379076, 'validation/loss': 0.12435762712870449, 'validation/num_examples': 83274637, 'test/loss': 0.12669904657689146, 'test/num_examples': 95000000, 'score': 5686.472228527069, 'total_duration': 36724.265239953995, 'accumulated_submission_time': 5686.472228527069, 'accumulated_eval_time': 31036.441600561142, 'accumulated_logging_time': 1.0248916149139404}
I0306 23:18:58.450543 140325129529088 logging_writer.py:48] [5956] accumulated_eval_time=31036.4, accumulated_logging_time=1.02489, accumulated_submission_time=5686.47, global_step=5956, preemption_count=0, score=5686.47, test/loss=0.126699, test/num_examples=95000000, total_duration=36724.3, train/loss=0.121256, validation/loss=0.124358, validation/num_examples=83274637
I0306 23:19:21.292604 140325121136384 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.010611740872263908, loss=0.1237739846110344
I0306 23:20:58.829261 140478046332096 spec.py:321] Evaluating on the training split.
I0306 23:21:06.286718 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 23:24:08.134543 140478046332096 spec.py:349] Evaluating on the test split.
I0306 23:29:51.524219 140478046332096 submission_runner.py:469] Time since start: 37377.35s, 	Step: 6082, 	{'train/loss': 0.12247866962643915, 'validation/loss': 0.12424460383061321, 'validation/num_examples': 83274637, 'test/loss': 0.12656346942845395, 'test/num_examples': 95000000, 'score': 5806.838034152985, 'total_duration': 37377.34880542755, 'accumulated_submission_time': 5806.838034152985, 'accumulated_eval_time': 31569.136499643326, 'accumulated_logging_time': 1.041074514389038}
I0306 23:29:51.535323 140325129529088 logging_writer.py:48] [6082] accumulated_eval_time=31569.1, accumulated_logging_time=1.04107, accumulated_submission_time=5806.84, global_step=6082, preemption_count=0, score=5806.84, test/loss=0.126563, test/num_examples=95000000, total_duration=37377.3, train/loss=0.122479, validation/loss=0.124245, validation/num_examples=83274637
I0306 23:29:53.560458 140325121136384 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.0053332350216805935, loss=0.1199829950928688
I0306 23:31:43.341012 140325129529088 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.0052223484963178635, loss=0.12007106840610504
I0306 23:31:53.220277 140478046332096 spec.py:321] Evaluating on the training split.
I0306 23:32:00.620913 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 23:35:02.248722 140478046332096 spec.py:349] Evaluating on the test split.
I0306 23:41:06.889861 140478046332096 submission_runner.py:469] Time since start: 38052.71s, 	Step: 6209, 	{'train/loss': 0.12420746072564486, 'validation/loss': 0.12428582982933027, 'validation/num_examples': 83274637, 'test/loss': 0.12666848103412828, 'test/num_examples': 95000000, 'score': 5928.509002447128, 'total_duration': 38052.71443295479, 'accumulated_submission_time': 5928.509002447128, 'accumulated_eval_time': 32122.80600452423, 'accumulated_logging_time': 1.059844732284546}
I0306 23:41:06.901032 140325121136384 logging_writer.py:48] [6209] accumulated_eval_time=32122.8, accumulated_logging_time=1.05984, accumulated_submission_time=5928.51, global_step=6209, preemption_count=0, score=5928.51, test/loss=0.126668, test/num_examples=95000000, total_duration=38052.7, train/loss=0.124207, validation/loss=0.124286, validation/num_examples=83274637
I0306 23:42:25.923564 140325129529088 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.014963275752961636, loss=0.1209370344877243
I0306 23:43:07.941064 140478046332096 spec.py:321] Evaluating on the training split.
I0306 23:43:15.294222 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 23:46:17.452332 140478046332096 spec.py:349] Evaluating on the test split.
I0306 23:52:15.523247 140478046332096 submission_runner.py:469] Time since start: 38721.35s, 	Step: 6334, 	{'train/loss': 0.12386423016681611, 'validation/loss': 0.12418130691306518, 'validation/num_examples': 83274637, 'test/loss': 0.1264827673725329, 'test/num_examples': 95000000, 'score': 6049.486996173859, 'total_duration': 38721.347831726074, 'accumulated_submission_time': 6049.486996173859, 'accumulated_eval_time': 32670.38813471794, 'accumulated_logging_time': 1.1264541149139404}
I0306 23:52:15.533023 140325121136384 logging_writer.py:48] [6334] accumulated_eval_time=32670.4, accumulated_logging_time=1.12645, accumulated_submission_time=6049.49, global_step=6334, preemption_count=0, score=6049.49, test/loss=0.126483, test/num_examples=95000000, total_duration=38721.3, train/loss=0.123864, validation/loss=0.124181, validation/num_examples=83274637
I0306 23:53:07.111602 140325129529088 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.009149306453764439, loss=0.13055434823036194
I0306 23:54:16.244677 140478046332096 spec.py:321] Evaluating on the training split.
I0306 23:54:23.671703 140478046332096 spec.py:333] Evaluating on the validation split.
I0306 23:57:27.208078 140478046332096 spec.py:349] Evaluating on the test split.
I0307 00:03:23.454410 140478046332096 submission_runner.py:469] Time since start: 39389.28s, 	Step: 6459, 	{'train/loss': 0.12012535797537498, 'validation/loss': 0.12440043238626636, 'validation/num_examples': 83274637, 'test/loss': 0.12678369260896383, 'test/num_examples': 95000000, 'score': 6170.18382692337, 'total_duration': 39389.278977394104, 'accumulated_submission_time': 6170.18382692337, 'accumulated_eval_time': 33217.59778857231, 'accumulated_logging_time': 1.1426310539245605}
I0307 00:03:23.465123 140325121136384 logging_writer.py:48] [6459] accumulated_eval_time=33217.6, accumulated_logging_time=1.14263, accumulated_submission_time=6170.18, global_step=6459, preemption_count=0, score=6170.18, test/loss=0.126784, test/num_examples=95000000, total_duration=39389.3, train/loss=0.120125, validation/loss=0.1244, validation/num_examples=83274637
I0307 00:03:43.475130 140325129529088 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.005976055283099413, loss=0.12140077352523804
I0307 00:05:24.394433 140478046332096 spec.py:321] Evaluating on the training split.
I0307 00:05:31.794403 140478046332096 spec.py:333] Evaluating on the validation split.
I0307 00:08:35.706622 140478046332096 spec.py:349] Evaluating on the test split.
I0307 00:14:21.784753 140478046332096 submission_runner.py:469] Time since start: 40047.61s, 	Step: 6584, 	{'train/loss': 0.1229934609442387, 'validation/loss': 0.12413341103669229, 'validation/num_examples': 83274637, 'test/loss': 0.1263835552631579, 'test/num_examples': 95000000, 'score': 6291.100393533707, 'total_duration': 40047.60932278633, 'accumulated_submission_time': 6291.100393533707, 'accumulated_eval_time': 33754.988033533096, 'accumulated_logging_time': 1.1595585346221924}
I0307 00:14:21.795332 140325121136384 logging_writer.py:48] [6584] accumulated_eval_time=33755, accumulated_logging_time=1.15956, accumulated_submission_time=6291.1, global_step=6584, preemption_count=0, score=6291.1, test/loss=0.126384, test/num_examples=95000000, total_duration=40047.6, train/loss=0.122993, validation/loss=0.124133, validation/num_examples=83274637
I0307 00:14:23.627925 140325129529088 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.014182349666953087, loss=0.1213672086596489
I0307 00:16:06.786096 140325121136384 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.025398870930075645, loss=0.11833510547876358
I0307 00:16:22.190981 140478046332096 spec.py:321] Evaluating on the training split.
I0307 00:16:29.593642 140478046332096 spec.py:333] Evaluating on the validation split.
I0307 00:19:30.732572 140478046332096 spec.py:349] Evaluating on the test split.
I0307 00:25:35.752964 140478046332096 submission_runner.py:469] Time since start: 40721.58s, 	Step: 6714, 	{'train/loss': 0.12475773239941718, 'validation/loss': 0.12417273561214608, 'validation/num_examples': 83274637, 'test/loss': 0.12655604581620067, 'test/num_examples': 95000000, 'score': 6411.4386830329895, 'total_duration': 40721.5775282383, 'accumulated_submission_time': 6411.4386830329895, 'accumulated_eval_time': 34308.54993247986, 'accumulated_logging_time': 1.220541000366211}
I0307 00:25:35.763459 140325129529088 logging_writer.py:48] [6714] accumulated_eval_time=34308.5, accumulated_logging_time=1.22054, accumulated_submission_time=6411.44, global_step=6714, preemption_count=0, score=6411.44, test/loss=0.126556, test/num_examples=95000000, total_duration=40721.6, train/loss=0.124758, validation/loss=0.124173, validation/num_examples=83274637
I0307 00:26:49.369494 140325121136384 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.010670807212591171, loss=0.11947314441204071
I0307 00:27:35.788335 140478046332096 spec.py:321] Evaluating on the training split.
I0307 00:27:43.148906 140478046332096 spec.py:333] Evaluating on the validation split.
I0307 00:30:50.299722 140478046332096 spec.py:349] Evaluating on the test split.
I0307 00:36:56.996945 140478046332096 submission_runner.py:469] Time since start: 41402.82s, 	Step: 6839, 	{'train/loss': 0.1222414523480261, 'validation/loss': 0.12407304840467587, 'validation/num_examples': 83274637, 'test/loss': 0.1265190462890625, 'test/num_examples': 95000000, 'score': 6531.450929880142, 'total_duration': 41402.82151770592, 'accumulated_submission_time': 6531.450929880142, 'accumulated_eval_time': 34869.758487701416, 'accumulated_logging_time': 1.2374017238616943}
I0307 00:36:57.008734 140325129529088 logging_writer.py:48] [6839] accumulated_eval_time=34869.8, accumulated_logging_time=1.2374, accumulated_submission_time=6531.45, global_step=6839, preemption_count=0, score=6531.45, test/loss=0.126519, test/num_examples=95000000, total_duration=41402.8, train/loss=0.122241, validation/loss=0.124073, validation/num_examples=83274637
I0307 00:37:41.947080 140325121136384 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.01436613965779543, loss=0.12286735326051712
I0307 00:38:57.065641 140478046332096 spec.py:321] Evaluating on the training split.
I0307 00:39:04.469758 140478046332096 spec.py:333] Evaluating on the validation split.
I0307 00:42:08.272287 140478046332096 spec.py:349] Evaluating on the test split.
I0307 00:48:12.611112 140478046332096 submission_runner.py:469] Time since start: 42078.44s, 	Step: 6966, 	{'train/loss': 0.12182714131736905, 'validation/loss': 0.12399624123868142, 'validation/num_examples': 83274637, 'test/loss': 0.1263292083573191, 'test/num_examples': 95000000, 'score': 6651.494872570038, 'total_duration': 42078.43567228317, 'accumulated_submission_time': 6651.494872570038, 'accumulated_eval_time': 35425.30387020111, 'accumulated_logging_time': 1.255868911743164}
I0307 00:48:12.621049 140325129529088 logging_writer.py:48] [6966] accumulated_eval_time=35425.3, accumulated_logging_time=1.25587, accumulated_submission_time=6651.49, global_step=6966, preemption_count=0, score=6651.49, test/loss=0.126329, test/num_examples=95000000, total_duration=42078.4, train/loss=0.121827, validation/loss=0.123996, validation/num_examples=83274637
I0307 00:48:23.865745 140325121136384 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.008860793896019459, loss=0.12828615307807922
I0307 00:50:13.531893 140478046332096 spec.py:321] Evaluating on the training split.
I0307 00:50:20.912666 140478046332096 spec.py:333] Evaluating on the validation split.
I0307 00:53:19.784033 140478046332096 spec.py:349] Evaluating on the test split.
I0307 00:59:18.452735 140478046332096 submission_runner.py:469] Time since start: 42744.28s, 	Step: 7097, 	{'train/loss': 0.12048831093564348, 'validation/loss': 0.12406210452441314, 'validation/num_examples': 83274637, 'test/loss': 0.1264270882709704, 'test/num_examples': 95000000, 'score': 6772.39278793335, 'total_duration': 42744.27722668648, 'accumulated_submission_time': 6772.39278793335, 'accumulated_eval_time': 35970.224558353424, 'accumulated_logging_time': 1.2722792625427246}
I0307 00:59:18.462994 140325129529088 logging_writer.py:48] [7097] accumulated_eval_time=35970.2, accumulated_logging_time=1.27228, accumulated_submission_time=6772.39, global_step=7097, preemption_count=0, score=6772.39, test/loss=0.126427, test/num_examples=95000000, total_duration=42744.3, train/loss=0.120488, validation/loss=0.124062, validation/num_examples=83274637
I0307 00:59:18.951461 140325121136384 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.00620557414367795, loss=0.11830922961235046
I0307 01:00:58.988054 140325129529088 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.0080190971493721, loss=0.11717268079519272
I0307 01:01:19.627839 140478046332096 spec.py:321] Evaluating on the training split.
I0307 01:01:27.016645 140478046332096 spec.py:333] Evaluating on the validation split.
I0307 01:04:31.339133 140478046332096 spec.py:349] Evaluating on the test split.
I0307 01:10:38.002466 140478046332096 submission_runner.py:469] Time since start: 43423.83s, 	Step: 7216, 	{'train/loss': 0.12261890179518634, 'validation/loss': 0.12395781535091119, 'validation/num_examples': 83274637, 'test/loss': 0.1263496765727796, 'test/num_examples': 95000000, 'score': 6893.498379230499, 'total_duration': 43423.82703614235, 'accumulated_submission_time': 6893.498379230499, 'accumulated_eval_time': 36528.599128484726, 'accumulated_logging_time': 1.3358654975891113}
I0307 01:10:38.014217 140325121136384 logging_writer.py:48] [7216] accumulated_eval_time=36528.6, accumulated_logging_time=1.33587, accumulated_submission_time=6893.5, global_step=7216, preemption_count=0, score=6893.5, test/loss=0.12635, test/num_examples=95000000, total_duration=43423.8, train/loss=0.122619, validation/loss=0.123958, validation/num_examples=83274637
I0307 01:11:48.538667 140325129529088 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.031765084713697433, loss=0.1320221722126007
I0307 01:12:38.359164 140478046332096 spec.py:321] Evaluating on the training split.
I0307 01:12:45.811646 140478046332096 spec.py:333] Evaluating on the validation split.
I0307 01:15:47.901057 140478046332096 spec.py:349] Evaluating on the test split.
I0307 01:21:48.005165 140478046332096 submission_runner.py:469] Time since start: 44093.83s, 	Step: 7342, 	{'train/loss': 0.12163152678067204, 'validation/loss': 0.12390389310482862, 'validation/num_examples': 83274637, 'test/loss': 0.12620343162006578, 'test/num_examples': 95000000, 'score': 7013.829412460327, 'total_duration': 44093.829728126526, 'accumulated_submission_time': 7013.829412460327, 'accumulated_eval_time': 37078.245043992996, 'accumulated_logging_time': 1.3545777797698975}
I0307 01:21:48.017030 140325121136384 logging_writer.py:48] [7342] accumulated_eval_time=37078.2, accumulated_logging_time=1.35458, accumulated_submission_time=7013.83, global_step=7342, preemption_count=0, score=7013.83, test/loss=0.126203, test/num_examples=95000000, total_duration=44093.8, train/loss=0.121632, validation/loss=0.123904, validation/num_examples=83274637
I0307 01:22:28.096290 140325129529088 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.00936869066208601, loss=0.1210530698299408
I0307 01:23:48.064452 140478046332096 spec.py:321] Evaluating on the training split.
I0307 01:23:55.500132 140478046332096 spec.py:333] Evaluating on the validation split.
I0307 01:26:57.253972 140478046332096 spec.py:349] Evaluating on the test split.
I0307 01:33:06.615907 140478046332096 submission_runner.py:469] Time since start: 44772.44s, 	Step: 7470, 	{'train/loss': 0.12162094794026336, 'validation/loss': 0.12399620363602389, 'validation/num_examples': 83274637, 'test/loss': 0.12637023974095396, 'test/num_examples': 95000000, 'score': 7133.862388134003, 'total_duration': 44772.440490722656, 'accumulated_submission_time': 7133.862388134003, 'accumulated_eval_time': 37636.79644012451, 'accumulated_logging_time': 1.373603105545044}
I0307 01:33:06.627750 140325121136384 logging_writer.py:48] [7470] accumulated_eval_time=37636.8, accumulated_logging_time=1.3736, accumulated_submission_time=7133.86, global_step=7470, preemption_count=0, score=7133.86, test/loss=0.12637, test/num_examples=95000000, total_duration=44772.4, train/loss=0.121621, validation/loss=0.123996, validation/num_examples=83274637
I0307 01:33:14.357015 140325129529088 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.01092006266117096, loss=0.11875253915786743
I0307 01:35:07.284044 140478046332096 spec.py:321] Evaluating on the training split.
I0307 01:35:14.669227 140478046332096 spec.py:333] Evaluating on the validation split.
I0307 01:38:16.887827 140478046332096 spec.py:349] Evaluating on the test split.
I0307 01:44:06.119267 140478046332096 submission_runner.py:469] Time since start: 45431.94s, 	Step: 7598, 	{'train/loss': 0.12269650876475205, 'validation/loss': 0.1238488391729645, 'validation/num_examples': 83274637, 'test/loss': 0.1261855595805921, 'test/num_examples': 95000000, 'score': 7254.488116025925, 'total_duration': 45431.943836688995, 'accumulated_submission_time': 7254.488116025925, 'accumulated_eval_time': 38175.63158893585, 'accumulated_logging_time': 1.4097251892089844}
I0307 01:44:06.131068 140325121136384 logging_writer.py:48] [7598] accumulated_eval_time=38175.6, accumulated_logging_time=1.40973, accumulated_submission_time=7254.49, global_step=7598, preemption_count=0, score=7254.49, test/loss=0.126186, test/num_examples=95000000, total_duration=45431.9, train/loss=0.122697, validation/loss=0.123849, validation/num_examples=83274637
I0307 01:44:06.475630 140325129529088 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.02019038423895836, loss=0.12183493375778198
I0307 01:45:36.955228 140325121136384 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.011204936541616917, loss=0.11411461979150772
I0307 01:46:06.426572 140478046332096 spec.py:321] Evaluating on the training split.
I0307 01:46:13.826178 140478046332096 spec.py:333] Evaluating on the validation split.
I0307 01:49:19.385995 140478046332096 spec.py:349] Evaluating on the test split.
I0307 01:55:14.384713 140478046332096 submission_runner.py:469] Time since start: 46100.21s, 	Step: 7729, 	{'train/loss': 0.12266768947384267, 'validation/loss': 0.12392073532516945, 'validation/num_examples': 83274637, 'test/loss': 0.12619902677837172, 'test/num_examples': 95000000, 'score': 7374.769803524017, 'total_duration': 46100.2093000412, 'accumulated_submission_time': 7374.769803524017, 'accumulated_eval_time': 38723.58967280388, 'accumulated_logging_time': 1.4285788536071777}
I0307 01:55:14.394791 140325129529088 logging_writer.py:48] [7729] accumulated_eval_time=38723.6, accumulated_logging_time=1.42858, accumulated_submission_time=7374.77, global_step=7729, preemption_count=0, score=7374.77, test/loss=0.126199, test/num_examples=95000000, total_duration=46100.2, train/loss=0.122668, validation/loss=0.123921, validation/num_examples=83274637
I0307 01:56:08.795237 140325121136384 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.008155346848070621, loss=0.12551531195640564
I0307 01:57:15.012627 140478046332096 spec.py:321] Evaluating on the training split.
I0307 01:57:22.387879 140478046332096 spec.py:333] Evaluating on the validation split.
I0307 02:00:24.915617 140478046332096 spec.py:349] Evaluating on the test split.
I0307 02:06:26.060737 140478046332096 submission_runner.py:469] Time since start: 46771.89s, 	Step: 7855, 	{'train/loss': 0.12253306262523124, 'validation/loss': 0.12398465178651874, 'validation/num_examples': 83274637, 'test/loss': 0.1264430478207237, 'test/num_examples': 95000000, 'score': 7495.374024629593, 'total_duration': 46771.88530111313, 'accumulated_submission_time': 7495.374024629593, 'accumulated_eval_time': 39274.63772916794, 'accumulated_logging_time': 1.4456846714019775}
I0307 02:06:26.072844 140325129529088 logging_writer.py:48] [7855] accumulated_eval_time=39274.6, accumulated_logging_time=1.44568, accumulated_submission_time=7495.37, global_step=7855, preemption_count=0, score=7495.37, test/loss=0.126443, test/num_examples=95000000, total_duration=46771.9, train/loss=0.122533, validation/loss=0.123985, validation/num_examples=83274637
I0307 02:06:49.452234 140325121136384 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.013722477480769157, loss=0.12601470947265625
I0307 02:08:26.283849 140478046332096 spec.py:321] Evaluating on the training split.
I0307 02:08:33.620416 140478046332096 spec.py:333] Evaluating on the validation split.
I0307 02:11:35.597497 140478046332096 spec.py:349] Evaluating on the test split.
I0307 02:17:28.765581 140478046332096 submission_runner.py:469] Time since start: 47434.59s, 	Step: 7986, 	{'train/loss': 0.12294367833191869, 'validation/loss': 0.12387096765382402, 'validation/num_examples': 83274637, 'test/loss': 0.1261948740234375, 'test/num_examples': 95000000, 'score': 7615.571768283844, 'total_duration': 47434.59015703201, 'accumulated_submission_time': 7615.571768283844, 'accumulated_eval_time': 39817.11939907074, 'accumulated_logging_time': 1.4646415710449219}
I0307 02:17:28.778388 140325129529088 logging_writer.py:48] [7986] accumulated_eval_time=39817.1, accumulated_logging_time=1.46464, accumulated_submission_time=7615.57, global_step=7986, preemption_count=0, score=7615.57, test/loss=0.126195, test/num_examples=95000000, total_duration=47434.6, train/loss=0.122944, validation/loss=0.123871, validation/num_examples=83274637
I0307 02:17:30.380135 140325121136384 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.015848858281970024, loss=0.1228865459561348
I0307 02:19:15.896869 140325129529088 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.0115532036870718, loss=0.12240171432495117
I0307 02:19:28.839867 140325121136384 logging_writer.py:48] [8112] global_step=8112, preemption_count=0, score=7735.61
I0307 02:19:37.608205 140478046332096 submission_runner.py:646] Tuning trial 3/5
I0307 02:19:37.627827 140478046332096 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.0, learning_rate=0.001308209823469072, one_minus_beta1=0.02686663061, beta2=0.9981232922116359, weight_decay=0.16375311233774334, warmup_factor=0.1)
I0307 02:19:37.629105 140478046332096 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/loss': 1.5643279462490443, 'validation/loss': 1.554338093362088, 'validation/num_examples': 83274637, 'test/loss': 1.558430137006579, 'test/num_examples': 95000000, 'score': 17.554768323898315, 'total_duration': 1196.383222579956, 'accumulated_submission_time': 17.554768323898315, 'accumulated_eval_time': 1178.8283214569092, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (124, {'train/loss': 0.14676508773703995, 'validation/loss': 0.1469547006204227, 'validation/num_examples': 83274637, 'test/loss': 0.15087009793379935, 'test/num_examples': 95000000, 'score': 138.4368302822113, 'total_duration': 2368.6558921337128, 'accumulated_submission_time': 138.4368302822113, 'accumulated_eval_time': 2230.14080953598, 'accumulated_logging_time': 0.0710759162902832, 'global_step': 124, 'preemption_count': 0}), (251, {'train/loss': 0.13063181601699042, 'validation/loss': 0.1298651045800547, 'validation/num_examples': 83274637, 'test/loss': 0.13298397574013157, 'test/num_examples': 95000000, 'score': 259.3906283378601, 'total_duration': 3565.693806409836, 'accumulated_submission_time': 259.3906283378601, 'accumulated_eval_time': 3306.1975412368774, 'accumulated_logging_time': 0.09196019172668457, 'global_step': 251, 'preemption_count': 0}), (377, {'train/loss': 0.12744358409219567, 'validation/loss': 0.12830548942099412, 'validation/num_examples': 83274637, 'test/loss': 0.13087449351356908, 'test/num_examples': 95000000, 'score': 379.6320559978485, 'total_duration': 4757.464533805847, 'accumulated_submission_time': 379.6320559978485, 'accumulated_eval_time': 4377.624646663666, 'accumulated_logging_time': 0.18748736381530762, 'global_step': 377, 'preemption_count': 0}), (506, {'train/loss': 0.12841418257814907, 'validation/loss': 0.12750278034249155, 'validation/num_examples': 83274637, 'test/loss': 0.1302071578433388, 'test/num_examples': 95000000, 'score': 500.7431161403656, 'total_duration': 5917.297533988953, 'accumulated_submission_time': 500.7431161403656, 'accumulated_eval_time': 5416.323463439941, 'accumulated_logging_time': 0.2034609317779541, 'global_step': 506, 'preemption_count': 0}), (630, {'train/loss': 0.1266249223910975, 'validation/loss': 0.12703634700463703, 'validation/num_examples': 83274637, 'test/loss': 0.12957333250411185, 'test/num_examples': 95000000, 'score': 620.8961129188538, 'total_duration': 7032.36092209816, 'accumulated_submission_time': 620.8961129188538, 'accumulated_eval_time': 6411.21263384819, 'accumulated_logging_time': 0.2177901268005371, 'global_step': 630, 'preemption_count': 0}), (754, {'train/loss': 0.1254932541259617, 'validation/loss': 0.12704325561489876, 'validation/num_examples': 83274637, 'test/loss': 0.12945047961554276, 'test/num_examples': 95000000, 'score': 740.9032416343689, 'total_duration': 8140.613120794296, 'accumulated_submission_time': 740.9032416343689, 'accumulated_eval_time': 7399.435496330261, 'accumulated_logging_time': 0.23218345642089844, 'global_step': 754, 'preemption_count': 0}), (881, {'train/loss': 0.12575014156974712, 'validation/loss': 0.12629015590483375, 'validation/num_examples': 83274637, 'test/loss': 0.1288488301089638, 'test/num_examples': 95000000, 'score': 861.3150129318237, 'total_duration': 9170.825680017471, 'accumulated_submission_time': 861.3150129318237, 'accumulated_eval_time': 8309.212390422821, 'accumulated_logging_time': 0.24882149696350098, 'global_step': 881, 'preemption_count': 0}), (1011, {'train/loss': 0.12976076452752705, 'validation/loss': 0.12623448636944373, 'validation/num_examples': 83274637, 'test/loss': 0.12875196859580593, 'test/num_examples': 95000000, 'score': 982.06720495224, 'total_duration': 10065.492263555527, 'accumulated_submission_time': 982.06720495224, 'accumulated_eval_time': 9083.105635643005, 'accumulated_logging_time': 0.26323938369750977, 'global_step': 1011, 'preemption_count': 0}), (1141, {'train/loss': 0.1261857660639586, 'validation/loss': 0.12606750919166046, 'validation/num_examples': 83274637, 'test/loss': 0.12861445922080592, 'test/num_examples': 95000000, 'score': 1102.2286915779114, 'total_duration': 10808.429029464722, 'accumulated_submission_time': 1102.2286915779114, 'accumulated_eval_time': 9705.8595225811, 'accumulated_logging_time': 0.27788281440734863, 'global_step': 1141, 'preemption_count': 0}), (1273, {'train/loss': 0.12435483262411454, 'validation/loss': 0.1257960795769421, 'validation/num_examples': 83274637, 'test/loss': 0.12814976915090462, 'test/num_examples': 95000000, 'score': 1223.0243318080902, 'total_duration': 11490.45410823822, 'accumulated_submission_time': 1223.0243318080902, 'accumulated_eval_time': 10267.066249608994, 'accumulated_logging_time': 0.2926304340362549, 'global_step': 1273, 'preemption_count': 0}), (1399, {'train/loss': 0.1246185830483834, 'validation/loss': 0.12581940183810109, 'validation/num_examples': 83274637, 'test/loss': 0.12824688838404605, 'test/num_examples': 95000000, 'score': 1343.1694192886353, 'total_duration': 12178.343220472336, 'accumulated_submission_time': 1343.1694192886353, 'accumulated_eval_time': 10834.788488149643, 'accumulated_logging_time': 0.30718183517456055, 'global_step': 1399, 'preemption_count': 0}), (1528, {'train/loss': 0.12407894063530103, 'validation/loss': 0.12569256951080285, 'validation/num_examples': 83274637, 'test/loss': 0.1279889480571546, 'test/num_examples': 95000000, 'score': 1463.177746295929, 'total_duration': 12869.653655290604, 'accumulated_submission_time': 1463.177746295929, 'accumulated_eval_time': 11406.067941188812, 'accumulated_logging_time': 0.3225138187408447, 'global_step': 1528, 'preemption_count': 0}), (1663, {'train/loss': 0.12587155346647375, 'validation/loss': 0.12572233399903623, 'validation/num_examples': 83274637, 'test/loss': 0.12817866753700657, 'test/num_examples': 95000000, 'score': 1583.961757183075, 'total_duration': 13554.934842586517, 'accumulated_submission_time': 1583.961757183075, 'accumulated_eval_time': 11970.541976690292, 'accumulated_logging_time': 0.3386857509613037, 'global_step': 1663, 'preemption_count': 0}), (1793, {'train/loss': 0.12390250415078499, 'validation/loss': 0.1259307169447362, 'validation/num_examples': 83274637, 'test/loss': 0.12837540990953947, 'test/num_examples': 95000000, 'score': 1704.4877960681915, 'total_duration': 14235.588782787323, 'accumulated_submission_time': 1704.4877960681915, 'accumulated_eval_time': 12530.647500038147, 'accumulated_logging_time': 0.3540196418762207, 'global_step': 1793, 'preemption_count': 0}), (1921, {'train/loss': 0.12448471761162176, 'validation/loss': 0.1255535986375532, 'validation/num_examples': 83274637, 'test/loss': 0.12805319506578947, 'test/num_examples': 95000000, 'score': 1824.8284029960632, 'total_duration': 14929.457396507263, 'accumulated_submission_time': 1824.8284029960632, 'accumulated_eval_time': 13104.153054714203, 'accumulated_logging_time': 0.36905360221862793, 'global_step': 1921, 'preemption_count': 0}), (2047, {'train/loss': 0.12460140702343962, 'validation/loss': 0.12541039834192516, 'validation/num_examples': 83274637, 'test/loss': 0.12787072002467106, 'test/num_examples': 95000000, 'score': 1945.380578994751, 'total_duration': 15637.5589864254, 'accumulated_submission_time': 1945.380578994751, 'accumulated_eval_time': 13691.679047584534, 'accumulated_logging_time': 0.38525819778442383, 'global_step': 2047, 'preemption_count': 0}), (2179, {'train/loss': 0.12478902863350304, 'validation/loss': 0.1255483392494779, 'validation/num_examples': 83274637, 'test/loss': 0.12806700280633224, 'test/num_examples': 95000000, 'score': 2065.8742623329163, 'total_duration': 16317.40709900856, 'accumulated_submission_time': 2065.8742623329163, 'accumulated_eval_time': 14251.01211977005, 'accumulated_logging_time': 0.40017032623291016, 'global_step': 2179, 'preemption_count': 0}), (2305, {'train/loss': 0.12417204009146436, 'validation/loss': 0.12546434597698433, 'validation/num_examples': 83274637, 'test/loss': 0.12786355264185856, 'test/num_examples': 95000000, 'score': 2186.51450920105, 'total_duration': 17014.404703378677, 'accumulated_submission_time': 2186.51450920105, 'accumulated_eval_time': 14827.320286273956, 'accumulated_logging_time': 0.4418661594390869, 'global_step': 2305, 'preemption_count': 0}), (2432, {'train/loss': 0.1256449488020918, 'validation/loss': 0.12549165574989612, 'validation/num_examples': 83274637, 'test/loss': 0.1277846369449013, 'test/num_examples': 95000000, 'score': 2307.8695497512817, 'total_duration': 17699.1404004097, 'accumulated_submission_time': 2307.8695497512817, 'accumulated_eval_time': 15390.679008960724, 'accumulated_logging_time': 0.4575679302215576, 'global_step': 2432, 'preemption_count': 0}), (2559, {'train/loss': 0.12484655393369543, 'validation/loss': 0.12536965207173276, 'validation/num_examples': 83274637, 'test/loss': 0.1277759156455592, 'test/num_examples': 95000000, 'score': 2428.619769334793, 'total_duration': 18375.833077430725, 'accumulated_submission_time': 2428.619769334793, 'accumulated_eval_time': 15946.599844932556, 'accumulated_logging_time': 0.4726545810699463, 'global_step': 2559, 'preemption_count': 0}), (2688, {'train/loss': 0.12509728698704228, 'validation/loss': 0.12530836832998968, 'validation/num_examples': 83274637, 'test/loss': 0.127854564453125, 'test/num_examples': 95000000, 'score': 2549.931867837906, 'total_duration': 19072.559165477753, 'accumulated_submission_time': 2549.931867837906, 'accumulated_eval_time': 16521.986930131912, 'accumulated_logging_time': 0.49251866340637207, 'global_step': 2688, 'preemption_count': 0}), (2822, {'train/loss': 0.12225597497052366, 'validation/loss': 0.1255851622836592, 'validation/num_examples': 83274637, 'test/loss': 0.12811425926192435, 'test/num_examples': 95000000, 'score': 2671.3471899032593, 'total_duration': 19772.064861297607, 'accumulated_submission_time': 2671.3471899032593, 'accumulated_eval_time': 17100.055140018463, 'accumulated_logging_time': 0.5082402229309082, 'global_step': 2822, 'preemption_count': 0}), (2948, {'train/loss': 0.12546463493468626, 'validation/loss': 0.12507515874710823, 'validation/num_examples': 83274637, 'test/loss': 0.1273711386821546, 'test/num_examples': 95000000, 'score': 2792.3495619297028, 'total_duration': 20459.07313323021, 'accumulated_submission_time': 2792.3495619297028, 'accumulated_eval_time': 17666.014655590057, 'accumulated_logging_time': 0.5479557514190674, 'global_step': 2948, 'preemption_count': 0}), (3071, {'train/loss': 0.12355792243619385, 'validation/loss': 0.12503744198576858, 'validation/num_examples': 83274637, 'test/loss': 0.12734697806332237, 'test/num_examples': 95000000, 'score': 2914.1416778564453, 'total_duration': 21139.089408636093, 'accumulated_submission_time': 2914.1416778564453, 'accumulated_eval_time': 18224.216467142105, 'accumulated_logging_time': 0.5634949207305908, 'global_step': 3071, 'preemption_count': 0}), (3195, {'train/loss': 0.12356853861150877, 'validation/loss': 0.12507293460825705, 'validation/num_examples': 83274637, 'test/loss': 0.12743322465049342, 'test/num_examples': 95000000, 'score': 3034.6326928138733, 'total_duration': 21829.816714525223, 'accumulated_submission_time': 3034.6326928138733, 'accumulated_eval_time': 18794.422073602676, 'accumulated_logging_time': 0.5880229473114014, 'global_step': 3195, 'preemption_count': 0}), (3319, {'train/loss': 0.1251623838460483, 'validation/loss': 0.125159601855978, 'validation/num_examples': 83274637, 'test/loss': 0.12743895261101973, 'test/num_examples': 95000000, 'score': 3154.732905626297, 'total_duration': 22523.8699259758, 'accumulated_submission_time': 3154.732905626297, 'accumulated_eval_time': 19368.351719856262, 'accumulated_logging_time': 0.6046538352966309, 'global_step': 3319, 'preemption_count': 0}), (3441, {'train/loss': 0.12427752511868687, 'validation/loss': 0.12514792980462047, 'validation/num_examples': 83274637, 'test/loss': 0.12753883857935855, 'test/num_examples': 95000000, 'score': 3275.197326898575, 'total_duration': 23216.38505935669, 'accumulated_submission_time': 3275.197326898575, 'accumulated_eval_time': 19940.378561735153, 'accumulated_logging_time': 0.6212949752807617, 'global_step': 3441, 'preemption_count': 0}), (3562, {'train/loss': 0.12295111234786, 'validation/loss': 0.12510137096570104, 'validation/num_examples': 83274637, 'test/loss': 0.127446999609375, 'test/num_examples': 95000000, 'score': 3395.5289919376373, 'total_duration': 23902.17893576622, 'accumulated_submission_time': 3395.5289919376373, 'accumulated_eval_time': 20505.819056272507, 'accumulated_logging_time': 0.6364827156066895, 'global_step': 3562, 'preemption_count': 0}), (3693, {'train/loss': 0.124784325231921, 'validation/loss': 0.1251223912206625, 'validation/num_examples': 83274637, 'test/loss': 0.12740889857113488, 'test/num_examples': 95000000, 'score': 3516.2516479492188, 'total_duration': 24570.264561653137, 'accumulated_submission_time': 3516.2516479492188, 'accumulated_eval_time': 21053.160164117813, 'accumulated_logging_time': 0.6517095565795898, 'global_step': 3693, 'preemption_count': 0}), (3816, {'train/loss': 0.12479039511215761, 'validation/loss': 0.12499024841656996, 'validation/num_examples': 83274637, 'test/loss': 0.12726430571546052, 'test/num_examples': 95000000, 'score': 3637.113730430603, 'total_duration': 25240.753722906113, 'accumulated_submission_time': 3637.113730430603, 'accumulated_eval_time': 21602.765113830566, 'accumulated_logging_time': 0.6670820713043213, 'global_step': 3816, 'preemption_count': 0}), (3945, {'train/loss': 0.12263125864168008, 'validation/loss': 0.12509838908023588, 'validation/num_examples': 83274637, 'test/loss': 0.12736087434210527, 'test/num_examples': 95000000, 'score': 3757.9903812408447, 'total_duration': 25933.274955511093, 'accumulated_submission_time': 3757.9903812408447, 'accumulated_eval_time': 22174.386714696884, 'accumulated_logging_time': 0.6830539703369141, 'global_step': 3945, 'preemption_count': 0}), (4072, {'train/loss': 0.1237830160736288, 'validation/loss': 0.12494631665656496, 'validation/num_examples': 83274637, 'test/loss': 0.1272601976459704, 'test/num_examples': 95000000, 'score': 3879.001822948456, 'total_duration': 26602.1903860569, 'accumulated_submission_time': 3879.001822948456, 'accumulated_eval_time': 22722.244903087616, 'accumulated_logging_time': 0.7213518619537354, 'global_step': 4072, 'preemption_count': 0}), (4195, {'train/loss': 0.12372184517857789, 'validation/loss': 0.1249731570617654, 'validation/num_examples': 83274637, 'test/loss': 0.12739083367598683, 'test/num_examples': 95000000, 'score': 4000.045855283737, 'total_duration': 27280.09962797165, 'accumulated_submission_time': 4000.045855283737, 'accumulated_eval_time': 23279.087752580643, 'accumulated_logging_time': 0.7364778518676758, 'global_step': 4195, 'preemption_count': 0}), (4320, {'train/loss': 0.12372396534906244, 'validation/loss': 0.12509821552048803, 'validation/num_examples': 83274637, 'test/loss': 0.12745343686266447, 'test/num_examples': 95000000, 'score': 4120.079644441605, 'total_duration': 27965.468767642975, 'accumulated_submission_time': 4120.079644441605, 'accumulated_eval_time': 23844.39912223816, 'accumulated_logging_time': 0.7537472248077393, 'global_step': 4320, 'preemption_count': 0}), (4452, {'train/loss': 0.12582913360927464, 'validation/loss': 0.12492268979218502, 'validation/num_examples': 83274637, 'test/loss': 0.12723401062911185, 'test/num_examples': 95000000, 'score': 4241.191298484802, 'total_duration': 28641.424456834793, 'accumulated_submission_time': 4241.191298484802, 'accumulated_eval_time': 24399.18756389618, 'accumulated_logging_time': 0.8021435737609863, 'global_step': 4452, 'preemption_count': 0}), (4581, {'train/loss': 0.1247426931213283, 'validation/loss': 0.12481299998463592, 'validation/num_examples': 83274637, 'test/loss': 0.12724466645764804, 'test/num_examples': 95000000, 'score': 4361.552614688873, 'total_duration': 29323.13425898552, 'accumulated_submission_time': 4361.552614688873, 'accumulated_eval_time': 24960.49365758896, 'accumulated_logging_time': 0.8378274440765381, 'global_step': 4581, 'preemption_count': 0}), (4708, {'train/loss': 0.12230284909173003, 'validation/loss': 0.1246844894635731, 'validation/num_examples': 83274637, 'test/loss': 0.12702142392064145, 'test/num_examples': 95000000, 'score': 4482.209956645966, 'total_duration': 29996.961845874786, 'accumulated_submission_time': 4482.209956645966, 'accumulated_eval_time': 25513.64185810089, 'accumulated_logging_time': 0.8537154197692871, 'global_step': 4708, 'preemption_count': 0}), (4833, {'train/loss': 0.12358026265067125, 'validation/loss': 0.1248654430091324, 'validation/num_examples': 83274637, 'test/loss': 0.12727901067023026, 'test/num_examples': 95000000, 'score': 4602.503079891205, 'total_duration': 30670.396349191666, 'accumulated_submission_time': 4602.503079891205, 'accumulated_eval_time': 26066.76176381111, 'accumulated_logging_time': 0.8691861629486084, 'global_step': 4833, 'preemption_count': 0}), (4950, {'train/loss': 0.12218069735000718, 'validation/loss': 0.12477362345852788, 'validation/num_examples': 83274637, 'test/loss': 0.12730673182565788, 'test/num_examples': 95000000, 'score': 4722.854833602905, 'total_duration': 31341.097544193268, 'accumulated_submission_time': 4722.854833602905, 'accumulated_eval_time': 26617.08167076111, 'accumulated_logging_time': 0.8915328979492188, 'global_step': 4950, 'preemption_count': 0}), (5076, {'train/loss': 0.12343536292747506, 'validation/loss': 0.12463917394570682, 'validation/num_examples': 83274637, 'test/loss': 0.12701670238486842, 'test/num_examples': 95000000, 'score': 4843.595588445663, 'total_duration': 32012.897755622864, 'accumulated_submission_time': 4843.595588445663, 'accumulated_eval_time': 27168.117213249207, 'accumulated_logging_time': 0.9082489013671875, 'global_step': 5076, 'preemption_count': 0}), (5196, {'train/loss': 0.1246374396126975, 'validation/loss': 0.12452992669792425, 'validation/num_examples': 83274637, 'test/loss': 0.12683617874177633, 'test/num_examples': 95000000, 'score': 4964.177098751068, 'total_duration': 32704.073038816452, 'accumulated_submission_time': 4964.177098751068, 'accumulated_eval_time': 27738.687275648117, 'accumulated_logging_time': 0.9254529476165771, 'global_step': 5196, 'preemption_count': 0}), (5323, {'train/loss': 0.12161061971348787, 'validation/loss': 0.12455201786930148, 'validation/num_examples': 83274637, 'test/loss': 0.12700974284539474, 'test/num_examples': 95000000, 'score': 5084.154655694962, 'total_duration': 33378.96115016937, 'accumulated_submission_time': 5084.154655694962, 'accumulated_eval_time': 28293.572871923447, 'accumulated_logging_time': 0.9430966377258301, 'global_step': 5323, 'preemption_count': 0}), (5451, {'train/loss': 0.12193303583365567, 'validation/loss': 0.12460708516409347, 'validation/num_examples': 83274637, 'test/loss': 0.12702956279810856, 'test/num_examples': 95000000, 'score': 5204.415857791901, 'total_duration': 34051.39586830139, 'accumulated_submission_time': 5204.415857791901, 'accumulated_eval_time': 28845.72306203842, 'accumulated_logging_time': 0.9593415260314941, 'global_step': 5451, 'preemption_count': 0}), (5576, {'train/loss': 0.12207660556964155, 'validation/loss': 0.12421180242205679, 'validation/num_examples': 83274637, 'test/loss': 0.1266040540604441, 'test/num_examples': 95000000, 'score': 5325.550531387329, 'total_duration': 34726.99320721626, 'accumulated_submission_time': 5325.550531387329, 'accumulated_eval_time': 29400.161841869354, 'accumulated_logging_time': 0.9761569499969482, 'global_step': 5576, 'preemption_count': 0}), (5703, {'train/loss': 0.12074117238322894, 'validation/loss': 0.12442536233254235, 'validation/num_examples': 83274637, 'test/loss': 0.12677003684210528, 'test/num_examples': 95000000, 'score': 5446.205047607422, 'total_duration': 35404.694294929504, 'accumulated_submission_time': 5446.205047607422, 'accumulated_eval_time': 29957.184755325317, 'accumulated_logging_time': 0.9923720359802246, 'global_step': 5703, 'preemption_count': 0}), (5828, {'train/loss': 0.12107502301252863, 'validation/loss': 0.12445772843448795, 'validation/num_examples': 83274637, 'test/loss': 0.12686341712582236, 'test/num_examples': 95000000, 'score': 5566.244394779205, 'total_duration': 36059.35145139694, 'accumulated_submission_time': 5566.244394779205, 'accumulated_eval_time': 30491.779702425003, 'accumulated_logging_time': 1.00844144821167, 'global_step': 5828, 'preemption_count': 0}), (5956, {'train/loss': 0.12125630059379076, 'validation/loss': 0.12435762712870449, 'validation/num_examples': 83274637, 'test/loss': 0.12669904657689146, 'test/num_examples': 95000000, 'score': 5686.472228527069, 'total_duration': 36724.265239953995, 'accumulated_submission_time': 5686.472228527069, 'accumulated_eval_time': 31036.441600561142, 'accumulated_logging_time': 1.0248916149139404, 'global_step': 5956, 'preemption_count': 0}), (6082, {'train/loss': 0.12247866962643915, 'validation/loss': 0.12424460383061321, 'validation/num_examples': 83274637, 'test/loss': 0.12656346942845395, 'test/num_examples': 95000000, 'score': 5806.838034152985, 'total_duration': 37377.34880542755, 'accumulated_submission_time': 5806.838034152985, 'accumulated_eval_time': 31569.136499643326, 'accumulated_logging_time': 1.041074514389038, 'global_step': 6082, 'preemption_count': 0}), (6209, {'train/loss': 0.12420746072564486, 'validation/loss': 0.12428582982933027, 'validation/num_examples': 83274637, 'test/loss': 0.12666848103412828, 'test/num_examples': 95000000, 'score': 5928.509002447128, 'total_duration': 38052.71443295479, 'accumulated_submission_time': 5928.509002447128, 'accumulated_eval_time': 32122.80600452423, 'accumulated_logging_time': 1.059844732284546, 'global_step': 6209, 'preemption_count': 0}), (6334, {'train/loss': 0.12386423016681611, 'validation/loss': 0.12418130691306518, 'validation/num_examples': 83274637, 'test/loss': 0.1264827673725329, 'test/num_examples': 95000000, 'score': 6049.486996173859, 'total_duration': 38721.347831726074, 'accumulated_submission_time': 6049.486996173859, 'accumulated_eval_time': 32670.38813471794, 'accumulated_logging_time': 1.1264541149139404, 'global_step': 6334, 'preemption_count': 0}), (6459, {'train/loss': 0.12012535797537498, 'validation/loss': 0.12440043238626636, 'validation/num_examples': 83274637, 'test/loss': 0.12678369260896383, 'test/num_examples': 95000000, 'score': 6170.18382692337, 'total_duration': 39389.278977394104, 'accumulated_submission_time': 6170.18382692337, 'accumulated_eval_time': 33217.59778857231, 'accumulated_logging_time': 1.1426310539245605, 'global_step': 6459, 'preemption_count': 0}), (6584, {'train/loss': 0.1229934609442387, 'validation/loss': 0.12413341103669229, 'validation/num_examples': 83274637, 'test/loss': 0.1263835552631579, 'test/num_examples': 95000000, 'score': 6291.100393533707, 'total_duration': 40047.60932278633, 'accumulated_submission_time': 6291.100393533707, 'accumulated_eval_time': 33754.988033533096, 'accumulated_logging_time': 1.1595585346221924, 'global_step': 6584, 'preemption_count': 0}), (6714, {'train/loss': 0.12475773239941718, 'validation/loss': 0.12417273561214608, 'validation/num_examples': 83274637, 'test/loss': 0.12655604581620067, 'test/num_examples': 95000000, 'score': 6411.4386830329895, 'total_duration': 40721.5775282383, 'accumulated_submission_time': 6411.4386830329895, 'accumulated_eval_time': 34308.54993247986, 'accumulated_logging_time': 1.220541000366211, 'global_step': 6714, 'preemption_count': 0}), (6839, {'train/loss': 0.1222414523480261, 'validation/loss': 0.12407304840467587, 'validation/num_examples': 83274637, 'test/loss': 0.1265190462890625, 'test/num_examples': 95000000, 'score': 6531.450929880142, 'total_duration': 41402.82151770592, 'accumulated_submission_time': 6531.450929880142, 'accumulated_eval_time': 34869.758487701416, 'accumulated_logging_time': 1.2374017238616943, 'global_step': 6839, 'preemption_count': 0}), (6966, {'train/loss': 0.12182714131736905, 'validation/loss': 0.12399624123868142, 'validation/num_examples': 83274637, 'test/loss': 0.1263292083573191, 'test/num_examples': 95000000, 'score': 6651.494872570038, 'total_duration': 42078.43567228317, 'accumulated_submission_time': 6651.494872570038, 'accumulated_eval_time': 35425.30387020111, 'accumulated_logging_time': 1.255868911743164, 'global_step': 6966, 'preemption_count': 0}), (7097, {'train/loss': 0.12048831093564348, 'validation/loss': 0.12406210452441314, 'validation/num_examples': 83274637, 'test/loss': 0.1264270882709704, 'test/num_examples': 95000000, 'score': 6772.39278793335, 'total_duration': 42744.27722668648, 'accumulated_submission_time': 6772.39278793335, 'accumulated_eval_time': 35970.224558353424, 'accumulated_logging_time': 1.2722792625427246, 'global_step': 7097, 'preemption_count': 0}), (7216, {'train/loss': 0.12261890179518634, 'validation/loss': 0.12395781535091119, 'validation/num_examples': 83274637, 'test/loss': 0.1263496765727796, 'test/num_examples': 95000000, 'score': 6893.498379230499, 'total_duration': 43423.82703614235, 'accumulated_submission_time': 6893.498379230499, 'accumulated_eval_time': 36528.599128484726, 'accumulated_logging_time': 1.3358654975891113, 'global_step': 7216, 'preemption_count': 0}), (7342, {'train/loss': 0.12163152678067204, 'validation/loss': 0.12390389310482862, 'validation/num_examples': 83274637, 'test/loss': 0.12620343162006578, 'test/num_examples': 95000000, 'score': 7013.829412460327, 'total_duration': 44093.829728126526, 'accumulated_submission_time': 7013.829412460327, 'accumulated_eval_time': 37078.245043992996, 'accumulated_logging_time': 1.3545777797698975, 'global_step': 7342, 'preemption_count': 0}), (7470, {'train/loss': 0.12162094794026336, 'validation/loss': 0.12399620363602389, 'validation/num_examples': 83274637, 'test/loss': 0.12637023974095396, 'test/num_examples': 95000000, 'score': 7133.862388134003, 'total_duration': 44772.440490722656, 'accumulated_submission_time': 7133.862388134003, 'accumulated_eval_time': 37636.79644012451, 'accumulated_logging_time': 1.373603105545044, 'global_step': 7470, 'preemption_count': 0}), (7598, {'train/loss': 0.12269650876475205, 'validation/loss': 0.1238488391729645, 'validation/num_examples': 83274637, 'test/loss': 0.1261855595805921, 'test/num_examples': 95000000, 'score': 7254.488116025925, 'total_duration': 45431.943836688995, 'accumulated_submission_time': 7254.488116025925, 'accumulated_eval_time': 38175.63158893585, 'accumulated_logging_time': 1.4097251892089844, 'global_step': 7598, 'preemption_count': 0}), (7729, {'train/loss': 0.12266768947384267, 'validation/loss': 0.12392073532516945, 'validation/num_examples': 83274637, 'test/loss': 0.12619902677837172, 'test/num_examples': 95000000, 'score': 7374.769803524017, 'total_duration': 46100.2093000412, 'accumulated_submission_time': 7374.769803524017, 'accumulated_eval_time': 38723.58967280388, 'accumulated_logging_time': 1.4285788536071777, 'global_step': 7729, 'preemption_count': 0}), (7855, {'train/loss': 0.12253306262523124, 'validation/loss': 0.12398465178651874, 'validation/num_examples': 83274637, 'test/loss': 0.1264430478207237, 'test/num_examples': 95000000, 'score': 7495.374024629593, 'total_duration': 46771.88530111313, 'accumulated_submission_time': 7495.374024629593, 'accumulated_eval_time': 39274.63772916794, 'accumulated_logging_time': 1.4456846714019775, 'global_step': 7855, 'preemption_count': 0}), (7986, {'train/loss': 0.12294367833191869, 'validation/loss': 0.12387096765382402, 'validation/num_examples': 83274637, 'test/loss': 0.1261948740234375, 'test/num_examples': 95000000, 'score': 7615.571768283844, 'total_duration': 47434.59015703201, 'accumulated_submission_time': 7615.571768283844, 'accumulated_eval_time': 39817.11939907074, 'accumulated_logging_time': 1.4646415710449219, 'global_step': 7986, 'preemption_count': 0})], 'global_step': 8112}
I0307 02:19:37.629218 140478046332096 submission_runner.py:649] Timing: 7735.613810062408
I0307 02:19:37.629258 140478046332096 submission_runner.py:651] Total number of evals: 64
I0307 02:19:37.629288 140478046332096 submission_runner.py:652] ====================
I0307 02:19:37.629443 140478046332096 submission_runner.py:750] Final criteo1tb score: 2
