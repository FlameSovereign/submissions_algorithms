python submission_runner.py --framework=jax --workload=criteo1tb --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_1 --overwrite=True --save_checkpoints=False --rng_seed=717581396 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=0 --hparam_end_index=1 2>&1 | tee -a /logs/criteo1tb_jax_03-06-2025-13-00-11.log
2025-03-06 13:00:29.343623: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741266029.922675       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741266030.150205       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0306 13:01:19.980010 140224878134464 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax.
I0306 13:01:23.235707 140224878134464 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0306 13:01:23.239778 140224878134464 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0306 13:01:23.259037 140224878134464 submission_runner.py:606] Using RNG seed 717581396
I0306 13:01:26.503513 140224878134464 submission_runner.py:615] --- Tuning run 1/5 ---
I0306 13:01:26.503745 140224878134464 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_1.
I0306 13:01:26.503941 140224878134464 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_1/hparams.json.
I0306 13:01:26.744010 140224878134464 submission_runner.py:218] Initializing dataset.
I0306 13:01:26.744191 140224878134464 submission_runner.py:229] Initializing model.
I0306 13:01:36.320270 140224878134464 submission_runner.py:272] Initializing optimizer.
I0306 13:01:36.988532 140224878134464 submission_runner.py:279] Initializing metrics bundle.
I0306 13:01:36.988791 140224878134464 submission_runner.py:301] Initializing checkpoint and logger.
I0306 13:01:36.989550 140224878134464 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_1 with prefix checkpoint_
I0306 13:01:36.989661 140224878134464 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_1/meta_data_0.json.
I0306 13:01:36.989841 140224878134464 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0306 13:01:36.989889 140224878134464 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0306 13:01:37.581120 140224878134464 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_1/flags_0.json.
I0306 13:01:38.132797 140224878134464 submission_runner.py:337] Starting training loop.
I0306 13:01:54.844706 140082799437568 logging_writer.py:48] [0] global_step=0, grad_norm=5.169749736785889, loss=0.9159358739852905
I0306 13:01:55.190385 140224878134464 spec.py:321] Evaluating on the training split.
I0306 13:08:03.513030 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 13:13:43.070392 140224878134464 spec.py:349] Evaluating on the test split.
I0306 13:20:34.419147 140224878134464 submission_runner.py:469] Time since start: 1136.29s, 	Step: 1, 	{'train/loss': 0.9196143575809287, 'validation/loss': 0.9229366760009864, 'validation/num_examples': 83274637, 'test/loss': 0.9205822050164474, 'test/num_examples': 95000000, 'score': 17.057493925094604, 'total_duration': 1136.2862927913666, 'accumulated_submission_time': 17.057493925094604, 'accumulated_eval_time': 1119.228694677353, 'accumulated_logging_time': 0}
I0306 13:20:34.447839 140071550310144 logging_writer.py:48] [1] accumulated_eval_time=1119.23, accumulated_logging_time=0, accumulated_submission_time=17.0575, global_step=1, preemption_count=0, score=17.0575, test/loss=0.920582, test/num_examples=95000000, total_duration=1136.29, train/loss=0.919614, validation/loss=0.922937, validation/num_examples=83274637
I0306 13:21:58.933662 140071541917440 logging_writer.py:48] [100] global_step=100, grad_norm=0.28323519229888916, loss=0.15180477499961853
I0306 13:22:34.430827 140224878134464 spec.py:321] Evaluating on the training split.
I0306 13:28:19.353888 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 13:32:36.839141 140224878134464 spec.py:349] Evaluating on the test split.
I0306 13:38:28.759853 140224878134464 submission_runner.py:469] Time since start: 2210.63s, 	Step: 130, 	{'train/loss': 0.13922051668354551, 'validation/loss': 0.13990981591204654, 'validation/num_examples': 83274637, 'test/loss': 0.14331528757195724, 'test/num_examples': 95000000, 'score': 137.01685905456543, 'total_duration': 2210.627004623413, 'accumulated_submission_time': 137.01685905456543, 'accumulated_eval_time': 2073.557671546936, 'accumulated_logging_time': 0.04588913917541504}
I0306 13:38:28.767639 140071550310144 logging_writer.py:48] [130] accumulated_eval_time=2073.56, accumulated_logging_time=0.0458891, accumulated_submission_time=137.017, global_step=130, preemption_count=0, score=137.017, test/loss=0.143315, test/num_examples=95000000, total_duration=2210.63, train/loss=0.139221, validation/loss=0.13991, validation/num_examples=83274637
I0306 13:39:20.344446 140071541917440 logging_writer.py:48] [200] global_step=200, grad_norm=0.020012538880109787, loss=0.13955959677696228
I0306 13:40:30.012828 140224878134464 spec.py:321] Evaluating on the training split.
I0306 13:46:12.172378 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 13:50:30.867576 140224878134464 spec.py:349] Evaluating on the test split.
I0306 13:56:44.304145 140224878134464 submission_runner.py:469] Time since start: 3306.17s, 	Step: 256, 	{'train/loss': 0.12762024203233374, 'validation/loss': 0.12992502655794375, 'validation/num_examples': 83274637, 'test/loss': 0.13247987954358553, 'test/num_examples': 95000000, 'score': 258.24850249290466, 'total_duration': 3306.1713054180145, 'accumulated_submission_time': 258.24850249290466, 'accumulated_eval_time': 3047.8489394187927, 'accumulated_logging_time': 0.06103968620300293}
I0306 13:56:44.311420 140071550310144 logging_writer.py:48] [256] accumulated_eval_time=3047.85, accumulated_logging_time=0.0610397, accumulated_submission_time=258.249, global_step=256, preemption_count=0, score=258.249, test/loss=0.13248, test/num_examples=95000000, total_duration=3306.17, train/loss=0.12762, validation/loss=0.129925, validation/num_examples=83274637
I0306 13:57:07.992384 140071541917440 logging_writer.py:48] [300] global_step=300, grad_norm=0.01386052556335926, loss=0.126119002699852
I0306 13:58:44.661865 140224878134464 spec.py:321] Evaluating on the training split.
I0306 14:04:33.682023 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 14:08:55.293264 140224878134464 spec.py:349] Evaluating on the test split.
I0306 14:15:17.528153 140224878134464 submission_runner.py:469] Time since start: 4419.40s, 	Step: 386, 	{'train/loss': 0.1273922823931811, 'validation/loss': 0.1284392818518549, 'validation/num_examples': 83274637, 'test/loss': 0.13103932433182566, 'test/num_examples': 95000000, 'score': 378.58532333374023, 'total_duration': 4419.395301818848, 'accumulated_submission_time': 378.58532333374023, 'accumulated_eval_time': 4040.7151696681976, 'accumulated_logging_time': 0.0752713680267334}
I0306 14:15:17.535803 140071550310144 logging_writer.py:48] [386] accumulated_eval_time=4040.72, accumulated_logging_time=0.0752714, accumulated_submission_time=378.585, global_step=386, preemption_count=0, score=378.585, test/loss=0.131039, test/num_examples=95000000, total_duration=4419.4, train/loss=0.127392, validation/loss=0.128439, validation/num_examples=83274637
I0306 14:15:19.160411 140071541917440 logging_writer.py:48] [400] global_step=400, grad_norm=0.01144163217395544, loss=0.12474571168422699
I0306 14:17:02.781923 140071550310144 logging_writer.py:48] [500] global_step=500, grad_norm=0.03426659107208252, loss=0.12248270958662033
I0306 14:17:17.931450 140224878134464 spec.py:321] Evaluating on the training split.
I0306 14:23:01.650601 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 14:27:05.461873 140224878134464 spec.py:349] Evaluating on the test split.
I0306 14:32:42.391912 140224878134464 submission_runner.py:469] Time since start: 5464.26s, 	Step: 515, 	{'train/loss': 0.12857550129575548, 'validation/loss': 0.12798972288980265, 'validation/num_examples': 83274637, 'test/loss': 0.13063444089226975, 'test/num_examples': 95000000, 'score': 498.9430103302002, 'total_duration': 5464.259056806564, 'accumulated_submission_time': 498.9430103302002, 'accumulated_eval_time': 4965.175580739975, 'accumulated_logging_time': 0.11451911926269531}
I0306 14:32:42.401305 140071541917440 logging_writer.py:48] [515] accumulated_eval_time=4965.18, accumulated_logging_time=0.114519, accumulated_submission_time=498.943, global_step=515, preemption_count=0, score=498.943, test/loss=0.130634, test/num_examples=95000000, total_duration=5464.26, train/loss=0.128576, validation/loss=0.12799, validation/num_examples=83274637
I0306 14:33:54.322846 140071550310144 logging_writer.py:48] [600] global_step=600, grad_norm=0.03872301056981087, loss=0.12753921747207642
I0306 14:34:43.683162 140224878134464 spec.py:321] Evaluating on the training split.
I0306 14:40:18.277049 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 14:44:22.935095 140224878134464 spec.py:349] Evaluating on the test split.
I0306 14:50:15.805748 140224878134464 submission_runner.py:469] Time since start: 6517.67s, 	Step: 641, 	{'train/loss': 0.12528002923998818, 'validation/loss': 0.12740319713600942, 'validation/num_examples': 83274637, 'test/loss': 0.12995577141241776, 'test/num_examples': 95000000, 'score': 620.2118453979492, 'total_duration': 6517.672875881195, 'accumulated_submission_time': 620.2118453979492, 'accumulated_eval_time': 5897.298082113266, 'accumulated_logging_time': 0.13039636611938477}
I0306 14:50:15.815124 140071541917440 logging_writer.py:48] [641] accumulated_eval_time=5897.3, accumulated_logging_time=0.130396, accumulated_submission_time=620.212, global_step=641, preemption_count=0, score=620.212, test/loss=0.129956, test/num_examples=95000000, total_duration=6517.67, train/loss=0.12528, validation/loss=0.127403, validation/num_examples=83274637
I0306 14:50:56.739371 140071550310144 logging_writer.py:48] [700] global_step=700, grad_norm=0.012549684382975101, loss=0.12336123734712601
I0306 14:52:16.513869 140224878134464 spec.py:321] Evaluating on the training split.
I0306 14:57:37.773714 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 15:01:34.472775 140224878134464 spec.py:349] Evaluating on the test split.
I0306 15:07:13.745300 140224878134464 submission_runner.py:469] Time since start: 7535.61s, 	Step: 764, 	{'train/loss': 0.12635891236739713, 'validation/loss': 0.12723421475092447, 'validation/num_examples': 83274637, 'test/loss': 0.12957280272409538, 'test/num_examples': 95000000, 'score': 740.8949818611145, 'total_duration': 7535.612446546555, 'accumulated_submission_time': 740.8949818611145, 'accumulated_eval_time': 6794.529451608658, 'accumulated_logging_time': 0.14700818061828613}
I0306 15:07:13.753106 140071541917440 logging_writer.py:48] [764] accumulated_eval_time=6794.53, accumulated_logging_time=0.147008, accumulated_submission_time=740.895, global_step=764, preemption_count=0, score=740.895, test/loss=0.129573, test/num_examples=95000000, total_duration=7535.61, train/loss=0.126359, validation/loss=0.127234, validation/num_examples=83274637
I0306 15:07:28.005819 140071550310144 logging_writer.py:48] [800] global_step=800, grad_norm=0.029310477897524834, loss=0.12297677248716354
I0306 15:09:13.934803 140224878134464 spec.py:321] Evaluating on the training split.
I0306 15:13:47.477675 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 15:17:19.898844 140224878134464 spec.py:349] Evaluating on the test split.
I0306 15:23:06.457372 140224878134464 submission_runner.py:469] Time since start: 8488.32s, 	Step: 892, 	{'train/loss': 0.12562455738303047, 'validation/loss': 0.1267581362346651, 'validation/num_examples': 83274637, 'test/loss': 0.12901707156661185, 'test/num_examples': 95000000, 'score': 861.0626103878021, 'total_duration': 8488.324535131454, 'accumulated_submission_time': 861.0626103878021, 'accumulated_eval_time': 7627.0519897937775, 'accumulated_logging_time': 0.16220474243164062}
I0306 15:23:06.465169 140071541917440 logging_writer.py:48] [892] accumulated_eval_time=7627.05, accumulated_logging_time=0.162205, accumulated_submission_time=861.063, global_step=892, preemption_count=0, score=861.063, test/loss=0.129017, test/num_examples=95000000, total_duration=8488.32, train/loss=0.125625, validation/loss=0.126758, validation/num_examples=83274637
I0306 15:23:07.457862 140071550310144 logging_writer.py:48] [900] global_step=900, grad_norm=0.01865837723016739, loss=0.11594945937395096
I0306 15:24:44.377169 140071541917440 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.0136477155610919, loss=0.12226223200559616
I0306 15:25:07.097069 140224878134464 spec.py:321] Evaluating on the training split.
I0306 15:28:20.337969 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 15:30:54.703691 140224878134464 spec.py:349] Evaluating on the test split.
I0306 15:36:56.077313 140224878134464 submission_runner.py:469] Time since start: 9317.94s, 	Step: 1020, 	{'train/loss': 0.12587331695798434, 'validation/loss': 0.12649442674516326, 'validation/num_examples': 83274637, 'test/loss': 0.12887928706825658, 'test/num_examples': 95000000, 'score': 981.636682510376, 'total_duration': 9317.944452524185, 'accumulated_submission_time': 981.636682510376, 'accumulated_eval_time': 8336.03215789795, 'accumulated_logging_time': 0.2215116024017334}
I0306 15:36:56.085157 140071550310144 logging_writer.py:48] [1020] accumulated_eval_time=8336.03, accumulated_logging_time=0.221512, accumulated_submission_time=981.637, global_step=1020, preemption_count=0, score=981.637, test/loss=0.128879, test/num_examples=95000000, total_duration=9317.94, train/loss=0.125873, validation/loss=0.126494, validation/num_examples=83274637
I0306 15:38:06.475315 140071541917440 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.01050518173724413, loss=0.12885722517967224
I0306 15:38:56.585712 140224878134464 spec.py:321] Evaluating on the training split.
I0306 15:39:51.323314 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 15:42:24.892964 140224878134464 spec.py:349] Evaluating on the test split.
I0306 15:48:14.111592 140224878134464 submission_runner.py:469] Time since start: 9995.98s, 	Step: 1145, 	{'train/loss': 0.12514338843852468, 'validation/loss': 0.1264490381152532, 'validation/num_examples': 83274637, 'test/loss': 0.12874205677425987, 'test/num_examples': 95000000, 'score': 1102.1241688728333, 'total_duration': 9995.978727817535, 'accumulated_submission_time': 1102.1241688728333, 'accumulated_eval_time': 8893.557971954346, 'accumulated_logging_time': 0.23534250259399414}
I0306 15:48:14.120645 140071550310144 logging_writer.py:48] [1145] accumulated_eval_time=8893.56, accumulated_logging_time=0.235343, accumulated_submission_time=1102.12, global_step=1145, preemption_count=0, score=1102.12, test/loss=0.128742, test/num_examples=95000000, total_duration=9995.98, train/loss=0.125143, validation/loss=0.126449, validation/num_examples=83274637
I0306 15:48:50.102294 140071541917440 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.014841286465525627, loss=0.12421868741512299
I0306 15:50:14.783757 140224878134464 spec.py:321] Evaluating on the training split.
I0306 15:51:08.375681 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 15:53:40.084449 140224878134464 spec.py:349] Evaluating on the test split.
I0306 15:59:35.553515 140224878134464 submission_runner.py:469] Time since start: 10677.42s, 	Step: 1266, 	{'train/loss': 0.12630892903456148, 'validation/loss': 0.12614313065140184, 'validation/num_examples': 83274637, 'test/loss': 0.1285532289165296, 'test/num_examples': 95000000, 'score': 1222.7741160392761, 'total_duration': 10677.420635700226, 'accumulated_submission_time': 1222.7741160392761, 'accumulated_eval_time': 9454.327657461166, 'accumulated_logging_time': 0.2506680488586426}
I0306 15:59:35.564258 140071550310144 logging_writer.py:48] [1266] accumulated_eval_time=9454.33, accumulated_logging_time=0.250668, accumulated_submission_time=1222.77, global_step=1266, preemption_count=0, score=1222.77, test/loss=0.128553, test/num_examples=95000000, total_duration=10677.4, train/loss=0.126309, validation/loss=0.126143, validation/num_examples=83274637
I0306 15:59:47.616466 140071541917440 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.00839292537420988, loss=0.12251964956521988
I0306 16:01:36.269493 140224878134464 spec.py:321] Evaluating on the training split.
I0306 16:02:30.567183 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 16:05:03.760276 140224878134464 spec.py:349] Evaluating on the test split.
I0306 16:11:09.816988 140224878134464 submission_runner.py:469] Time since start: 11371.68s, 	Step: 1394, 	{'train/loss': 0.12490461475022559, 'validation/loss': 0.12608888799408885, 'validation/num_examples': 83274637, 'test/loss': 0.12858147589432567, 'test/num_examples': 95000000, 'score': 1343.465006828308, 'total_duration': 11371.684135913849, 'accumulated_submission_time': 1343.465006828308, 'accumulated_eval_time': 10027.875089168549, 'accumulated_logging_time': 0.2687344551086426}
I0306 16:11:09.826054 140071550310144 logging_writer.py:48] [1394] accumulated_eval_time=10027.9, accumulated_logging_time=0.268734, accumulated_submission_time=1343.47, global_step=1394, preemption_count=0, score=1343.47, test/loss=0.128581, test/num_examples=95000000, total_duration=11371.7, train/loss=0.124905, validation/loss=0.126089, validation/num_examples=83274637
I0306 16:11:10.573590 140071541917440 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.01583896204829216, loss=0.12537047266960144
I0306 16:12:40.502352 140071550310144 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.012750896625220776, loss=0.12591952085494995
I0306 16:13:10.756478 140224878134464 spec.py:321] Evaluating on the training split.
I0306 16:14:06.223939 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 16:16:40.553570 140224878134464 spec.py:349] Evaluating on the test split.
I0306 16:22:39.777676 140224878134464 submission_runner.py:469] Time since start: 12061.64s, 	Step: 1527, 	{'train/loss': 0.12292702337902672, 'validation/loss': 0.125851692611598, 'validation/num_examples': 83274637, 'test/loss': 0.12801924130345393, 'test/num_examples': 95000000, 'score': 1464.3829531669617, 'total_duration': 12061.64479804039, 'accumulated_submission_time': 1464.3829531669617, 'accumulated_eval_time': 10596.896197080612, 'accumulated_logging_time': 0.2842082977294922}
I0306 16:22:39.785762 140071541917440 logging_writer.py:48] [1527] accumulated_eval_time=10596.9, accumulated_logging_time=0.284208, accumulated_submission_time=1464.38, global_step=1527, preemption_count=0, score=1464.38, test/loss=0.128019, test/num_examples=95000000, total_duration=12061.6, train/loss=0.122927, validation/loss=0.125852, validation/num_examples=83274637
I0306 16:23:38.002958 140071550310144 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.012264308519661427, loss=0.11472416669130325
I0306 16:24:40.072570 140224878134464 spec.py:321] Evaluating on the training split.
I0306 16:25:36.061053 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 16:28:09.710136 140224878134464 spec.py:349] Evaluating on the test split.
I0306 16:34:01.959931 140224878134464 submission_runner.py:469] Time since start: 12743.83s, 	Step: 1653, 	{'train/loss': 0.1245990877607896, 'validation/loss': 0.12588276019931796, 'validation/num_examples': 83274637, 'test/loss': 0.12834948683182565, 'test/num_examples': 95000000, 'score': 1584.6566817760468, 'total_duration': 12743.827060699463, 'accumulated_submission_time': 1584.6566817760468, 'accumulated_eval_time': 11158.783473968506, 'accumulated_logging_time': 0.29814767837524414}
I0306 16:34:01.968437 140071541917440 logging_writer.py:48] [1653] accumulated_eval_time=11158.8, accumulated_logging_time=0.298148, accumulated_submission_time=1584.66, global_step=1653, preemption_count=0, score=1584.66, test/loss=0.128349, test/num_examples=95000000, total_duration=12743.8, train/loss=0.124599, validation/loss=0.125883, validation/num_examples=83274637
I0306 16:34:27.973316 140071550310144 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.042237985879182816, loss=0.1318712681531906
I0306 16:36:02.076759 140224878134464 spec.py:321] Evaluating on the training split.
I0306 16:36:58.503273 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 16:39:31.712038 140224878134464 spec.py:349] Evaluating on the test split.
I0306 16:45:28.770240 140224878134464 submission_runner.py:469] Time since start: 13430.64s, 	Step: 1784, 	{'train/loss': 0.12264213886744571, 'validation/loss': 0.1253606469418061, 'validation/num_examples': 83274637, 'test/loss': 0.1278376279296875, 'test/num_examples': 95000000, 'score': 1704.750562429428, 'total_duration': 13430.637394428253, 'accumulated_submission_time': 1704.750562429428, 'accumulated_eval_time': 11725.476895809174, 'accumulated_logging_time': 0.31386566162109375}
I0306 16:45:28.777848 140071541917440 logging_writer.py:48] [1784] accumulated_eval_time=11725.5, accumulated_logging_time=0.313866, accumulated_submission_time=1704.75, global_step=1784, preemption_count=0, score=1704.75, test/loss=0.127838, test/num_examples=95000000, total_duration=13430.6, train/loss=0.122642, validation/loss=0.125361, validation/num_examples=83274637
I0306 16:45:30.561576 140071550310144 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.009483362548053265, loss=0.12299653887748718
I0306 16:47:11.221265 140071541917440 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.009618377313017845, loss=0.12545830011367798
I0306 16:47:29.289186 140224878134464 spec.py:321] Evaluating on the training split.
I0306 16:48:24.204440 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 16:50:57.100603 140224878134464 spec.py:349] Evaluating on the test split.
I0306 16:56:49.062399 140224878134464 submission_runner.py:469] Time since start: 14110.93s, 	Step: 1917, 	{'train/loss': 0.12535944368994836, 'validation/loss': 0.12577087633269832, 'validation/num_examples': 83274637, 'test/loss': 0.12823409129317434, 'test/num_examples': 95000000, 'score': 1825.2497191429138, 'total_duration': 14110.929565191269, 'accumulated_submission_time': 1825.2497191429138, 'accumulated_eval_time': 12285.25005865097, 'accumulated_logging_time': 0.32752180099487305}
I0306 16:56:49.070508 140071550310144 logging_writer.py:48] [1917] accumulated_eval_time=12285.3, accumulated_logging_time=0.327522, accumulated_submission_time=1825.25, global_step=1917, preemption_count=0, score=1825.25, test/loss=0.128234, test/num_examples=95000000, total_duration=14110.9, train/loss=0.125359, validation/loss=0.125771, validation/num_examples=83274637
I0306 16:57:56.961261 140071541917440 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.009851650334894657, loss=0.12249435484409332
I0306 16:58:49.655796 140224878134464 spec.py:321] Evaluating on the training split.
I0306 16:59:43.232849 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 17:02:17.559792 140224878134464 spec.py:349] Evaluating on the test split.
I0306 17:07:58.306587 140224878134464 submission_runner.py:469] Time since start: 14780.17s, 	Step: 2046, 	{'train/loss': 0.12301988857534696, 'validation/loss': 0.12540330944647535, 'validation/num_examples': 83274637, 'test/loss': 0.1278205515316612, 'test/num_examples': 95000000, 'score': 1945.8221802711487, 'total_duration': 14780.173733949661, 'accumulated_submission_time': 1945.8221802711487, 'accumulated_eval_time': 12833.900797128677, 'accumulated_logging_time': 0.3416569232940674}
I0306 17:07:58.316050 140071550310144 logging_writer.py:48] [2046] accumulated_eval_time=12833.9, accumulated_logging_time=0.341657, accumulated_submission_time=1945.82, global_step=2046, preemption_count=0, score=1945.82, test/loss=0.127821, test/num_examples=95000000, total_duration=14780.2, train/loss=0.12302, validation/loss=0.125403, validation/num_examples=83274637
I0306 17:08:35.340578 140071541917440 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.006730667781084776, loss=0.11715201288461685
I0306 17:09:59.316579 140224878134464 spec.py:321] Evaluating on the training split.
I0306 17:10:58.364456 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 17:13:33.732747 140224878134464 spec.py:349] Evaluating on the test split.
I0306 17:19:15.404436 140224878134464 submission_runner.py:469] Time since start: 15457.27s, 	Step: 2171, 	{'train/loss': 0.1244098251603497, 'validation/loss': 0.1254197488029785, 'validation/num_examples': 83274637, 'test/loss': 0.12780723820929277, 'test/num_examples': 95000000, 'score': 2066.8094573020935, 'total_duration': 15457.271560430527, 'accumulated_submission_time': 2066.8094573020935, 'accumulated_eval_time': 13389.988570451736, 'accumulated_logging_time': 0.3577542304992676}
I0306 17:19:15.413930 140071550310144 logging_writer.py:48] [2171] accumulated_eval_time=13390, accumulated_logging_time=0.357754, accumulated_submission_time=2066.81, global_step=2171, preemption_count=0, score=2066.81, test/loss=0.127807, test/num_examples=95000000, total_duration=15457.3, train/loss=0.12441, validation/loss=0.12542, validation/num_examples=83274637
I0306 17:19:21.150670 140071541917440 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.010963978245854378, loss=0.12052154541015625
I0306 17:21:15.668060 140224878134464 spec.py:321] Evaluating on the training split.
I0306 17:22:09.961125 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 17:24:43.916395 140224878134464 spec.py:349] Evaluating on the test split.
I0306 17:30:34.746656 140224878134464 submission_runner.py:469] Time since start: 16136.61s, 	Step: 2299, 	{'train/loss': 0.12340157155720692, 'validation/loss': 0.12537425304096866, 'validation/num_examples': 83274637, 'test/loss': 0.1278177814041941, 'test/num_examples': 95000000, 'score': 2187.048721075058, 'total_duration': 16136.613797426224, 'accumulated_submission_time': 2187.048721075058, 'accumulated_eval_time': 13949.067103862762, 'accumulated_logging_time': 0.3739655017852783}
I0306 17:30:34.755064 140071550310144 logging_writer.py:48] [2299] accumulated_eval_time=13949.1, accumulated_logging_time=0.373966, accumulated_submission_time=2187.05, global_step=2299, preemption_count=0, score=2187.05, test/loss=0.127818, test/num_examples=95000000, total_duration=16136.6, train/loss=0.123402, validation/loss=0.125374, validation/num_examples=83274637
I0306 17:30:34.988811 140071541917440 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.04742554947733879, loss=0.1279233694076538
I0306 17:32:03.664532 140071550310144 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.019152838736772537, loss=0.11561788618564606
I0306 17:32:34.889243 140224878134464 spec.py:321] Evaluating on the training split.
I0306 17:33:30.275719 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 17:36:02.996182 140224878134464 spec.py:349] Evaluating on the test split.
I0306 17:41:43.097239 140224878134464 submission_runner.py:469] Time since start: 16804.96s, 	Step: 2427, 	{'train/loss': 0.12252721272455822, 'validation/loss': 0.12537723249307928, 'validation/num_examples': 83274637, 'test/loss': 0.1280610507504112, 'test/num_examples': 95000000, 'score': 2307.169387102127, 'total_duration': 16804.96439599991, 'accumulated_submission_time': 2307.169387102127, 'accumulated_eval_time': 14497.275040626526, 'accumulated_logging_time': 0.38918328285217285}
I0306 17:41:43.106309 140071541917440 logging_writer.py:48] [2427] accumulated_eval_time=14497.3, accumulated_logging_time=0.389183, accumulated_submission_time=2307.17, global_step=2427, preemption_count=0, score=2307.17, test/loss=0.128061, test/num_examples=95000000, total_duration=16805, train/loss=0.122527, validation/loss=0.125377, validation/num_examples=83274637
I0306 17:42:37.131051 140071550310144 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.01372671127319336, loss=0.11602596938610077
I0306 17:43:43.322863 140224878134464 spec.py:321] Evaluating on the training split.
I0306 17:44:40.144153 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 17:47:12.651746 140224878134464 spec.py:349] Evaluating on the test split.
I0306 17:53:18.799069 140224878134464 submission_runner.py:469] Time since start: 17500.67s, 	Step: 2562, 	{'train/loss': 0.12417189441855599, 'validation/loss': 0.12530777134895563, 'validation/num_examples': 83274637, 'test/loss': 0.12777654502467106, 'test/num_examples': 95000000, 'score': 2427.372974872589, 'total_duration': 17500.666215658188, 'accumulated_submission_time': 2427.372974872589, 'accumulated_eval_time': 15072.751198768616, 'accumulated_logging_time': 0.40448474884033203}
I0306 17:53:18.808978 140071541917440 logging_writer.py:48] [2562] accumulated_eval_time=15072.8, accumulated_logging_time=0.404485, accumulated_submission_time=2427.37, global_step=2562, preemption_count=0, score=2427.37, test/loss=0.127777, test/num_examples=95000000, total_duration=17500.7, train/loss=0.124172, validation/loss=0.125308, validation/num_examples=83274637
I0306 17:53:34.664571 140071550310144 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.017394596710801125, loss=0.11880604922771454
I0306 17:55:19.511250 140224878134464 spec.py:321] Evaluating on the training split.
I0306 17:56:17.255134 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 17:58:53.133342 140224878134464 spec.py:349] Evaluating on the test split.
I0306 18:04:40.382905 140224878134464 submission_runner.py:469] Time since start: 18182.25s, 	Step: 2691, 	{'train/loss': 0.12240270522874107, 'validation/loss': 0.12508291670365898, 'validation/num_examples': 83274637, 'test/loss': 0.1277035269839638, 'test/num_examples': 95000000, 'score': 2548.062455892563, 'total_duration': 18182.250067472458, 'accumulated_submission_time': 2548.062455892563, 'accumulated_eval_time': 15633.6228017807, 'accumulated_logging_time': 0.4209916591644287}
I0306 18:04:40.391353 140071541917440 logging_writer.py:48] [2691] accumulated_eval_time=15633.6, accumulated_logging_time=0.420992, accumulated_submission_time=2548.06, global_step=2691, preemption_count=0, score=2548.06, test/loss=0.127704, test/num_examples=95000000, total_duration=18182.3, train/loss=0.122403, validation/loss=0.125083, validation/num_examples=83274637
I0306 18:04:41.453414 140071550310144 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.007060781586915255, loss=0.12207366526126862
I0306 18:06:18.963762 140071541917440 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.009894299320876598, loss=0.11730951070785522
I0306 18:06:41.092983 140224878134464 spec.py:321] Evaluating on the training split.
I0306 18:07:32.980700 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 18:10:05.978448 140224878134464 spec.py:349] Evaluating on the test split.
I0306 18:16:03.406281 140224878134464 submission_runner.py:469] Time since start: 18865.27s, 	Step: 2818, 	{'train/loss': 0.12535251147529614, 'validation/loss': 0.12507060621628707, 'validation/num_examples': 83274637, 'test/loss': 0.12752194386307567, 'test/num_examples': 95000000, 'score': 2668.7524321079254, 'total_duration': 18865.27342605591, 'accumulated_submission_time': 2668.7524321079254, 'accumulated_eval_time': 16195.936029672623, 'accumulated_logging_time': 0.4352147579193115}
I0306 18:16:03.414682 140071550310144 logging_writer.py:48] [2818] accumulated_eval_time=16195.9, accumulated_logging_time=0.435215, accumulated_submission_time=2668.75, global_step=2818, preemption_count=0, score=2668.75, test/loss=0.127522, test/num_examples=95000000, total_duration=18865.3, train/loss=0.125353, validation/loss=0.125071, validation/num_examples=83274637
I0306 18:17:13.083584 140071541917440 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.007718817330896854, loss=0.1230885460972786
I0306 18:18:04.320922 140224878134464 spec.py:321] Evaluating on the training split.
I0306 18:18:57.730785 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 18:21:29.741213 140224878134464 spec.py:349] Evaluating on the test split.
I0306 18:26:55.227024 140224878134464 submission_runner.py:469] Time since start: 19517.09s, 	Step: 2943, 	{'train/loss': 0.12436027984199284, 'validation/loss': 0.12495253003103941, 'validation/num_examples': 83274637, 'test/loss': 0.12741443683182566, 'test/num_examples': 95000000, 'score': 2789.6443026065826, 'total_duration': 19517.09415245056, 'accumulated_submission_time': 2789.6443026065826, 'accumulated_eval_time': 16726.84206223488, 'accumulated_logging_time': 0.4499239921569824}
I0306 18:26:55.237432 140071550310144 logging_writer.py:48] [2943] accumulated_eval_time=16726.8, accumulated_logging_time=0.449924, accumulated_submission_time=2789.64, global_step=2943, preemption_count=0, score=2789.64, test/loss=0.127414, test/num_examples=95000000, total_duration=19517.1, train/loss=0.12436, validation/loss=0.124953, validation/num_examples=83274637
I0306 18:27:32.375365 140071541917440 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.006253017112612724, loss=0.13260053098201752
I0306 18:28:55.499404 140224878134464 spec.py:321] Evaluating on the training split.
I0306 18:29:47.845763 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 18:32:20.462443 140224878134464 spec.py:349] Evaluating on the test split.
I0306 18:38:04.502077 140224878134464 submission_runner.py:469] Time since start: 20186.37s, 	Step: 3075, 	{'train/loss': 0.1252777920274427, 'validation/loss': 0.1251647673400208, 'validation/num_examples': 83274637, 'test/loss': 0.1277256572162829, 'test/num_examples': 95000000, 'score': 2909.8936796188354, 'total_duration': 20186.36921620369, 'accumulated_submission_time': 2909.8936796188354, 'accumulated_eval_time': 17275.844663381577, 'accumulated_logging_time': 0.46686792373657227}
I0306 18:38:04.512279 140071550310144 logging_writer.py:48] [3075] accumulated_eval_time=17275.8, accumulated_logging_time=0.466868, accumulated_submission_time=2909.89, global_step=3075, preemption_count=0, score=2909.89, test/loss=0.127726, test/num_examples=95000000, total_duration=20186.4, train/loss=0.125278, validation/loss=0.125165, validation/num_examples=83274637
I0306 18:38:07.282151 140071541917440 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.027287838980555534, loss=0.11525626480579376
I0306 18:40:00.983052 140071550310144 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.027828728780150414, loss=0.12797920405864716
I0306 18:40:05.094380 140224878134464 spec.py:321] Evaluating on the training split.
I0306 18:41:00.235776 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 18:43:32.634085 140224878134464 spec.py:349] Evaluating on the test split.
I0306 18:49:25.735292 140224878134464 submission_runner.py:469] Time since start: 20867.60s, 	Step: 3205, 	{'train/loss': 0.12344116626201936, 'validation/loss': 0.12494947198450787, 'validation/num_examples': 83274637, 'test/loss': 0.12730607398231908, 'test/num_examples': 95000000, 'score': 3030.4621341228485, 'total_duration': 20867.6024582386, 'accumulated_submission_time': 3030.4621341228485, 'accumulated_eval_time': 17836.485538721085, 'accumulated_logging_time': 0.48363161087036133}
I0306 18:49:25.743898 140071541917440 logging_writer.py:48] [3205] accumulated_eval_time=17836.5, accumulated_logging_time=0.483632, accumulated_submission_time=3030.46, global_step=3205, preemption_count=0, score=3030.46, test/loss=0.127306, test/num_examples=95000000, total_duration=20867.6, train/loss=0.123441, validation/loss=0.124949, validation/num_examples=83274637
I0306 18:50:49.978203 140071550310144 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.010176199488341808, loss=0.12479813396930695
I0306 18:51:27.036221 140224878134464 spec.py:321] Evaluating on the training split.
I0306 18:52:22.097862 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 18:54:56.618823 140224878134464 spec.py:349] Evaluating on the test split.
I0306 19:00:50.495026 140224878134464 submission_runner.py:469] Time since start: 21552.36s, 	Step: 3333, 	{'train/loss': 0.1216664397679035, 'validation/loss': 0.12489098168690643, 'validation/num_examples': 83274637, 'test/loss': 0.12750650538651315, 'test/num_examples': 95000000, 'score': 3151.7421967983246, 'total_duration': 21552.362196207047, 'accumulated_submission_time': 3151.7421967983246, 'accumulated_eval_time': 18399.944298267365, 'accumulated_logging_time': 0.49811744689941406}
I0306 19:00:50.503413 140071541917440 logging_writer.py:48] [3333] accumulated_eval_time=18399.9, accumulated_logging_time=0.498117, accumulated_submission_time=3151.74, global_step=3333, preemption_count=0, score=3151.74, test/loss=0.127507, test/num_examples=95000000, total_duration=21552.4, train/loss=0.121666, validation/loss=0.124891, validation/num_examples=83274637
I0306 19:01:43.630424 140071550310144 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.018134525045752525, loss=0.1231355369091034
I0306 19:02:52.313263 140224878134464 spec.py:321] Evaluating on the training split.
I0306 19:03:50.301791 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 19:06:24.295365 140224878134464 spec.py:349] Evaluating on the test split.
I0306 19:12:28.346054 140224878134464 submission_runner.py:469] Time since start: 22250.21s, 	Step: 3455, 	{'train/loss': 0.12431325717776451, 'validation/loss': 0.12489553437604223, 'validation/num_examples': 83274637, 'test/loss': 0.12738070264185855, 'test/num_examples': 95000000, 'score': 3273.5389590263367, 'total_duration': 22250.213220834732, 'accumulated_submission_time': 3273.5389590263367, 'accumulated_eval_time': 18975.97704052925, 'accumulated_logging_time': 0.5124452114105225}
I0306 19:12:28.369926 140071541917440 logging_writer.py:48] [3455] accumulated_eval_time=18976, accumulated_logging_time=0.512445, accumulated_submission_time=3273.54, global_step=3455, preemption_count=0, score=3273.54, test/loss=0.127381, test/num_examples=95000000, total_duration=22250.2, train/loss=0.124313, validation/loss=0.124896, validation/num_examples=83274637
I0306 19:12:49.610083 140071550310144 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.009090342558920383, loss=0.12619753181934357
I0306 19:14:28.410492 140224878134464 spec.py:321] Evaluating on the training split.
I0306 19:15:21.715486 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 19:17:57.889299 140224878134464 spec.py:349] Evaluating on the test split.
I0306 19:23:34.653571 140224878134464 submission_runner.py:469] Time since start: 22916.52s, 	Step: 3588, 	{'train/loss': 0.12449788787173775, 'validation/loss': 0.12492325431871891, 'validation/num_examples': 83274637, 'test/loss': 0.12757245074013157, 'test/num_examples': 95000000, 'score': 3393.566992044449, 'total_duration': 22916.520711421967, 'accumulated_submission_time': 3393.566992044449, 'accumulated_eval_time': 19522.220046281815, 'accumulated_logging_time': 0.5424127578735352}
I0306 19:23:34.662644 140071541917440 logging_writer.py:48] [3588] accumulated_eval_time=19522.2, accumulated_logging_time=0.542413, accumulated_submission_time=3393.57, global_step=3588, preemption_count=0, score=3393.57, test/loss=0.127572, test/num_examples=95000000, total_duration=22916.5, train/loss=0.124498, validation/loss=0.124923, validation/num_examples=83274637
I0306 19:23:36.045109 140071550310144 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.014267747290432453, loss=0.1314869374036789
I0306 19:25:16.644781 140071541917440 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.016850873827934265, loss=0.12506577372550964
I0306 19:25:34.884930 140224878134464 spec.py:321] Evaluating on the training split.
I0306 19:26:33.434999 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 19:29:04.758149 140224878134464 spec.py:349] Evaluating on the test split.
I0306 19:34:57.851813 140224878134464 submission_runner.py:469] Time since start: 23599.72s, 	Step: 3717, 	{'train/loss': 0.12352896885911249, 'validation/loss': 0.12459393288262698, 'validation/num_examples': 83274637, 'test/loss': 0.12695890315583883, 'test/num_examples': 95000000, 'score': 3513.7626888751984, 'total_duration': 23599.71896505356, 'accumulated_submission_time': 3513.7626888751984, 'accumulated_eval_time': 20085.18686771393, 'accumulated_logging_time': 0.5716984272003174}
I0306 19:34:57.860768 140071550310144 logging_writer.py:48] [3717] accumulated_eval_time=20085.2, accumulated_logging_time=0.571698, accumulated_submission_time=3513.76, global_step=3717, preemption_count=0, score=3513.76, test/loss=0.126959, test/num_examples=95000000, total_duration=23599.7, train/loss=0.123529, validation/loss=0.124594, validation/num_examples=83274637
I0306 19:36:05.797097 140071541917440 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.014082222245633602, loss=0.12368440628051758
I0306 19:36:58.203555 140224878134464 spec.py:321] Evaluating on the training split.
I0306 19:37:52.031291 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 19:40:26.256138 140224878134464 spec.py:349] Evaluating on the test split.
I0306 19:46:21.300114 140224878134464 submission_runner.py:469] Time since start: 24283.17s, 	Step: 3848, 	{'train/loss': 0.12256894839353531, 'validation/loss': 0.12482275678072191, 'validation/num_examples': 83274637, 'test/loss': 0.12731566148231907, 'test/num_examples': 95000000, 'score': 3634.09300160408, 'total_duration': 24283.167216300964, 'accumulated_submission_time': 3634.09300160408, 'accumulated_eval_time': 20648.283315181732, 'accumulated_logging_time': 0.5868194103240967}
I0306 19:46:21.308599 140071550310144 logging_writer.py:48] [3848] accumulated_eval_time=20648.3, accumulated_logging_time=0.586819, accumulated_submission_time=3634.09, global_step=3848, preemption_count=0, score=3634.09, test/loss=0.127316, test/num_examples=95000000, total_duration=24283.2, train/loss=0.122569, validation/loss=0.124823, validation/num_examples=83274637
I0306 19:46:53.598098 140071541917440 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.03484206274151802, loss=0.12843111157417297
I0306 19:48:22.039814 140224878134464 spec.py:321] Evaluating on the training split.
I0306 19:49:17.404648 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 19:51:49.129390 140224878134464 spec.py:349] Evaluating on the test split.
I0306 19:57:21.869093 140224878134464 submission_runner.py:469] Time since start: 24943.74s, 	Step: 3974, 	{'train/loss': 0.12282707302028653, 'validation/loss': 0.12496869514555044, 'validation/num_examples': 83274637, 'test/loss': 0.12744110803865133, 'test/num_examples': 95000000, 'score': 3754.8112637996674, 'total_duration': 24943.73623919487, 'accumulated_submission_time': 3754.8112637996674, 'accumulated_eval_time': 21188.112539291382, 'accumulated_logging_time': 0.6012668609619141}
I0306 19:57:21.879997 140071550310144 logging_writer.py:48] [3974] accumulated_eval_time=21188.1, accumulated_logging_time=0.601267, accumulated_submission_time=3754.81, global_step=3974, preemption_count=0, score=3754.81, test/loss=0.127441, test/num_examples=95000000, total_duration=24943.7, train/loss=0.122827, validation/loss=0.124969, validation/num_examples=83274637
I0306 19:57:24.674304 140071541917440 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.0065834359265863895, loss=0.1160879135131836
I0306 19:59:21.950163 140224878134464 spec.py:321] Evaluating on the training split.
I0306 20:00:20.362838 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 20:02:55.651551 140224878134464 spec.py:349] Evaluating on the test split.
I0306 20:08:40.466613 140224878134464 submission_runner.py:469] Time since start: 25622.33s, 	Step: 4100, 	{'train/loss': 0.12203927611076981, 'validation/loss': 0.12475957804798056, 'validation/num_examples': 83274637, 'test/loss': 0.1272321628597862, 'test/num_examples': 95000000, 'score': 3874.8642818927765, 'total_duration': 25622.333768844604, 'accumulated_submission_time': 3874.8642818927765, 'accumulated_eval_time': 21746.6289331913, 'accumulated_logging_time': 0.6189756393432617}
I0306 20:08:40.490338 140071550310144 logging_writer.py:48] [4100] accumulated_eval_time=21746.6, accumulated_logging_time=0.618976, accumulated_submission_time=3874.86, global_step=4100, preemption_count=0, score=3874.86, test/loss=0.127232, test/num_examples=95000000, total_duration=25622.3, train/loss=0.122039, validation/loss=0.12476, validation/num_examples=83274637
I0306 20:08:40.604916 140071541917440 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.034089118242263794, loss=0.1258554458618164
I0306 20:10:08.826189 140071550310144 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.0088792210444808, loss=0.122268907725811
I0306 20:10:41.322704 140224878134464 spec.py:321] Evaluating on the training split.
I0306 20:11:33.864554 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 20:14:06.624042 140224878134464 spec.py:349] Evaluating on the test split.
I0306 20:19:51.526708 140224878134464 submission_runner.py:469] Time since start: 26293.39s, 	Step: 4227, 	{'train/loss': 0.1226345696164377, 'validation/loss': 0.1246792436905564, 'validation/num_examples': 83274637, 'test/loss': 0.1271604459087171, 'test/num_examples': 95000000, 'score': 3995.6841626167297, 'total_duration': 26293.393870592117, 'accumulated_submission_time': 3995.6841626167297, 'accumulated_eval_time': 22296.83288550377, 'accumulated_logging_time': 0.6486067771911621}
I0306 20:19:51.535369 140071541917440 logging_writer.py:48] [4227] accumulated_eval_time=22296.8, accumulated_logging_time=0.648607, accumulated_submission_time=3995.68, global_step=4227, preemption_count=0, score=3995.68, test/loss=0.12716, test/num_examples=95000000, total_duration=26293.4, train/loss=0.122635, validation/loss=0.124679, validation/num_examples=83274637
I0306 20:20:48.646770 140071550310144 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.00751922745257616, loss=0.12019535154104233
I0306 20:21:51.804001 140224878134464 spec.py:321] Evaluating on the training split.
I0306 20:22:48.424455 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 20:25:23.379651 140224878134464 spec.py:349] Evaluating on the test split.
I0306 20:30:58.182220 140224878134464 submission_runner.py:469] Time since start: 26960.05s, 	Step: 4350, 	{'train/loss': 0.12593889537519254, 'validation/loss': 0.12459765845402117, 'validation/num_examples': 83274637, 'test/loss': 0.1271155992084704, 'test/num_examples': 95000000, 'score': 4115.939559698105, 'total_duration': 26960.049354076385, 'accumulated_submission_time': 4115.939559698105, 'accumulated_eval_time': 22843.21102309227, 'accumulated_logging_time': 0.6647293567657471}
I0306 20:30:58.190692 140071541917440 logging_writer.py:48] [4350] accumulated_eval_time=22843.2, accumulated_logging_time=0.664729, accumulated_submission_time=4115.94, global_step=4350, preemption_count=0, score=4115.94, test/loss=0.127116, test/num_examples=95000000, total_duration=26960, train/loss=0.125939, validation/loss=0.124598, validation/num_examples=83274637
I0306 20:31:27.913380 140071550310144 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.010458501055836678, loss=0.12028656899929047
I0306 20:32:58.330788 140224878134464 spec.py:321] Evaluating on the training split.
I0306 20:33:51.723159 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 20:36:25.628179 140224878134464 spec.py:349] Evaluating on the test split.
I0306 20:42:08.023991 140224878134464 submission_runner.py:469] Time since start: 27629.89s, 	Step: 4480, 	{'train/loss': 0.12527000107480296, 'validation/loss': 0.12451749909876708, 'validation/num_examples': 83274637, 'test/loss': 0.12691873182565788, 'test/num_examples': 95000000, 'score': 4236.066785335541, 'total_duration': 27629.891148090363, 'accumulated_submission_time': 4236.066785335541, 'accumulated_eval_time': 23392.90416932106, 'accumulated_logging_time': 0.6793820858001709}
I0306 20:42:08.034985 140071541917440 logging_writer.py:48] [4480] accumulated_eval_time=23392.9, accumulated_logging_time=0.679382, accumulated_submission_time=4236.07, global_step=4480, preemption_count=0, score=4236.07, test/loss=0.126919, test/num_examples=95000000, total_duration=27629.9, train/loss=0.12527, validation/loss=0.124517, validation/num_examples=83274637
I0306 20:42:10.281454 140071550310144 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.006030170246958733, loss=0.11846300214529037
I0306 20:43:58.926113 140071541917440 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.017653800547122955, loss=0.12440619617700577
I0306 20:44:08.766485 140224878134464 spec.py:321] Evaluating on the training split.
I0306 20:45:06.711445 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 20:47:41.702070 140224878134464 spec.py:349] Evaluating on the test split.
I0306 20:53:34.351937 140224878134464 submission_runner.py:469] Time since start: 28316.22s, 	Step: 4609, 	{'train/loss': 0.12355698498680531, 'validation/loss': 0.12469633129271776, 'validation/num_examples': 83274637, 'test/loss': 0.12707774661800986, 'test/num_examples': 95000000, 'score': 4356.717090129852, 'total_duration': 28316.219083070755, 'accumulated_submission_time': 4356.717090129852, 'accumulated_eval_time': 23958.48954963684, 'accumulated_logging_time': 0.7655763626098633}
I0306 20:53:34.361134 140071550310144 logging_writer.py:48] [4609] accumulated_eval_time=23958.5, accumulated_logging_time=0.765576, accumulated_submission_time=4356.72, global_step=4609, preemption_count=0, score=4356.72, test/loss=0.127078, test/num_examples=95000000, total_duration=28316.2, train/loss=0.123557, validation/loss=0.124696, validation/num_examples=83274637
I0306 20:54:55.333263 140071541917440 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.006228956859558821, loss=0.12088882923126221
I0306 20:55:35.662446 140224878134464 spec.py:321] Evaluating on the training split.
I0306 20:56:29.469510 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 20:59:00.779011 140224878134464 spec.py:349] Evaluating on the test split.
I0306 21:04:46.036453 140224878134464 submission_runner.py:469] Time since start: 28987.90s, 	Step: 4736, 	{'train/loss': 0.12265450030612121, 'validation/loss': 0.12470377046809245, 'validation/num_examples': 83274637, 'test/loss': 0.12711668795230263, 'test/num_examples': 95000000, 'score': 4478.004957914352, 'total_duration': 28987.90357351303, 'accumulated_submission_time': 4478.004957914352, 'accumulated_eval_time': 24508.863488912582, 'accumulated_logging_time': 0.7812635898590088}
I0306 21:04:46.046766 140071550310144 logging_writer.py:48] [4736] accumulated_eval_time=24508.9, accumulated_logging_time=0.781264, accumulated_submission_time=4478, global_step=4736, preemption_count=0, score=4478, test/loss=0.127117, test/num_examples=95000000, total_duration=28987.9, train/loss=0.122655, validation/loss=0.124704, validation/num_examples=83274637
I0306 21:05:29.121351 140071541917440 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.006493919994682074, loss=0.11907593905925751
I0306 21:06:46.932641 140224878134464 spec.py:321] Evaluating on the training split.
I0306 21:07:42.311369 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 21:10:16.974237 140224878134464 spec.py:349] Evaluating on the test split.
I0306 21:16:12.968048 140224878134464 submission_runner.py:469] Time since start: 29674.84s, 	Step: 4867, 	{'train/loss': 0.12283101563090049, 'validation/loss': 0.1246223319540427, 'validation/num_examples': 83274637, 'test/loss': 0.12701407571957238, 'test/num_examples': 95000000, 'score': 4598.8775753974915, 'total_duration': 29674.835211277008, 'accumulated_submission_time': 4598.8775753974915, 'accumulated_eval_time': 25074.898844718933, 'accumulated_logging_time': 0.7984135150909424}
I0306 21:16:12.976949 140071550310144 logging_writer.py:48] [4867] accumulated_eval_time=25074.9, accumulated_logging_time=0.798414, accumulated_submission_time=4598.88, global_step=4867, preemption_count=0, score=4598.88, test/loss=0.127014, test/num_examples=95000000, total_duration=29674.8, train/loss=0.122831, validation/loss=0.124622, validation/num_examples=83274637
I0306 21:16:22.147366 140071541917440 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.008228377439081669, loss=0.11601581424474716
I0306 21:18:13.051090 140224878134464 spec.py:321] Evaluating on the training split.
I0306 21:19:06.263295 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 21:21:39.984686 140224878134464 spec.py:349] Evaluating on the test split.
I0306 21:27:17.277064 140224878134464 submission_runner.py:469] Time since start: 30339.14s, 	Step: 4996, 	{'train/loss': 0.12219214165266955, 'validation/loss': 0.12464436641946312, 'validation/num_examples': 83274637, 'test/loss': 0.12708347902960526, 'test/num_examples': 95000000, 'score': 4718.937885046005, 'total_duration': 30339.14422273636, 'accumulated_submission_time': 4718.937885046005, 'accumulated_eval_time': 25619.124763965607, 'accumulated_logging_time': 0.8142538070678711}
I0306 21:27:17.286282 140071550310144 logging_writer.py:48] [4996] accumulated_eval_time=25619.1, accumulated_logging_time=0.814254, accumulated_submission_time=4718.94, global_step=4996, preemption_count=0, score=4718.94, test/loss=0.127083, test/num_examples=95000000, total_duration=30339.1, train/loss=0.122192, validation/loss=0.124644, validation/num_examples=83274637
I0306 21:27:17.840102 140071541917440 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.0060380492359399796, loss=0.13136395812034607
I0306 21:28:52.249781 140071550310144 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.008605015464127064, loss=0.12043492496013641
I0306 21:29:17.985953 140224878134464 spec.py:321] Evaluating on the training split.
I0306 21:30:14.204581 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 21:32:45.987061 140224878134464 spec.py:349] Evaluating on the test split.
I0306 21:38:26.448901 140224878134464 submission_runner.py:469] Time since start: 31008.32s, 	Step: 5122, 	{'train/loss': 0.12114184270115019, 'validation/loss': 0.12434557003856446, 'validation/num_examples': 83274637, 'test/loss': 0.12668795190172696, 'test/num_examples': 95000000, 'score': 4839.624628067017, 'total_duration': 31008.31607079506, 'accumulated_submission_time': 4839.624628067017, 'accumulated_eval_time': 26167.5876660347, 'accumulated_logging_time': 0.829601526260376}
I0306 21:38:26.458118 140071541917440 logging_writer.py:48] [5122] accumulated_eval_time=26167.6, accumulated_logging_time=0.829602, accumulated_submission_time=4839.62, global_step=5122, preemption_count=0, score=4839.62, test/loss=0.126688, test/num_examples=95000000, total_duration=31008.3, train/loss=0.121142, validation/loss=0.124346, validation/num_examples=83274637
I0306 21:39:29.061593 140071550310144 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.018511394038796425, loss=0.1223512813448906
I0306 21:40:26.526597 140224878134464 spec.py:321] Evaluating on the training split.
I0306 21:41:26.153141 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 21:43:58.169425 140224878134464 spec.py:349] Evaluating on the test split.
I0306 21:49:43.425231 140224878134464 submission_runner.py:469] Time since start: 31685.29s, 	Step: 5250, 	{'train/loss': 0.1228061374394024, 'validation/loss': 0.12453792557416822, 'validation/num_examples': 83274637, 'test/loss': 0.12696020143914474, 'test/num_examples': 95000000, 'score': 4959.679259777069, 'total_duration': 31685.29237318039, 'accumulated_submission_time': 4959.679259777069, 'accumulated_eval_time': 26724.486232042313, 'accumulated_logging_time': 0.8456065654754639}
I0306 21:49:43.436321 140071541917440 logging_writer.py:48] [5250] accumulated_eval_time=26724.5, accumulated_logging_time=0.845607, accumulated_submission_time=4959.68, global_step=5250, preemption_count=0, score=4959.68, test/loss=0.12696, test/num_examples=95000000, total_duration=31685.3, train/loss=0.122806, validation/loss=0.124538, validation/num_examples=83274637
I0306 21:50:13.642285 140071550310144 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.009050633758306503, loss=0.11841389536857605
I0306 21:51:44.257507 140224878134464 spec.py:321] Evaluating on the training split.
I0306 21:52:40.833332 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 21:55:14.899591 140224878134464 spec.py:349] Evaluating on the test split.
I0306 22:00:52.704801 140224878134464 submission_runner.py:469] Time since start: 32354.57s, 	Step: 5377, 	{'train/loss': 0.1239787239183045, 'validation/loss': 0.12451761126761764, 'validation/num_examples': 83274637, 'test/loss': 0.1268497204872533, 'test/num_examples': 95000000, 'score': 5080.4880838394165, 'total_duration': 32354.57195043564, 'accumulated_submission_time': 5080.4880838394165, 'accumulated_eval_time': 27272.933461666107, 'accumulated_logging_time': 0.8630964756011963}
I0306 22:00:52.713948 140071541917440 logging_writer.py:48] [5377] accumulated_eval_time=27272.9, accumulated_logging_time=0.863096, accumulated_submission_time=5080.49, global_step=5377, preemption_count=0, score=5080.49, test/loss=0.12685, test/num_examples=95000000, total_duration=32354.6, train/loss=0.123979, validation/loss=0.124518, validation/num_examples=83274637
I0306 22:00:55.245714 140071550310144 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.006238159723579884, loss=0.12423386424779892
I0306 22:02:52.123588 140071541917440 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.0177215114235878, loss=0.12425761669874191
I0306 22:02:53.118871 140224878134464 spec.py:321] Evaluating on the training split.
I0306 22:03:51.796174 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 22:06:25.163739 140224878134464 spec.py:349] Evaluating on the test split.
I0306 22:12:01.890285 140224878134464 submission_runner.py:469] Time since start: 33023.76s, 	Step: 5502, 	{'train/loss': 0.1228777592029399, 'validation/loss': 0.12448152623762901, 'validation/num_examples': 83274637, 'test/loss': 0.12684942938939145, 'test/num_examples': 95000000, 'score': 5200.867920160294, 'total_duration': 33023.75745844841, 'accumulated_submission_time': 5200.867920160294, 'accumulated_eval_time': 27821.704835176468, 'accumulated_logging_time': 0.891512393951416}
I0306 22:12:01.899455 140071550310144 logging_writer.py:48] [5502] accumulated_eval_time=27821.7, accumulated_logging_time=0.891512, accumulated_submission_time=5200.87, global_step=5502, preemption_count=0, score=5200.87, test/loss=0.126849, test/num_examples=95000000, total_duration=33023.8, train/loss=0.122878, validation/loss=0.124482, validation/num_examples=83274637
I0306 22:13:21.975356 140071541917440 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.007271608337759972, loss=0.11915985494852066
I0306 22:14:02.726307 140224878134464 spec.py:321] Evaluating on the training split.
I0306 22:14:52.854747 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 22:17:26.491395 140224878134464 spec.py:349] Evaluating on the test split.
I0306 22:23:09.131976 140224878134464 submission_runner.py:469] Time since start: 33691.00s, 	Step: 5636, 	{'train/loss': 0.12133296596694668, 'validation/loss': 0.12420103121028915, 'validation/num_examples': 83274637, 'test/loss': 0.12656467734375, 'test/num_examples': 95000000, 'score': 5321.682158470154, 'total_duration': 33690.99912047386, 'accumulated_submission_time': 5321.682158470154, 'accumulated_eval_time': 28368.11043357849, 'accumulated_logging_time': 0.9068918228149414}
I0306 22:23:09.141503 140071550310144 logging_writer.py:48] [5636] accumulated_eval_time=28368.1, accumulated_logging_time=0.906892, accumulated_submission_time=5321.68, global_step=5636, preemption_count=0, score=5321.68, test/loss=0.126565, test/num_examples=95000000, total_duration=33691, train/loss=0.121333, validation/loss=0.124201, validation/num_examples=83274637
I0306 22:23:55.741257 140071541917440 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.012362449429929256, loss=0.12354645878076553
I0306 22:25:09.588789 140224878134464 spec.py:321] Evaluating on the training split.
I0306 22:26:03.370649 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 22:28:37.834573 140224878134464 spec.py:349] Evaluating on the test split.
I0306 22:34:24.747191 140224878134464 submission_runner.py:469] Time since start: 34366.61s, 	Step: 5762, 	{'train/loss': 0.12351754499868776, 'validation/loss': 0.12423273173991928, 'validation/num_examples': 83274637, 'test/loss': 0.126722354296875, 'test/num_examples': 95000000, 'score': 5442.116317987442, 'total_duration': 34366.61434197426, 'accumulated_submission_time': 5442.116317987442, 'accumulated_eval_time': 28923.268782377243, 'accumulated_logging_time': 0.9226040840148926}
I0306 22:34:24.756613 140071550310144 logging_writer.py:48] [5762] accumulated_eval_time=28923.3, accumulated_logging_time=0.922604, accumulated_submission_time=5442.12, global_step=5762, preemption_count=0, score=5442.12, test/loss=0.126722, test/num_examples=95000000, total_duration=34366.6, train/loss=0.123518, validation/loss=0.124233, validation/num_examples=83274637
I0306 22:34:40.024619 140071541917440 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.0147447120398283, loss=0.11810382455587387
I0306 22:36:26.299449 140224878134464 spec.py:321] Evaluating on the training split.
I0306 22:37:19.528110 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 22:39:54.199583 140224878134464 spec.py:349] Evaluating on the test split.
I0306 22:45:51.779572 140224878134464 submission_runner.py:469] Time since start: 35053.65s, 	Step: 5891, 	{'train/loss': 0.12289350550129728, 'validation/loss': 0.12413692956772511, 'validation/num_examples': 83274637, 'test/loss': 0.12654816418585527, 'test/num_examples': 95000000, 'score': 5563.645479679108, 'total_duration': 35053.64669895172, 'accumulated_submission_time': 5563.645479679108, 'accumulated_eval_time': 29488.748819351196, 'accumulated_logging_time': 0.9389252662658691}
I0306 22:45:51.789110 140071550310144 logging_writer.py:48] [5891] accumulated_eval_time=29488.7, accumulated_logging_time=0.938925, accumulated_submission_time=5563.65, global_step=5891, preemption_count=0, score=5563.65, test/loss=0.126548, test/num_examples=95000000, total_duration=35053.6, train/loss=0.122894, validation/loss=0.124137, validation/num_examples=83274637
I0306 22:45:52.846651 140071541917440 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.01597515679895878, loss=0.133765310049057
I0306 22:47:31.891099 140071550310144 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.009752115234732628, loss=0.11858505755662918
I0306 22:47:51.899078 140224878134464 spec.py:321] Evaluating on the training split.
I0306 22:48:47.839834 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 22:51:21.395100 140224878134464 spec.py:349] Evaluating on the test split.
I0306 22:57:09.475663 140224878134464 submission_runner.py:469] Time since start: 35731.34s, 	Step: 6019, 	{'train/loss': 0.12192594835171534, 'validation/loss': 0.12424312751146209, 'validation/num_examples': 83274637, 'test/loss': 0.12668825615748355, 'test/num_examples': 95000000, 'score': 5683.7428233623505, 'total_duration': 35731.34281158447, 'accumulated_submission_time': 5683.7428233623505, 'accumulated_eval_time': 30046.325338363647, 'accumulated_logging_time': 0.9545319080352783}
I0306 22:57:09.485101 140071541917440 logging_writer.py:48] [6019] accumulated_eval_time=30046.3, accumulated_logging_time=0.954532, accumulated_submission_time=5683.74, global_step=6019, preemption_count=0, score=5683.74, test/loss=0.126688, test/num_examples=95000000, total_duration=35731.3, train/loss=0.121926, validation/loss=0.124243, validation/num_examples=83274637
I0306 22:58:08.862567 140071550310144 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.009007523767650127, loss=0.12339254468679428
I0306 22:59:09.731462 140224878134464 spec.py:321] Evaluating on the training split.
I0306 23:00:04.368295 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 23:02:40.521833 140224878134464 spec.py:349] Evaluating on the test split.
I0306 23:08:33.717232 140224878134464 submission_runner.py:469] Time since start: 36415.58s, 	Step: 6155, 	{'train/loss': 0.12420413578690598, 'validation/loss': 0.12420431697776418, 'validation/num_examples': 83274637, 'test/loss': 0.12665821828741777, 'test/num_examples': 95000000, 'score': 5803.976886034012, 'total_duration': 36415.58439898491, 'accumulated_submission_time': 5803.976886034012, 'accumulated_eval_time': 30610.311059474945, 'accumulated_logging_time': 0.9698781967163086}
I0306 23:08:33.726858 140071541917440 logging_writer.py:48] [6155] accumulated_eval_time=30610.3, accumulated_logging_time=0.969878, accumulated_submission_time=5803.98, global_step=6155, preemption_count=0, score=5803.98, test/loss=0.126658, test/num_examples=95000000, total_duration=36415.6, train/loss=0.124204, validation/loss=0.124204, validation/num_examples=83274637
I0306 23:08:57.907146 140071550310144 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.012285696342587471, loss=0.12520058453083038
I0306 23:10:33.834347 140224878134464 spec.py:321] Evaluating on the training split.
I0306 23:11:28.068537 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 23:14:02.301740 140224878134464 spec.py:349] Evaluating on the test split.
I0306 23:19:56.096582 140224878134464 submission_runner.py:469] Time since start: 37097.96s, 	Step: 6282, 	{'train/loss': 0.12210245076684081, 'validation/loss': 0.12418290745643314, 'validation/num_examples': 83274637, 'test/loss': 0.12653820660978618, 'test/num_examples': 95000000, 'score': 5924.071258544922, 'total_duration': 37097.96375012398, 'accumulated_submission_time': 5924.071258544922, 'accumulated_eval_time': 31172.573248386383, 'accumulated_logging_time': 0.9865877628326416}
I0306 23:19:56.105946 140071541917440 logging_writer.py:48] [6282] accumulated_eval_time=31172.6, accumulated_logging_time=0.986588, accumulated_submission_time=5924.07, global_step=6282, preemption_count=0, score=5924.07, test/loss=0.126538, test/num_examples=95000000, total_duration=37098, train/loss=0.122102, validation/loss=0.124183, validation/num_examples=83274637
I0306 23:19:58.162305 140071550310144 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.006896876264363527, loss=0.12805531919002533
I0306 23:21:40.967916 140071541917440 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.006863522343337536, loss=0.12874363362789154
I0306 23:21:57.338730 140224878134464 spec.py:321] Evaluating on the training split.
I0306 23:22:56.162491 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 23:25:28.504261 140224878134464 spec.py:349] Evaluating on the test split.
I0306 23:31:09.980233 140224878134464 submission_runner.py:469] Time since start: 37771.85s, 	Step: 6416, 	{'train/loss': 0.12320304582328917, 'validation/loss': 0.12415039366452373, 'validation/num_examples': 83274637, 'test/loss': 0.1264688036903783, 'test/num_examples': 95000000, 'score': 6045.241501092911, 'total_duration': 37771.84740066528, 'accumulated_submission_time': 6045.241501092911, 'accumulated_eval_time': 31725.214702367783, 'accumulated_logging_time': 1.0516777038574219}
I0306 23:31:09.989640 140071550310144 logging_writer.py:48] [6416] accumulated_eval_time=31725.2, accumulated_logging_time=1.05168, accumulated_submission_time=6045.24, global_step=6416, preemption_count=0, score=6045.24, test/loss=0.126469, test/num_examples=95000000, total_duration=37771.8, train/loss=0.123203, validation/loss=0.12415, validation/num_examples=83274637
I0306 23:32:18.551384 140071541917440 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.006299606990069151, loss=0.11937923729419708
I0306 23:33:10.569100 140224878134464 spec.py:321] Evaluating on the training split.
I0306 23:34:09.339790 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 23:36:41.805233 140224878134464 spec.py:349] Evaluating on the test split.
I0306 23:42:23.987373 140224878134464 submission_runner.py:469] Time since start: 38445.85s, 	Step: 6546, 	{'train/loss': 0.12100375023137473, 'validation/loss': 0.12412816681750441, 'validation/num_examples': 83274637, 'test/loss': 0.12659344424342106, 'test/num_examples': 95000000, 'score': 6165.807867765427, 'total_duration': 38445.85452270508, 'accumulated_submission_time': 6165.807867765427, 'accumulated_eval_time': 32278.632910251617, 'accumulated_logging_time': 1.0673913955688477}
I0306 23:42:23.998375 140071550310144 logging_writer.py:48] [6546] accumulated_eval_time=32278.6, accumulated_logging_time=1.06739, accumulated_submission_time=6165.81, global_step=6546, preemption_count=0, score=6165.81, test/loss=0.126593, test/num_examples=95000000, total_duration=38445.9, train/loss=0.121004, validation/loss=0.124128, validation/num_examples=83274637
I0306 23:42:58.626253 140071541917440 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.014483492821455002, loss=0.1230357363820076
I0306 23:44:24.214136 140224878134464 spec.py:321] Evaluating on the training split.
I0306 23:45:18.681780 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 23:47:52.311477 140224878134464 spec.py:349] Evaluating on the test split.
I0306 23:53:30.708413 140224878134464 submission_runner.py:469] Time since start: 39112.58s, 	Step: 6675, 	{'train/loss': 0.12437639526038799, 'validation/loss': 0.12403830547820903, 'validation/num_examples': 83274637, 'test/loss': 0.12641606010485198, 'test/num_examples': 95000000, 'score': 6286.010834693909, 'total_duration': 39112.57557082176, 'accumulated_submission_time': 6286.010834693909, 'accumulated_eval_time': 32825.127130270004, 'accumulated_logging_time': 1.0849800109863281}
I0306 23:53:30.717568 140071550310144 logging_writer.py:48] [6675] accumulated_eval_time=32825.1, accumulated_logging_time=1.08498, accumulated_submission_time=6286.01, global_step=6675, preemption_count=0, score=6286.01, test/loss=0.126416, test/num_examples=95000000, total_duration=39112.6, train/loss=0.124376, validation/loss=0.124038, validation/num_examples=83274637
I0306 23:53:33.463858 140071541917440 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.0072157122194767, loss=0.12699280679225922
I0306 23:55:24.384328 140071550310144 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.012869705446064472, loss=0.1321353018283844
I0306 23:55:30.877993 140224878134464 spec.py:321] Evaluating on the training split.
I0306 23:56:26.519275 140224878134464 spec.py:333] Evaluating on the validation split.
I0306 23:59:01.072099 140224878134464 spec.py:349] Evaluating on the test split.
I0307 00:04:59.536761 140224878134464 submission_runner.py:469] Time since start: 39801.40s, 	Step: 6807, 	{'train/loss': 0.12243977374157065, 'validation/loss': 0.1240464353568816, 'validation/num_examples': 83274637, 'test/loss': 0.12652246586143093, 'test/num_examples': 95000000, 'score': 6406.157833337784, 'total_duration': 39801.40392279625, 'accumulated_submission_time': 6406.157833337784, 'accumulated_eval_time': 33393.785843372345, 'accumulated_logging_time': 1.1012561321258545}
I0307 00:04:59.546440 140071541917440 logging_writer.py:48] [6807] accumulated_eval_time=33393.8, accumulated_logging_time=1.10126, accumulated_submission_time=6406.16, global_step=6807, preemption_count=0, score=6406.16, test/loss=0.126522, test/num_examples=95000000, total_duration=39801.4, train/loss=0.12244, validation/loss=0.124046, validation/num_examples=83274637
I0307 00:06:15.434845 140071550310144 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.009667201898992062, loss=0.12378410249948502
I0307 00:06:59.681298 140224878134464 spec.py:321] Evaluating on the training split.
I0307 00:07:54.078150 140224878134464 spec.py:333] Evaluating on the validation split.
I0307 00:10:26.289344 140224878134464 spec.py:349] Evaluating on the test split.
I0307 00:16:28.758618 140224878134464 submission_runner.py:469] Time since start: 40490.63s, 	Step: 6941, 	{'train/loss': 0.12474828953825452, 'validation/loss': 0.12416046614585513, 'validation/num_examples': 83274637, 'test/loss': 0.12656612782689144, 'test/num_examples': 95000000, 'score': 6526.280298233032, 'total_duration': 40490.6257686615, 'accumulated_submission_time': 6526.280298233032, 'accumulated_eval_time': 33962.86309671402, 'accumulated_logging_time': 1.1171345710754395}
I0307 00:16:28.768474 140071541917440 logging_writer.py:48] [6941] accumulated_eval_time=33962.9, accumulated_logging_time=1.11713, accumulated_submission_time=6526.28, global_step=6941, preemption_count=0, score=6526.28, test/loss=0.126566, test/num_examples=95000000, total_duration=40490.6, train/loss=0.124748, validation/loss=0.12416, validation/num_examples=83274637
I0307 00:17:08.823407 140071550310144 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.008069849573075771, loss=0.12015273422002792
I0307 00:18:29.546495 140224878134464 spec.py:321] Evaluating on the training split.
I0307 00:19:18.573182 140224878134464 spec.py:333] Evaluating on the validation split.
I0307 00:21:51.482640 140224878134464 spec.py:349] Evaluating on the test split.
I0307 00:27:47.584543 140224878134464 submission_runner.py:469] Time since start: 41169.45s, 	Step: 7073, 	{'train/loss': 0.12164396970714413, 'validation/loss': 0.12390258661037266, 'validation/num_examples': 83274637, 'test/loss': 0.12620509709087172, 'test/num_examples': 95000000, 'score': 6647.045482635498, 'total_duration': 41169.45170092583, 'accumulated_submission_time': 6647.045482635498, 'accumulated_eval_time': 34520.90109157562, 'accumulated_logging_time': 1.1334724426269531}
I0307 00:27:47.594667 140071541917440 logging_writer.py:48] [7073] accumulated_eval_time=34520.9, accumulated_logging_time=1.13347, accumulated_submission_time=6647.05, global_step=7073, preemption_count=0, score=6647.05, test/loss=0.126205, test/num_examples=95000000, total_duration=41169.5, train/loss=0.121644, validation/loss=0.123903, validation/num_examples=83274637
I0307 00:27:50.899773 140071550310144 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.007509835995733738, loss=0.11673472076654434
I0307 00:29:40.575284 140071541917440 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.007946657948195934, loss=0.1200791746377945
I0307 00:29:48.694829 140224878134464 spec.py:321] Evaluating on the training split.
I0307 00:30:51.578623 140224878134464 spec.py:333] Evaluating on the validation split.
I0307 00:33:27.576553 140224878134464 spec.py:349] Evaluating on the test split.
I0307 00:39:05.937333 140224878134464 submission_runner.py:469] Time since start: 41847.80s, 	Step: 7208, 	{'train/loss': 0.12051316481903664, 'validation/loss': 0.12397587416058588, 'validation/num_examples': 83274637, 'test/loss': 0.12633598976151317, 'test/num_examples': 95000000, 'score': 6768.132524251938, 'total_duration': 41847.80449938774, 'accumulated_submission_time': 6768.132524251938, 'accumulated_eval_time': 35078.14354515076, 'accumulated_logging_time': 1.1505305767059326}
I0307 00:39:06.014227 140071550310144 logging_writer.py:48] [7208] accumulated_eval_time=35078.1, accumulated_logging_time=1.15053, accumulated_submission_time=6768.13, global_step=7208, preemption_count=0, score=6768.13, test/loss=0.126336, test/num_examples=95000000, total_duration=41847.8, train/loss=0.120513, validation/loss=0.123976, validation/num_examples=83274637
I0307 00:40:26.985020 140071541917440 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.007946591824293137, loss=0.1266850233078003
I0307 00:41:06.468103 140224878134464 spec.py:321] Evaluating on the training split.
I0307 00:42:02.553691 140224878134464 spec.py:333] Evaluating on the validation split.
I0307 00:44:36.182211 140224878134464 spec.py:349] Evaluating on the test split.
I0307 00:50:11.521290 140224878134464 submission_runner.py:469] Time since start: 42513.39s, 	Step: 7335, 	{'train/loss': 0.11955316145699355, 'validation/loss': 0.12395800349319595, 'validation/num_examples': 83274637, 'test/loss': 0.1263557696751645, 'test/num_examples': 95000000, 'score': 6888.551467657089, 'total_duration': 42513.38844347, 'accumulated_submission_time': 6888.551467657089, 'accumulated_eval_time': 35623.19666957855, 'accumulated_logging_time': 1.256185531616211}
I0307 00:50:11.530854 140071550310144 logging_writer.py:48] [7335] accumulated_eval_time=35623.2, accumulated_logging_time=1.25619, accumulated_submission_time=6888.55, global_step=7335, preemption_count=0, score=6888.55, test/loss=0.126356, test/num_examples=95000000, total_duration=42513.4, train/loss=0.119553, validation/loss=0.123958, validation/num_examples=83274637
I0307 00:50:59.631836 140071541917440 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.01834321953356266, loss=0.11991974711418152
I0307 00:52:11.558097 140224878134464 spec.py:321] Evaluating on the training split.
I0307 00:53:08.546281 140224878134464 spec.py:333] Evaluating on the validation split.
I0307 00:55:42.551917 140224878134464 spec.py:349] Evaluating on the test split.
I0307 01:01:41.089868 140224878134464 submission_runner.py:469] Time since start: 43202.96s, 	Step: 7459, 	{'train/loss': 0.1222746321615183, 'validation/loss': 0.12392816266799105, 'validation/num_examples': 83274637, 'test/loss': 0.12629452386924342, 'test/num_examples': 95000000, 'score': 7008.565945148468, 'total_duration': 43202.95703482628, 'accumulated_submission_time': 7008.565945148468, 'accumulated_eval_time': 36192.72839617729, 'accumulated_logging_time': 1.272413969039917}
I0307 01:01:41.157253 140071550310144 logging_writer.py:48] [7459] accumulated_eval_time=36192.7, accumulated_logging_time=1.27241, accumulated_submission_time=7008.57, global_step=7459, preemption_count=0, score=7008.57, test/loss=0.126295, test/num_examples=95000000, total_duration=43203, train/loss=0.122275, validation/loss=0.123928, validation/num_examples=83274637
I0307 01:01:58.739396 140071541917440 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.007422619499266148, loss=0.12161770462989807
I0307 01:03:42.772164 140224878134464 spec.py:321] Evaluating on the training split.
I0307 01:04:38.554176 140224878134464 spec.py:333] Evaluating on the validation split.
I0307 01:07:13.137688 140224878134464 spec.py:349] Evaluating on the test split.
I0307 01:12:46.753140 140224878134464 submission_runner.py:469] Time since start: 43868.62s, 	Step: 7590, 	{'train/loss': 0.12255739569429706, 'validation/loss': 0.12394873398369256, 'validation/num_examples': 83274637, 'test/loss': 0.1262888908614309, 'test/num_examples': 95000000, 'score': 7130.166995048523, 'total_duration': 43868.62030649185, 'accumulated_submission_time': 7130.166995048523, 'accumulated_eval_time': 36736.70932388306, 'accumulated_logging_time': 1.3473093509674072}
I0307 01:12:46.763453 140071550310144 logging_writer.py:48] [7590] accumulated_eval_time=36736.7, accumulated_logging_time=1.34731, accumulated_submission_time=7130.17, global_step=7590, preemption_count=0, score=7130.17, test/loss=0.126289, test/num_examples=95000000, total_duration=43868.6, train/loss=0.122557, validation/loss=0.123949, validation/num_examples=83274637
I0307 01:12:47.938691 140071541917440 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.014434468001127243, loss=0.12441624701023102
I0307 01:14:26.041247 140071550310144 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.006886468734592199, loss=0.12019815295934677
I0307 01:14:47.055882 140224878134464 spec.py:321] Evaluating on the training split.
I0307 01:15:41.550335 140224878134464 spec.py:333] Evaluating on the validation split.
I0307 01:18:15.114050 140224878134464 spec.py:349] Evaluating on the test split.
I0307 01:23:53.471706 140224878134464 submission_runner.py:469] Time since start: 44535.34s, 	Step: 7719, 	{'train/loss': 0.12169821299143932, 'validation/loss': 0.12391652641919502, 'validation/num_examples': 83274637, 'test/loss': 0.12618027586348685, 'test/num_examples': 95000000, 'score': 7250.4461896419525, 'total_duration': 44535.33886241913, 'accumulated_submission_time': 7250.4461896419525, 'accumulated_eval_time': 37283.125086545944, 'accumulated_logging_time': 1.364640474319458}
I0307 01:23:53.481931 140071541917440 logging_writer.py:48] [7719] accumulated_eval_time=37283.1, accumulated_logging_time=1.36464, accumulated_submission_time=7250.45, global_step=7719, preemption_count=0, score=7250.45, test/loss=0.12618, test/num_examples=95000000, total_duration=44535.3, train/loss=0.121698, validation/loss=0.123917, validation/num_examples=83274637
I0307 01:24:53.943130 140071550310144 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.009636289440095425, loss=0.12834152579307556
I0307 01:25:54.106966 140224878134464 spec.py:321] Evaluating on the training split.
I0307 01:26:45.916866 140224878134464 spec.py:333] Evaluating on the validation split.
I0307 01:29:18.448216 140224878134464 spec.py:349] Evaluating on the test split.
I0307 01:35:01.686391 140224878134464 submission_runner.py:469] Time since start: 45203.55s, 	Step: 7856, 	{'train/loss': 0.1207770668555918, 'validation/loss': 0.1239022196956841, 'validation/num_examples': 83274637, 'test/loss': 0.12626854133429277, 'test/num_examples': 95000000, 'score': 7371.057455539703, 'total_duration': 45203.55355024338, 'accumulated_submission_time': 7371.057455539703, 'accumulated_eval_time': 37830.704484939575, 'accumulated_logging_time': 1.3817527294158936}
I0307 01:35:01.695970 140071541917440 logging_writer.py:48] [7856] accumulated_eval_time=37830.7, accumulated_logging_time=1.38175, accumulated_submission_time=7371.06, global_step=7856, preemption_count=0, score=7371.06, test/loss=0.126269, test/num_examples=95000000, total_duration=45203.6, train/loss=0.120777, validation/loss=0.123902, validation/num_examples=83274637
I0307 01:35:23.393616 140071550310144 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.008597576059401035, loss=0.11953245103359222
I0307 01:37:01.803730 140224878134464 spec.py:321] Evaluating on the training split.
I0307 01:37:55.595059 140224878134464 spec.py:333] Evaluating on the validation split.
I0307 01:40:28.947051 140224878134464 spec.py:349] Evaluating on the test split.
I0307 01:46:21.997209 140224878134464 submission_runner.py:469] Time since start: 45883.86s, 	Step: 7992, 	{'train/loss': 0.1200458640056961, 'validation/loss': 0.12391613738736562, 'validation/num_examples': 83274637, 'test/loss': 0.12630741820518093, 'test/num_examples': 95000000, 'score': 7491.152491807938, 'total_duration': 45883.86437487602, 'accumulated_submission_time': 7491.152491807938, 'accumulated_eval_time': 38390.897914648056, 'accumulated_logging_time': 1.3975636959075928}
I0307 01:46:22.007283 140071541917440 logging_writer.py:48] [7992] accumulated_eval_time=38390.9, accumulated_logging_time=1.39756, accumulated_submission_time=7491.15, global_step=7992, preemption_count=0, score=7491.15, test/loss=0.126307, test/num_examples=95000000, total_duration=45883.9, train/loss=0.120046, validation/loss=0.123916, validation/num_examples=83274637
I0307 01:46:22.964083 140071550310144 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.009175284765660763, loss=0.12043043971061707
I0307 01:47:55.873274 140071541917440 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.010350661352276802, loss=0.12378270924091339
I0307 01:48:22.151396 140224878134464 spec.py:321] Evaluating on the training split.
I0307 01:49:17.032398 140224878134464 spec.py:333] Evaluating on the validation split.
I0307 01:51:51.524445 140224878134464 spec.py:349] Evaluating on the test split.
I0307 01:57:32.120430 140224878134464 submission_runner.py:469] Time since start: 46553.99s, 	Step: 8125, 	{'train/loss': 0.1209765484544841, 'validation/loss': 0.12390205023452625, 'validation/num_examples': 83274637, 'test/loss': 0.12613941277754934, 'test/num_examples': 95000000, 'score': 7611.283947467804, 'total_duration': 46553.98759508133, 'accumulated_submission_time': 7611.283947467804, 'accumulated_eval_time': 38940.866898059845, 'accumulated_logging_time': 1.4134716987609863}
I0307 01:57:32.198588 140071550310144 logging_writer.py:48] [8125] accumulated_eval_time=38940.9, accumulated_logging_time=1.41347, accumulated_submission_time=7611.28, global_step=8125, preemption_count=0, score=7611.28, test/loss=0.126139, test/num_examples=95000000, total_duration=46554, train/loss=0.120977, validation/loss=0.123902, validation/num_examples=83274637
I0307 01:58:27.601293 140071541917440 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.008281932212412357, loss=0.12138758599758148
I0307 01:59:33.119501 140071550310144 logging_writer.py:48] [8256] global_step=8256, preemption_count=0, score=7732.1
I0307 01:59:38.583046 140224878134464 submission_runner.py:646] Tuning trial 1/5
I0307 01:59:38.599977 140224878134464 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.1, learning_rate=0.001308209823469072, one_minus_beta1=0.02686663061, beta2=0.9981232922116359, weight_decay=0.16375311233774334, warmup_factor=0.1)
I0307 01:59:38.601325 140224878134464 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/loss': 0.9196143575809287, 'validation/loss': 0.9229366760009864, 'validation/num_examples': 83274637, 'test/loss': 0.9205822050164474, 'test/num_examples': 95000000, 'score': 17.057493925094604, 'total_duration': 1136.2862927913666, 'accumulated_submission_time': 17.057493925094604, 'accumulated_eval_time': 1119.228694677353, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (130, {'train/loss': 0.13922051668354551, 'validation/loss': 0.13990981591204654, 'validation/num_examples': 83274637, 'test/loss': 0.14331528757195724, 'test/num_examples': 95000000, 'score': 137.01685905456543, 'total_duration': 2210.627004623413, 'accumulated_submission_time': 137.01685905456543, 'accumulated_eval_time': 2073.557671546936, 'accumulated_logging_time': 0.04588913917541504, 'global_step': 130, 'preemption_count': 0}), (256, {'train/loss': 0.12762024203233374, 'validation/loss': 0.12992502655794375, 'validation/num_examples': 83274637, 'test/loss': 0.13247987954358553, 'test/num_examples': 95000000, 'score': 258.24850249290466, 'total_duration': 3306.1713054180145, 'accumulated_submission_time': 258.24850249290466, 'accumulated_eval_time': 3047.8489394187927, 'accumulated_logging_time': 0.06103968620300293, 'global_step': 256, 'preemption_count': 0}), (386, {'train/loss': 0.1273922823931811, 'validation/loss': 0.1284392818518549, 'validation/num_examples': 83274637, 'test/loss': 0.13103932433182566, 'test/num_examples': 95000000, 'score': 378.58532333374023, 'total_duration': 4419.395301818848, 'accumulated_submission_time': 378.58532333374023, 'accumulated_eval_time': 4040.7151696681976, 'accumulated_logging_time': 0.0752713680267334, 'global_step': 386, 'preemption_count': 0}), (515, {'train/loss': 0.12857550129575548, 'validation/loss': 0.12798972288980265, 'validation/num_examples': 83274637, 'test/loss': 0.13063444089226975, 'test/num_examples': 95000000, 'score': 498.9430103302002, 'total_duration': 5464.259056806564, 'accumulated_submission_time': 498.9430103302002, 'accumulated_eval_time': 4965.175580739975, 'accumulated_logging_time': 0.11451911926269531, 'global_step': 515, 'preemption_count': 0}), (641, {'train/loss': 0.12528002923998818, 'validation/loss': 0.12740319713600942, 'validation/num_examples': 83274637, 'test/loss': 0.12995577141241776, 'test/num_examples': 95000000, 'score': 620.2118453979492, 'total_duration': 6517.672875881195, 'accumulated_submission_time': 620.2118453979492, 'accumulated_eval_time': 5897.298082113266, 'accumulated_logging_time': 0.13039636611938477, 'global_step': 641, 'preemption_count': 0}), (764, {'train/loss': 0.12635891236739713, 'validation/loss': 0.12723421475092447, 'validation/num_examples': 83274637, 'test/loss': 0.12957280272409538, 'test/num_examples': 95000000, 'score': 740.8949818611145, 'total_duration': 7535.612446546555, 'accumulated_submission_time': 740.8949818611145, 'accumulated_eval_time': 6794.529451608658, 'accumulated_logging_time': 0.14700818061828613, 'global_step': 764, 'preemption_count': 0}), (892, {'train/loss': 0.12562455738303047, 'validation/loss': 0.1267581362346651, 'validation/num_examples': 83274637, 'test/loss': 0.12901707156661185, 'test/num_examples': 95000000, 'score': 861.0626103878021, 'total_duration': 8488.324535131454, 'accumulated_submission_time': 861.0626103878021, 'accumulated_eval_time': 7627.0519897937775, 'accumulated_logging_time': 0.16220474243164062, 'global_step': 892, 'preemption_count': 0}), (1020, {'train/loss': 0.12587331695798434, 'validation/loss': 0.12649442674516326, 'validation/num_examples': 83274637, 'test/loss': 0.12887928706825658, 'test/num_examples': 95000000, 'score': 981.636682510376, 'total_duration': 9317.944452524185, 'accumulated_submission_time': 981.636682510376, 'accumulated_eval_time': 8336.03215789795, 'accumulated_logging_time': 0.2215116024017334, 'global_step': 1020, 'preemption_count': 0}), (1145, {'train/loss': 0.12514338843852468, 'validation/loss': 0.1264490381152532, 'validation/num_examples': 83274637, 'test/loss': 0.12874205677425987, 'test/num_examples': 95000000, 'score': 1102.1241688728333, 'total_duration': 9995.978727817535, 'accumulated_submission_time': 1102.1241688728333, 'accumulated_eval_time': 8893.557971954346, 'accumulated_logging_time': 0.23534250259399414, 'global_step': 1145, 'preemption_count': 0}), (1266, {'train/loss': 0.12630892903456148, 'validation/loss': 0.12614313065140184, 'validation/num_examples': 83274637, 'test/loss': 0.1285532289165296, 'test/num_examples': 95000000, 'score': 1222.7741160392761, 'total_duration': 10677.420635700226, 'accumulated_submission_time': 1222.7741160392761, 'accumulated_eval_time': 9454.327657461166, 'accumulated_logging_time': 0.2506680488586426, 'global_step': 1266, 'preemption_count': 0}), (1394, {'train/loss': 0.12490461475022559, 'validation/loss': 0.12608888799408885, 'validation/num_examples': 83274637, 'test/loss': 0.12858147589432567, 'test/num_examples': 95000000, 'score': 1343.465006828308, 'total_duration': 11371.684135913849, 'accumulated_submission_time': 1343.465006828308, 'accumulated_eval_time': 10027.875089168549, 'accumulated_logging_time': 0.2687344551086426, 'global_step': 1394, 'preemption_count': 0}), (1527, {'train/loss': 0.12292702337902672, 'validation/loss': 0.125851692611598, 'validation/num_examples': 83274637, 'test/loss': 0.12801924130345393, 'test/num_examples': 95000000, 'score': 1464.3829531669617, 'total_duration': 12061.64479804039, 'accumulated_submission_time': 1464.3829531669617, 'accumulated_eval_time': 10596.896197080612, 'accumulated_logging_time': 0.2842082977294922, 'global_step': 1527, 'preemption_count': 0}), (1653, {'train/loss': 0.1245990877607896, 'validation/loss': 0.12588276019931796, 'validation/num_examples': 83274637, 'test/loss': 0.12834948683182565, 'test/num_examples': 95000000, 'score': 1584.6566817760468, 'total_duration': 12743.827060699463, 'accumulated_submission_time': 1584.6566817760468, 'accumulated_eval_time': 11158.783473968506, 'accumulated_logging_time': 0.29814767837524414, 'global_step': 1653, 'preemption_count': 0}), (1784, {'train/loss': 0.12264213886744571, 'validation/loss': 0.1253606469418061, 'validation/num_examples': 83274637, 'test/loss': 0.1278376279296875, 'test/num_examples': 95000000, 'score': 1704.750562429428, 'total_duration': 13430.637394428253, 'accumulated_submission_time': 1704.750562429428, 'accumulated_eval_time': 11725.476895809174, 'accumulated_logging_time': 0.31386566162109375, 'global_step': 1784, 'preemption_count': 0}), (1917, {'train/loss': 0.12535944368994836, 'validation/loss': 0.12577087633269832, 'validation/num_examples': 83274637, 'test/loss': 0.12823409129317434, 'test/num_examples': 95000000, 'score': 1825.2497191429138, 'total_duration': 14110.929565191269, 'accumulated_submission_time': 1825.2497191429138, 'accumulated_eval_time': 12285.25005865097, 'accumulated_logging_time': 0.32752180099487305, 'global_step': 1917, 'preemption_count': 0}), (2046, {'train/loss': 0.12301988857534696, 'validation/loss': 0.12540330944647535, 'validation/num_examples': 83274637, 'test/loss': 0.1278205515316612, 'test/num_examples': 95000000, 'score': 1945.8221802711487, 'total_duration': 14780.173733949661, 'accumulated_submission_time': 1945.8221802711487, 'accumulated_eval_time': 12833.900797128677, 'accumulated_logging_time': 0.3416569232940674, 'global_step': 2046, 'preemption_count': 0}), (2171, {'train/loss': 0.1244098251603497, 'validation/loss': 0.1254197488029785, 'validation/num_examples': 83274637, 'test/loss': 0.12780723820929277, 'test/num_examples': 95000000, 'score': 2066.8094573020935, 'total_duration': 15457.271560430527, 'accumulated_submission_time': 2066.8094573020935, 'accumulated_eval_time': 13389.988570451736, 'accumulated_logging_time': 0.3577542304992676, 'global_step': 2171, 'preemption_count': 0}), (2299, {'train/loss': 0.12340157155720692, 'validation/loss': 0.12537425304096866, 'validation/num_examples': 83274637, 'test/loss': 0.1278177814041941, 'test/num_examples': 95000000, 'score': 2187.048721075058, 'total_duration': 16136.613797426224, 'accumulated_submission_time': 2187.048721075058, 'accumulated_eval_time': 13949.067103862762, 'accumulated_logging_time': 0.3739655017852783, 'global_step': 2299, 'preemption_count': 0}), (2427, {'train/loss': 0.12252721272455822, 'validation/loss': 0.12537723249307928, 'validation/num_examples': 83274637, 'test/loss': 0.1280610507504112, 'test/num_examples': 95000000, 'score': 2307.169387102127, 'total_duration': 16804.96439599991, 'accumulated_submission_time': 2307.169387102127, 'accumulated_eval_time': 14497.275040626526, 'accumulated_logging_time': 0.38918328285217285, 'global_step': 2427, 'preemption_count': 0}), (2562, {'train/loss': 0.12417189441855599, 'validation/loss': 0.12530777134895563, 'validation/num_examples': 83274637, 'test/loss': 0.12777654502467106, 'test/num_examples': 95000000, 'score': 2427.372974872589, 'total_duration': 17500.666215658188, 'accumulated_submission_time': 2427.372974872589, 'accumulated_eval_time': 15072.751198768616, 'accumulated_logging_time': 0.40448474884033203, 'global_step': 2562, 'preemption_count': 0}), (2691, {'train/loss': 0.12240270522874107, 'validation/loss': 0.12508291670365898, 'validation/num_examples': 83274637, 'test/loss': 0.1277035269839638, 'test/num_examples': 95000000, 'score': 2548.062455892563, 'total_duration': 18182.250067472458, 'accumulated_submission_time': 2548.062455892563, 'accumulated_eval_time': 15633.6228017807, 'accumulated_logging_time': 0.4209916591644287, 'global_step': 2691, 'preemption_count': 0}), (2818, {'train/loss': 0.12535251147529614, 'validation/loss': 0.12507060621628707, 'validation/num_examples': 83274637, 'test/loss': 0.12752194386307567, 'test/num_examples': 95000000, 'score': 2668.7524321079254, 'total_duration': 18865.27342605591, 'accumulated_submission_time': 2668.7524321079254, 'accumulated_eval_time': 16195.936029672623, 'accumulated_logging_time': 0.4352147579193115, 'global_step': 2818, 'preemption_count': 0}), (2943, {'train/loss': 0.12436027984199284, 'validation/loss': 0.12495253003103941, 'validation/num_examples': 83274637, 'test/loss': 0.12741443683182566, 'test/num_examples': 95000000, 'score': 2789.6443026065826, 'total_duration': 19517.09415245056, 'accumulated_submission_time': 2789.6443026065826, 'accumulated_eval_time': 16726.84206223488, 'accumulated_logging_time': 0.4499239921569824, 'global_step': 2943, 'preemption_count': 0}), (3075, {'train/loss': 0.1252777920274427, 'validation/loss': 0.1251647673400208, 'validation/num_examples': 83274637, 'test/loss': 0.1277256572162829, 'test/num_examples': 95000000, 'score': 2909.8936796188354, 'total_duration': 20186.36921620369, 'accumulated_submission_time': 2909.8936796188354, 'accumulated_eval_time': 17275.844663381577, 'accumulated_logging_time': 0.46686792373657227, 'global_step': 3075, 'preemption_count': 0}), (3205, {'train/loss': 0.12344116626201936, 'validation/loss': 0.12494947198450787, 'validation/num_examples': 83274637, 'test/loss': 0.12730607398231908, 'test/num_examples': 95000000, 'score': 3030.4621341228485, 'total_duration': 20867.6024582386, 'accumulated_submission_time': 3030.4621341228485, 'accumulated_eval_time': 17836.485538721085, 'accumulated_logging_time': 0.48363161087036133, 'global_step': 3205, 'preemption_count': 0}), (3333, {'train/loss': 0.1216664397679035, 'validation/loss': 0.12489098168690643, 'validation/num_examples': 83274637, 'test/loss': 0.12750650538651315, 'test/num_examples': 95000000, 'score': 3151.7421967983246, 'total_duration': 21552.362196207047, 'accumulated_submission_time': 3151.7421967983246, 'accumulated_eval_time': 18399.944298267365, 'accumulated_logging_time': 0.49811744689941406, 'global_step': 3333, 'preemption_count': 0}), (3455, {'train/loss': 0.12431325717776451, 'validation/loss': 0.12489553437604223, 'validation/num_examples': 83274637, 'test/loss': 0.12738070264185855, 'test/num_examples': 95000000, 'score': 3273.5389590263367, 'total_duration': 22250.213220834732, 'accumulated_submission_time': 3273.5389590263367, 'accumulated_eval_time': 18975.97704052925, 'accumulated_logging_time': 0.5124452114105225, 'global_step': 3455, 'preemption_count': 0}), (3588, {'train/loss': 0.12449788787173775, 'validation/loss': 0.12492325431871891, 'validation/num_examples': 83274637, 'test/loss': 0.12757245074013157, 'test/num_examples': 95000000, 'score': 3393.566992044449, 'total_duration': 22916.520711421967, 'accumulated_submission_time': 3393.566992044449, 'accumulated_eval_time': 19522.220046281815, 'accumulated_logging_time': 0.5424127578735352, 'global_step': 3588, 'preemption_count': 0}), (3717, {'train/loss': 0.12352896885911249, 'validation/loss': 0.12459393288262698, 'validation/num_examples': 83274637, 'test/loss': 0.12695890315583883, 'test/num_examples': 95000000, 'score': 3513.7626888751984, 'total_duration': 23599.71896505356, 'accumulated_submission_time': 3513.7626888751984, 'accumulated_eval_time': 20085.18686771393, 'accumulated_logging_time': 0.5716984272003174, 'global_step': 3717, 'preemption_count': 0}), (3848, {'train/loss': 0.12256894839353531, 'validation/loss': 0.12482275678072191, 'validation/num_examples': 83274637, 'test/loss': 0.12731566148231907, 'test/num_examples': 95000000, 'score': 3634.09300160408, 'total_duration': 24283.167216300964, 'accumulated_submission_time': 3634.09300160408, 'accumulated_eval_time': 20648.283315181732, 'accumulated_logging_time': 0.5868194103240967, 'global_step': 3848, 'preemption_count': 0}), (3974, {'train/loss': 0.12282707302028653, 'validation/loss': 0.12496869514555044, 'validation/num_examples': 83274637, 'test/loss': 0.12744110803865133, 'test/num_examples': 95000000, 'score': 3754.8112637996674, 'total_duration': 24943.73623919487, 'accumulated_submission_time': 3754.8112637996674, 'accumulated_eval_time': 21188.112539291382, 'accumulated_logging_time': 0.6012668609619141, 'global_step': 3974, 'preemption_count': 0}), (4100, {'train/loss': 0.12203927611076981, 'validation/loss': 0.12475957804798056, 'validation/num_examples': 83274637, 'test/loss': 0.1272321628597862, 'test/num_examples': 95000000, 'score': 3874.8642818927765, 'total_duration': 25622.333768844604, 'accumulated_submission_time': 3874.8642818927765, 'accumulated_eval_time': 21746.6289331913, 'accumulated_logging_time': 0.6189756393432617, 'global_step': 4100, 'preemption_count': 0}), (4227, {'train/loss': 0.1226345696164377, 'validation/loss': 0.1246792436905564, 'validation/num_examples': 83274637, 'test/loss': 0.1271604459087171, 'test/num_examples': 95000000, 'score': 3995.6841626167297, 'total_duration': 26293.393870592117, 'accumulated_submission_time': 3995.6841626167297, 'accumulated_eval_time': 22296.83288550377, 'accumulated_logging_time': 0.6486067771911621, 'global_step': 4227, 'preemption_count': 0}), (4350, {'train/loss': 0.12593889537519254, 'validation/loss': 0.12459765845402117, 'validation/num_examples': 83274637, 'test/loss': 0.1271155992084704, 'test/num_examples': 95000000, 'score': 4115.939559698105, 'total_duration': 26960.049354076385, 'accumulated_submission_time': 4115.939559698105, 'accumulated_eval_time': 22843.21102309227, 'accumulated_logging_time': 0.6647293567657471, 'global_step': 4350, 'preemption_count': 0}), (4480, {'train/loss': 0.12527000107480296, 'validation/loss': 0.12451749909876708, 'validation/num_examples': 83274637, 'test/loss': 0.12691873182565788, 'test/num_examples': 95000000, 'score': 4236.066785335541, 'total_duration': 27629.891148090363, 'accumulated_submission_time': 4236.066785335541, 'accumulated_eval_time': 23392.90416932106, 'accumulated_logging_time': 0.6793820858001709, 'global_step': 4480, 'preemption_count': 0}), (4609, {'train/loss': 0.12355698498680531, 'validation/loss': 0.12469633129271776, 'validation/num_examples': 83274637, 'test/loss': 0.12707774661800986, 'test/num_examples': 95000000, 'score': 4356.717090129852, 'total_duration': 28316.219083070755, 'accumulated_submission_time': 4356.717090129852, 'accumulated_eval_time': 23958.48954963684, 'accumulated_logging_time': 0.7655763626098633, 'global_step': 4609, 'preemption_count': 0}), (4736, {'train/loss': 0.12265450030612121, 'validation/loss': 0.12470377046809245, 'validation/num_examples': 83274637, 'test/loss': 0.12711668795230263, 'test/num_examples': 95000000, 'score': 4478.004957914352, 'total_duration': 28987.90357351303, 'accumulated_submission_time': 4478.004957914352, 'accumulated_eval_time': 24508.863488912582, 'accumulated_logging_time': 0.7812635898590088, 'global_step': 4736, 'preemption_count': 0}), (4867, {'train/loss': 0.12283101563090049, 'validation/loss': 0.1246223319540427, 'validation/num_examples': 83274637, 'test/loss': 0.12701407571957238, 'test/num_examples': 95000000, 'score': 4598.8775753974915, 'total_duration': 29674.835211277008, 'accumulated_submission_time': 4598.8775753974915, 'accumulated_eval_time': 25074.898844718933, 'accumulated_logging_time': 0.7984135150909424, 'global_step': 4867, 'preemption_count': 0}), (4996, {'train/loss': 0.12219214165266955, 'validation/loss': 0.12464436641946312, 'validation/num_examples': 83274637, 'test/loss': 0.12708347902960526, 'test/num_examples': 95000000, 'score': 4718.937885046005, 'total_duration': 30339.14422273636, 'accumulated_submission_time': 4718.937885046005, 'accumulated_eval_time': 25619.124763965607, 'accumulated_logging_time': 0.8142538070678711, 'global_step': 4996, 'preemption_count': 0}), (5122, {'train/loss': 0.12114184270115019, 'validation/loss': 0.12434557003856446, 'validation/num_examples': 83274637, 'test/loss': 0.12668795190172696, 'test/num_examples': 95000000, 'score': 4839.624628067017, 'total_duration': 31008.31607079506, 'accumulated_submission_time': 4839.624628067017, 'accumulated_eval_time': 26167.5876660347, 'accumulated_logging_time': 0.829601526260376, 'global_step': 5122, 'preemption_count': 0}), (5250, {'train/loss': 0.1228061374394024, 'validation/loss': 0.12453792557416822, 'validation/num_examples': 83274637, 'test/loss': 0.12696020143914474, 'test/num_examples': 95000000, 'score': 4959.679259777069, 'total_duration': 31685.29237318039, 'accumulated_submission_time': 4959.679259777069, 'accumulated_eval_time': 26724.486232042313, 'accumulated_logging_time': 0.8456065654754639, 'global_step': 5250, 'preemption_count': 0}), (5377, {'train/loss': 0.1239787239183045, 'validation/loss': 0.12451761126761764, 'validation/num_examples': 83274637, 'test/loss': 0.1268497204872533, 'test/num_examples': 95000000, 'score': 5080.4880838394165, 'total_duration': 32354.57195043564, 'accumulated_submission_time': 5080.4880838394165, 'accumulated_eval_time': 27272.933461666107, 'accumulated_logging_time': 0.8630964756011963, 'global_step': 5377, 'preemption_count': 0}), (5502, {'train/loss': 0.1228777592029399, 'validation/loss': 0.12448152623762901, 'validation/num_examples': 83274637, 'test/loss': 0.12684942938939145, 'test/num_examples': 95000000, 'score': 5200.867920160294, 'total_duration': 33023.75745844841, 'accumulated_submission_time': 5200.867920160294, 'accumulated_eval_time': 27821.704835176468, 'accumulated_logging_time': 0.891512393951416, 'global_step': 5502, 'preemption_count': 0}), (5636, {'train/loss': 0.12133296596694668, 'validation/loss': 0.12420103121028915, 'validation/num_examples': 83274637, 'test/loss': 0.12656467734375, 'test/num_examples': 95000000, 'score': 5321.682158470154, 'total_duration': 33690.99912047386, 'accumulated_submission_time': 5321.682158470154, 'accumulated_eval_time': 28368.11043357849, 'accumulated_logging_time': 0.9068918228149414, 'global_step': 5636, 'preemption_count': 0}), (5762, {'train/loss': 0.12351754499868776, 'validation/loss': 0.12423273173991928, 'validation/num_examples': 83274637, 'test/loss': 0.126722354296875, 'test/num_examples': 95000000, 'score': 5442.116317987442, 'total_duration': 34366.61434197426, 'accumulated_submission_time': 5442.116317987442, 'accumulated_eval_time': 28923.268782377243, 'accumulated_logging_time': 0.9226040840148926, 'global_step': 5762, 'preemption_count': 0}), (5891, {'train/loss': 0.12289350550129728, 'validation/loss': 0.12413692956772511, 'validation/num_examples': 83274637, 'test/loss': 0.12654816418585527, 'test/num_examples': 95000000, 'score': 5563.645479679108, 'total_duration': 35053.64669895172, 'accumulated_submission_time': 5563.645479679108, 'accumulated_eval_time': 29488.748819351196, 'accumulated_logging_time': 0.9389252662658691, 'global_step': 5891, 'preemption_count': 0}), (6019, {'train/loss': 0.12192594835171534, 'validation/loss': 0.12424312751146209, 'validation/num_examples': 83274637, 'test/loss': 0.12668825615748355, 'test/num_examples': 95000000, 'score': 5683.7428233623505, 'total_duration': 35731.34281158447, 'accumulated_submission_time': 5683.7428233623505, 'accumulated_eval_time': 30046.325338363647, 'accumulated_logging_time': 0.9545319080352783, 'global_step': 6019, 'preemption_count': 0}), (6155, {'train/loss': 0.12420413578690598, 'validation/loss': 0.12420431697776418, 'validation/num_examples': 83274637, 'test/loss': 0.12665821828741777, 'test/num_examples': 95000000, 'score': 5803.976886034012, 'total_duration': 36415.58439898491, 'accumulated_submission_time': 5803.976886034012, 'accumulated_eval_time': 30610.311059474945, 'accumulated_logging_time': 0.9698781967163086, 'global_step': 6155, 'preemption_count': 0}), (6282, {'train/loss': 0.12210245076684081, 'validation/loss': 0.12418290745643314, 'validation/num_examples': 83274637, 'test/loss': 0.12653820660978618, 'test/num_examples': 95000000, 'score': 5924.071258544922, 'total_duration': 37097.96375012398, 'accumulated_submission_time': 5924.071258544922, 'accumulated_eval_time': 31172.573248386383, 'accumulated_logging_time': 0.9865877628326416, 'global_step': 6282, 'preemption_count': 0}), (6416, {'train/loss': 0.12320304582328917, 'validation/loss': 0.12415039366452373, 'validation/num_examples': 83274637, 'test/loss': 0.1264688036903783, 'test/num_examples': 95000000, 'score': 6045.241501092911, 'total_duration': 37771.84740066528, 'accumulated_submission_time': 6045.241501092911, 'accumulated_eval_time': 31725.214702367783, 'accumulated_logging_time': 1.0516777038574219, 'global_step': 6416, 'preemption_count': 0}), (6546, {'train/loss': 0.12100375023137473, 'validation/loss': 0.12412816681750441, 'validation/num_examples': 83274637, 'test/loss': 0.12659344424342106, 'test/num_examples': 95000000, 'score': 6165.807867765427, 'total_duration': 38445.85452270508, 'accumulated_submission_time': 6165.807867765427, 'accumulated_eval_time': 32278.632910251617, 'accumulated_logging_time': 1.0673913955688477, 'global_step': 6546, 'preemption_count': 0}), (6675, {'train/loss': 0.12437639526038799, 'validation/loss': 0.12403830547820903, 'validation/num_examples': 83274637, 'test/loss': 0.12641606010485198, 'test/num_examples': 95000000, 'score': 6286.010834693909, 'total_duration': 39112.57557082176, 'accumulated_submission_time': 6286.010834693909, 'accumulated_eval_time': 32825.127130270004, 'accumulated_logging_time': 1.0849800109863281, 'global_step': 6675, 'preemption_count': 0}), (6807, {'train/loss': 0.12243977374157065, 'validation/loss': 0.1240464353568816, 'validation/num_examples': 83274637, 'test/loss': 0.12652246586143093, 'test/num_examples': 95000000, 'score': 6406.157833337784, 'total_duration': 39801.40392279625, 'accumulated_submission_time': 6406.157833337784, 'accumulated_eval_time': 33393.785843372345, 'accumulated_logging_time': 1.1012561321258545, 'global_step': 6807, 'preemption_count': 0}), (6941, {'train/loss': 0.12474828953825452, 'validation/loss': 0.12416046614585513, 'validation/num_examples': 83274637, 'test/loss': 0.12656612782689144, 'test/num_examples': 95000000, 'score': 6526.280298233032, 'total_duration': 40490.6257686615, 'accumulated_submission_time': 6526.280298233032, 'accumulated_eval_time': 33962.86309671402, 'accumulated_logging_time': 1.1171345710754395, 'global_step': 6941, 'preemption_count': 0}), (7073, {'train/loss': 0.12164396970714413, 'validation/loss': 0.12390258661037266, 'validation/num_examples': 83274637, 'test/loss': 0.12620509709087172, 'test/num_examples': 95000000, 'score': 6647.045482635498, 'total_duration': 41169.45170092583, 'accumulated_submission_time': 6647.045482635498, 'accumulated_eval_time': 34520.90109157562, 'accumulated_logging_time': 1.1334724426269531, 'global_step': 7073, 'preemption_count': 0}), (7208, {'train/loss': 0.12051316481903664, 'validation/loss': 0.12397587416058588, 'validation/num_examples': 83274637, 'test/loss': 0.12633598976151317, 'test/num_examples': 95000000, 'score': 6768.132524251938, 'total_duration': 41847.80449938774, 'accumulated_submission_time': 6768.132524251938, 'accumulated_eval_time': 35078.14354515076, 'accumulated_logging_time': 1.1505305767059326, 'global_step': 7208, 'preemption_count': 0}), (7335, {'train/loss': 0.11955316145699355, 'validation/loss': 0.12395800349319595, 'validation/num_examples': 83274637, 'test/loss': 0.1263557696751645, 'test/num_examples': 95000000, 'score': 6888.551467657089, 'total_duration': 42513.38844347, 'accumulated_submission_time': 6888.551467657089, 'accumulated_eval_time': 35623.19666957855, 'accumulated_logging_time': 1.256185531616211, 'global_step': 7335, 'preemption_count': 0}), (7459, {'train/loss': 0.1222746321615183, 'validation/loss': 0.12392816266799105, 'validation/num_examples': 83274637, 'test/loss': 0.12629452386924342, 'test/num_examples': 95000000, 'score': 7008.565945148468, 'total_duration': 43202.95703482628, 'accumulated_submission_time': 7008.565945148468, 'accumulated_eval_time': 36192.72839617729, 'accumulated_logging_time': 1.272413969039917, 'global_step': 7459, 'preemption_count': 0}), (7590, {'train/loss': 0.12255739569429706, 'validation/loss': 0.12394873398369256, 'validation/num_examples': 83274637, 'test/loss': 0.1262888908614309, 'test/num_examples': 95000000, 'score': 7130.166995048523, 'total_duration': 43868.62030649185, 'accumulated_submission_time': 7130.166995048523, 'accumulated_eval_time': 36736.70932388306, 'accumulated_logging_time': 1.3473093509674072, 'global_step': 7590, 'preemption_count': 0}), (7719, {'train/loss': 0.12169821299143932, 'validation/loss': 0.12391652641919502, 'validation/num_examples': 83274637, 'test/loss': 0.12618027586348685, 'test/num_examples': 95000000, 'score': 7250.4461896419525, 'total_duration': 44535.33886241913, 'accumulated_submission_time': 7250.4461896419525, 'accumulated_eval_time': 37283.125086545944, 'accumulated_logging_time': 1.364640474319458, 'global_step': 7719, 'preemption_count': 0}), (7856, {'train/loss': 0.1207770668555918, 'validation/loss': 0.1239022196956841, 'validation/num_examples': 83274637, 'test/loss': 0.12626854133429277, 'test/num_examples': 95000000, 'score': 7371.057455539703, 'total_duration': 45203.55355024338, 'accumulated_submission_time': 7371.057455539703, 'accumulated_eval_time': 37830.704484939575, 'accumulated_logging_time': 1.3817527294158936, 'global_step': 7856, 'preemption_count': 0}), (7992, {'train/loss': 0.1200458640056961, 'validation/loss': 0.12391613738736562, 'validation/num_examples': 83274637, 'test/loss': 0.12630741820518093, 'test/num_examples': 95000000, 'score': 7491.152491807938, 'total_duration': 45883.86437487602, 'accumulated_submission_time': 7491.152491807938, 'accumulated_eval_time': 38390.897914648056, 'accumulated_logging_time': 1.3975636959075928, 'global_step': 7992, 'preemption_count': 0}), (8125, {'train/loss': 0.1209765484544841, 'validation/loss': 0.12390205023452625, 'validation/num_examples': 83274637, 'test/loss': 0.12613941277754934, 'test/num_examples': 95000000, 'score': 7611.283947467804, 'total_duration': 46553.98759508133, 'accumulated_submission_time': 7611.283947467804, 'accumulated_eval_time': 38940.866898059845, 'accumulated_logging_time': 1.4134716987609863, 'global_step': 8125, 'preemption_count': 0})], 'global_step': 8256}
I0307 01:59:38.601418 140224878134464 submission_runner.py:649] Timing: 7732.102814912796
I0307 01:59:38.601454 140224878134464 submission_runner.py:651] Total number of evals: 64
I0307 01:59:38.601482 140224878134464 submission_runner.py:652] ====================
I0307 01:59:38.601612 140224878134464 submission_runner.py:750] Final criteo1tb score: 0
