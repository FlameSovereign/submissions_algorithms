python submission_runner.py --framework=jax --workload=criteo1tb --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_1 --overwrite=True --save_checkpoints=False --rng_seed=-1249104031 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=3 --hparam_end_index=4 2>&1 | tee -a /logs/criteo1tb_jax_03-06-2025-13-05-50.log
2025-03-06 13:06:07.428888: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741266367.888317       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741266368.045752       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0306 13:06:56.006120 140022987785408 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax.
I0306 13:06:59.440666 140022987785408 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0306 13:06:59.443651 140022987785408 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0306 13:06:59.466555 140022987785408 submission_runner.py:606] Using RNG seed -1249104031
I0306 13:07:02.682120 140022987785408 submission_runner.py:615] --- Tuning run 4/5 ---
I0306 13:07:02.682326 140022987785408 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_4.
I0306 13:07:02.682554 140022987785408 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_4/hparams.json.
I0306 13:07:02.928778 140022987785408 submission_runner.py:218] Initializing dataset.
I0306 13:07:02.928983 140022987785408 submission_runner.py:229] Initializing model.
I0306 13:07:13.160418 140022987785408 submission_runner.py:272] Initializing optimizer.
I0306 13:07:13.813677 140022987785408 submission_runner.py:279] Initializing metrics bundle.
I0306 13:07:13.813910 140022987785408 submission_runner.py:301] Initializing checkpoint and logger.
I0306 13:07:13.814732 140022987785408 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_4 with prefix checkpoint_
I0306 13:07:13.814848 140022987785408 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_4/meta_data_0.json.
I0306 13:07:13.815030 140022987785408 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0306 13:07:13.815075 140022987785408 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0306 13:07:14.433043 140022987785408 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_4/flags_0.json.
I0306 13:07:15.053145 140022987785408 submission_runner.py:337] Starting training loop.
I0306 13:07:31.432762 139881397344000 logging_writer.py:48] [0] global_step=0, grad_norm=1.8787798881530762, loss=0.25073543190956116
I0306 13:07:31.656594 140022987785408 spec.py:321] Evaluating on the training split.
I0306 13:13:46.634250 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 13:19:45.795214 140022987785408 spec.py:349] Evaluating on the test split.
I0306 13:26:34.269289 140022987785408 submission_runner.py:469] Time since start: 1159.22s, 	Step: 1, 	{'train/loss': 0.2509465323725961, 'validation/loss': 0.2516580542432671, 'validation/num_examples': 83274637, 'test/loss': 0.25232802732319076, 'test/num_examples': 95000000, 'score': 16.603291034698486, 'total_duration': 1159.2160654067993, 'accumulated_submission_time': 16.603291034698486, 'accumulated_eval_time': 1142.6126191616058, 'accumulated_logging_time': 0}
I0306 13:26:34.304610 139870399866624 logging_writer.py:48] [1] accumulated_eval_time=1142.61, accumulated_logging_time=0, accumulated_submission_time=16.6033, global_step=1, preemption_count=0, score=16.6033, test/loss=0.252328, test/num_examples=95000000, total_duration=1159.22, train/loss=0.250947, validation/loss=0.251658, validation/num_examples=83274637
I0306 13:28:06.997574 139870391473920 logging_writer.py:48] [100] global_step=100, grad_norm=0.05094809830188751, loss=0.12994295358657837
I0306 13:28:35.124632 140022987785408 spec.py:321] Evaluating on the training split.
I0306 13:34:26.340636 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 13:39:33.009417 140022987785408 spec.py:349] Evaluating on the test split.
I0306 13:45:13.735908 140022987785408 submission_runner.py:469] Time since start: 2278.68s, 	Step: 125, 	{'train/loss': 0.1277972835250808, 'validation/loss': 0.1298201242963595, 'validation/num_examples': 83274637, 'test/loss': 0.13229225739103617, 'test/num_examples': 95000000, 'score': 137.38647437095642, 'total_duration': 2278.6827023029327, 'accumulated_submission_time': 137.38647437095642, 'accumulated_eval_time': 2141.223840713501, 'accumulated_logging_time': 0.06505513191223145}
I0306 13:45:13.744524 139870399866624 logging_writer.py:48] [125] accumulated_eval_time=2141.22, accumulated_logging_time=0.0650551, accumulated_submission_time=137.386, global_step=125, preemption_count=0, score=137.386, test/loss=0.132292, test/num_examples=95000000, total_duration=2278.68, train/loss=0.127797, validation/loss=0.12982, validation/num_examples=83274637
I0306 13:46:12.543109 139870391473920 logging_writer.py:48] [200] global_step=200, grad_norm=0.039800260215997696, loss=0.13197574019432068
I0306 13:47:14.944051 140022987785408 spec.py:321] Evaluating on the training split.
I0306 13:53:12.611085 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 13:58:21.153267 140022987785408 spec.py:349] Evaluating on the test split.
I0306 14:04:13.535336 140022987785408 submission_runner.py:469] Time since start: 3418.48s, 	Step: 251, 	{'train/loss': 0.12997444738991232, 'validation/loss': 0.12898226948618746, 'validation/num_examples': 83274637, 'test/loss': 0.13148883191817434, 'test/num_examples': 95000000, 'score': 258.5711226463318, 'total_duration': 3418.4821331501007, 'accumulated_submission_time': 258.5711226463318, 'accumulated_eval_time': 3159.8150672912598, 'accumulated_logging_time': 0.08140349388122559}
I0306 14:04:13.547282 139870399866624 logging_writer.py:48] [251] accumulated_eval_time=3159.82, accumulated_logging_time=0.0814035, accumulated_submission_time=258.571, global_step=251, preemption_count=0, score=258.571, test/loss=0.131489, test/num_examples=95000000, total_duration=3418.48, train/loss=0.129974, validation/loss=0.128982, validation/num_examples=83274637
I0306 14:04:42.980567 139870391473920 logging_writer.py:48] [300] global_step=300, grad_norm=0.04540923982858658, loss=0.13392692804336548
I0306 14:06:13.989021 140022987785408 spec.py:321] Evaluating on the training split.
I0306 14:12:11.816311 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 14:17:00.896726 140022987785408 spec.py:349] Evaluating on the test split.
I0306 14:22:43.362740 140022987785408 submission_runner.py:469] Time since start: 4528.31s, 	Step: 374, 	{'train/loss': 0.13036083264873838, 'validation/loss': 0.12841289324144134, 'validation/num_examples': 83274637, 'test/loss': 0.13065439366776316, 'test/num_examples': 95000000, 'score': 378.9796357154846, 'total_duration': 4528.309536457062, 'accumulated_submission_time': 378.9796357154846, 'accumulated_eval_time': 4149.188739299774, 'accumulated_logging_time': 0.11925506591796875}
I0306 14:22:43.370990 139870399866624 logging_writer.py:48] [374] accumulated_eval_time=4149.19, accumulated_logging_time=0.119255, accumulated_submission_time=378.98, global_step=374, preemption_count=0, score=378.98, test/loss=0.130654, test/num_examples=95000000, total_duration=4528.31, train/loss=0.130361, validation/loss=0.128413, validation/num_examples=83274637
I0306 14:22:46.213496 139870391473920 logging_writer.py:48] [400] global_step=400, grad_norm=0.037762582302093506, loss=0.12518447637557983
I0306 14:24:43.571895 140022987785408 spec.py:321] Evaluating on the training split.
I0306 14:30:16.467165 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 14:35:22.383872 140022987785408 spec.py:349] Evaluating on the test split.
I0306 14:41:05.683698 140022987785408 submission_runner.py:469] Time since start: 5630.63s, 	Step: 500, 	{'train/loss': 0.12715936708703357, 'validation/loss': 0.1266983133851915, 'validation/num_examples': 83274637, 'test/loss': 0.1291668531558388, 'test/num_examples': 95000000, 'score': 499.1653962135315, 'total_duration': 5630.630497455597, 'accumulated_submission_time': 499.1653962135315, 'accumulated_eval_time': 5131.300492048264, 'accumulated_logging_time': 0.13508152961730957}
I0306 14:41:05.692140 139870399866624 logging_writer.py:48] [500] accumulated_eval_time=5131.3, accumulated_logging_time=0.135082, accumulated_submission_time=499.165, global_step=500, preemption_count=0, score=499.165, test/loss=0.129167, test/num_examples=95000000, total_duration=5630.63, train/loss=0.127159, validation/loss=0.126698, validation/num_examples=83274637
I0306 14:41:05.808194 139870391473920 logging_writer.py:48] [500] global_step=500, grad_norm=0.0042829355224967, loss=0.1264343559741974
I0306 14:42:37.572066 139870399866624 logging_writer.py:48] [600] global_step=600, grad_norm=0.012200062163174152, loss=0.13268357515335083
I0306 14:43:06.557799 140022987785408 spec.py:321] Evaluating on the training split.
I0306 14:48:51.506191 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 14:53:44.930088 140022987785408 spec.py:349] Evaluating on the test split.
I0306 14:59:33.982815 140022987785408 submission_runner.py:469] Time since start: 6738.93s, 	Step: 626, 	{'train/loss': 0.12575888127650856, 'validation/loss': 0.12708499413672392, 'validation/num_examples': 83274637, 'test/loss': 0.12949205010279605, 'test/num_examples': 95000000, 'score': 620.0170094966888, 'total_duration': 6738.929611682892, 'accumulated_submission_time': 620.0170094966888, 'accumulated_eval_time': 6118.725446462631, 'accumulated_logging_time': 0.1498405933380127}
I0306 14:59:33.991026 139870391473920 logging_writer.py:48] [626] accumulated_eval_time=6118.73, accumulated_logging_time=0.149841, accumulated_submission_time=620.017, global_step=626, preemption_count=0, score=620.017, test/loss=0.129492, test/num_examples=95000000, total_duration=6738.93, train/loss=0.125759, validation/loss=0.127085, validation/num_examples=83274637
I0306 15:00:35.460124 139870399866624 logging_writer.py:48] [700] global_step=700, grad_norm=0.008067093789577484, loss=0.13012808561325073
I0306 15:01:33.984706 140022987785408 spec.py:321] Evaluating on the training split.
I0306 15:06:52.029082 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 15:11:25.672101 140022987785408 spec.py:349] Evaluating on the test split.
I0306 15:16:59.946781 140022987785408 submission_runner.py:469] Time since start: 7784.89s, 	Step: 750, 	{'train/loss': 0.12711582385565875, 'validation/loss': 0.1266634960918908, 'validation/num_examples': 83274637, 'test/loss': 0.12918152583264803, 'test/num_examples': 95000000, 'score': 739.9958882331848, 'total_duration': 7784.89354801178, 'accumulated_submission_time': 739.9958882331848, 'accumulated_eval_time': 7044.687438011169, 'accumulated_logging_time': 0.16451668739318848}
I0306 15:16:59.954983 139870391473920 logging_writer.py:48] [750] accumulated_eval_time=7044.69, accumulated_logging_time=0.164517, accumulated_submission_time=739.996, global_step=750, preemption_count=0, score=739.996, test/loss=0.129182, test/num_examples=95000000, total_duration=7784.89, train/loss=0.127116, validation/loss=0.126663, validation/num_examples=83274637
I0306 15:17:33.209178 139870399866624 logging_writer.py:48] [800] global_step=800, grad_norm=0.02499142661690712, loss=0.12342055886983871
I0306 15:19:00.344313 140022987785408 spec.py:321] Evaluating on the training split.
I0306 15:23:31.155303 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 15:27:41.153496 140022987785408 spec.py:349] Evaluating on the test split.
I0306 15:33:21.315256 140022987785408 submission_runner.py:469] Time since start: 8766.26s, 	Step: 871, 	{'train/loss': 0.12724061527014155, 'validation/loss': 0.12690473307696803, 'validation/num_examples': 83274637, 'test/loss': 0.12956963517680922, 'test/num_examples': 95000000, 'score': 860.371467590332, 'total_duration': 8766.262031316757, 'accumulated_submission_time': 860.371467590332, 'accumulated_eval_time': 7905.658302783966, 'accumulated_logging_time': 0.1795637607574463}
I0306 15:33:21.323202 139870391473920 logging_writer.py:48] [871] accumulated_eval_time=7905.66, accumulated_logging_time=0.179564, accumulated_submission_time=860.371, global_step=871, preemption_count=0, score=860.371, test/loss=0.12957, test/num_examples=95000000, total_duration=8766.26, train/loss=0.127241, validation/loss=0.126905, validation/num_examples=83274637
I0306 15:33:26.834655 139870399866624 logging_writer.py:48] [900] global_step=900, grad_norm=0.03436875715851784, loss=0.13172383606433868
I0306 15:35:22.146575 140022987785408 spec.py:321] Evaluating on the training split.
I0306 15:38:50.235589 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 15:41:58.389308 140022987785408 spec.py:349] Evaluating on the test split.
I0306 15:47:54.819015 140022987785408 submission_runner.py:469] Time since start: 9639.77s, 	Step: 995, 	{'train/loss': 0.12558471183028985, 'validation/loss': 0.12690303457788565, 'validation/num_examples': 83274637, 'test/loss': 0.1293273913754112, 'test/num_examples': 95000000, 'score': 981.181099653244, 'total_duration': 9639.765812635422, 'accumulated_submission_time': 981.181099653244, 'accumulated_eval_time': 8658.330698251724, 'accumulated_logging_time': 0.19405269622802734}
I0306 15:47:54.827257 139870391473920 logging_writer.py:48] [995] accumulated_eval_time=8658.33, accumulated_logging_time=0.194053, accumulated_submission_time=981.181, global_step=995, preemption_count=0, score=981.181, test/loss=0.129327, test/num_examples=95000000, total_duration=9639.77, train/loss=0.125585, validation/loss=0.126903, validation/num_examples=83274637
I0306 15:47:55.483599 139870399866624 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.011940236203372478, loss=0.12493263185024261
I0306 15:49:33.675453 139870391473920 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.01734445057809353, loss=0.13932202756404877
I0306 15:49:55.499722 140022987785408 spec.py:321] Evaluating on the training split.
I0306 15:50:50.607286 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 15:53:54.699812 140022987785408 spec.py:349] Evaluating on the test split.
I0306 16:00:03.774794 140022987785408 submission_runner.py:469] Time since start: 10368.72s, 	Step: 1120, 	{'train/loss': 0.12460700770453462, 'validation/loss': 0.1267237349746343, 'validation/num_examples': 83274637, 'test/loss': 0.12918999201274672, 'test/num_examples': 95000000, 'score': 1101.839154958725, 'total_duration': 10368.721593856812, 'accumulated_submission_time': 1101.839154958725, 'accumulated_eval_time': 9266.605711698532, 'accumulated_logging_time': 0.20864152908325195}
I0306 16:00:03.782977 139870399866624 logging_writer.py:48] [1120] accumulated_eval_time=9266.61, accumulated_logging_time=0.208642, accumulated_submission_time=1101.84, global_step=1120, preemption_count=0, score=1101.84, test/loss=0.12919, test/num_examples=95000000, total_duration=10368.7, train/loss=0.124607, validation/loss=0.126724, validation/num_examples=83274637
I0306 16:01:11.661184 139870391473920 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.004867617040872574, loss=0.12416074424982071
I0306 16:02:04.693883 140022987785408 spec.py:321] Evaluating on the training split.
I0306 16:02:12.140372 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 16:05:21.085189 140022987785408 spec.py:349] Evaluating on the test split.
I0306 16:11:14.740406 140022987785408 submission_runner.py:469] Time since start: 11039.69s, 	Step: 1244, 	{'train/loss': 0.12523812840475976, 'validation/loss': 0.12731657913000344, 'validation/num_examples': 83274637, 'test/loss': 0.13006149768708883, 'test/num_examples': 95000000, 'score': 1222.7235498428345, 'total_duration': 11039.687205791473, 'accumulated_submission_time': 1222.7235498428345, 'accumulated_eval_time': 9816.652180671692, 'accumulated_logging_time': 0.23595476150512695}
I0306 16:11:14.748945 139870399866624 logging_writer.py:48] [1244] accumulated_eval_time=9816.65, accumulated_logging_time=0.235955, accumulated_submission_time=1222.72, global_step=1244, preemption_count=0, score=1222.72, test/loss=0.130061, test/num_examples=95000000, total_duration=11039.7, train/loss=0.125238, validation/loss=0.127317, validation/num_examples=83274637
I0306 16:11:53.047733 139870391473920 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.04210478812456131, loss=0.11728765815496445
I0306 16:13:15.141329 140022987785408 spec.py:321] Evaluating on the training split.
I0306 16:13:22.575712 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 16:16:30.665052 140022987785408 spec.py:349] Evaluating on the test split.
I0306 16:22:20.136890 140022987785408 submission_runner.py:469] Time since start: 11705.08s, 	Step: 1370, 	{'train/loss': 0.12550758312708177, 'validation/loss': 0.126875931563887, 'validation/num_examples': 83274637, 'test/loss': 0.1291274539165296, 'test/num_examples': 95000000, 'score': 1343.102076292038, 'total_duration': 11705.08368563652, 'accumulated_submission_time': 1343.102076292038, 'accumulated_eval_time': 10361.647680997849, 'accumulated_logging_time': 0.25097012519836426}
I0306 16:22:20.146743 139870399866624 logging_writer.py:48] [1370] accumulated_eval_time=10361.6, accumulated_logging_time=0.25097, accumulated_submission_time=1343.1, global_step=1370, preemption_count=0, score=1343.1, test/loss=0.129127, test/num_examples=95000000, total_duration=11705.1, train/loss=0.125508, validation/loss=0.126876, validation/num_examples=83274637
I0306 16:22:26.845494 139870391473920 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.030909158289432526, loss=0.12330958992242813
I0306 16:24:21.605067 140022987785408 spec.py:321] Evaluating on the training split.
I0306 16:24:28.989293 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 16:27:34.738272 140022987785408 spec.py:349] Evaluating on the test split.
I0306 16:33:31.045670 140022987785408 submission_runner.py:469] Time since start: 12375.99s, 	Step: 1498, 	{'train/loss': 0.1259618219363052, 'validation/loss': 0.1264329921588907, 'validation/num_examples': 83274637, 'test/loss': 0.12870160359786184, 'test/num_examples': 95000000, 'score': 1464.5471246242523, 'total_duration': 12375.992455005646, 'accumulated_submission_time': 1464.5471246242523, 'accumulated_eval_time': 10911.08821439743, 'accumulated_logging_time': 0.26755189895629883}
I0306 16:33:31.054009 139870399866624 logging_writer.py:48] [1498] accumulated_eval_time=10911.1, accumulated_logging_time=0.267552, accumulated_submission_time=1464.55, global_step=1498, preemption_count=0, score=1464.55, test/loss=0.128702, test/num_examples=95000000, total_duration=12376, train/loss=0.125962, validation/loss=0.126433, validation/num_examples=83274637
I0306 16:33:31.393688 139870391473920 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.018800029531121254, loss=0.13073261082172394
I0306 16:35:03.376366 139870399866624 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.02286800555884838, loss=0.1187194436788559
I0306 16:35:31.185374 140022987785408 spec.py:321] Evaluating on the training split.
I0306 16:35:38.773560 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 16:38:45.816915 140022987785408 spec.py:349] Evaluating on the test split.
I0306 16:44:48.772053 140022987785408 submission_runner.py:469] Time since start: 13053.72s, 	Step: 1625, 	{'train/loss': 0.1279231200240693, 'validation/loss': 0.12739650198078356, 'validation/num_examples': 83274637, 'test/loss': 0.12978484440789473, 'test/num_examples': 95000000, 'score': 1584.665519475937, 'total_duration': 13053.7188103199, 'accumulated_submission_time': 1584.665519475937, 'accumulated_eval_time': 11468.674791574478, 'accumulated_logging_time': 0.28241705894470215}
I0306 16:44:48.780607 139870391473920 logging_writer.py:48] [1625] accumulated_eval_time=11468.7, accumulated_logging_time=0.282417, accumulated_submission_time=1584.67, global_step=1625, preemption_count=0, score=1584.67, test/loss=0.129785, test/num_examples=95000000, total_duration=13053.7, train/loss=0.127923, validation/loss=0.127397, validation/num_examples=83274637
I0306 16:45:51.674694 139870399866624 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.03862788528203964, loss=0.12132278084754944
I0306 16:46:49.000709 140022987785408 spec.py:321] Evaluating on the training split.
I0306 16:46:56.400398 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 16:50:07.480048 140022987785408 spec.py:349] Evaluating on the test split.
I0306 16:55:56.964293 140022987785408 submission_runner.py:469] Time since start: 13721.91s, 	Step: 1750, 	{'train/loss': 0.1253683938404674, 'validation/loss': 0.12599360898726433, 'validation/num_examples': 83274637, 'test/loss': 0.12839599438733554, 'test/num_examples': 95000000, 'score': 1704.8727819919586, 'total_duration': 13721.911089658737, 'accumulated_submission_time': 1704.8727819919586, 'accumulated_eval_time': 12016.638314247131, 'accumulated_logging_time': 0.29730725288391113}
I0306 16:55:56.973929 139870391473920 logging_writer.py:48] [1750] accumulated_eval_time=12016.6, accumulated_logging_time=0.297307, accumulated_submission_time=1704.87, global_step=1750, preemption_count=0, score=1704.87, test/loss=0.128396, test/num_examples=95000000, total_duration=13721.9, train/loss=0.125368, validation/loss=0.125994, validation/num_examples=83274637
I0306 16:56:29.499598 139870399866624 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.03951197490096092, loss=0.12958869338035583
I0306 16:57:57.314679 140022987785408 spec.py:321] Evaluating on the training split.
I0306 16:58:04.739032 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 17:01:13.736685 140022987785408 spec.py:349] Evaluating on the test split.
I0306 17:07:17.018856 140022987785408 submission_runner.py:469] Time since start: 14401.97s, 	Step: 1877, 	{'train/loss': 0.12318887717365844, 'validation/loss': 0.12618847893453403, 'validation/num_examples': 83274637, 'test/loss': 0.12849650739103619, 'test/num_examples': 95000000, 'score': 1825.1373069286346, 'total_duration': 14401.965655088425, 'accumulated_submission_time': 1825.1373069286346, 'accumulated_eval_time': 12576.342436790466, 'accumulated_logging_time': 0.376727819442749}
I0306 17:07:17.028464 139870391473920 logging_writer.py:48] [1877] accumulated_eval_time=12576.3, accumulated_logging_time=0.376728, accumulated_submission_time=1825.14, global_step=1877, preemption_count=0, score=1825.14, test/loss=0.128497, test/num_examples=95000000, total_duration=14402, train/loss=0.123189, validation/loss=0.126188, validation/num_examples=83274637
I0306 17:07:19.551583 139870399866624 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.01885567046701908, loss=0.12075909972190857
I0306 17:09:16.074665 139870391473920 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.010775121860206127, loss=0.13158458471298218
I0306 17:09:17.196877 140022987785408 spec.py:321] Evaluating on the training split.
I0306 17:09:24.646151 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 17:12:35.683895 140022987785408 spec.py:349] Evaluating on the test split.
I0306 17:18:19.535233 140022987785408 submission_runner.py:469] Time since start: 15064.48s, 	Step: 2002, 	{'train/loss': 0.1266906499487799, 'validation/loss': 0.1262907139287406, 'validation/num_examples': 83274637, 'test/loss': 0.1284673326377467, 'test/num_examples': 95000000, 'score': 1945.2924230098724, 'total_duration': 15064.482035636902, 'accumulated_submission_time': 1945.2924230098724, 'accumulated_eval_time': 13118.680730342865, 'accumulated_logging_time': 0.39308857917785645}
I0306 17:18:19.543617 139870399866624 logging_writer.py:48] [2002] accumulated_eval_time=13118.7, accumulated_logging_time=0.393089, accumulated_submission_time=1945.29, global_step=2002, preemption_count=0, score=1945.29, test/loss=0.128467, test/num_examples=95000000, total_duration=15064.5, train/loss=0.126691, validation/loss=0.126291, validation/num_examples=83274637
I0306 17:19:47.442257 139870391473920 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.015531495213508606, loss=0.1185707151889801
I0306 17:20:20.145531 140022987785408 spec.py:321] Evaluating on the training split.
I0306 17:20:27.563208 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 17:23:36.360692 140022987785408 spec.py:349] Evaluating on the test split.
I0306 17:29:36.215342 140022987785408 submission_runner.py:469] Time since start: 15741.16s, 	Step: 2130, 	{'train/loss': 0.12497292816310933, 'validation/loss': 0.12622930517707104, 'validation/num_examples': 83274637, 'test/loss': 0.12866723861019738, 'test/num_examples': 95000000, 'score': 2065.880598306656, 'total_duration': 15741.162140130997, 'accumulated_submission_time': 2065.880598306656, 'accumulated_eval_time': 13674.75047826767, 'accumulated_logging_time': 0.40823864936828613}
I0306 17:29:36.224372 139870399866624 logging_writer.py:48] [2130] accumulated_eval_time=13674.8, accumulated_logging_time=0.408239, accumulated_submission_time=2065.88, global_step=2130, preemption_count=0, score=2065.88, test/loss=0.128667, test/num_examples=95000000, total_duration=15741.2, train/loss=0.124973, validation/loss=0.126229, validation/num_examples=83274637
I0306 17:30:30.899477 139870391473920 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.006006191950291395, loss=0.12725679576396942
I0306 17:31:36.739686 140022987785408 spec.py:321] Evaluating on the training split.
I0306 17:31:44.220399 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 17:34:52.911210 140022987785408 spec.py:349] Evaluating on the test split.
I0306 17:40:54.340555 140022987785408 submission_runner.py:469] Time since start: 16419.29s, 	Step: 2255, 	{'train/loss': 0.12531408114628223, 'validation/loss': 0.12617392125300933, 'validation/num_examples': 83274637, 'test/loss': 0.12861008138363486, 'test/num_examples': 95000000, 'score': 2186.38156414032, 'total_duration': 16419.287349700928, 'accumulated_submission_time': 2186.38156414032, 'accumulated_eval_time': 14232.351284265518, 'accumulated_logging_time': 0.4240541458129883}
I0306 17:40:54.350864 139870399866624 logging_writer.py:48] [2255] accumulated_eval_time=14232.4, accumulated_logging_time=0.424054, accumulated_submission_time=2186.38, global_step=2255, preemption_count=0, score=2186.38, test/loss=0.12861, test/num_examples=95000000, total_duration=16419.3, train/loss=0.125314, validation/loss=0.126174, validation/num_examples=83274637
I0306 17:41:18.314761 139870391473920 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.03306393697857857, loss=0.12553009390830994
I0306 17:42:54.647588 140022987785408 spec.py:321] Evaluating on the training split.
I0306 17:43:02.059152 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 17:46:11.350764 140022987785408 spec.py:349] Evaluating on the test split.
I0306 17:51:58.670485 140022987785408 submission_runner.py:469] Time since start: 17083.62s, 	Step: 2383, 	{'train/loss': 0.12518631724301, 'validation/loss': 0.12597907946815412, 'validation/num_examples': 83274637, 'test/loss': 0.12822789676192434, 'test/num_examples': 95000000, 'score': 2306.6645402908325, 'total_duration': 17083.617247104645, 'accumulated_submission_time': 2306.6645402908325, 'accumulated_eval_time': 14776.37408566475, 'accumulated_logging_time': 0.4412398338317871}
I0306 17:51:58.678985 139870399866624 logging_writer.py:48] [2383] accumulated_eval_time=14776.4, accumulated_logging_time=0.44124, accumulated_submission_time=2306.66, global_step=2383, preemption_count=0, score=2306.66, test/loss=0.128228, test/num_examples=95000000, total_duration=17083.6, train/loss=0.125186, validation/loss=0.125979, validation/num_examples=83274637
I0306 17:52:00.619164 139870391473920 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.031110331416130066, loss=0.130140483379364
I0306 17:53:53.425687 139870399866624 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.007875137031078339, loss=0.13817061483860016
I0306 17:53:58.845708 140022987785408 spec.py:321] Evaluating on the training split.
I0306 17:54:06.288314 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 17:57:14.826225 140022987785408 spec.py:349] Evaluating on the test split.
I0306 18:03:09.885940 140022987785408 submission_runner.py:469] Time since start: 17754.83s, 	Step: 2506, 	{'train/loss': 0.12583325604129136, 'validation/loss': 0.12691802298662377, 'validation/num_examples': 83274637, 'test/loss': 0.1291637644942434, 'test/num_examples': 95000000, 'score': 2426.8186416625977, 'total_duration': 17754.832736730576, 'accumulated_submission_time': 2426.8186416625977, 'accumulated_eval_time': 15327.414250850677, 'accumulated_logging_time': 0.4562673568725586}
I0306 18:03:09.894413 139870391473920 logging_writer.py:48] [2506] accumulated_eval_time=15327.4, accumulated_logging_time=0.456267, accumulated_submission_time=2426.82, global_step=2506, preemption_count=0, score=2426.82, test/loss=0.129164, test/num_examples=95000000, total_duration=17754.8, train/loss=0.125833, validation/loss=0.126918, validation/num_examples=83274637
I0306 18:04:27.941726 139870399866624 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.03149524703621864, loss=0.12766382098197937
I0306 18:05:09.965597 140022987785408 spec.py:321] Evaluating on the training split.
I0306 18:05:17.453008 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 18:08:25.377324 140022987785408 spec.py:349] Evaluating on the test split.
I0306 18:14:22.479164 140022987785408 submission_runner.py:469] Time since start: 18427.43s, 	Step: 2635, 	{'train/loss': 0.1252346053930386, 'validation/loss': 0.12596960522264683, 'validation/num_examples': 83274637, 'test/loss': 0.12807666451480262, 'test/num_examples': 95000000, 'score': 2546.8753385543823, 'total_duration': 18427.42596578598, 'accumulated_submission_time': 2546.8753385543823, 'accumulated_eval_time': 15879.927757263184, 'accumulated_logging_time': 0.4712231159210205}
I0306 18:14:22.488137 139870391473920 logging_writer.py:48] [2635] accumulated_eval_time=15879.9, accumulated_logging_time=0.471223, accumulated_submission_time=2546.88, global_step=2635, preemption_count=0, score=2546.88, test/loss=0.128077, test/num_examples=95000000, total_duration=18427.4, train/loss=0.125235, validation/loss=0.12597, validation/num_examples=83274637
I0306 18:15:10.990851 139870399866624 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.004725346807390451, loss=0.12893758714199066
I0306 18:16:23.288041 140022987785408 spec.py:321] Evaluating on the training split.
I0306 18:16:30.748703 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 18:19:36.890189 140022987785408 spec.py:349] Evaluating on the test split.
I0306 18:25:37.883910 140022987785408 submission_runner.py:469] Time since start: 19102.83s, 	Step: 2764, 	{'train/loss': 0.1248437513790603, 'validation/loss': 0.12610392977831295, 'validation/num_examples': 83274637, 'test/loss': 0.1284236583573191, 'test/num_examples': 95000000, 'score': 2667.638345718384, 'total_duration': 19102.830713033676, 'accumulated_submission_time': 2667.638345718384, 'accumulated_eval_time': 16434.523574590683, 'accumulated_logging_time': 0.5097551345825195}
I0306 18:25:37.892994 139870391473920 logging_writer.py:48] [2764] accumulated_eval_time=16434.5, accumulated_logging_time=0.509755, accumulated_submission_time=2667.64, global_step=2764, preemption_count=0, score=2667.64, test/loss=0.128424, test/num_examples=95000000, total_duration=19102.8, train/loss=0.124844, validation/loss=0.126104, validation/num_examples=83274637
I0306 18:25:51.367450 139870399866624 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.05508700758218765, loss=0.1367626041173935
I0306 18:27:39.005926 140022987785408 spec.py:321] Evaluating on the training split.
I0306 18:27:46.445388 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 18:30:54.981754 140022987785408 spec.py:349] Evaluating on the test split.
I0306 18:36:58.707725 140022987785408 submission_runner.py:469] Time since start: 19783.65s, 	Step: 2891, 	{'train/loss': 0.12495001063406842, 'validation/loss': 0.12691384405488687, 'validation/num_examples': 83274637, 'test/loss': 0.12919286506990132, 'test/num_examples': 95000000, 'score': 2788.7375621795654, 'total_duration': 19783.654524564743, 'accumulated_submission_time': 2788.7375621795654, 'accumulated_eval_time': 16994.225315332413, 'accumulated_logging_time': 0.5251400470733643}
I0306 18:36:58.716463 139870391473920 logging_writer.py:48] [2891] accumulated_eval_time=16994.2, accumulated_logging_time=0.52514, accumulated_submission_time=2788.74, global_step=2891, preemption_count=0, score=2788.74, test/loss=0.129193, test/num_examples=95000000, total_duration=19783.7, train/loss=0.12495, validation/loss=0.126914, validation/num_examples=83274637
I0306 18:36:59.791690 139870399866624 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.006446646526455879, loss=0.13451647758483887
I0306 18:38:46.519049 139870391473920 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.004662731196731329, loss=0.12746502459049225
I0306 18:38:59.257408 140022987785408 spec.py:321] Evaluating on the training split.
I0306 18:39:06.635672 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 18:42:14.694769 140022987785408 spec.py:349] Evaluating on the test split.
I0306 18:48:12.661201 140022987785408 submission_runner.py:469] Time since start: 20457.61s, 	Step: 3011, 	{'train/loss': 0.12571690044125672, 'validation/loss': 0.12608301908880581, 'validation/num_examples': 83274637, 'test/loss': 0.12849711043379936, 'test/num_examples': 95000000, 'score': 2909.2646622657776, 'total_duration': 20457.607976198196, 'accumulated_submission_time': 2909.2646622657776, 'accumulated_eval_time': 17547.62901711464, 'accumulated_logging_time': 0.5402824878692627}
I0306 18:48:12.670318 139870399866624 logging_writer.py:48] [3011] accumulated_eval_time=17547.6, accumulated_logging_time=0.540282, accumulated_submission_time=2909.26, global_step=3011, preemption_count=0, score=2909.26, test/loss=0.128497, test/num_examples=95000000, total_duration=20457.6, train/loss=0.125717, validation/loss=0.126083, validation/num_examples=83274637
I0306 18:49:33.111249 139870391473920 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.05054270476102829, loss=0.11952414363622665
I0306 18:50:13.677025 140022987785408 spec.py:321] Evaluating on the training split.
I0306 18:50:21.089625 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 18:53:27.823477 140022987785408 spec.py:349] Evaluating on the test split.
I0306 18:59:28.696987 140022987785408 submission_runner.py:469] Time since start: 21133.64s, 	Step: 3136, 	{'train/loss': 0.12555573316021534, 'validation/loss': 0.12582178565192026, 'validation/num_examples': 83274637, 'test/loss': 0.12798885750411185, 'test/num_examples': 95000000, 'score': 3030.2573783397675, 'total_duration': 21133.64375448227, 'accumulated_submission_time': 3030.2573783397675, 'accumulated_eval_time': 18102.64888548851, 'accumulated_logging_time': 0.5568068027496338}
I0306 18:59:28.710293 139870399866624 logging_writer.py:48] [3136] accumulated_eval_time=18102.6, accumulated_logging_time=0.556807, accumulated_submission_time=3030.26, global_step=3136, preemption_count=0, score=3030.26, test/loss=0.127989, test/num_examples=95000000, total_duration=21133.6, train/loss=0.125556, validation/loss=0.125822, validation/num_examples=83274637
I0306 19:00:16.787979 139870391473920 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.011115680448710918, loss=0.12331390380859375
I0306 19:01:29.714143 140022987785408 spec.py:321] Evaluating on the training split.
I0306 19:01:37.160633 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 19:04:49.449767 140022987785408 spec.py:349] Evaluating on the test split.
I0306 19:10:45.020065 140022987785408 submission_runner.py:469] Time since start: 21809.97s, 	Step: 3265, 	{'train/loss': 0.12269448827506986, 'validation/loss': 0.12598353943182192, 'validation/num_examples': 83274637, 'test/loss': 0.12830099226973685, 'test/num_examples': 95000000, 'score': 3151.2484159469604, 'total_duration': 21809.966855049133, 'accumulated_submission_time': 3151.2484159469604, 'accumulated_eval_time': 18657.954735517502, 'accumulated_logging_time': 0.5763859748840332}
I0306 19:10:45.030272 139870399866624 logging_writer.py:48] [3265] accumulated_eval_time=18658, accumulated_logging_time=0.576386, accumulated_submission_time=3151.25, global_step=3265, preemption_count=0, score=3151.25, test/loss=0.128301, test/num_examples=95000000, total_duration=21810, train/loss=0.122694, validation/loss=0.125984, validation/num_examples=83274637
I0306 19:10:57.486824 139870391473920 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.013110361061990261, loss=0.12287379056215286
I0306 19:12:45.172811 140022987785408 spec.py:321] Evaluating on the training split.
I0306 19:12:52.542590 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 19:16:00.695062 140022987785408 spec.py:349] Evaluating on the test split.
I0306 19:21:56.540992 140022987785408 submission_runner.py:469] Time since start: 22481.49s, 	Step: 3395, 	{'train/loss': 0.12467443467404857, 'validation/loss': 0.12644476969470309, 'validation/num_examples': 83274637, 'test/loss': 0.12895673567023028, 'test/num_examples': 95000000, 'score': 3271.3753945827484, 'total_duration': 22481.48777627945, 'accumulated_submission_time': 3271.3753945827484, 'accumulated_eval_time': 19209.32284283638, 'accumulated_logging_time': 0.5933666229248047}
I0306 19:21:56.550189 139870399866624 logging_writer.py:48] [3395] accumulated_eval_time=19209.3, accumulated_logging_time=0.593367, accumulated_submission_time=3271.38, global_step=3395, preemption_count=0, score=3271.38, test/loss=0.128957, test/num_examples=95000000, total_duration=22481.5, train/loss=0.124674, validation/loss=0.126445, validation/num_examples=83274637
I0306 19:21:57.206022 139870391473920 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.038901761174201965, loss=0.1314244568347931
I0306 19:23:26.901642 139870399866624 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.023581381887197495, loss=0.12823930382728577
I0306 19:23:57.723396 140022987785408 spec.py:321] Evaluating on the training split.
I0306 19:24:05.203677 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 19:27:14.512384 140022987785408 spec.py:349] Evaluating on the test split.
I0306 19:33:04.886941 140022987785408 submission_runner.py:469] Time since start: 23149.83s, 	Step: 3527, 	{'train/loss': 0.1281411052921658, 'validation/loss': 0.1270574091777957, 'validation/num_examples': 83274637, 'test/loss': 0.12945708173314144, 'test/num_examples': 95000000, 'score': 3392.5349164009094, 'total_duration': 23149.83373785019, 'accumulated_submission_time': 3392.5349164009094, 'accumulated_eval_time': 19756.486323833466, 'accumulated_logging_time': 0.6090471744537354}
I0306 19:33:04.895716 139870391473920 logging_writer.py:48] [3527] accumulated_eval_time=19756.5, accumulated_logging_time=0.609047, accumulated_submission_time=3392.53, global_step=3527, preemption_count=0, score=3392.53, test/loss=0.129457, test/num_examples=95000000, total_duration=23149.8, train/loss=0.128141, validation/loss=0.127057, validation/num_examples=83274637
I0306 19:34:07.312652 139870399866624 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.05495402589440346, loss=0.11986137181520462
I0306 19:35:05.974888 140022987785408 spec.py:321] Evaluating on the training split.
I0306 19:35:13.509757 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 19:38:25.360253 140022987785408 spec.py:349] Evaluating on the test split.
I0306 19:44:17.360976 140022987785408 submission_runner.py:469] Time since start: 23822.31s, 	Step: 3655, 	{'train/loss': 0.12303450776252357, 'validation/loss': 0.1259141807876291, 'validation/num_examples': 83274637, 'test/loss': 0.12801078988486841, 'test/num_examples': 95000000, 'score': 3513.5808939933777, 'total_duration': 23822.307765245438, 'accumulated_submission_time': 3513.5808939933777, 'accumulated_eval_time': 20307.87234044075, 'accumulated_logging_time': 0.6443257331848145}
I0306 19:44:17.370539 139870391473920 logging_writer.py:48] [3655] accumulated_eval_time=20307.9, accumulated_logging_time=0.644326, accumulated_submission_time=3513.58, global_step=3655, preemption_count=0, score=3513.58, test/loss=0.128011, test/num_examples=95000000, total_duration=23822.3, train/loss=0.123035, validation/loss=0.125914, validation/num_examples=83274637
I0306 19:44:41.888237 139870399866624 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.010258463211357594, loss=0.12583446502685547
I0306 19:46:18.110362 140022987785408 spec.py:321] Evaluating on the training split.
I0306 19:46:25.489187 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 19:49:37.268595 140022987785408 spec.py:349] Evaluating on the test split.
I0306 19:55:31.325825 140022987785408 submission_runner.py:469] Time since start: 24496.27s, 	Step: 3784, 	{'train/loss': 0.12526198842053143, 'validation/loss': 0.1261484424357578, 'validation/num_examples': 83274637, 'test/loss': 0.12859563779810856, 'test/num_examples': 95000000, 'score': 3634.3075506687164, 'total_duration': 24496.27262377739, 'accumulated_submission_time': 3634.3075506687164, 'accumulated_eval_time': 20861.087744951248, 'accumulated_logging_time': 0.6605300903320312}
I0306 19:55:31.335468 139870391473920 logging_writer.py:48] [3784] accumulated_eval_time=20861.1, accumulated_logging_time=0.66053, accumulated_submission_time=3634.31, global_step=3784, preemption_count=0, score=3634.31, test/loss=0.128596, test/num_examples=95000000, total_duration=24496.3, train/loss=0.125262, validation/loss=0.126148, validation/num_examples=83274637
I0306 19:55:33.133907 139870399866624 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.054939836263656616, loss=0.13489137589931488
I0306 19:57:24.867687 139870391473920 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.017200930044054985, loss=0.1307477056980133
I0306 19:57:31.850011 140022987785408 spec.py:321] Evaluating on the training split.
I0306 19:57:39.312921 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 20:00:49.675051 140022987785408 spec.py:349] Evaluating on the test split.
I0306 20:06:39.426060 140022987785408 submission_runner.py:469] Time since start: 25164.37s, 	Step: 3907, 	{'train/loss': 0.12330334808138556, 'validation/loss': 0.12618688567950279, 'validation/num_examples': 83274637, 'test/loss': 0.12860007470189144, 'test/num_examples': 95000000, 'score': 3754.808585166931, 'total_duration': 25164.372837781906, 'accumulated_submission_time': 3754.808585166931, 'accumulated_eval_time': 21408.663711071014, 'accumulated_logging_time': 0.6767020225524902}
I0306 20:06:39.436377 139870399866624 logging_writer.py:48] [3907] accumulated_eval_time=21408.7, accumulated_logging_time=0.676702, accumulated_submission_time=3754.81, global_step=3907, preemption_count=0, score=3754.81, test/loss=0.1286, test/num_examples=95000000, total_duration=25164.4, train/loss=0.123303, validation/loss=0.126187, validation/num_examples=83274637
I0306 20:07:57.748301 139870391473920 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.01476714015007019, loss=0.12716121971607208
I0306 20:08:39.597223 140022987785408 spec.py:321] Evaluating on the training split.
I0306 20:08:47.015658 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 20:11:57.895537 140022987785408 spec.py:349] Evaluating on the test split.
I0306 20:17:44.374871 140022987785408 submission_runner.py:469] Time since start: 25829.32s, 	Step: 4035, 	{'train/loss': 0.12541248593127952, 'validation/loss': 0.12664954910027482, 'validation/num_examples': 83274637, 'test/loss': 0.1289878077919408, 'test/num_examples': 95000000, 'score': 3874.918527841568, 'total_duration': 25829.321654319763, 'accumulated_submission_time': 3874.918527841568, 'accumulated_eval_time': 21953.44127702713, 'accumulated_logging_time': 0.7310771942138672}
I0306 20:17:44.383642 139870399866624 logging_writer.py:48] [4035] accumulated_eval_time=21953.4, accumulated_logging_time=0.731077, accumulated_submission_time=3874.92, global_step=4035, preemption_count=0, score=3874.92, test/loss=0.128988, test/num_examples=95000000, total_duration=25829.3, train/loss=0.125412, validation/loss=0.12665, validation/num_examples=83274637
I0306 20:18:34.496229 139870391473920 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.028294064104557037, loss=0.1260557919740677
I0306 20:19:45.684688 140022987785408 spec.py:321] Evaluating on the training split.
I0306 20:19:53.087001 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 20:23:00.715260 140022987785408 spec.py:349] Evaluating on the test split.
I0306 20:28:52.597722 140022987785408 submission_runner.py:469] Time since start: 26497.54s, 	Step: 4159, 	{'train/loss': 0.124196991078415, 'validation/loss': 0.1260545073090971, 'validation/num_examples': 83274637, 'test/loss': 0.12818708149671051, 'test/num_examples': 95000000, 'score': 3996.2059915065765, 'total_duration': 26497.54452419281, 'accumulated_submission_time': 3996.2059915065765, 'accumulated_eval_time': 22500.35425376892, 'accumulated_logging_time': 0.7463197708129883}
I0306 20:28:52.607017 139870399866624 logging_writer.py:48] [4159] accumulated_eval_time=22500.4, accumulated_logging_time=0.74632, accumulated_submission_time=3996.21, global_step=4159, preemption_count=0, score=3996.21, test/loss=0.128187, test/num_examples=95000000, total_duration=26497.5, train/loss=0.124197, validation/loss=0.126055, validation/num_examples=83274637
I0306 20:29:12.594489 139870391473920 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.012001155875623226, loss=0.12072854489088058
I0306 20:30:53.248962 140022987785408 spec.py:321] Evaluating on the training split.
I0306 20:31:00.635319 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 20:34:13.362000 140022987785408 spec.py:349] Evaluating on the test split.
I0306 20:40:09.728132 140022987785408 submission_runner.py:469] Time since start: 27174.67s, 	Step: 4286, 	{'train/loss': 0.12367790301312816, 'validation/loss': 0.12604607353082412, 'validation/num_examples': 83274637, 'test/loss': 0.12836553532072367, 'test/num_examples': 95000000, 'score': 4116.83499288559, 'total_duration': 27174.674921751022, 'accumulated_submission_time': 4116.83499288559, 'accumulated_eval_time': 23056.83335709572, 'accumulated_logging_time': 0.7619421482086182}
I0306 20:40:09.737594 139870399866624 logging_writer.py:48] [4286] accumulated_eval_time=23056.8, accumulated_logging_time=0.761942, accumulated_submission_time=4116.83, global_step=4286, preemption_count=0, score=4116.83, test/loss=0.128366, test/num_examples=95000000, total_duration=27174.7, train/loss=0.123678, validation/loss=0.126046, validation/num_examples=83274637
I0306 20:40:11.367941 139870391473920 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.04250919446349144, loss=0.11824944615364075
I0306 20:41:56.122564 139870399866624 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.04034731537103653, loss=0.12093175202608109
I0306 20:42:10.834533 140022987785408 spec.py:321] Evaluating on the training split.
I0306 20:42:18.289187 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 20:45:29.855267 140022987785408 spec.py:349] Evaluating on the test split.
I0306 20:51:32.223585 140022987785408 submission_runner.py:469] Time since start: 27857.17s, 	Step: 4414, 	{'train/loss': 0.1229117611926869, 'validation/loss': 0.12586923637685746, 'validation/num_examples': 83274637, 'test/loss': 0.12832687640830592, 'test/num_examples': 95000000, 'score': 4237.9069221019745, 'total_duration': 27857.17037653923, 'accumulated_submission_time': 4237.9069221019745, 'accumulated_eval_time': 23618.22234916687, 'accumulated_logging_time': 0.7881443500518799}
I0306 20:51:32.232788 139870391473920 logging_writer.py:48] [4414] accumulated_eval_time=23618.2, accumulated_logging_time=0.788144, accumulated_submission_time=4237.91, global_step=4414, preemption_count=0, score=4237.91, test/loss=0.128327, test/num_examples=95000000, total_duration=27857.2, train/loss=0.122912, validation/loss=0.125869, validation/num_examples=83274637
I0306 20:52:48.435533 139870399866624 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.01565530337393284, loss=0.12585291266441345
I0306 20:53:33.282587 140022987785408 spec.py:321] Evaluating on the training split.
I0306 20:53:40.656728 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 20:56:48.673053 140022987785408 spec.py:349] Evaluating on the test split.
I0306 21:02:35.114353 140022987785408 submission_runner.py:469] Time since start: 28520.06s, 	Step: 4537, 	{'train/loss': 0.12619396235864117, 'validation/loss': 0.12695026993042086, 'validation/num_examples': 83274637, 'test/loss': 0.12915587281044408, 'test/num_examples': 95000000, 'score': 4358.944235086441, 'total_duration': 28520.06114435196, 'accumulated_submission_time': 4358.944235086441, 'accumulated_eval_time': 24160.054053544998, 'accumulated_logging_time': 0.803687334060669}
I0306 21:02:35.123830 139870391473920 logging_writer.py:48] [4537] accumulated_eval_time=24160.1, accumulated_logging_time=0.803687, accumulated_submission_time=4358.94, global_step=4537, preemption_count=0, score=4358.94, test/loss=0.129156, test/num_examples=95000000, total_duration=28520.1, train/loss=0.126194, validation/loss=0.12695, validation/num_examples=83274637
I0306 21:03:20.710973 139870399866624 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.005199095234274864, loss=0.12207995355129242
I0306 21:04:35.238656 140022987785408 spec.py:321] Evaluating on the training split.
I0306 21:04:42.646707 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 21:07:54.738718 140022987785408 spec.py:349] Evaluating on the test split.
I0306 21:13:55.020680 140022987785408 submission_runner.py:469] Time since start: 29199.97s, 	Step: 4664, 	{'train/loss': 0.12427905280400747, 'validation/loss': 0.1258684332467148, 'validation/num_examples': 83274637, 'test/loss': 0.12829094929070722, 'test/num_examples': 95000000, 'score': 4479.044402837753, 'total_duration': 29199.967454195023, 'accumulated_submission_time': 4479.044402837753, 'accumulated_eval_time': 24719.835995197296, 'accumulated_logging_time': 0.8195834159851074}
I0306 21:13:55.030429 139870391473920 logging_writer.py:48] [4664] accumulated_eval_time=24719.8, accumulated_logging_time=0.819583, accumulated_submission_time=4479.04, global_step=4664, preemption_count=0, score=4479.04, test/loss=0.128291, test/num_examples=95000000, total_duration=29200, train/loss=0.124279, validation/loss=0.125868, validation/num_examples=83274637
I0306 21:14:08.763679 139870399866624 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.021357256919145584, loss=0.12193386256694794
I0306 21:15:56.100733 140022987785408 spec.py:321] Evaluating on the training split.
I0306 21:16:03.564193 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 21:19:15.141423 140022987785408 spec.py:349] Evaluating on the test split.
I0306 21:25:08.702901 140022987785408 submission_runner.py:469] Time since start: 29873.65s, 	Step: 4792, 	{'train/loss': 0.12454855688056855, 'validation/loss': 0.1257982293958675, 'validation/num_examples': 83274637, 'test/loss': 0.1279534648334704, 'test/num_examples': 95000000, 'score': 4600.101249694824, 'total_duration': 29873.64969420433, 'accumulated_submission_time': 4600.101249694824, 'accumulated_eval_time': 25272.43809914589, 'accumulated_logging_time': 0.8358571529388428}
I0306 21:25:08.712640 139870391473920 logging_writer.py:48] [4792] accumulated_eval_time=25272.4, accumulated_logging_time=0.835857, accumulated_submission_time=4600.1, global_step=4792, preemption_count=0, score=4600.1, test/loss=0.127953, test/num_examples=95000000, total_duration=29873.6, train/loss=0.124549, validation/loss=0.125798, validation/num_examples=83274637
I0306 21:25:09.720791 139870399866624 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.05503176897764206, loss=0.12304621934890747
I0306 21:26:43.859980 139870391473920 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.04754875972867012, loss=0.12496158480644226
I0306 21:27:08.849720 140022987785408 spec.py:321] Evaluating on the training split.
I0306 21:27:16.249857 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 21:30:26.871358 140022987785408 spec.py:349] Evaluating on the test split.
I0306 21:36:12.293683 140022987785408 submission_runner.py:469] Time since start: 30537.24s, 	Step: 4925, 	{'train/loss': 0.125202842068466, 'validation/loss': 0.12578071055050427, 'validation/num_examples': 83274637, 'test/loss': 0.12812187866981908, 'test/num_examples': 95000000, 'score': 4720.178936004639, 'total_duration': 30537.2404692173, 'accumulated_submission_time': 4720.178936004639, 'accumulated_eval_time': 25815.881989002228, 'accumulated_logging_time': 0.8983609676361084}
I0306 21:36:12.304732 139870399866624 logging_writer.py:48] [4925] accumulated_eval_time=25815.9, accumulated_logging_time=0.898361, accumulated_submission_time=4720.18, global_step=4925, preemption_count=0, score=4720.18, test/loss=0.128122, test/num_examples=95000000, total_duration=30537.2, train/loss=0.125203, validation/loss=0.125781, validation/num_examples=83274637
I0306 21:37:11.024377 139870391473920 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.025667784735560417, loss=0.1281147450208664
I0306 21:38:12.676267 140022987785408 spec.py:321] Evaluating on the training split.
I0306 21:38:20.076570 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 21:41:33.079992 140022987785408 spec.py:349] Evaluating on the test split.
I0306 21:47:27.836164 140022987785408 submission_runner.py:469] Time since start: 31212.78s, 	Step: 5053, 	{'train/loss': 0.12563495872155675, 'validation/loss': 0.1255344917967227, 'validation/num_examples': 83274637, 'test/loss': 0.12780451163651316, 'test/num_examples': 95000000, 'score': 4840.537198781967, 'total_duration': 31212.782967329025, 'accumulated_submission_time': 4840.537198781967, 'accumulated_eval_time': 26371.041830301285, 'accumulated_logging_time': 0.9162437915802002}
I0306 21:47:27.860019 139870399866624 logging_writer.py:48] [5053] accumulated_eval_time=26371, accumulated_logging_time=0.916244, accumulated_submission_time=4840.54, global_step=5053, preemption_count=0, score=4840.54, test/loss=0.127805, test/num_examples=95000000, total_duration=31212.8, train/loss=0.125635, validation/loss=0.125534, validation/num_examples=83274637
I0306 21:47:54.301079 139870391473920 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.009054590947926044, loss=0.12448541820049286
I0306 21:49:27.931504 140022987785408 spec.py:321] Evaluating on the training split.
I0306 21:49:35.303183 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 21:52:47.597607 140022987785408 spec.py:349] Evaluating on the test split.
I0306 21:58:36.948438 140022987785408 submission_runner.py:469] Time since start: 31881.90s, 	Step: 5180, 	{'train/loss': 0.12325210438209509, 'validation/loss': 0.1256814108034441, 'validation/num_examples': 83274637, 'test/loss': 0.12804753811677633, 'test/num_examples': 95000000, 'score': 4960.59445810318, 'total_duration': 31881.8952088356, 'accumulated_submission_time': 4960.59445810318, 'accumulated_eval_time': 26920.058677196503, 'accumulated_logging_time': 0.9477136135101318}
I0306 21:58:37.000829 139870399866624 logging_writer.py:48] [5180] accumulated_eval_time=26920.1, accumulated_logging_time=0.947714, accumulated_submission_time=4960.59, global_step=5180, preemption_count=0, score=4960.59, test/loss=0.128048, test/num_examples=95000000, total_duration=31881.9, train/loss=0.123252, validation/loss=0.125681, validation/num_examples=83274637
I0306 21:58:39.252373 139870391473920 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.014708840288221836, loss=0.13195037841796875
I0306 22:00:32.388005 139870399866624 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.04358595237135887, loss=0.12458068877458572
I0306 22:00:37.656510 140022987785408 spec.py:321] Evaluating on the training split.
I0306 22:00:45.019369 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 22:03:54.475246 140022987785408 spec.py:349] Evaluating on the test split.
I0306 22:09:49.071290 140022987785408 submission_runner.py:469] Time since start: 32554.02s, 	Step: 5305, 	{'train/loss': 0.12574201215456868, 'validation/loss': 0.12553748525674674, 'validation/num_examples': 83274637, 'test/loss': 0.1278597552837171, 'test/num_examples': 95000000, 'score': 5081.237327337265, 'total_duration': 32554.01807332039, 'accumulated_submission_time': 5081.237327337265, 'accumulated_eval_time': 27471.473376989365, 'accumulated_logging_time': 1.0065724849700928}
I0306 22:09:49.080703 139870391473920 logging_writer.py:48] [5305] accumulated_eval_time=27471.5, accumulated_logging_time=1.00657, accumulated_submission_time=5081.24, global_step=5305, preemption_count=0, score=5081.24, test/loss=0.12786, test/num_examples=95000000, total_duration=32554, train/loss=0.125742, validation/loss=0.125537, validation/num_examples=83274637
I0306 22:11:13.426830 139870399866624 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.015004717744886875, loss=0.12330035865306854
I0306 22:11:49.195781 140022987785408 spec.py:321] Evaluating on the training split.
I0306 22:11:56.635970 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 22:15:06.355014 140022987785408 spec.py:349] Evaluating on the test split.
I0306 22:20:58.340182 140022987785408 submission_runner.py:469] Time since start: 33223.29s, 	Step: 5433, 	{'train/loss': 0.12662533226674832, 'validation/loss': 0.12593061418094767, 'validation/num_examples': 83274637, 'test/loss': 0.12834961351768093, 'test/num_examples': 95000000, 'score': 5201.337510108948, 'total_duration': 33223.28698015213, 'accumulated_submission_time': 5201.337510108948, 'accumulated_eval_time': 28020.61771774292, 'accumulated_logging_time': 1.022935152053833}
I0306 22:20:58.351173 139870391473920 logging_writer.py:48] [5433] accumulated_eval_time=28020.6, accumulated_logging_time=1.02294, accumulated_submission_time=5201.34, global_step=5433, preemption_count=0, score=5201.34, test/loss=0.12835, test/num_examples=95000000, total_duration=33223.3, train/loss=0.126625, validation/loss=0.125931, validation/num_examples=83274637
I0306 22:21:45.340378 139870399866624 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.035641200840473175, loss=0.1215168684720993
I0306 22:22:58.550046 140022987785408 spec.py:321] Evaluating on the training split.
I0306 22:23:05.946441 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 22:26:17.451496 140022987785408 spec.py:349] Evaluating on the test split.
I0306 22:32:04.284696 140022987785408 submission_runner.py:469] Time since start: 33889.23s, 	Step: 5565, 	{'train/loss': 0.126142426985521, 'validation/loss': 0.12664872446865935, 'validation/num_examples': 83274637, 'test/loss': 0.12910995327919408, 'test/num_examples': 95000000, 'score': 5321.522775411606, 'total_duration': 33889.23147749901, 'accumulated_submission_time': 5321.522775411606, 'accumulated_eval_time': 28566.35228562355, 'accumulated_logging_time': 1.0409409999847412}
I0306 22:32:04.294365 139870391473920 logging_writer.py:48] [5565] accumulated_eval_time=28566.4, accumulated_logging_time=1.04094, accumulated_submission_time=5321.52, global_step=5565, preemption_count=0, score=5321.52, test/loss=0.12911, test/num_examples=95000000, total_duration=33889.2, train/loss=0.126142, validation/loss=0.126649, validation/num_examples=83274637
I0306 22:32:16.399000 139870399866624 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.014896885491907597, loss=0.1243690475821495
I0306 22:34:04.367722 140022987785408 spec.py:321] Evaluating on the training split.
I0306 22:34:11.723707 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 22:37:23.422711 140022987785408 spec.py:349] Evaluating on the test split.
I0306 22:43:22.293646 140022987785408 submission_runner.py:469] Time since start: 34567.24s, 	Step: 5692, 	{'train/loss': 0.12399337641051356, 'validation/loss': 0.12559064101372935, 'validation/num_examples': 83274637, 'test/loss': 0.12793836279810855, 'test/num_examples': 95000000, 'score': 5441.582203626633, 'total_duration': 34567.240421533585, 'accumulated_submission_time': 5441.582203626633, 'accumulated_eval_time': 29124.27813243866, 'accumulated_logging_time': 1.0569000244140625}
I0306 22:43:22.303396 139870391473920 logging_writer.py:48] [5692] accumulated_eval_time=29124.3, accumulated_logging_time=1.0569, accumulated_submission_time=5441.58, global_step=5692, preemption_count=0, score=5441.58, test/loss=0.127938, test/num_examples=95000000, total_duration=34567.2, train/loss=0.123993, validation/loss=0.125591, validation/num_examples=83274637
I0306 22:43:23.274301 139870399866624 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.0060044024139642715, loss=0.13031327724456787
I0306 22:45:01.397089 139870391473920 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.010686967521905899, loss=0.11805850267410278
I0306 22:45:23.024530 140022987785408 spec.py:321] Evaluating on the training split.
I0306 22:45:30.422573 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 22:48:40.971002 140022987785408 spec.py:349] Evaluating on the test split.
I0306 22:54:30.009814 140022987785408 submission_runner.py:469] Time since start: 35234.96s, 	Step: 5820, 	{'train/loss': 0.12459776343180323, 'validation/loss': 0.12602980396969862, 'validation/num_examples': 83274637, 'test/loss': 0.12847252081620067, 'test/num_examples': 95000000, 'score': 5562.278552770615, 'total_duration': 35234.95661067963, 'accumulated_submission_time': 5562.278552770615, 'accumulated_eval_time': 29671.263358831406, 'accumulated_logging_time': 1.0844929218292236}
I0306 22:54:30.019303 139870399866624 logging_writer.py:48] [5820] accumulated_eval_time=29671.3, accumulated_logging_time=1.08449, accumulated_submission_time=5562.28, global_step=5820, preemption_count=0, score=5562.28, test/loss=0.128473, test/num_examples=95000000, total_duration=35235, train/loss=0.124598, validation/loss=0.12603, validation/num_examples=83274637
I0306 22:55:37.867764 139870391473920 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.021624457091093063, loss=0.12398087978363037
I0306 22:56:31.051211 140022987785408 spec.py:321] Evaluating on the training split.
I0306 22:56:38.527066 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 22:59:49.733762 140022987785408 spec.py:349] Evaluating on the test split.
I0306 23:05:44.536326 140022987785408 submission_runner.py:469] Time since start: 35909.48s, 	Step: 5949, 	{'train/loss': 0.12485608998568928, 'validation/loss': 0.1258855489526556, 'validation/num_examples': 83274637, 'test/loss': 0.12822382660361842, 'test/num_examples': 95000000, 'score': 5683.296730995178, 'total_duration': 35909.48312497139, 'accumulated_submission_time': 5683.296730995178, 'accumulated_eval_time': 30224.74841117859, 'accumulated_logging_time': 1.1002686023712158}
I0306 23:05:44.546473 139870399866624 logging_writer.py:48] [5949] accumulated_eval_time=30224.7, accumulated_logging_time=1.10027, accumulated_submission_time=5683.3, global_step=5949, preemption_count=0, score=5683.3, test/loss=0.128224, test/num_examples=95000000, total_duration=35909.5, train/loss=0.124856, validation/loss=0.125886, validation/num_examples=83274637
I0306 23:06:16.957693 139870391473920 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.027276335284113884, loss=0.11657024174928665
I0306 23:07:44.802962 140022987785408 spec.py:321] Evaluating on the training split.
I0306 23:07:52.222820 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 23:11:05.241198 140022987785408 spec.py:349] Evaluating on the test split.
I0306 23:16:54.459899 140022987785408 submission_runner.py:469] Time since start: 36579.41s, 	Step: 6072, 	{'train/loss': 0.12469858910490132, 'validation/loss': 0.12554585780243704, 'validation/num_examples': 83274637, 'test/loss': 0.12778621375411184, 'test/num_examples': 95000000, 'score': 5803.539839982986, 'total_duration': 36579.40667915344, 'accumulated_submission_time': 5803.539839982986, 'accumulated_eval_time': 30774.405269145966, 'accumulated_logging_time': 1.1171298027038574}
I0306 23:16:54.471324 139870399866624 logging_writer.py:48] [6072] accumulated_eval_time=30774.4, accumulated_logging_time=1.11713, accumulated_submission_time=5803.54, global_step=6072, preemption_count=0, score=5803.54, test/loss=0.127786, test/num_examples=95000000, total_duration=36579.4, train/loss=0.124699, validation/loss=0.125546, validation/num_examples=83274637
I0306 23:16:59.467333 139870391473920 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.019613249227404594, loss=0.1281452775001526
I0306 23:18:53.856170 139870399866624 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.018804043531417847, loss=0.1243196576833725
I0306 23:18:54.993216 140022987785408 spec.py:321] Evaluating on the training split.
I0306 23:19:02.386729 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 23:22:11.392617 140022987785408 spec.py:349] Evaluating on the test split.
I0306 23:28:03.018916 140022987785408 submission_runner.py:469] Time since start: 37247.97s, 	Step: 6202, 	{'train/loss': 0.12280461188616618, 'validation/loss': 0.12574165323360814, 'validation/num_examples': 83274637, 'test/loss': 0.1281431732113487, 'test/num_examples': 95000000, 'score': 5924.048048496246, 'total_duration': 37247.96570587158, 'accumulated_submission_time': 5924.048048496246, 'accumulated_eval_time': 31322.43089580536, 'accumulated_logging_time': 1.135511875152588}
I0306 23:28:03.031006 139870391473920 logging_writer.py:48] [6202] accumulated_eval_time=31322.4, accumulated_logging_time=1.13551, accumulated_submission_time=5924.05, global_step=6202, preemption_count=0, score=5924.05, test/loss=0.128143, test/num_examples=95000000, total_duration=37248, train/loss=0.122805, validation/loss=0.125742, validation/num_examples=83274637
I0306 23:29:29.100365 139870399866624 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.011138461530208588, loss=0.13067367672920227
I0306 23:30:03.569914 140022987785408 spec.py:321] Evaluating on the training split.
I0306 23:30:11.081278 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 23:33:21.436012 140022987785408 spec.py:349] Evaluating on the test split.
I0306 23:39:13.963254 140022987785408 submission_runner.py:469] Time since start: 37918.91s, 	Step: 6328, 	{'train/loss': 0.12612826654792958, 'validation/loss': 0.1254203525622243, 'validation/num_examples': 83274637, 'test/loss': 0.1278418680098684, 'test/num_examples': 95000000, 'score': 6044.545758962631, 'total_duration': 37918.910048007965, 'accumulated_submission_time': 6044.545758962631, 'accumulated_eval_time': 31872.824172496796, 'accumulated_logging_time': 1.1826276779174805}
I0306 23:39:13.973273 139870391473920 logging_writer.py:48] [6328] accumulated_eval_time=31872.8, accumulated_logging_time=1.18263, accumulated_submission_time=6044.55, global_step=6328, preemption_count=0, score=6044.55, test/loss=0.127842, test/num_examples=95000000, total_duration=37918.9, train/loss=0.126128, validation/loss=0.12542, validation/num_examples=83274637
I0306 23:40:09.605378 139870399866624 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.008980927057564259, loss=0.13219603896141052
I0306 23:41:14.560023 140022987785408 spec.py:321] Evaluating on the training split.
I0306 23:41:21.939734 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 23:44:34.532958 140022987785408 spec.py:349] Evaluating on the test split.
I0306 23:50:30.259541 140022987785408 submission_runner.py:469] Time since start: 38595.21s, 	Step: 6457, 	{'train/loss': 0.12558597749181138, 'validation/loss': 0.12554849194687498, 'validation/num_examples': 83274637, 'test/loss': 0.12775707196751646, 'test/num_examples': 95000000, 'score': 6165.118328094482, 'total_duration': 38595.20632696152, 'accumulated_submission_time': 6165.118328094482, 'accumulated_eval_time': 32428.523628234863, 'accumulated_logging_time': 1.1998388767242432}
I0306 23:50:30.269702 139870391473920 logging_writer.py:48] [6457] accumulated_eval_time=32428.5, accumulated_logging_time=1.19984, accumulated_submission_time=6165.12, global_step=6457, preemption_count=0, score=6165.12, test/loss=0.127757, test/num_examples=95000000, total_duration=38595.2, train/loss=0.125586, validation/loss=0.125548, validation/num_examples=83274637
I0306 23:50:51.493726 139870399866624 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.011061437427997589, loss=0.12804706394672394
I0306 23:52:30.980733 140022987785408 spec.py:321] Evaluating on the training split.
I0306 23:52:38.422967 140022987785408 spec.py:333] Evaluating on the validation split.
I0306 23:55:54.493430 140022987785408 spec.py:349] Evaluating on the test split.
I0307 00:01:55.508887 140022987785408 submission_runner.py:469] Time since start: 39280.46s, 	Step: 6589, 	{'train/loss': 0.12214060917309245, 'validation/loss': 0.1255395900967253, 'validation/num_examples': 83274637, 'test/loss': 0.12793072337582237, 'test/num_examples': 95000000, 'score': 6285.816227912903, 'total_duration': 39280.455682992935, 'accumulated_submission_time': 6285.816227912903, 'accumulated_eval_time': 32993.051721572876, 'accumulated_logging_time': 1.216524362564087}
I0307 00:01:55.524838 139870391473920 logging_writer.py:48] [6589] accumulated_eval_time=32993.1, accumulated_logging_time=1.21652, accumulated_submission_time=6285.82, global_step=6589, preemption_count=0, score=6285.82, test/loss=0.127931, test/num_examples=95000000, total_duration=39280.5, train/loss=0.122141, validation/loss=0.12554, validation/num_examples=83274637
I0307 00:01:56.821187 139870399866624 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.020849362015724182, loss=0.12348029017448425
I0307 00:03:39.557749 139870391473920 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.00480096647515893, loss=0.12140432000160217
I0307 00:03:55.718868 140022987785408 spec.py:321] Evaluating on the training split.
I0307 00:04:03.245718 140022987785408 spec.py:333] Evaluating on the validation split.
I0307 00:07:13.025532 140022987785408 spec.py:349] Evaluating on the test split.
I0307 00:13:09.095301 140022987785408 submission_runner.py:469] Time since start: 39954.04s, 	Step: 6715, 	{'train/loss': 0.12488706385330209, 'validation/loss': 0.126294317064287, 'validation/num_examples': 83274637, 'test/loss': 0.1288234370888158, 'test/num_examples': 95000000, 'score': 6405.997116327286, 'total_duration': 39954.0420794487, 'accumulated_submission_time': 6405.997116327286, 'accumulated_eval_time': 33546.42807149887, 'accumulated_logging_time': 1.2387185096740723}
I0307 00:13:09.105668 139870399866624 logging_writer.py:48] [6715] accumulated_eval_time=33546.4, accumulated_logging_time=1.23872, accumulated_submission_time=6406, global_step=6715, preemption_count=0, score=6406, test/loss=0.128823, test/num_examples=95000000, total_duration=39954, train/loss=0.124887, validation/loss=0.126294, validation/num_examples=83274637
I0307 00:14:19.716530 139870391473920 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.014179814606904984, loss=0.12564100325107574
I0307 00:15:09.806473 140022987785408 spec.py:321] Evaluating on the training split.
I0307 00:15:17.327724 140022987785408 spec.py:333] Evaluating on the validation split.
I0307 00:18:25.015412 140022987785408 spec.py:349] Evaluating on the test split.
I0307 00:24:11.437243 140022987785408 submission_runner.py:469] Time since start: 40616.38s, 	Step: 6844, 	{'train/loss': 0.1232764860673708, 'validation/loss': 0.12601066475645709, 'validation/num_examples': 83274637, 'test/loss': 0.12839166787623355, 'test/num_examples': 95000000, 'score': 6526.6845009326935, 'total_duration': 40616.38400864601, 'accumulated_submission_time': 6526.6845009326935, 'accumulated_eval_time': 34088.058755874634, 'accumulated_logging_time': 1.2557930946350098}
I0307 00:24:11.447619 139870399866624 logging_writer.py:48] [6844] accumulated_eval_time=34088.1, accumulated_logging_time=1.25579, accumulated_submission_time=6526.68, global_step=6844, preemption_count=0, score=6526.68, test/loss=0.128392, test/num_examples=95000000, total_duration=40616.4, train/loss=0.123276, validation/loss=0.126011, validation/num_examples=83274637
I0307 00:24:51.652838 139870391473920 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.006714593153446913, loss=0.11900727450847626
I0307 00:26:12.313843 140022987785408 spec.py:321] Evaluating on the training split.
I0307 00:26:19.739425 140022987785408 spec.py:333] Evaluating on the validation split.
I0307 00:29:29.868133 140022987785408 spec.py:349] Evaluating on the test split.
I0307 00:35:16.680142 140022987785408 submission_runner.py:469] Time since start: 41281.63s, 	Step: 6967, 	{'train/loss': 0.1233566506361624, 'validation/loss': 0.12556776816677426, 'validation/num_examples': 83274637, 'test/loss': 0.12782639921875, 'test/num_examples': 95000000, 'score': 6647.536203622818, 'total_duration': 41281.626939058304, 'accumulated_submission_time': 6647.536203622818, 'accumulated_eval_time': 34632.42500042915, 'accumulated_logging_time': 1.272350549697876}
I0307 00:35:16.690507 139870399866624 logging_writer.py:48] [6967] accumulated_eval_time=34632.4, accumulated_logging_time=1.27235, accumulated_submission_time=6647.54, global_step=6967, preemption_count=0, score=6647.54, test/loss=0.127826, test/num_examples=95000000, total_duration=41281.6, train/loss=0.123357, validation/loss=0.125568, validation/num_examples=83274637
I0307 00:35:27.519201 139870391473920 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.025787947699427605, loss=0.12720973789691925
I0307 00:37:17.458359 140022987785408 spec.py:321] Evaluating on the training split.
I0307 00:37:24.860837 140022987785408 spec.py:333] Evaluating on the validation split.
I0307 00:40:35.937935 140022987785408 spec.py:349] Evaluating on the test split.
I0307 00:46:31.614022 140022987785408 submission_runner.py:469] Time since start: 41956.56s, 	Step: 7092, 	{'train/loss': 0.1268444780799203, 'validation/loss': 0.12567669764190365, 'validation/num_examples': 83274637, 'test/loss': 0.12783058797286184, 'test/num_examples': 95000000, 'score': 6768.290092468262, 'total_duration': 41956.56082201004, 'accumulated_submission_time': 6768.290092468262, 'accumulated_eval_time': 35186.58060860634, 'accumulated_logging_time': 1.2891650199890137}
I0307 00:46:31.673057 139870399866624 logging_writer.py:48] [7092] accumulated_eval_time=35186.6, accumulated_logging_time=1.28917, accumulated_submission_time=6768.29, global_step=7092, preemption_count=0, score=6768.29, test/loss=0.127831, test/num_examples=95000000, total_duration=41956.6, train/loss=0.126844, validation/loss=0.125677, validation/num_examples=83274637
I0307 00:46:32.650749 139870391473920 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.022282294929027557, loss=0.12907108664512634
I0307 00:48:13.933740 139870399866624 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.007031901273876429, loss=0.12120188772678375
I0307 00:48:31.774321 140022987785408 spec.py:321] Evaluating on the training split.
I0307 00:48:39.147110 140022987785408 spec.py:333] Evaluating on the validation split.
I0307 00:51:49.438080 140022987785408 spec.py:349] Evaluating on the test split.
I0307 00:57:33.294348 140022987785408 submission_runner.py:469] Time since start: 42618.24s, 	Step: 7215, 	{'train/loss': 0.12436518668191238, 'validation/loss': 0.12543766079635163, 'validation/num_examples': 83274637, 'test/loss': 0.1276590529194079, 'test/num_examples': 95000000, 'score': 6888.370259046555, 'total_duration': 42618.241144657135, 'accumulated_submission_time': 6888.370259046555, 'accumulated_eval_time': 35728.100570201874, 'accumulated_logging_time': 1.3625969886779785}
I0307 00:57:33.304391 139870391473920 logging_writer.py:48] [7215] accumulated_eval_time=35728.1, accumulated_logging_time=1.3626, accumulated_submission_time=6888.37, global_step=7215, preemption_count=0, score=6888.37, test/loss=0.127659, test/num_examples=95000000, total_duration=42618.2, train/loss=0.124365, validation/loss=0.125438, validation/num_examples=83274637
I0307 00:58:48.785500 139870399866624 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.020236190408468246, loss=0.12659664452075958
I0307 00:59:33.888397 140022987785408 spec.py:321] Evaluating on the training split.
I0307 00:59:41.326558 140022987785408 spec.py:333] Evaluating on the validation split.
I0307 01:02:51.824975 140022987785408 spec.py:349] Evaluating on the test split.
I0307 01:08:56.775594 140022987785408 submission_runner.py:469] Time since start: 43301.72s, 	Step: 7339, 	{'train/loss': 0.12231560141644762, 'validation/loss': 0.12562505944210278, 'validation/num_examples': 83274637, 'test/loss': 0.12792445806949013, 'test/num_examples': 95000000, 'score': 7008.939987659454, 'total_duration': 43301.72239255905, 'accumulated_submission_time': 7008.939987659454, 'accumulated_eval_time': 36290.98770880699, 'accumulated_logging_time': 1.3793237209320068}
I0307 01:08:56.812780 139870391473920 logging_writer.py:48] [7339] accumulated_eval_time=36291, accumulated_logging_time=1.37932, accumulated_submission_time=7008.94, global_step=7339, preemption_count=0, score=7008.94, test/loss=0.127924, test/num_examples=95000000, total_duration=43301.7, train/loss=0.122316, validation/loss=0.125625, validation/num_examples=83274637
I0307 01:09:41.277478 139870399866624 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.01301866676658392, loss=0.12026244401931763
I0307 01:10:57.491572 140022987785408 spec.py:321] Evaluating on the training split.
I0307 01:11:04.948302 140022987785408 spec.py:333] Evaluating on the validation split.
I0307 01:14:14.124430 140022987785408 spec.py:349] Evaluating on the test split.
I0307 01:20:15.320602 140022987785408 submission_runner.py:469] Time since start: 43980.27s, 	Step: 7467, 	{'train/loss': 0.12364895959273449, 'validation/loss': 0.12551741600366043, 'validation/num_examples': 83274637, 'test/loss': 0.1278510863178454, 'test/num_examples': 95000000, 'score': 7129.605026483536, 'total_duration': 43980.267384529114, 'accumulated_submission_time': 7129.605026483536, 'accumulated_eval_time': 36848.81667971611, 'accumulated_logging_time': 1.422806978225708}
I0307 01:20:15.333253 139870391473920 logging_writer.py:48] [7467] accumulated_eval_time=36848.8, accumulated_logging_time=1.42281, accumulated_submission_time=7129.61, global_step=7467, preemption_count=0, score=7129.61, test/loss=0.127851, test/num_examples=95000000, total_duration=43980.3, train/loss=0.123649, validation/loss=0.125517, validation/num_examples=83274637
I0307 01:20:25.768441 139870399866624 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.008094006218016148, loss=0.12068501114845276
I0307 01:22:16.821449 140022987785408 spec.py:321] Evaluating on the training split.
I0307 01:22:24.280971 140022987785408 spec.py:333] Evaluating on the validation split.
I0307 01:25:36.250728 140022987785408 spec.py:349] Evaluating on the test split.
I0307 01:31:27.170080 140022987785408 submission_runner.py:469] Time since start: 44652.12s, 	Step: 7593, 	{'train/loss': 0.1231487039008043, 'validation/loss': 0.12543822203932273, 'validation/num_examples': 83274637, 'test/loss': 0.12767926079358552, 'test/num_examples': 95000000, 'score': 7251.062160730362, 'total_duration': 44652.116861343384, 'accumulated_submission_time': 7251.062160730362, 'accumulated_eval_time': 37399.165251255035, 'accumulated_logging_time': 1.4581055641174316}
I0307 01:31:27.180935 139870391473920 logging_writer.py:48] [7593] accumulated_eval_time=37399.2, accumulated_logging_time=1.45811, accumulated_submission_time=7251.06, global_step=7593, preemption_count=0, score=7251.06, test/loss=0.127679, test/num_examples=95000000, total_duration=44652.1, train/loss=0.123149, validation/loss=0.125438, validation/num_examples=83274637
I0307 01:31:28.053426 139870399866624 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.008252093568444252, loss=0.13034453988075256
I0307 01:33:08.100978 139870391473920 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.006848499178886414, loss=0.12013357877731323
I0307 01:33:28.140760 140022987785408 spec.py:321] Evaluating on the training split.
I0307 01:33:35.575118 140022987785408 spec.py:333] Evaluating on the validation split.
I0307 01:36:44.178422 140022987785408 spec.py:349] Evaluating on the test split.
I0307 01:42:46.136710 140022987785408 submission_runner.py:469] Time since start: 45331.08s, 	Step: 7719, 	{'train/loss': 0.12260216182835822, 'validation/loss': 0.12550342548138335, 'validation/num_examples': 83274637, 'test/loss': 0.12783025872738488, 'test/num_examples': 95000000, 'score': 7372.008162498474, 'total_duration': 45331.0835108757, 'accumulated_submission_time': 7372.008162498474, 'accumulated_eval_time': 37957.16113948822, 'accumulated_logging_time': 1.475797176361084}
I0307 01:42:46.147642 139870399866624 logging_writer.py:48] [7719] accumulated_eval_time=37957.2, accumulated_logging_time=1.4758, accumulated_submission_time=7372.01, global_step=7719, preemption_count=0, score=7372.01, test/loss=0.12783, test/num_examples=95000000, total_duration=45331.1, train/loss=0.122602, validation/loss=0.125503, validation/num_examples=83274637
I0307 01:43:57.009279 139870391473920 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.01983368955552578, loss=0.12478561699390411
I0307 01:44:46.142564 140022987785408 spec.py:321] Evaluating on the training split.
I0307 01:44:53.507419 140022987785408 spec.py:333] Evaluating on the validation split.
I0307 01:48:04.180456 140022987785408 spec.py:349] Evaluating on the test split.
I0307 01:53:45.822986 140022987785408 submission_runner.py:469] Time since start: 45990.77s, 	Step: 7844, 	{'train/loss': 0.12320951815202551, 'validation/loss': 0.1253598089062182, 'validation/num_examples': 83274637, 'test/loss': 0.1275256275185033, 'test/num_examples': 95000000, 'score': 7491.990569114685, 'total_duration': 45990.76977801323, 'accumulated_submission_time': 7491.990569114685, 'accumulated_eval_time': 38496.841492176056, 'accumulated_logging_time': 1.4927349090576172}
I0307 01:53:45.833782 139870399866624 logging_writer.py:48] [7844] accumulated_eval_time=38496.8, accumulated_logging_time=1.49273, accumulated_submission_time=7491.99, global_step=7844, preemption_count=0, score=7491.99, test/loss=0.127526, test/num_examples=95000000, total_duration=45990.8, train/loss=0.12321, validation/loss=0.12536, validation/num_examples=83274637
I0307 01:54:24.236865 139870391473920 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.012461578473448753, loss=0.11990593373775482
I0307 01:55:46.110781 140022987785408 spec.py:321] Evaluating on the training split.
I0307 01:55:53.569510 140022987785408 spec.py:333] Evaluating on the validation split.
I0307 01:59:04.201427 140022987785408 spec.py:349] Evaluating on the test split.
I0307 02:05:06.773344 140022987785408 submission_runner.py:469] Time since start: 46671.72s, 	Step: 7969, 	{'train/loss': 0.1253233829618625, 'validation/loss': 0.12529426131159538, 'validation/num_examples': 83274637, 'test/loss': 0.12746008592722038, 'test/num_examples': 95000000, 'score': 7612.254379749298, 'total_duration': 46671.72014546394, 'accumulated_submission_time': 7612.254379749298, 'accumulated_eval_time': 39057.503997802734, 'accumulated_logging_time': 1.510080099105835}
I0307 02:05:06.783976 139870399866624 logging_writer.py:48] [7969] accumulated_eval_time=39057.5, accumulated_logging_time=1.51008, accumulated_submission_time=7612.25, global_step=7969, preemption_count=0, score=7612.25, test/loss=0.12746, test/num_examples=95000000, total_duration=46671.7, train/loss=0.125323, validation/loss=0.125294, validation/num_examples=83274637
I0307 02:05:14.790913 139870391473920 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.008423236198723316, loss=0.12718363106250763
I0307 02:07:07.490634 139870399866624 logging_writer.py:48] [8095] global_step=8095, preemption_count=0, score=7732.88
I0307 02:07:11.608926 140022987785408 submission_runner.py:646] Tuning trial 4/5
I0307 02:07:11.646678 140022987785408 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.0, learning_rate=0.004958460849689891, one_minus_beta1=0.13625575743, beta2=0.6291854735396584, weight_decay=0.1147386261512052, warmup_factor=0.02)
I0307 02:07:11.647672 140022987785408 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/loss': 0.2509465323725961, 'validation/loss': 0.2516580542432671, 'validation/num_examples': 83274637, 'test/loss': 0.25232802732319076, 'test/num_examples': 95000000, 'score': 16.603291034698486, 'total_duration': 1159.2160654067993, 'accumulated_submission_time': 16.603291034698486, 'accumulated_eval_time': 1142.6126191616058, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (125, {'train/loss': 0.1277972835250808, 'validation/loss': 0.1298201242963595, 'validation/num_examples': 83274637, 'test/loss': 0.13229225739103617, 'test/num_examples': 95000000, 'score': 137.38647437095642, 'total_duration': 2278.6827023029327, 'accumulated_submission_time': 137.38647437095642, 'accumulated_eval_time': 2141.223840713501, 'accumulated_logging_time': 0.06505513191223145, 'global_step': 125, 'preemption_count': 0}), (251, {'train/loss': 0.12997444738991232, 'validation/loss': 0.12898226948618746, 'validation/num_examples': 83274637, 'test/loss': 0.13148883191817434, 'test/num_examples': 95000000, 'score': 258.5711226463318, 'total_duration': 3418.4821331501007, 'accumulated_submission_time': 258.5711226463318, 'accumulated_eval_time': 3159.8150672912598, 'accumulated_logging_time': 0.08140349388122559, 'global_step': 251, 'preemption_count': 0}), (374, {'train/loss': 0.13036083264873838, 'validation/loss': 0.12841289324144134, 'validation/num_examples': 83274637, 'test/loss': 0.13065439366776316, 'test/num_examples': 95000000, 'score': 378.9796357154846, 'total_duration': 4528.309536457062, 'accumulated_submission_time': 378.9796357154846, 'accumulated_eval_time': 4149.188739299774, 'accumulated_logging_time': 0.11925506591796875, 'global_step': 374, 'preemption_count': 0}), (500, {'train/loss': 0.12715936708703357, 'validation/loss': 0.1266983133851915, 'validation/num_examples': 83274637, 'test/loss': 0.1291668531558388, 'test/num_examples': 95000000, 'score': 499.1653962135315, 'total_duration': 5630.630497455597, 'accumulated_submission_time': 499.1653962135315, 'accumulated_eval_time': 5131.300492048264, 'accumulated_logging_time': 0.13508152961730957, 'global_step': 500, 'preemption_count': 0}), (626, {'train/loss': 0.12575888127650856, 'validation/loss': 0.12708499413672392, 'validation/num_examples': 83274637, 'test/loss': 0.12949205010279605, 'test/num_examples': 95000000, 'score': 620.0170094966888, 'total_duration': 6738.929611682892, 'accumulated_submission_time': 620.0170094966888, 'accumulated_eval_time': 6118.725446462631, 'accumulated_logging_time': 0.1498405933380127, 'global_step': 626, 'preemption_count': 0}), (750, {'train/loss': 0.12711582385565875, 'validation/loss': 0.1266634960918908, 'validation/num_examples': 83274637, 'test/loss': 0.12918152583264803, 'test/num_examples': 95000000, 'score': 739.9958882331848, 'total_duration': 7784.89354801178, 'accumulated_submission_time': 739.9958882331848, 'accumulated_eval_time': 7044.687438011169, 'accumulated_logging_time': 0.16451668739318848, 'global_step': 750, 'preemption_count': 0}), (871, {'train/loss': 0.12724061527014155, 'validation/loss': 0.12690473307696803, 'validation/num_examples': 83274637, 'test/loss': 0.12956963517680922, 'test/num_examples': 95000000, 'score': 860.371467590332, 'total_duration': 8766.262031316757, 'accumulated_submission_time': 860.371467590332, 'accumulated_eval_time': 7905.658302783966, 'accumulated_logging_time': 0.1795637607574463, 'global_step': 871, 'preemption_count': 0}), (995, {'train/loss': 0.12558471183028985, 'validation/loss': 0.12690303457788565, 'validation/num_examples': 83274637, 'test/loss': 0.1293273913754112, 'test/num_examples': 95000000, 'score': 981.181099653244, 'total_duration': 9639.765812635422, 'accumulated_submission_time': 981.181099653244, 'accumulated_eval_time': 8658.330698251724, 'accumulated_logging_time': 0.19405269622802734, 'global_step': 995, 'preemption_count': 0}), (1120, {'train/loss': 0.12460700770453462, 'validation/loss': 0.1267237349746343, 'validation/num_examples': 83274637, 'test/loss': 0.12918999201274672, 'test/num_examples': 95000000, 'score': 1101.839154958725, 'total_duration': 10368.721593856812, 'accumulated_submission_time': 1101.839154958725, 'accumulated_eval_time': 9266.605711698532, 'accumulated_logging_time': 0.20864152908325195, 'global_step': 1120, 'preemption_count': 0}), (1244, {'train/loss': 0.12523812840475976, 'validation/loss': 0.12731657913000344, 'validation/num_examples': 83274637, 'test/loss': 0.13006149768708883, 'test/num_examples': 95000000, 'score': 1222.7235498428345, 'total_duration': 11039.687205791473, 'accumulated_submission_time': 1222.7235498428345, 'accumulated_eval_time': 9816.652180671692, 'accumulated_logging_time': 0.23595476150512695, 'global_step': 1244, 'preemption_count': 0}), (1370, {'train/loss': 0.12550758312708177, 'validation/loss': 0.126875931563887, 'validation/num_examples': 83274637, 'test/loss': 0.1291274539165296, 'test/num_examples': 95000000, 'score': 1343.102076292038, 'total_duration': 11705.08368563652, 'accumulated_submission_time': 1343.102076292038, 'accumulated_eval_time': 10361.647680997849, 'accumulated_logging_time': 0.25097012519836426, 'global_step': 1370, 'preemption_count': 0}), (1498, {'train/loss': 0.1259618219363052, 'validation/loss': 0.1264329921588907, 'validation/num_examples': 83274637, 'test/loss': 0.12870160359786184, 'test/num_examples': 95000000, 'score': 1464.5471246242523, 'total_duration': 12375.992455005646, 'accumulated_submission_time': 1464.5471246242523, 'accumulated_eval_time': 10911.08821439743, 'accumulated_logging_time': 0.26755189895629883, 'global_step': 1498, 'preemption_count': 0}), (1625, {'train/loss': 0.1279231200240693, 'validation/loss': 0.12739650198078356, 'validation/num_examples': 83274637, 'test/loss': 0.12978484440789473, 'test/num_examples': 95000000, 'score': 1584.665519475937, 'total_duration': 13053.7188103199, 'accumulated_submission_time': 1584.665519475937, 'accumulated_eval_time': 11468.674791574478, 'accumulated_logging_time': 0.28241705894470215, 'global_step': 1625, 'preemption_count': 0}), (1750, {'train/loss': 0.1253683938404674, 'validation/loss': 0.12599360898726433, 'validation/num_examples': 83274637, 'test/loss': 0.12839599438733554, 'test/num_examples': 95000000, 'score': 1704.8727819919586, 'total_duration': 13721.911089658737, 'accumulated_submission_time': 1704.8727819919586, 'accumulated_eval_time': 12016.638314247131, 'accumulated_logging_time': 0.29730725288391113, 'global_step': 1750, 'preemption_count': 0}), (1877, {'train/loss': 0.12318887717365844, 'validation/loss': 0.12618847893453403, 'validation/num_examples': 83274637, 'test/loss': 0.12849650739103619, 'test/num_examples': 95000000, 'score': 1825.1373069286346, 'total_duration': 14401.965655088425, 'accumulated_submission_time': 1825.1373069286346, 'accumulated_eval_time': 12576.342436790466, 'accumulated_logging_time': 0.376727819442749, 'global_step': 1877, 'preemption_count': 0}), (2002, {'train/loss': 0.1266906499487799, 'validation/loss': 0.1262907139287406, 'validation/num_examples': 83274637, 'test/loss': 0.1284673326377467, 'test/num_examples': 95000000, 'score': 1945.2924230098724, 'total_duration': 15064.482035636902, 'accumulated_submission_time': 1945.2924230098724, 'accumulated_eval_time': 13118.680730342865, 'accumulated_logging_time': 0.39308857917785645, 'global_step': 2002, 'preemption_count': 0}), (2130, {'train/loss': 0.12497292816310933, 'validation/loss': 0.12622930517707104, 'validation/num_examples': 83274637, 'test/loss': 0.12866723861019738, 'test/num_examples': 95000000, 'score': 2065.880598306656, 'total_duration': 15741.162140130997, 'accumulated_submission_time': 2065.880598306656, 'accumulated_eval_time': 13674.75047826767, 'accumulated_logging_time': 0.40823864936828613, 'global_step': 2130, 'preemption_count': 0}), (2255, {'train/loss': 0.12531408114628223, 'validation/loss': 0.12617392125300933, 'validation/num_examples': 83274637, 'test/loss': 0.12861008138363486, 'test/num_examples': 95000000, 'score': 2186.38156414032, 'total_duration': 16419.287349700928, 'accumulated_submission_time': 2186.38156414032, 'accumulated_eval_time': 14232.351284265518, 'accumulated_logging_time': 0.4240541458129883, 'global_step': 2255, 'preemption_count': 0}), (2383, {'train/loss': 0.12518631724301, 'validation/loss': 0.12597907946815412, 'validation/num_examples': 83274637, 'test/loss': 0.12822789676192434, 'test/num_examples': 95000000, 'score': 2306.6645402908325, 'total_duration': 17083.617247104645, 'accumulated_submission_time': 2306.6645402908325, 'accumulated_eval_time': 14776.37408566475, 'accumulated_logging_time': 0.4412398338317871, 'global_step': 2383, 'preemption_count': 0}), (2506, {'train/loss': 0.12583325604129136, 'validation/loss': 0.12691802298662377, 'validation/num_examples': 83274637, 'test/loss': 0.1291637644942434, 'test/num_examples': 95000000, 'score': 2426.8186416625977, 'total_duration': 17754.832736730576, 'accumulated_submission_time': 2426.8186416625977, 'accumulated_eval_time': 15327.414250850677, 'accumulated_logging_time': 0.4562673568725586, 'global_step': 2506, 'preemption_count': 0}), (2635, {'train/loss': 0.1252346053930386, 'validation/loss': 0.12596960522264683, 'validation/num_examples': 83274637, 'test/loss': 0.12807666451480262, 'test/num_examples': 95000000, 'score': 2546.8753385543823, 'total_duration': 18427.42596578598, 'accumulated_submission_time': 2546.8753385543823, 'accumulated_eval_time': 15879.927757263184, 'accumulated_logging_time': 0.4712231159210205, 'global_step': 2635, 'preemption_count': 0}), (2764, {'train/loss': 0.1248437513790603, 'validation/loss': 0.12610392977831295, 'validation/num_examples': 83274637, 'test/loss': 0.1284236583573191, 'test/num_examples': 95000000, 'score': 2667.638345718384, 'total_duration': 19102.830713033676, 'accumulated_submission_time': 2667.638345718384, 'accumulated_eval_time': 16434.523574590683, 'accumulated_logging_time': 0.5097551345825195, 'global_step': 2764, 'preemption_count': 0}), (2891, {'train/loss': 0.12495001063406842, 'validation/loss': 0.12691384405488687, 'validation/num_examples': 83274637, 'test/loss': 0.12919286506990132, 'test/num_examples': 95000000, 'score': 2788.7375621795654, 'total_duration': 19783.654524564743, 'accumulated_submission_time': 2788.7375621795654, 'accumulated_eval_time': 16994.225315332413, 'accumulated_logging_time': 0.5251400470733643, 'global_step': 2891, 'preemption_count': 0}), (3011, {'train/loss': 0.12571690044125672, 'validation/loss': 0.12608301908880581, 'validation/num_examples': 83274637, 'test/loss': 0.12849711043379936, 'test/num_examples': 95000000, 'score': 2909.2646622657776, 'total_duration': 20457.607976198196, 'accumulated_submission_time': 2909.2646622657776, 'accumulated_eval_time': 17547.62901711464, 'accumulated_logging_time': 0.5402824878692627, 'global_step': 3011, 'preemption_count': 0}), (3136, {'train/loss': 0.12555573316021534, 'validation/loss': 0.12582178565192026, 'validation/num_examples': 83274637, 'test/loss': 0.12798885750411185, 'test/num_examples': 95000000, 'score': 3030.2573783397675, 'total_duration': 21133.64375448227, 'accumulated_submission_time': 3030.2573783397675, 'accumulated_eval_time': 18102.64888548851, 'accumulated_logging_time': 0.5568068027496338, 'global_step': 3136, 'preemption_count': 0}), (3265, {'train/loss': 0.12269448827506986, 'validation/loss': 0.12598353943182192, 'validation/num_examples': 83274637, 'test/loss': 0.12830099226973685, 'test/num_examples': 95000000, 'score': 3151.2484159469604, 'total_duration': 21809.966855049133, 'accumulated_submission_time': 3151.2484159469604, 'accumulated_eval_time': 18657.954735517502, 'accumulated_logging_time': 0.5763859748840332, 'global_step': 3265, 'preemption_count': 0}), (3395, {'train/loss': 0.12467443467404857, 'validation/loss': 0.12644476969470309, 'validation/num_examples': 83274637, 'test/loss': 0.12895673567023028, 'test/num_examples': 95000000, 'score': 3271.3753945827484, 'total_duration': 22481.48777627945, 'accumulated_submission_time': 3271.3753945827484, 'accumulated_eval_time': 19209.32284283638, 'accumulated_logging_time': 0.5933666229248047, 'global_step': 3395, 'preemption_count': 0}), (3527, {'train/loss': 0.1281411052921658, 'validation/loss': 0.1270574091777957, 'validation/num_examples': 83274637, 'test/loss': 0.12945708173314144, 'test/num_examples': 95000000, 'score': 3392.5349164009094, 'total_duration': 23149.83373785019, 'accumulated_submission_time': 3392.5349164009094, 'accumulated_eval_time': 19756.486323833466, 'accumulated_logging_time': 0.6090471744537354, 'global_step': 3527, 'preemption_count': 0}), (3655, {'train/loss': 0.12303450776252357, 'validation/loss': 0.1259141807876291, 'validation/num_examples': 83274637, 'test/loss': 0.12801078988486841, 'test/num_examples': 95000000, 'score': 3513.5808939933777, 'total_duration': 23822.307765245438, 'accumulated_submission_time': 3513.5808939933777, 'accumulated_eval_time': 20307.87234044075, 'accumulated_logging_time': 0.6443257331848145, 'global_step': 3655, 'preemption_count': 0}), (3784, {'train/loss': 0.12526198842053143, 'validation/loss': 0.1261484424357578, 'validation/num_examples': 83274637, 'test/loss': 0.12859563779810856, 'test/num_examples': 95000000, 'score': 3634.3075506687164, 'total_duration': 24496.27262377739, 'accumulated_submission_time': 3634.3075506687164, 'accumulated_eval_time': 20861.087744951248, 'accumulated_logging_time': 0.6605300903320312, 'global_step': 3784, 'preemption_count': 0}), (3907, {'train/loss': 0.12330334808138556, 'validation/loss': 0.12618688567950279, 'validation/num_examples': 83274637, 'test/loss': 0.12860007470189144, 'test/num_examples': 95000000, 'score': 3754.808585166931, 'total_duration': 25164.372837781906, 'accumulated_submission_time': 3754.808585166931, 'accumulated_eval_time': 21408.663711071014, 'accumulated_logging_time': 0.6767020225524902, 'global_step': 3907, 'preemption_count': 0}), (4035, {'train/loss': 0.12541248593127952, 'validation/loss': 0.12664954910027482, 'validation/num_examples': 83274637, 'test/loss': 0.1289878077919408, 'test/num_examples': 95000000, 'score': 3874.918527841568, 'total_duration': 25829.321654319763, 'accumulated_submission_time': 3874.918527841568, 'accumulated_eval_time': 21953.44127702713, 'accumulated_logging_time': 0.7310771942138672, 'global_step': 4035, 'preemption_count': 0}), (4159, {'train/loss': 0.124196991078415, 'validation/loss': 0.1260545073090971, 'validation/num_examples': 83274637, 'test/loss': 0.12818708149671051, 'test/num_examples': 95000000, 'score': 3996.2059915065765, 'total_duration': 26497.54452419281, 'accumulated_submission_time': 3996.2059915065765, 'accumulated_eval_time': 22500.35425376892, 'accumulated_logging_time': 0.7463197708129883, 'global_step': 4159, 'preemption_count': 0}), (4286, {'train/loss': 0.12367790301312816, 'validation/loss': 0.12604607353082412, 'validation/num_examples': 83274637, 'test/loss': 0.12836553532072367, 'test/num_examples': 95000000, 'score': 4116.83499288559, 'total_duration': 27174.674921751022, 'accumulated_submission_time': 4116.83499288559, 'accumulated_eval_time': 23056.83335709572, 'accumulated_logging_time': 0.7619421482086182, 'global_step': 4286, 'preemption_count': 0}), (4414, {'train/loss': 0.1229117611926869, 'validation/loss': 0.12586923637685746, 'validation/num_examples': 83274637, 'test/loss': 0.12832687640830592, 'test/num_examples': 95000000, 'score': 4237.9069221019745, 'total_duration': 27857.17037653923, 'accumulated_submission_time': 4237.9069221019745, 'accumulated_eval_time': 23618.22234916687, 'accumulated_logging_time': 0.7881443500518799, 'global_step': 4414, 'preemption_count': 0}), (4537, {'train/loss': 0.12619396235864117, 'validation/loss': 0.12695026993042086, 'validation/num_examples': 83274637, 'test/loss': 0.12915587281044408, 'test/num_examples': 95000000, 'score': 4358.944235086441, 'total_duration': 28520.06114435196, 'accumulated_submission_time': 4358.944235086441, 'accumulated_eval_time': 24160.054053544998, 'accumulated_logging_time': 0.803687334060669, 'global_step': 4537, 'preemption_count': 0}), (4664, {'train/loss': 0.12427905280400747, 'validation/loss': 0.1258684332467148, 'validation/num_examples': 83274637, 'test/loss': 0.12829094929070722, 'test/num_examples': 95000000, 'score': 4479.044402837753, 'total_duration': 29199.967454195023, 'accumulated_submission_time': 4479.044402837753, 'accumulated_eval_time': 24719.835995197296, 'accumulated_logging_time': 0.8195834159851074, 'global_step': 4664, 'preemption_count': 0}), (4792, {'train/loss': 0.12454855688056855, 'validation/loss': 0.1257982293958675, 'validation/num_examples': 83274637, 'test/loss': 0.1279534648334704, 'test/num_examples': 95000000, 'score': 4600.101249694824, 'total_duration': 29873.64969420433, 'accumulated_submission_time': 4600.101249694824, 'accumulated_eval_time': 25272.43809914589, 'accumulated_logging_time': 0.8358571529388428, 'global_step': 4792, 'preemption_count': 0}), (4925, {'train/loss': 0.125202842068466, 'validation/loss': 0.12578071055050427, 'validation/num_examples': 83274637, 'test/loss': 0.12812187866981908, 'test/num_examples': 95000000, 'score': 4720.178936004639, 'total_duration': 30537.2404692173, 'accumulated_submission_time': 4720.178936004639, 'accumulated_eval_time': 25815.881989002228, 'accumulated_logging_time': 0.8983609676361084, 'global_step': 4925, 'preemption_count': 0}), (5053, {'train/loss': 0.12563495872155675, 'validation/loss': 0.1255344917967227, 'validation/num_examples': 83274637, 'test/loss': 0.12780451163651316, 'test/num_examples': 95000000, 'score': 4840.537198781967, 'total_duration': 31212.782967329025, 'accumulated_submission_time': 4840.537198781967, 'accumulated_eval_time': 26371.041830301285, 'accumulated_logging_time': 0.9162437915802002, 'global_step': 5053, 'preemption_count': 0}), (5180, {'train/loss': 0.12325210438209509, 'validation/loss': 0.1256814108034441, 'validation/num_examples': 83274637, 'test/loss': 0.12804753811677633, 'test/num_examples': 95000000, 'score': 4960.59445810318, 'total_duration': 31881.8952088356, 'accumulated_submission_time': 4960.59445810318, 'accumulated_eval_time': 26920.058677196503, 'accumulated_logging_time': 0.9477136135101318, 'global_step': 5180, 'preemption_count': 0}), (5305, {'train/loss': 0.12574201215456868, 'validation/loss': 0.12553748525674674, 'validation/num_examples': 83274637, 'test/loss': 0.1278597552837171, 'test/num_examples': 95000000, 'score': 5081.237327337265, 'total_duration': 32554.01807332039, 'accumulated_submission_time': 5081.237327337265, 'accumulated_eval_time': 27471.473376989365, 'accumulated_logging_time': 1.0065724849700928, 'global_step': 5305, 'preemption_count': 0}), (5433, {'train/loss': 0.12662533226674832, 'validation/loss': 0.12593061418094767, 'validation/num_examples': 83274637, 'test/loss': 0.12834961351768093, 'test/num_examples': 95000000, 'score': 5201.337510108948, 'total_duration': 33223.28698015213, 'accumulated_submission_time': 5201.337510108948, 'accumulated_eval_time': 28020.61771774292, 'accumulated_logging_time': 1.022935152053833, 'global_step': 5433, 'preemption_count': 0}), (5565, {'train/loss': 0.126142426985521, 'validation/loss': 0.12664872446865935, 'validation/num_examples': 83274637, 'test/loss': 0.12910995327919408, 'test/num_examples': 95000000, 'score': 5321.522775411606, 'total_duration': 33889.23147749901, 'accumulated_submission_time': 5321.522775411606, 'accumulated_eval_time': 28566.35228562355, 'accumulated_logging_time': 1.0409409999847412, 'global_step': 5565, 'preemption_count': 0}), (5692, {'train/loss': 0.12399337641051356, 'validation/loss': 0.12559064101372935, 'validation/num_examples': 83274637, 'test/loss': 0.12793836279810855, 'test/num_examples': 95000000, 'score': 5441.582203626633, 'total_duration': 34567.240421533585, 'accumulated_submission_time': 5441.582203626633, 'accumulated_eval_time': 29124.27813243866, 'accumulated_logging_time': 1.0569000244140625, 'global_step': 5692, 'preemption_count': 0}), (5820, {'train/loss': 0.12459776343180323, 'validation/loss': 0.12602980396969862, 'validation/num_examples': 83274637, 'test/loss': 0.12847252081620067, 'test/num_examples': 95000000, 'score': 5562.278552770615, 'total_duration': 35234.95661067963, 'accumulated_submission_time': 5562.278552770615, 'accumulated_eval_time': 29671.263358831406, 'accumulated_logging_time': 1.0844929218292236, 'global_step': 5820, 'preemption_count': 0}), (5949, {'train/loss': 0.12485608998568928, 'validation/loss': 0.1258855489526556, 'validation/num_examples': 83274637, 'test/loss': 0.12822382660361842, 'test/num_examples': 95000000, 'score': 5683.296730995178, 'total_duration': 35909.48312497139, 'accumulated_submission_time': 5683.296730995178, 'accumulated_eval_time': 30224.74841117859, 'accumulated_logging_time': 1.1002686023712158, 'global_step': 5949, 'preemption_count': 0}), (6072, {'train/loss': 0.12469858910490132, 'validation/loss': 0.12554585780243704, 'validation/num_examples': 83274637, 'test/loss': 0.12778621375411184, 'test/num_examples': 95000000, 'score': 5803.539839982986, 'total_duration': 36579.40667915344, 'accumulated_submission_time': 5803.539839982986, 'accumulated_eval_time': 30774.405269145966, 'accumulated_logging_time': 1.1171298027038574, 'global_step': 6072, 'preemption_count': 0}), (6202, {'train/loss': 0.12280461188616618, 'validation/loss': 0.12574165323360814, 'validation/num_examples': 83274637, 'test/loss': 0.1281431732113487, 'test/num_examples': 95000000, 'score': 5924.048048496246, 'total_duration': 37247.96570587158, 'accumulated_submission_time': 5924.048048496246, 'accumulated_eval_time': 31322.43089580536, 'accumulated_logging_time': 1.135511875152588, 'global_step': 6202, 'preemption_count': 0}), (6328, {'train/loss': 0.12612826654792958, 'validation/loss': 0.1254203525622243, 'validation/num_examples': 83274637, 'test/loss': 0.1278418680098684, 'test/num_examples': 95000000, 'score': 6044.545758962631, 'total_duration': 37918.910048007965, 'accumulated_submission_time': 6044.545758962631, 'accumulated_eval_time': 31872.824172496796, 'accumulated_logging_time': 1.1826276779174805, 'global_step': 6328, 'preemption_count': 0}), (6457, {'train/loss': 0.12558597749181138, 'validation/loss': 0.12554849194687498, 'validation/num_examples': 83274637, 'test/loss': 0.12775707196751646, 'test/num_examples': 95000000, 'score': 6165.118328094482, 'total_duration': 38595.20632696152, 'accumulated_submission_time': 6165.118328094482, 'accumulated_eval_time': 32428.523628234863, 'accumulated_logging_time': 1.1998388767242432, 'global_step': 6457, 'preemption_count': 0}), (6589, {'train/loss': 0.12214060917309245, 'validation/loss': 0.1255395900967253, 'validation/num_examples': 83274637, 'test/loss': 0.12793072337582237, 'test/num_examples': 95000000, 'score': 6285.816227912903, 'total_duration': 39280.455682992935, 'accumulated_submission_time': 6285.816227912903, 'accumulated_eval_time': 32993.051721572876, 'accumulated_logging_time': 1.216524362564087, 'global_step': 6589, 'preemption_count': 0}), (6715, {'train/loss': 0.12488706385330209, 'validation/loss': 0.126294317064287, 'validation/num_examples': 83274637, 'test/loss': 0.1288234370888158, 'test/num_examples': 95000000, 'score': 6405.997116327286, 'total_duration': 39954.0420794487, 'accumulated_submission_time': 6405.997116327286, 'accumulated_eval_time': 33546.42807149887, 'accumulated_logging_time': 1.2387185096740723, 'global_step': 6715, 'preemption_count': 0}), (6844, {'train/loss': 0.1232764860673708, 'validation/loss': 0.12601066475645709, 'validation/num_examples': 83274637, 'test/loss': 0.12839166787623355, 'test/num_examples': 95000000, 'score': 6526.6845009326935, 'total_duration': 40616.38400864601, 'accumulated_submission_time': 6526.6845009326935, 'accumulated_eval_time': 34088.058755874634, 'accumulated_logging_time': 1.2557930946350098, 'global_step': 6844, 'preemption_count': 0}), (6967, {'train/loss': 0.1233566506361624, 'validation/loss': 0.12556776816677426, 'validation/num_examples': 83274637, 'test/loss': 0.12782639921875, 'test/num_examples': 95000000, 'score': 6647.536203622818, 'total_duration': 41281.626939058304, 'accumulated_submission_time': 6647.536203622818, 'accumulated_eval_time': 34632.42500042915, 'accumulated_logging_time': 1.272350549697876, 'global_step': 6967, 'preemption_count': 0}), (7092, {'train/loss': 0.1268444780799203, 'validation/loss': 0.12567669764190365, 'validation/num_examples': 83274637, 'test/loss': 0.12783058797286184, 'test/num_examples': 95000000, 'score': 6768.290092468262, 'total_duration': 41956.56082201004, 'accumulated_submission_time': 6768.290092468262, 'accumulated_eval_time': 35186.58060860634, 'accumulated_logging_time': 1.2891650199890137, 'global_step': 7092, 'preemption_count': 0}), (7215, {'train/loss': 0.12436518668191238, 'validation/loss': 0.12543766079635163, 'validation/num_examples': 83274637, 'test/loss': 0.1276590529194079, 'test/num_examples': 95000000, 'score': 6888.370259046555, 'total_duration': 42618.241144657135, 'accumulated_submission_time': 6888.370259046555, 'accumulated_eval_time': 35728.100570201874, 'accumulated_logging_time': 1.3625969886779785, 'global_step': 7215, 'preemption_count': 0}), (7339, {'train/loss': 0.12231560141644762, 'validation/loss': 0.12562505944210278, 'validation/num_examples': 83274637, 'test/loss': 0.12792445806949013, 'test/num_examples': 95000000, 'score': 7008.939987659454, 'total_duration': 43301.72239255905, 'accumulated_submission_time': 7008.939987659454, 'accumulated_eval_time': 36290.98770880699, 'accumulated_logging_time': 1.3793237209320068, 'global_step': 7339, 'preemption_count': 0}), (7467, {'train/loss': 0.12364895959273449, 'validation/loss': 0.12551741600366043, 'validation/num_examples': 83274637, 'test/loss': 0.1278510863178454, 'test/num_examples': 95000000, 'score': 7129.605026483536, 'total_duration': 43980.267384529114, 'accumulated_submission_time': 7129.605026483536, 'accumulated_eval_time': 36848.81667971611, 'accumulated_logging_time': 1.422806978225708, 'global_step': 7467, 'preemption_count': 0}), (7593, {'train/loss': 0.1231487039008043, 'validation/loss': 0.12543822203932273, 'validation/num_examples': 83274637, 'test/loss': 0.12767926079358552, 'test/num_examples': 95000000, 'score': 7251.062160730362, 'total_duration': 44652.116861343384, 'accumulated_submission_time': 7251.062160730362, 'accumulated_eval_time': 37399.165251255035, 'accumulated_logging_time': 1.4581055641174316, 'global_step': 7593, 'preemption_count': 0}), (7719, {'train/loss': 0.12260216182835822, 'validation/loss': 0.12550342548138335, 'validation/num_examples': 83274637, 'test/loss': 0.12783025872738488, 'test/num_examples': 95000000, 'score': 7372.008162498474, 'total_duration': 45331.0835108757, 'accumulated_submission_time': 7372.008162498474, 'accumulated_eval_time': 37957.16113948822, 'accumulated_logging_time': 1.475797176361084, 'global_step': 7719, 'preemption_count': 0}), (7844, {'train/loss': 0.12320951815202551, 'validation/loss': 0.1253598089062182, 'validation/num_examples': 83274637, 'test/loss': 0.1275256275185033, 'test/num_examples': 95000000, 'score': 7491.990569114685, 'total_duration': 45990.76977801323, 'accumulated_submission_time': 7491.990569114685, 'accumulated_eval_time': 38496.841492176056, 'accumulated_logging_time': 1.4927349090576172, 'global_step': 7844, 'preemption_count': 0}), (7969, {'train/loss': 0.1253233829618625, 'validation/loss': 0.12529426131159538, 'validation/num_examples': 83274637, 'test/loss': 0.12746008592722038, 'test/num_examples': 95000000, 'score': 7612.254379749298, 'total_duration': 46671.72014546394, 'accumulated_submission_time': 7612.254379749298, 'accumulated_eval_time': 39057.503997802734, 'accumulated_logging_time': 1.510080099105835, 'global_step': 7969, 'preemption_count': 0})], 'global_step': 8095}
I0307 02:07:11.647805 140022987785408 submission_runner.py:649] Timing: 7732.87632727623
I0307 02:07:11.647841 140022987785408 submission_runner.py:651] Total number of evals: 64
I0307 02:07:11.647870 140022987785408 submission_runner.py:652] ====================
I0307 02:07:11.648018 140022987785408 submission_runner.py:750] Final criteo1tb score: 3
