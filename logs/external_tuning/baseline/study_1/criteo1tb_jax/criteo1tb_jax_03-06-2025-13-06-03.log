python submission_runner.py --framework=jax --workload=criteo1tb --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_1 --overwrite=True --save_checkpoints=False --rng_seed=1183306385 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=4 --hparam_end_index=5 2>&1 | tee -a /logs/criteo1tb_jax_03-06-2025-13-06-03.log
2025-03-06 13:06:20.455528: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741266380.899521       9 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741266381.051372       9 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0306 13:07:10.408895 139865041368256 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax.
I0306 13:07:13.716660 139865041368256 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0306 13:07:13.719752 139865041368256 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0306 13:07:13.732074 139865041368256 submission_runner.py:606] Using RNG seed 1183306385
I0306 13:07:16.809979 139865041368256 submission_runner.py:615] --- Tuning run 5/5 ---
I0306 13:07:16.810161 139865041368256 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_5.
I0306 13:07:16.810355 139865041368256 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_5/hparams.json.
I0306 13:07:17.053763 139865041368256 submission_runner.py:218] Initializing dataset.
I0306 13:07:17.053944 139865041368256 submission_runner.py:229] Initializing model.
I0306 13:07:27.222891 139865041368256 submission_runner.py:272] Initializing optimizer.
I0306 13:07:27.939323 139865041368256 submission_runner.py:279] Initializing metrics bundle.
I0306 13:07:27.939556 139865041368256 submission_runner.py:301] Initializing checkpoint and logger.
I0306 13:07:27.940415 139865041368256 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_5 with prefix checkpoint_
I0306 13:07:27.940531 139865041368256 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_5/meta_data_0.json.
I0306 13:07:27.940706 139865041368256 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0306 13:07:27.940759 139865041368256 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0306 13:07:28.645458 139865041368256 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/criteo1tb_jax/trial_5/flags_0.json.
I0306 13:07:29.183993 139865041368256 submission_runner.py:337] Starting training loop.
I0306 13:07:46.125070 139722433230592 logging_writer.py:48] [0] global_step=0, grad_norm=8.587844848632812, loss=1.966333031654358
I0306 13:07:46.545675 139865041368256 spec.py:321] Evaluating on the training split.
I0306 13:14:06.927379 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 13:20:24.568569 139865041368256 spec.py:349] Evaluating on the test split.
I0306 13:27:13.561038 139865041368256 submission_runner.py:469] Time since start: 1184.38s, 	Step: 1, 	{'train/loss': 1.972592979857007, 'validation/loss': 1.972452149975298, 'validation/num_examples': 83274637, 'test/loss': 1.970119709868421, 'test/num_examples': 95000000, 'score': 17.36156940460205, 'total_duration': 1184.376938343048, 'accumulated_submission_time': 17.36156940460205, 'accumulated_eval_time': 1167.0152463912964, 'accumulated_logging_time': 0}
I0306 13:27:13.595049 139711578363648 logging_writer.py:48] [1] accumulated_eval_time=1167.02, accumulated_logging_time=0, accumulated_submission_time=17.3616, global_step=1, preemption_count=0, score=17.3616, test/loss=1.97012, test/num_examples=95000000, total_duration=1184.38, train/loss=1.97259, validation/loss=1.97245, validation/num_examples=83274637
I0306 13:28:42.057980 139711569970944 logging_writer.py:48] [100] global_step=100, grad_norm=0.10158108919858932, loss=0.13799694180488586
I0306 13:29:14.187874 139865041368256 spec.py:321] Evaluating on the training split.
I0306 13:35:17.819176 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 13:40:41.138977 139865041368256 spec.py:349] Evaluating on the test split.
I0306 13:46:17.215528 139865041368256 submission_runner.py:469] Time since start: 2328.03s, 	Step: 125, 	{'train/loss': 0.13147800447384142, 'validation/loss': 0.13101069102566307, 'validation/num_examples': 83274637, 'test/loss': 0.13394166224300988, 'test/num_examples': 95000000, 'score': 137.88437604904175, 'total_duration': 2328.031477689743, 'accumulated_submission_time': 137.88437604904175, 'accumulated_eval_time': 2190.042842388153, 'accumulated_logging_time': 0.0967247486114502}
I0306 13:46:17.225066 139711578363648 logging_writer.py:48] [125] accumulated_eval_time=2190.04, accumulated_logging_time=0.0967247, accumulated_submission_time=137.884, global_step=125, preemption_count=0, score=137.884, test/loss=0.133942, test/num_examples=95000000, total_duration=2328.03, train/loss=0.131478, validation/loss=0.131011, validation/num_examples=83274637
I0306 13:47:19.217652 139711569970944 logging_writer.py:48] [200] global_step=200, grad_norm=0.21891213953495026, loss=0.14629684388637543
I0306 13:48:17.476300 139865041368256 spec.py:321] Evaluating on the training split.
I0306 13:54:13.741481 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 13:59:40.779832 139865041368256 spec.py:349] Evaluating on the test split.
I0306 14:05:15.822067 139865041368256 submission_runner.py:469] Time since start: 3466.64s, 	Step: 250, 	{'train/loss': 0.1291446589730071, 'validation/loss': 0.12996908323405915, 'validation/num_examples': 83274637, 'test/loss': 0.13300554146792762, 'test/num_examples': 95000000, 'score': 258.1208851337433, 'total_duration': 3466.6380219459534, 'accumulated_submission_time': 258.1208851337433, 'accumulated_eval_time': 3208.388557434082, 'accumulated_logging_time': 0.1134030818939209}
I0306 14:05:15.872678 139711578363648 logging_writer.py:48] [250] accumulated_eval_time=3208.39, accumulated_logging_time=0.113403, accumulated_submission_time=258.121, global_step=250, preemption_count=0, score=258.121, test/loss=0.133006, test/num_examples=95000000, total_duration=3466.64, train/loss=0.129145, validation/loss=0.129969, validation/num_examples=83274637
I0306 14:05:46.618689 139711569970944 logging_writer.py:48] [300] global_step=300, grad_norm=0.017898377031087875, loss=0.12677161395549774
I0306 14:07:16.257910 139865041368256 spec.py:321] Evaluating on the training split.
I0306 14:13:26.166394 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 14:18:42.479624 139865041368256 spec.py:349] Evaluating on the test split.
I0306 14:24:47.622268 139865041368256 submission_runner.py:469] Time since start: 4638.44s, 	Step: 369, 	{'train/loss': 0.12793116676826147, 'validation/loss': 0.12748181834145222, 'validation/num_examples': 83274637, 'test/loss': 0.12988641227384867, 'test/num_examples': 95000000, 'score': 378.49212741851807, 'total_duration': 4638.4382202625275, 'accumulated_submission_time': 378.49212741851807, 'accumulated_eval_time': 4259.752856492996, 'accumulated_logging_time': 0.17062592506408691}
I0306 14:24:47.629909 139711578363648 logging_writer.py:48] [369] accumulated_eval_time=4259.75, accumulated_logging_time=0.170626, accumulated_submission_time=378.492, global_step=369, preemption_count=0, score=378.492, test/loss=0.129886, test/num_examples=95000000, total_duration=4638.44, train/loss=0.127931, validation/loss=0.127482, validation/num_examples=83274637
I0306 14:24:55.420679 139711569970944 logging_writer.py:48] [400] global_step=400, grad_norm=0.02762165665626526, loss=0.12512877583503723
I0306 14:26:48.738253 139865041368256 spec.py:321] Evaluating on the training split.
I0306 14:32:40.305034 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 14:38:02.528321 139865041368256 spec.py:349] Evaluating on the test split.
I0306 14:43:31.235488 139865041368256 submission_runner.py:469] Time since start: 5762.05s, 	Step: 496, 	{'train/loss': 0.12582093169151237, 'validation/loss': 0.1272729076920297, 'validation/num_examples': 83274637, 'test/loss': 0.12986079280427631, 'test/num_examples': 95000000, 'score': 499.56796288490295, 'total_duration': 5762.051439285278, 'accumulated_submission_time': 499.56796288490295, 'accumulated_eval_time': 5262.250036716461, 'accumulated_logging_time': 0.20361781120300293}
I0306 14:43:31.243391 139711578363648 logging_writer.py:48] [496] accumulated_eval_time=5262.25, accumulated_logging_time=0.203618, accumulated_submission_time=499.568, global_step=496, preemption_count=0, score=499.568, test/loss=0.129861, test/num_examples=95000000, total_duration=5762.05, train/loss=0.125821, validation/loss=0.127273, validation/num_examples=83274637
I0306 14:43:31.789687 139711569970944 logging_writer.py:48] [500] global_step=500, grad_norm=0.17984680831432343, loss=0.13953609764575958
I0306 14:45:07.462956 139711578363648 logging_writer.py:48] [600] global_step=600, grad_norm=0.10893306881189346, loss=0.12877416610717773
I0306 14:45:31.530801 139865041368256 spec.py:321] Evaluating on the training split.
I0306 14:51:17.005298 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 14:56:10.557545 139865041368256 spec.py:349] Evaluating on the test split.
I0306 15:01:44.707269 139865041368256 submission_runner.py:469] Time since start: 6855.52s, 	Step: 620, 	{'train/loss': 0.1254835638610072, 'validation/loss': 0.12684869159013867, 'validation/num_examples': 83274637, 'test/loss': 0.12935885636307565, 'test/num_examples': 95000000, 'score': 619.8424777984619, 'total_duration': 6855.52321767807, 'accumulated_submission_time': 619.8424777984619, 'accumulated_eval_time': 6235.426440000534, 'accumulated_logging_time': 0.21775031089782715}
I0306 15:01:44.715300 139711569970944 logging_writer.py:48] [620] accumulated_eval_time=6235.43, accumulated_logging_time=0.21775, accumulated_submission_time=619.842, global_step=620, preemption_count=0, score=619.842, test/loss=0.129359, test/num_examples=95000000, total_duration=6855.52, train/loss=0.125484, validation/loss=0.126849, validation/num_examples=83274637
I0306 15:02:46.799091 139711578363648 logging_writer.py:48] [700] global_step=700, grad_norm=0.04481234773993492, loss=0.1293426752090454
I0306 15:03:45.653495 139865041368256 spec.py:321] Evaluating on the training split.
I0306 15:08:58.484787 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 15:13:51.114637 139865041368256 spec.py:349] Evaluating on the test split.
I0306 15:19:36.639161 139865041368256 submission_runner.py:469] Time since start: 7927.46s, 	Step: 752, 	{'train/loss': 0.12539261540854876, 'validation/loss': 0.12695798438562805, 'validation/num_examples': 83274637, 'test/loss': 0.1293796773745888, 'test/num_examples': 95000000, 'score': 740.7667157649994, 'total_duration': 7927.455089092255, 'accumulated_submission_time': 740.7667157649994, 'accumulated_eval_time': 7186.4120190143585, 'accumulated_logging_time': 0.23239994049072266}
I0306 15:19:36.647381 139711569970944 logging_writer.py:48] [752] accumulated_eval_time=7186.41, accumulated_logging_time=0.2324, accumulated_submission_time=740.767, global_step=752, preemption_count=0, score=740.767, test/loss=0.12938, test/num_examples=95000000, total_duration=7927.46, train/loss=0.125393, validation/loss=0.126958, validation/num_examples=83274637
I0306 15:20:04.877584 139711578363648 logging_writer.py:48] [800] global_step=800, grad_norm=0.03267993405461311, loss=0.12215965986251831
I0306 15:21:36.789318 139865041368256 spec.py:321] Evaluating on the training split.
I0306 15:26:18.326807 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 15:30:20.069041 139865041368256 spec.py:349] Evaluating on the test split.
I0306 15:36:04.575992 139865041368256 submission_runner.py:469] Time since start: 8915.39s, 	Step: 875, 	{'train/loss': 0.12566207868263782, 'validation/loss': 0.12653363627278555, 'validation/num_examples': 83274637, 'test/loss': 0.12899452788856908, 'test/num_examples': 95000000, 'score': 860.8952717781067, 'total_duration': 8915.391944885254, 'accumulated_submission_time': 860.8952717781067, 'accumulated_eval_time': 8054.1986429691315, 'accumulated_logging_time': 0.24739480018615723}
I0306 15:36:04.583750 139711569970944 logging_writer.py:48] [875] accumulated_eval_time=8054.2, accumulated_logging_time=0.247395, accumulated_submission_time=860.895, global_step=875, preemption_count=0, score=860.895, test/loss=0.128995, test/num_examples=95000000, total_duration=8915.39, train/loss=0.125662, validation/loss=0.126534, validation/num_examples=83274637
I0306 15:36:07.340326 139711578363648 logging_writer.py:48] [900] global_step=900, grad_norm=0.11331935971975327, loss=0.13046900928020477
I0306 15:38:02.857395 139711569970944 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.025376325473189354, loss=0.12396705150604248
I0306 15:38:04.827001 139865041368256 spec.py:321] Evaluating on the training split.
I0306 15:41:32.112815 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 15:45:46.216732 139865041368256 spec.py:349] Evaluating on the test split.
I0306 15:51:29.310090 139865041368256 submission_runner.py:469] Time since start: 9840.13s, 	Step: 1003, 	{'train/loss': 0.12528002878311295, 'validation/loss': 0.12600059765195976, 'validation/num_examples': 83274637, 'test/loss': 0.12844500265213815, 'test/num_examples': 95000000, 'score': 981.1251287460327, 'total_duration': 9840.12604522705, 'accumulated_submission_time': 981.1251287460327, 'accumulated_eval_time': 8858.681668043137, 'accumulated_logging_time': 0.26180100440979004}
I0306 15:51:29.318407 139711578363648 logging_writer.py:48] [1003] accumulated_eval_time=8858.68, accumulated_logging_time=0.261801, accumulated_submission_time=981.125, global_step=1003, preemption_count=0, score=981.125, test/loss=0.128445, test/num_examples=95000000, total_duration=9840.13, train/loss=0.12528, validation/loss=0.126001, validation/num_examples=83274637
I0306 15:52:53.166493 139711569970944 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.02361856959760189, loss=0.1198674887418747
I0306 15:53:29.718389 139865041368256 spec.py:321] Evaluating on the training split.
I0306 15:54:27.392829 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 15:58:38.610966 139865041368256 spec.py:349] Evaluating on the test split.
I0306 16:04:31.055543 139865041368256 submission_runner.py:469] Time since start: 10621.87s, 	Step: 1131, 	{'train/loss': 0.12499579486185275, 'validation/loss': 0.1284958704095638, 'validation/num_examples': 83274637, 'test/loss': 0.13098726649876644, 'test/num_examples': 95000000, 'score': 1101.5122396945953, 'total_duration': 10621.871497869492, 'accumulated_submission_time': 1101.5122396945953, 'accumulated_eval_time': 9520.018758296967, 'accumulated_logging_time': 0.27634716033935547}
I0306 16:04:31.063587 139711578363648 logging_writer.py:48] [1131] accumulated_eval_time=9520.02, accumulated_logging_time=0.276347, accumulated_submission_time=1101.51, global_step=1131, preemption_count=0, score=1101.51, test/loss=0.130987, test/num_examples=95000000, total_duration=10621.9, train/loss=0.124996, validation/loss=0.128496, validation/num_examples=83274637
I0306 16:05:25.744291 139711569970944 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.02475179359316826, loss=0.12285739183425903
I0306 16:06:31.455073 139865041368256 spec.py:321] Evaluating on the training split.
I0306 16:07:25.043815 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 16:11:40.868578 139865041368256 spec.py:349] Evaluating on the test split.
I0306 16:17:26.280988 139865041368256 submission_runner.py:469] Time since start: 11397.10s, 	Step: 1254, 	{'train/loss': 0.12857875537197544, 'validation/loss': 0.12623873398041463, 'validation/num_examples': 83274637, 'test/loss': 0.12864349541529604, 'test/num_examples': 95000000, 'score': 1221.8905608654022, 'total_duration': 11397.09691977501, 'accumulated_submission_time': 1221.8905608654022, 'accumulated_eval_time': 10174.844587802887, 'accumulated_logging_time': 0.29068994522094727}
I0306 16:17:26.290253 139711578363648 logging_writer.py:48] [1254] accumulated_eval_time=10174.8, accumulated_logging_time=0.29069, accumulated_submission_time=1221.89, global_step=1254, preemption_count=0, score=1221.89, test/loss=0.128643, test/num_examples=95000000, total_duration=11397.1, train/loss=0.128579, validation/loss=0.126239, validation/num_examples=83274637
I0306 16:17:53.528460 139711569970944 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.01136902254074812, loss=0.12509971857070923
I0306 16:19:26.453144 139865041368256 spec.py:321] Evaluating on the training split.
I0306 16:20:23.022032 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 16:24:38.254616 139865041368256 spec.py:349] Evaluating on the test split.
I0306 16:30:16.746088 139865041368256 submission_runner.py:469] Time since start: 12167.56s, 	Step: 1380, 	{'train/loss': 0.1238754253787627, 'validation/loss': 0.12624880045751694, 'validation/num_examples': 83274637, 'test/loss': 0.1287062955078125, 'test/num_examples': 95000000, 'score': 1342.039057970047, 'total_duration': 12167.562039136887, 'accumulated_submission_time': 1342.039057970047, 'accumulated_eval_time': 10825.137471914291, 'accumulated_logging_time': 0.30689072608947754}
I0306 16:30:16.754770 139711578363648 logging_writer.py:48] [1380] accumulated_eval_time=10825.1, accumulated_logging_time=0.306891, accumulated_submission_time=1342.04, global_step=1380, preemption_count=0, score=1342.04, test/loss=0.128706, test/num_examples=95000000, total_duration=12167.6, train/loss=0.123875, validation/loss=0.126249, validation/num_examples=83274637
I0306 16:30:18.977147 139711569970944 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.017236411571502686, loss=0.12416277825832367
I0306 16:32:05.255298 139711578363648 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.012879625894129276, loss=0.12959419190883636
I0306 16:32:17.845220 139865041368256 spec.py:321] Evaluating on the training split.
I0306 16:33:15.198873 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 16:37:26.314037 139865041368256 spec.py:349] Evaluating on the test split.
I0306 16:42:55.430724 139865041368256 submission_runner.py:469] Time since start: 12926.25s, 	Step: 1512, 	{'train/loss': 0.12277510780958259, 'validation/loss': 0.12545797770043493, 'validation/num_examples': 83274637, 'test/loss': 0.12762149575452303, 'test/num_examples': 95000000, 'score': 1463.1147665977478, 'total_duration': 12926.246686458588, 'accumulated_submission_time': 1463.1147665977478, 'accumulated_eval_time': 11462.722916841507, 'accumulated_logging_time': 0.3232078552246094}
I0306 16:42:55.439014 139711569970944 logging_writer.py:48] [1512] accumulated_eval_time=11462.7, accumulated_logging_time=0.323208, accumulated_submission_time=1463.11, global_step=1512, preemption_count=0, score=1463.11, test/loss=0.127621, test/num_examples=95000000, total_duration=12926.2, train/loss=0.122775, validation/loss=0.125458, validation/num_examples=83274637
I0306 16:44:12.162865 139711578363648 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.03730519115924835, loss=0.1270580142736435
I0306 16:44:55.959477 139865041368256 spec.py:321] Evaluating on the training split.
I0306 16:45:51.631899 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 16:50:05.922175 139865041368256 spec.py:349] Evaluating on the test split.
I0306 16:55:38.830218 139865041368256 submission_runner.py:469] Time since start: 13689.65s, 	Step: 1637, 	{'train/loss': 0.12469331334409474, 'validation/loss': 0.1260232490343312, 'validation/num_examples': 83274637, 'test/loss': 0.12835216860608553, 'test/num_examples': 95000000, 'score': 1583.622383594513, 'total_duration': 13689.646173715591, 'accumulated_submission_time': 1583.622383594513, 'accumulated_eval_time': 12105.593589782715, 'accumulated_logging_time': 0.3377704620361328}
I0306 16:55:38.838791 139711569970944 logging_writer.py:48] [1637] accumulated_eval_time=12105.6, accumulated_logging_time=0.33777, accumulated_submission_time=1583.62, global_step=1637, preemption_count=0, score=1583.62, test/loss=0.128352, test/num_examples=95000000, total_duration=13689.6, train/loss=0.124693, validation/loss=0.126023, validation/num_examples=83274637
I0306 16:56:26.028145 139711578363648 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.02735469676554203, loss=0.12042230367660522
I0306 16:57:38.885010 139865041368256 spec.py:321] Evaluating on the training split.
I0306 16:58:35.810676 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 17:02:45.472661 139865041368256 spec.py:349] Evaluating on the test split.
I0306 17:07:59.729566 139865041368256 submission_runner.py:469] Time since start: 14430.55s, 	Step: 1765, 	{'train/loss': 0.12326435942741686, 'validation/loss': 0.1254087468446988, 'validation/num_examples': 83274637, 'test/loss': 0.12782752257401317, 'test/num_examples': 95000000, 'score': 1703.6552188396454, 'total_duration': 14430.545518875122, 'accumulated_submission_time': 1703.6552188396454, 'accumulated_eval_time': 12726.43807888031, 'accumulated_logging_time': 0.3528621196746826}
I0306 17:07:59.737851 139711569970944 logging_writer.py:48] [1765] accumulated_eval_time=12726.4, accumulated_logging_time=0.352862, accumulated_submission_time=1703.66, global_step=1765, preemption_count=0, score=1703.66, test/loss=0.127828, test/num_examples=95000000, total_duration=14430.5, train/loss=0.123264, validation/loss=0.125409, validation/num_examples=83274637
I0306 17:08:12.499351 139711578363648 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.006214131601154804, loss=0.11935754865407944
I0306 17:10:00.967615 139865041368256 spec.py:321] Evaluating on the training split.
I0306 17:11:00.312440 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 17:15:09.845892 139865041368256 spec.py:349] Evaluating on the test split.
I0306 17:20:46.567092 139865041368256 submission_runner.py:469] Time since start: 15197.38s, 	Step: 1891, 	{'train/loss': 0.12580196183385714, 'validation/loss': 0.12626821417074482, 'validation/num_examples': 83274637, 'test/loss': 0.12890123374794407, 'test/num_examples': 95000000, 'score': 1824.8706848621368, 'total_duration': 15197.383055448532, 'accumulated_submission_time': 1824.8706848621368, 'accumulated_eval_time': 13372.037509679794, 'accumulated_logging_time': 0.3685150146484375}
I0306 17:20:46.575550 139711569970944 logging_writer.py:48] [1891] accumulated_eval_time=13372, accumulated_logging_time=0.368515, accumulated_submission_time=1824.87, global_step=1891, preemption_count=0, score=1824.87, test/loss=0.128901, test/num_examples=95000000, total_duration=15197.4, train/loss=0.125802, validation/loss=0.126268, validation/num_examples=83274637
I0306 17:20:47.639971 139711578363648 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.05453277379274368, loss=0.13632294535636902
I0306 17:22:25.602172 139711569970944 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.08520729839801788, loss=0.13089069724082947
I0306 17:22:47.218110 139865041368256 spec.py:321] Evaluating on the training split.
I0306 17:23:47.038597 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 17:28:05.099928 139865041368256 spec.py:349] Evaluating on the test split.
I0306 17:33:37.808486 139865041368256 submission_runner.py:469] Time since start: 15968.62s, 	Step: 2017, 	{'train/loss': 0.12362202993775688, 'validation/loss': 0.12528329007221836, 'validation/num_examples': 83274637, 'test/loss': 0.12763272173108553, 'test/num_examples': 95000000, 'score': 1945.5002789497375, 'total_duration': 15968.62443971634, 'accumulated_submission_time': 1945.5002789497375, 'accumulated_eval_time': 14022.627816200256, 'accumulated_logging_time': 0.383411169052124}
I0306 17:33:37.817185 139711578363648 logging_writer.py:48] [2017] accumulated_eval_time=14022.6, accumulated_logging_time=0.383411, accumulated_submission_time=1945.5, global_step=2017, preemption_count=0, score=1945.5, test/loss=0.127633, test/num_examples=95000000, total_duration=15968.6, train/loss=0.123622, validation/loss=0.125283, validation/num_examples=83274637
I0306 17:34:46.297098 139711569970944 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.07855815440416336, loss=0.12402316927909851
I0306 17:35:37.817741 139865041368256 spec.py:321] Evaluating on the training split.
I0306 17:36:32.884514 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 17:40:51.311269 139865041368256 spec.py:349] Evaluating on the test split.
I0306 17:46:11.300590 139865041368256 submission_runner.py:469] Time since start: 16722.12s, 	Step: 2146, 	{'train/loss': 0.1245359933624665, 'validation/loss': 0.1254195780049415, 'validation/num_examples': 83274637, 'test/loss': 0.12775079209498355, 'test/num_examples': 95000000, 'score': 2065.4876477718353, 'total_duration': 16722.116555452347, 'accumulated_submission_time': 2065.4876477718353, 'accumulated_eval_time': 14656.110614538193, 'accumulated_logging_time': 0.39873552322387695}
I0306 17:46:11.309021 139711578363648 logging_writer.py:48] [2146] accumulated_eval_time=14656.1, accumulated_logging_time=0.398736, accumulated_submission_time=2065.49, global_step=2146, preemption_count=0, score=2065.49, test/loss=0.127751, test/num_examples=95000000, total_duration=16722.1, train/loss=0.124536, validation/loss=0.12542, validation/num_examples=83274637
I0306 17:46:48.340277 139711569970944 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.006949978414922953, loss=0.1285548061132431
I0306 17:48:11.786101 139865041368256 spec.py:321] Evaluating on the training split.
I0306 17:49:06.478449 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 17:53:21.161878 139865041368256 spec.py:349] Evaluating on the test split.
I0306 17:59:02.332263 139865041368256 submission_runner.py:469] Time since start: 17493.15s, 	Step: 2271, 	{'train/loss': 0.12228986576386967, 'validation/loss': 0.12521852239412193, 'validation/num_examples': 83274637, 'test/loss': 0.12756393913445724, 'test/num_examples': 95000000, 'score': 2185.9515056610107, 'total_duration': 17493.14819931984, 'accumulated_submission_time': 2185.9515056610107, 'accumulated_eval_time': 15306.65669298172, 'accumulated_logging_time': 0.4140334129333496}
I0306 17:59:02.340790 139711578363648 logging_writer.py:48] [2271] accumulated_eval_time=15306.7, accumulated_logging_time=0.414033, accumulated_submission_time=2185.95, global_step=2271, preemption_count=0, score=2185.95, test/loss=0.127564, test/num_examples=95000000, total_duration=17493.1, train/loss=0.12229, validation/loss=0.125219, validation/num_examples=83274637
I0306 17:59:08.075608 139711569970944 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.03774028643965721, loss=0.12821859121322632
I0306 18:01:02.822314 139865041368256 spec.py:321] Evaluating on the training split.
I0306 18:01:59.818527 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 18:06:19.132259 139865041368256 spec.py:349] Evaluating on the test split.
I0306 18:12:07.832061 139865041368256 submission_runner.py:469] Time since start: 18278.65s, 	Step: 2394, 	{'train/loss': 0.12281155900197958, 'validation/loss': 0.12506288323554363, 'validation/num_examples': 83274637, 'test/loss': 0.12733497425986842, 'test/num_examples': 95000000, 'score': 2306.419098377228, 'total_duration': 18278.647995233536, 'accumulated_submission_time': 2306.419098377228, 'accumulated_eval_time': 15971.666358709335, 'accumulated_logging_time': 0.42966437339782715}
I0306 18:12:07.840878 139711578363648 logging_writer.py:48] [2394] accumulated_eval_time=15971.7, accumulated_logging_time=0.429664, accumulated_submission_time=2306.42, global_step=2394, preemption_count=0, score=2306.42, test/loss=0.127335, test/num_examples=95000000, total_duration=18278.6, train/loss=0.122812, validation/loss=0.125063, validation/num_examples=83274637
I0306 18:12:08.589820 139711569970944 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.022807443514466286, loss=0.13377904891967773
I0306 18:13:47.184206 139711578363648 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.04038922116160393, loss=0.12008681893348694
I0306 18:14:08.764374 139865041368256 spec.py:321] Evaluating on the training split.
I0306 18:15:05.271558 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 18:19:26.327015 139865041368256 spec.py:349] Evaluating on the test split.
I0306 18:25:05.322786 139865041368256 submission_runner.py:469] Time since start: 19056.14s, 	Step: 2517, 	{'train/loss': 0.1250451883570578, 'validation/loss': 0.1253004631173745, 'validation/num_examples': 83274637, 'test/loss': 0.12760791852384867, 'test/num_examples': 95000000, 'score': 2427.3290662765503, 'total_duration': 19056.138740062714, 'accumulated_submission_time': 2427.3290662765503, 'accumulated_eval_time': 16628.22469997406, 'accumulated_logging_time': 0.44553327560424805}
I0306 18:25:05.332710 139711569970944 logging_writer.py:48] [2517] accumulated_eval_time=16628.2, accumulated_logging_time=0.445533, accumulated_submission_time=2427.33, global_step=2517, preemption_count=0, score=2427.33, test/loss=0.127608, test/num_examples=95000000, total_duration=19056.1, train/loss=0.125045, validation/loss=0.1253, validation/num_examples=83274637
I0306 18:26:19.286098 139711578363648 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.008089025504887104, loss=0.11827293783426285
I0306 18:27:05.753189 139865041368256 spec.py:321] Evaluating on the training split.
I0306 18:28:07.133690 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 18:32:23.457087 139865041368256 spec.py:349] Evaluating on the test split.
I0306 18:37:59.210378 139865041368256 submission_runner.py:469] Time since start: 19830.03s, 	Step: 2642, 	{'train/loss': 0.12467686514481434, 'validation/loss': 0.12483446520926443, 'validation/num_examples': 83274637, 'test/loss': 0.12721343580386513, 'test/num_examples': 95000000, 'score': 2547.735762119293, 'total_duration': 19830.026311159134, 'accumulated_submission_time': 2547.735762119293, 'accumulated_eval_time': 17281.681800842285, 'accumulated_logging_time': 0.46231889724731445}
I0306 18:37:59.220659 139711569970944 logging_writer.py:48] [2642] accumulated_eval_time=17281.7, accumulated_logging_time=0.462319, accumulated_submission_time=2547.74, global_step=2642, preemption_count=0, score=2547.74, test/loss=0.127213, test/num_examples=95000000, total_duration=19830, train/loss=0.124677, validation/loss=0.124834, validation/num_examples=83274637
I0306 18:38:39.928271 139711578363648 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.027406249195337296, loss=0.12876687943935394
I0306 18:40:00.178440 139865041368256 spec.py:321] Evaluating on the training split.
I0306 18:40:58.120693 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 18:45:10.663728 139865041368256 spec.py:349] Evaluating on the test split.
I0306 18:50:51.992244 139865041368256 submission_runner.py:469] Time since start: 20602.81s, 	Step: 2772, 	{'train/loss': 0.12187498750504833, 'validation/loss': 0.1248254448576788, 'validation/num_examples': 83274637, 'test/loss': 0.12727931628289474, 'test/num_examples': 95000000, 'score': 2668.650507926941, 'total_duration': 20602.80819106102, 'accumulated_submission_time': 2668.650507926941, 'accumulated_eval_time': 17933.495532035828, 'accumulated_logging_time': 0.5086266994476318}
I0306 18:50:52.001003 139711569970944 logging_writer.py:48] [2772] accumulated_eval_time=17933.5, accumulated_logging_time=0.508627, accumulated_submission_time=2668.65, global_step=2772, preemption_count=0, score=2668.65, test/loss=0.127279, test/num_examples=95000000, total_duration=20602.8, train/loss=0.121875, validation/loss=0.124825, validation/num_examples=83274637
I0306 18:50:57.080600 139711578363648 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.06073879450559616, loss=0.1286783069372177
I0306 18:52:52.799339 139865041368256 spec.py:321] Evaluating on the training split.
I0306 18:53:49.372055 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 18:58:03.369889 139865041368256 spec.py:349] Evaluating on the test split.
I0306 19:03:33.847838 139865041368256 submission_runner.py:469] Time since start: 21364.66s, 	Step: 2896, 	{'train/loss': 0.1256080889523779, 'validation/loss': 0.12497680612614641, 'validation/num_examples': 83274637, 'test/loss': 0.12736894639185856, 'test/num_examples': 95000000, 'score': 2789.435708999634, 'total_duration': 21364.663791418076, 'accumulated_submission_time': 2789.435708999634, 'accumulated_eval_time': 18574.543964862823, 'accumulated_logging_time': 0.5240743160247803}
I0306 19:03:33.857789 139711569970944 logging_writer.py:48] [2896] accumulated_eval_time=18574.5, accumulated_logging_time=0.524074, accumulated_submission_time=2789.44, global_step=2896, preemption_count=0, score=2789.44, test/loss=0.127369, test/num_examples=95000000, total_duration=21364.7, train/loss=0.125608, validation/loss=0.124977, validation/num_examples=83274637
I0306 19:03:34.401836 139711578363648 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.01453329622745514, loss=0.12245902419090271
I0306 19:05:06.064197 139711569970944 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.05645595118403435, loss=0.13460992276668549
I0306 19:05:34.582555 139865041368256 spec.py:321] Evaluating on the training split.
I0306 19:06:32.687784 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 19:10:44.660110 139865041368256 spec.py:349] Evaluating on the test split.
I0306 19:16:30.410587 139865041368256 submission_runner.py:469] Time since start: 22141.23s, 	Step: 3027, 	{'train/loss': 0.12278606037392556, 'validation/loss': 0.12520512643125137, 'validation/num_examples': 83274637, 'test/loss': 0.1275594728515625, 'test/num_examples': 95000000, 'score': 2910.146694421768, 'total_duration': 22141.226526498795, 'accumulated_submission_time': 2910.146694421768, 'accumulated_eval_time': 19230.37192630768, 'accumulated_logging_time': 0.5407383441925049}
I0306 19:16:30.419137 139711578363648 logging_writer.py:48] [3027] accumulated_eval_time=19230.4, accumulated_logging_time=0.540738, accumulated_submission_time=2910.15, global_step=3027, preemption_count=0, score=2910.15, test/loss=0.127559, test/num_examples=95000000, total_duration=22141.2, train/loss=0.122786, validation/loss=0.125205, validation/num_examples=83274637
I0306 19:17:26.065843 139711569970944 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.026773611083626747, loss=0.11563847959041595
I0306 19:18:31.264115 139865041368256 spec.py:321] Evaluating on the training split.
I0306 19:19:27.420838 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 19:23:42.826723 139865041368256 spec.py:349] Evaluating on the test split.
I0306 19:29:19.144562 139865041368256 submission_runner.py:469] Time since start: 22909.96s, 	Step: 3152, 	{'train/loss': 0.12305885108199509, 'validation/loss': 0.12475046308874184, 'validation/num_examples': 83274637, 'test/loss': 0.12705676150287828, 'test/num_examples': 95000000, 'score': 3030.9786427021027, 'total_duration': 22909.960525751114, 'accumulated_submission_time': 3030.9786427021027, 'accumulated_eval_time': 19878.25231719017, 'accumulated_logging_time': 0.5558595657348633}
I0306 19:29:19.154236 139711578363648 logging_writer.py:48] [3152] accumulated_eval_time=19878.3, accumulated_logging_time=0.55586, accumulated_submission_time=3030.98, global_step=3152, preemption_count=0, score=3030.98, test/loss=0.127057, test/num_examples=95000000, total_duration=22910, train/loss=0.123059, validation/loss=0.12475, validation/num_examples=83274637
I0306 19:29:47.662879 139711569970944 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.019112760201096535, loss=0.13156339526176453
I0306 19:31:19.950755 139865041368256 spec.py:321] Evaluating on the training split.
I0306 19:32:14.576939 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 19:36:29.680418 139865041368256 spec.py:349] Evaluating on the test split.
I0306 19:42:01.838327 139865041368256 submission_runner.py:469] Time since start: 23672.65s, 	Step: 3282, 	{'train/loss': 0.12317724092482771, 'validation/loss': 0.125401695522589, 'validation/num_examples': 83274637, 'test/loss': 0.12789960460526315, 'test/num_examples': 95000000, 'score': 3151.762377500534, 'total_duration': 23672.65425157547, 'accumulated_submission_time': 3151.762377500534, 'accumulated_eval_time': 20520.139795303345, 'accumulated_logging_time': 0.5720400810241699}
I0306 19:42:01.847184 139711578363648 logging_writer.py:48] [3282] accumulated_eval_time=20520.1, accumulated_logging_time=0.57204, accumulated_submission_time=3151.76, global_step=3282, preemption_count=0, score=3151.76, test/loss=0.1279, test/num_examples=95000000, total_duration=23672.7, train/loss=0.123177, validation/loss=0.125402, validation/num_examples=83274637
I0306 19:42:03.909266 139711569970944 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.007952999323606491, loss=0.11870920658111572
I0306 19:43:54.920906 139711578363648 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.0560489185154438, loss=0.12088435888290405
I0306 19:44:02.681394 139865041368256 spec.py:321] Evaluating on the training split.
I0306 19:44:58.081891 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 19:49:17.708700 139865041368256 spec.py:349] Evaluating on the test split.
I0306 19:54:56.585148 139865041368256 submission_runner.py:469] Time since start: 24447.40s, 	Step: 3408, 	{'train/loss': 0.12315006217913432, 'validation/loss': 0.12503896775185733, 'validation/num_examples': 83274637, 'test/loss': 0.1275110765830592, 'test/num_examples': 95000000, 'score': 3272.5826694965363, 'total_duration': 24447.401106595993, 'accumulated_submission_time': 3272.5826694965363, 'accumulated_eval_time': 21174.043484210968, 'accumulated_logging_time': 0.5880351066589355}
I0306 19:54:56.594100 139711569970944 logging_writer.py:48] [3408] accumulated_eval_time=21174, accumulated_logging_time=0.588035, accumulated_submission_time=3272.58, global_step=3408, preemption_count=0, score=3272.58, test/loss=0.127511, test/num_examples=95000000, total_duration=24447.4, train/loss=0.12315, validation/loss=0.125039, validation/num_examples=83274637
I0306 19:56:13.722807 139711578363648 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.0074862767942249775, loss=0.12094223499298096
I0306 19:56:56.778874 139865041368256 spec.py:321] Evaluating on the training split.
I0306 19:57:53.352915 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 20:02:13.328612 139865041368256 spec.py:349] Evaluating on the test split.
I0306 20:08:04.617472 139865041368256 submission_runner.py:469] Time since start: 25235.43s, 	Step: 3535, 	{'train/loss': 0.1244228331829017, 'validation/loss': 0.12473789207411601, 'validation/num_examples': 83274637, 'test/loss': 0.12718617180304276, 'test/num_examples': 95000000, 'score': 3392.7539372444153, 'total_duration': 25235.433435440063, 'accumulated_submission_time': 3392.7539372444153, 'accumulated_eval_time': 21841.882022857666, 'accumulated_logging_time': 0.6039283275604248}
I0306 20:08:04.678301 139711569970944 logging_writer.py:48] [3535] accumulated_eval_time=21841.9, accumulated_logging_time=0.603928, accumulated_submission_time=3392.75, global_step=3535, preemption_count=0, score=3392.75, test/loss=0.127186, test/num_examples=95000000, total_duration=25235.4, train/loss=0.124423, validation/loss=0.124738, validation/num_examples=83274637
I0306 20:08:54.345535 139711578363648 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.009965918958187103, loss=0.12494690716266632
I0306 20:10:04.776091 139865041368256 spec.py:321] Evaluating on the training split.
I0306 20:11:01.133702 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 20:15:15.453507 139865041368256 spec.py:349] Evaluating on the test split.
I0306 20:20:51.482378 139865041368256 submission_runner.py:469] Time since start: 26002.30s, 	Step: 3660, 	{'train/loss': 0.12164591822140622, 'validation/loss': 0.12475963025076553, 'validation/num_examples': 83274637, 'test/loss': 0.12710908919613487, 'test/num_examples': 95000000, 'score': 3512.822916030884, 'total_duration': 26002.298308610916, 'accumulated_submission_time': 3512.822916030884, 'accumulated_eval_time': 22488.588221549988, 'accumulated_logging_time': 0.6862192153930664}
I0306 20:20:51.491467 139711569970944 logging_writer.py:48] [3660] accumulated_eval_time=22488.6, accumulated_logging_time=0.686219, accumulated_submission_time=3512.82, global_step=3660, preemption_count=0, score=3512.82, test/loss=0.127109, test/num_examples=95000000, total_duration=26002.3, train/loss=0.121646, validation/loss=0.12476, validation/num_examples=83274637
I0306 20:21:09.451201 139711578363648 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.005815551616251469, loss=0.12012405693531036
I0306 20:22:51.540105 139865041368256 spec.py:321] Evaluating on the training split.
I0306 20:23:50.004107 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 20:28:10.432382 139865041368256 spec.py:349] Evaluating on the test split.
I0306 20:33:50.088864 139865041368256 submission_runner.py:469] Time since start: 26780.90s, 	Step: 3783, 	{'train/loss': 0.12218525865167942, 'validation/loss': 0.1246299999351093, 'validation/num_examples': 83274637, 'test/loss': 0.1270731060958059, 'test/num_examples': 95000000, 'score': 3632.8586564064026, 'total_duration': 26780.904814958572, 'accumulated_submission_time': 3632.8586564064026, 'accumulated_eval_time': 23147.136930704117, 'accumulated_logging_time': 0.7024886608123779}
I0306 20:33:50.099424 139711569970944 logging_writer.py:48] [3783] accumulated_eval_time=23147.1, accumulated_logging_time=0.702489, accumulated_submission_time=3632.86, global_step=3783, preemption_count=0, score=3632.86, test/loss=0.127073, test/num_examples=95000000, total_duration=26780.9, train/loss=0.122185, validation/loss=0.12463, validation/num_examples=83274637
I0306 20:33:51.975851 139711578363648 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.008031602017581463, loss=0.12540142238140106
I0306 20:35:41.387399 139711569970944 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.004953203722834587, loss=0.12227782607078552
I0306 20:35:50.749472 139865041368256 spec.py:321] Evaluating on the training split.
I0306 20:36:48.979538 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 20:41:01.452265 139865041368256 spec.py:349] Evaluating on the test split.
I0306 20:46:27.521957 139865041368256 submission_runner.py:469] Time since start: 27538.34s, 	Step: 3909, 	{'train/loss': 0.12370519409155321, 'validation/loss': 0.12478973977108683, 'validation/num_examples': 83274637, 'test/loss': 0.1270896820518092, 'test/num_examples': 95000000, 'score': 3753.4954929351807, 'total_duration': 27538.337899684906, 'accumulated_submission_time': 3753.4954929351807, 'accumulated_eval_time': 23783.90933561325, 'accumulated_logging_time': 0.7199935913085938}
I0306 20:46:27.533172 139711578363648 logging_writer.py:48] [3909] accumulated_eval_time=23783.9, accumulated_logging_time=0.719994, accumulated_submission_time=3753.5, global_step=3909, preemption_count=0, score=3753.5, test/loss=0.12709, test/num_examples=95000000, total_duration=27538.3, train/loss=0.123705, validation/loss=0.12479, validation/num_examples=83274637
I0306 20:47:51.165299 139711569970944 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.01903213933110237, loss=0.1246785819530487
I0306 20:48:28.480887 139865041368256 spec.py:321] Evaluating on the training split.
I0306 20:49:25.750690 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 20:53:42.197263 139865041368256 spec.py:349] Evaluating on the test split.
I0306 20:59:14.272600 139865041368256 submission_runner.py:469] Time since start: 28305.09s, 	Step: 4029, 	{'train/loss': 0.12351017204002014, 'validation/loss': 0.12467005927810101, 'validation/num_examples': 83274637, 'test/loss': 0.1271703711040296, 'test/num_examples': 95000000, 'score': 3874.429486989975, 'total_duration': 28305.0885617733, 'accumulated_submission_time': 3874.429486989975, 'accumulated_eval_time': 24429.700989484787, 'accumulated_logging_time': 0.7382345199584961}
I0306 20:59:14.281788 139711578363648 logging_writer.py:48] [4029] accumulated_eval_time=24429.7, accumulated_logging_time=0.738235, accumulated_submission_time=3874.43, global_step=4029, preemption_count=0, score=3874.43, test/loss=0.12717, test/num_examples=95000000, total_duration=28305.1, train/loss=0.12351, validation/loss=0.12467, validation/num_examples=83274637
I0306 21:00:08.792947 139711569970944 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.03773779422044754, loss=0.11667756736278534
I0306 21:01:14.493611 139865041368256 spec.py:321] Evaluating on the training split.
I0306 21:02:12.362743 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 21:06:31.737835 139865041368256 spec.py:349] Evaluating on the test split.
I0306 21:12:08.664678 139865041368256 submission_runner.py:469] Time since start: 29079.48s, 	Step: 4158, 	{'train/loss': 0.12411163361895385, 'validation/loss': 0.1246524716538242, 'validation/num_examples': 83274637, 'test/loss': 0.12708525364925988, 'test/num_examples': 95000000, 'score': 3994.628307580948, 'total_duration': 29079.48060965538, 'accumulated_submission_time': 3994.628307580948, 'accumulated_eval_time': 25083.871973514557, 'accumulated_logging_time': 0.7537219524383545}
I0306 21:12:08.673849 139711578363648 logging_writer.py:48] [4158] accumulated_eval_time=25083.9, accumulated_logging_time=0.753722, accumulated_submission_time=3994.63, global_step=4158, preemption_count=0, score=3994.63, test/loss=0.127085, test/num_examples=95000000, total_duration=29079.5, train/loss=0.124112, validation/loss=0.124652, validation/num_examples=83274637
I0306 21:12:29.842479 139711569970944 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.007444380782544613, loss=0.12365863472223282
I0306 21:14:08.873272 139865041368256 spec.py:321] Evaluating on the training split.
I0306 21:15:03.999482 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 21:19:23.818217 139865041368256 spec.py:349] Evaluating on the test split.
I0306 21:25:02.938971 139865041368256 submission_runner.py:469] Time since start: 29853.75s, 	Step: 4281, 	{'train/loss': 0.12237459986980231, 'validation/loss': 0.12507064313291452, 'validation/num_examples': 83274637, 'test/loss': 0.12771258269942434, 'test/num_examples': 95000000, 'score': 4114.814796209335, 'total_duration': 29853.75492668152, 'accumulated_submission_time': 4114.814796209335, 'accumulated_eval_time': 25737.937618017197, 'accumulated_logging_time': 0.769340991973877}
I0306 21:25:02.948135 139711578363648 logging_writer.py:48] [4281] accumulated_eval_time=25737.9, accumulated_logging_time=0.769341, accumulated_submission_time=4114.81, global_step=4281, preemption_count=0, score=4114.81, test/loss=0.127713, test/num_examples=95000000, total_duration=29853.8, train/loss=0.122375, validation/loss=0.125071, validation/num_examples=83274637
I0306 21:25:05.061581 139711569970944 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.023200344294309616, loss=0.13021251559257507
I0306 21:26:56.848157 139711578363648 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.0051919263787567616, loss=0.1319853663444519
I0306 21:27:04.002563 139865041368256 spec.py:321] Evaluating on the training split.
I0306 21:28:02.152948 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 21:32:19.773924 139865041368256 spec.py:349] Evaluating on the test split.
I0306 21:38:00.614609 139865041368256 submission_runner.py:469] Time since start: 30631.43s, 	Step: 4407, 	{'train/loss': 0.12289856916656659, 'validation/loss': 0.12461468716313835, 'validation/num_examples': 83274637, 'test/loss': 0.12697791967516447, 'test/num_examples': 95000000, 'score': 4235.856360673904, 'total_duration': 30631.43055677414, 'accumulated_submission_time': 4235.856360673904, 'accumulated_eval_time': 26394.549590349197, 'accumulated_logging_time': 0.7852036952972412}
I0306 21:38:00.623672 139711569970944 logging_writer.py:48] [4407] accumulated_eval_time=26394.5, accumulated_logging_time=0.785204, accumulated_submission_time=4235.86, global_step=4407, preemption_count=0, score=4235.86, test/loss=0.126978, test/num_examples=95000000, total_duration=30631.4, train/loss=0.122899, validation/loss=0.124615, validation/num_examples=83274637
I0306 21:39:25.786667 139711578363648 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.0384691059589386, loss=0.12144453078508377
I0306 21:40:01.238498 139865041368256 spec.py:321] Evaluating on the training split.
I0306 21:40:55.702644 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 21:45:11.848294 139865041368256 spec.py:349] Evaluating on the test split.
I0306 21:50:44.549787 139865041368256 submission_runner.py:469] Time since start: 31395.37s, 	Step: 4533, 	{'train/loss': 0.12237647265992449, 'validation/loss': 0.12434284713825142, 'validation/num_examples': 83274637, 'test/loss': 0.1269124599917763, 'test/num_examples': 95000000, 'score': 4356.4244556427, 'total_duration': 31395.365745067596, 'accumulated_submission_time': 4356.4244556427, 'accumulated_eval_time': 27037.860816717148, 'accumulated_logging_time': 0.8345828056335449}
I0306 21:50:44.559421 139711569970944 logging_writer.py:48] [4533] accumulated_eval_time=27037.9, accumulated_logging_time=0.834583, accumulated_submission_time=4356.42, global_step=4533, preemption_count=0, score=4356.42, test/loss=0.126912, test/num_examples=95000000, total_duration=31395.4, train/loss=0.122376, validation/loss=0.124343, validation/num_examples=83274637
I0306 21:51:36.089427 139711578363648 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.008616078644990921, loss=0.12464544177055359
I0306 21:52:44.715222 139865041368256 spec.py:321] Evaluating on the training split.
I0306 21:53:42.295505 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 21:57:59.934214 139865041368256 spec.py:349] Evaluating on the test split.
I0306 22:03:39.185671 139865041368256 submission_runner.py:469] Time since start: 32170.00s, 	Step: 4661, 	{'train/loss': 0.12115773723794604, 'validation/loss': 0.12439585083695899, 'validation/num_examples': 83274637, 'test/loss': 0.12683016449424342, 'test/num_examples': 95000000, 'score': 4476.567169904709, 'total_duration': 32170.001632213593, 'accumulated_submission_time': 4476.567169904709, 'accumulated_eval_time': 27692.33120584488, 'accumulated_logging_time': 0.8507177829742432}
I0306 22:03:39.195165 139711569970944 logging_writer.py:48] [4661] accumulated_eval_time=27692.3, accumulated_logging_time=0.850718, accumulated_submission_time=4476.57, global_step=4661, preemption_count=0, score=4476.57, test/loss=0.12683, test/num_examples=95000000, total_duration=32170, train/loss=0.121158, validation/loss=0.124396, validation/num_examples=83274637
I0306 22:03:57.813271 139711578363648 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.013509010896086693, loss=0.1309770941734314
I0306 22:05:39.422303 139865041368256 spec.py:321] Evaluating on the training split.
I0306 22:06:33.760340 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 22:10:50.384632 139865041368256 spec.py:349] Evaluating on the test split.
I0306 22:16:38.439291 139865041368256 submission_runner.py:469] Time since start: 32949.26s, 	Step: 4790, 	{'train/loss': 0.12397603864002528, 'validation/loss': 0.12433848484298632, 'validation/num_examples': 83274637, 'test/loss': 0.12684073392269737, 'test/num_examples': 95000000, 'score': 4596.780594587326, 'total_duration': 32949.25524020195, 'accumulated_submission_time': 4596.780594587326, 'accumulated_eval_time': 28351.348131656647, 'accumulated_logging_time': 0.866657018661499}
I0306 22:16:38.448713 139711569970944 logging_writer.py:48] [4790] accumulated_eval_time=28351.3, accumulated_logging_time=0.866657, accumulated_submission_time=4596.78, global_step=4790, preemption_count=0, score=4596.78, test/loss=0.126841, test/num_examples=95000000, total_duration=32949.3, train/loss=0.123976, validation/loss=0.124338, validation/num_examples=83274637
I0306 22:16:39.631227 139711578363648 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.009520040825009346, loss=0.1210508793592453
I0306 22:18:17.521378 139711569970944 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.025673212483525276, loss=0.11954877525568008
I0306 22:18:39.021227 139865041368256 spec.py:321] Evaluating on the training split.
I0306 22:19:35.428728 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 22:23:54.723384 139865041368256 spec.py:349] Evaluating on the test split.
I0306 22:29:28.401545 139865041368256 submission_runner.py:469] Time since start: 33719.22s, 	Step: 4920, 	{'train/loss': 0.12287534676117343, 'validation/loss': 0.12415881947429339, 'validation/num_examples': 83274637, 'test/loss': 0.12655607018914475, 'test/num_examples': 95000000, 'score': 4717.340375423431, 'total_duration': 33719.217500925064, 'accumulated_submission_time': 4717.340375423431, 'accumulated_eval_time': 29000.728383779526, 'accumulated_logging_time': 0.8826417922973633}
I0306 22:29:28.410929 139711578363648 logging_writer.py:48] [4920] accumulated_eval_time=29000.7, accumulated_logging_time=0.882642, accumulated_submission_time=4717.34, global_step=4920, preemption_count=0, score=4717.34, test/loss=0.126556, test/num_examples=95000000, total_duration=33719.2, train/loss=0.122875, validation/loss=0.124159, validation/num_examples=83274637
I0306 22:30:38.707018 139711569970944 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.021711919456720352, loss=0.12382347881793976
I0306 22:31:28.447447 139865041368256 spec.py:321] Evaluating on the training split.
I0306 22:32:29.415654 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 22:36:48.534329 139865041368256 spec.py:349] Evaluating on the test split.
I0306 22:42:14.762053 139865041368256 submission_runner.py:469] Time since start: 34485.58s, 	Step: 5039, 	{'train/loss': 0.12229652480228143, 'validation/loss': 0.12433123311800282, 'validation/num_examples': 83274637, 'test/loss': 0.12670037003495066, 'test/num_examples': 95000000, 'score': 4837.363646507263, 'total_duration': 34485.5779876709, 'accumulated_submission_time': 4837.363646507263, 'accumulated_eval_time': 29647.042902469635, 'accumulated_logging_time': 0.8986783027648926}
I0306 22:42:14.772754 139711578363648 logging_writer.py:48] [5039] accumulated_eval_time=29647, accumulated_logging_time=0.898678, accumulated_submission_time=4837.36, global_step=5039, preemption_count=0, score=4837.36, test/loss=0.1267, test/num_examples=95000000, total_duration=34485.6, train/loss=0.122297, validation/loss=0.124331, validation/num_examples=83274637
I0306 22:42:59.708752 139711569970944 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.005624191369861364, loss=0.12139444053173065
I0306 22:44:16.262525 139865041368256 spec.py:321] Evaluating on the training split.
I0306 22:45:15.607342 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 22:49:33.959930 139865041368256 spec.py:349] Evaluating on the test split.
I0306 22:55:07.155858 139865041368256 submission_runner.py:469] Time since start: 35257.97s, 	Step: 5161, 	{'train/loss': 0.12325363068507528, 'validation/loss': 0.1243437993949166, 'validation/num_examples': 83274637, 'test/loss': 0.12676590653782896, 'test/num_examples': 95000000, 'score': 4958.840138196945, 'total_duration': 35257.97181534767, 'accumulated_submission_time': 4958.840138196945, 'accumulated_eval_time': 30297.93617129326, 'accumulated_logging_time': 0.916257381439209}
I0306 22:55:07.165528 139711578363648 logging_writer.py:48] [5161] accumulated_eval_time=30297.9, accumulated_logging_time=0.916257, accumulated_submission_time=4958.84, global_step=5161, preemption_count=0, score=4958.84, test/loss=0.126766, test/num_examples=95000000, total_duration=35258, train/loss=0.123254, validation/loss=0.124344, validation/num_examples=83274637
I0306 22:55:25.449605 139711569970944 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.03120497055351734, loss=0.12556131184101105
I0306 22:57:07.434235 139865041368256 spec.py:321] Evaluating on the training split.
I0306 22:58:03.956232 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 23:02:19.060196 139865041368256 spec.py:349] Evaluating on the test split.
I0306 23:07:59.046655 139865041368256 submission_runner.py:469] Time since start: 36029.86s, 	Step: 5287, 	{'train/loss': 0.12214451938070967, 'validation/loss': 0.12448618465748686, 'validation/num_examples': 83274637, 'test/loss': 0.12687910025699012, 'test/num_examples': 95000000, 'score': 5079.091540813446, 'total_duration': 36029.86261796951, 'accumulated_submission_time': 5079.091540813446, 'accumulated_eval_time': 30949.54853796959, 'accumulated_logging_time': 0.9365813732147217}
I0306 23:07:59.056479 139711578363648 logging_writer.py:48] [5287] accumulated_eval_time=30949.5, accumulated_logging_time=0.936581, accumulated_submission_time=5079.09, global_step=5287, preemption_count=0, score=5079.09, test/loss=0.126879, test/num_examples=95000000, total_duration=36029.9, train/loss=0.122145, validation/loss=0.124486, validation/num_examples=83274637
I0306 23:08:00.583225 139711569970944 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.01221643015742302, loss=0.1266014724969864
I0306 23:09:42.609347 139711578363648 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.03226958215236664, loss=0.12154676020145416
I0306 23:10:00.033307 139865041368256 spec.py:321] Evaluating on the training split.
I0306 23:10:56.944263 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 23:15:15.246638 139865041368256 spec.py:349] Evaluating on the test split.
I0306 23:20:50.643363 139865041368256 submission_runner.py:469] Time since start: 36801.46s, 	Step: 5414, 	{'train/loss': 0.12143726016646661, 'validation/loss': 0.12431993511135592, 'validation/num_examples': 83274637, 'test/loss': 0.1266653302528783, 'test/num_examples': 95000000, 'score': 5200.039031267166, 'total_duration': 36801.459287405014, 'accumulated_submission_time': 5200.039031267166, 'accumulated_eval_time': 31600.15849661827, 'accumulated_logging_time': 0.9690985679626465}
I0306 23:20:50.653342 139711569970944 logging_writer.py:48] [5414] accumulated_eval_time=31600.2, accumulated_logging_time=0.969099, accumulated_submission_time=5200.04, global_step=5414, preemption_count=0, score=5200.04, test/loss=0.126665, test/num_examples=95000000, total_duration=36801.5, train/loss=0.121437, validation/loss=0.12432, validation/num_examples=83274637
I0306 23:22:07.193594 139711578363648 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.02822229079902172, loss=0.12026141583919525
I0306 23:22:52.260371 139865041368256 spec.py:321] Evaluating on the training split.
I0306 23:23:48.639025 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 23:28:09.747326 139865041368256 spec.py:349] Evaluating on the test split.
I0306 23:33:43.850496 139865041368256 submission_runner.py:469] Time since start: 37574.67s, 	Step: 5538, 	{'train/loss': 0.12209599489732734, 'validation/loss': 0.12424783817514945, 'validation/num_examples': 83274637, 'test/loss': 0.12655464939350328, 'test/num_examples': 95000000, 'score': 5321.631330728531, 'total_duration': 37574.666451215744, 'accumulated_submission_time': 5321.631330728531, 'accumulated_eval_time': 32251.748555898666, 'accumulated_logging_time': 0.9868378639221191}
I0306 23:33:43.860608 139711569970944 logging_writer.py:48] [5538] accumulated_eval_time=32251.7, accumulated_logging_time=0.986838, accumulated_submission_time=5321.63, global_step=5538, preemption_count=0, score=5321.63, test/loss=0.126555, test/num_examples=95000000, total_duration=37574.7, train/loss=0.122096, validation/loss=0.124248, validation/num_examples=83274637
I0306 23:34:26.732075 139711578363648 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.008518348447978497, loss=0.12191430479288101
I0306 23:35:44.577390 139865041368256 spec.py:321] Evaluating on the training split.
I0306 23:36:38.948364 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 23:40:55.456949 139865041368256 spec.py:349] Evaluating on the test split.
I0306 23:46:39.359030 139865041368256 submission_runner.py:469] Time since start: 38350.17s, 	Step: 5666, 	{'train/loss': 0.12163322983579065, 'validation/loss': 0.12453471575667338, 'validation/num_examples': 83274637, 'test/loss': 0.12695514778988487, 'test/num_examples': 95000000, 'score': 5442.332728862762, 'total_duration': 38350.17497897148, 'accumulated_submission_time': 5442.332728862762, 'accumulated_eval_time': 32906.530125141144, 'accumulated_logging_time': 1.0043795108795166}
I0306 23:46:39.368731 139711569970944 logging_writer.py:48] [5666] accumulated_eval_time=32906.5, accumulated_logging_time=1.00438, accumulated_submission_time=5442.33, global_step=5666, preemption_count=0, score=5442.33, test/loss=0.126955, test/num_examples=95000000, total_duration=38350.2, train/loss=0.121633, validation/loss=0.124535, validation/num_examples=83274637
I0306 23:46:51.853710 139711578363648 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.013135972432792187, loss=0.11885074526071548
I0306 23:48:40.177021 139865041368256 spec.py:321] Evaluating on the training split.
I0306 23:49:36.105062 139865041368256 spec.py:333] Evaluating on the validation split.
I0306 23:53:49.049681 139865041368256 spec.py:349] Evaluating on the test split.
I0306 23:59:25.902798 139865041368256 submission_runner.py:469] Time since start: 39116.72s, 	Step: 5788, 	{'train/loss': 0.12286142632365227, 'validation/loss': 0.12462021526392056, 'validation/num_examples': 83274637, 'test/loss': 0.12697909620682565, 'test/num_examples': 95000000, 'score': 5563.126938343048, 'total_duration': 39116.718750715256, 'accumulated_submission_time': 5563.126938343048, 'accumulated_eval_time': 33552.25583744049, 'accumulated_logging_time': 1.0215568542480469}
I0306 23:59:25.912966 139711569970944 logging_writer.py:48] [5788] accumulated_eval_time=33552.3, accumulated_logging_time=1.02156, accumulated_submission_time=5563.13, global_step=5788, preemption_count=0, score=5563.13, test/loss=0.126979, test/num_examples=95000000, total_duration=39116.7, train/loss=0.122861, validation/loss=0.12462, validation/num_examples=83274637
I0306 23:59:27.356255 139711578363648 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.00669264467433095, loss=0.13603933155536652
I0307 00:01:13.671022 139711569970944 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.012646573595702648, loss=0.12271708995103836
I0307 00:01:26.461457 139865041368256 spec.py:321] Evaluating on the training split.
I0307 00:02:27.038849 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 00:06:46.177522 139865041368256 spec.py:349] Evaluating on the test split.
I0307 00:12:30.582798 139865041368256 submission_runner.py:469] Time since start: 39901.40s, 	Step: 5910, 	{'train/loss': 0.1227066037860119, 'validation/loss': 0.12441863638218824, 'validation/num_examples': 83274637, 'test/loss': 0.12667101260279606, 'test/num_examples': 95000000, 'score': 5683.617914915085, 'total_duration': 39901.398755311966, 'accumulated_submission_time': 5683.617914915085, 'accumulated_eval_time': 34216.377111911774, 'accumulated_logging_time': 1.0827691555023193}
I0307 00:12:30.593223 139711578363648 logging_writer.py:48] [5910] accumulated_eval_time=34216.4, accumulated_logging_time=1.08277, accumulated_submission_time=5683.62, global_step=5910, preemption_count=0, score=5683.62, test/loss=0.126671, test/num_examples=95000000, total_duration=39901.4, train/loss=0.122707, validation/loss=0.124419, validation/num_examples=83274637
I0307 00:13:48.188554 139711569970944 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.006532741244882345, loss=0.11899277567863464
I0307 00:14:30.986933 139865041368256 spec.py:321] Evaluating on the training split.
I0307 00:15:32.263611 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 00:19:48.943471 139865041368256 spec.py:349] Evaluating on the test split.
I0307 00:25:28.492407 139865041368256 submission_runner.py:469] Time since start: 40679.31s, 	Step: 6039, 	{'train/loss': 0.12196214542776909, 'validation/loss': 0.1242677823244932, 'validation/num_examples': 83274637, 'test/loss': 0.12663335814144736, 'test/num_examples': 95000000, 'score': 5803.99795794487, 'total_duration': 40679.30836939812, 'accumulated_submission_time': 5803.99795794487, 'accumulated_eval_time': 34873.882536649704, 'accumulated_logging_time': 1.0998148918151855}
I0307 00:25:28.505600 139711578363648 logging_writer.py:48] [6039] accumulated_eval_time=34873.9, accumulated_logging_time=1.09981, accumulated_submission_time=5804, global_step=6039, preemption_count=0, score=5804, test/loss=0.126633, test/num_examples=95000000, total_duration=40679.3, train/loss=0.121962, validation/loss=0.124268, validation/num_examples=83274637
I0307 00:26:14.333569 139711569970944 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.01777081936597824, loss=0.127061128616333
I0307 00:27:28.790411 139865041368256 spec.py:321] Evaluating on the training split.
I0307 00:28:28.051046 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 00:32:44.482698 139865041368256 spec.py:349] Evaluating on the test split.
I0307 00:38:06.330003 139865041368256 submission_runner.py:469] Time since start: 41437.15s, 	Step: 6159, 	{'train/loss': 0.12422683294979656, 'validation/loss': 0.12428363042274317, 'validation/num_examples': 83274637, 'test/loss': 0.12656100262129935, 'test/num_examples': 95000000, 'score': 5924.268723726273, 'total_duration': 41437.14596533775, 'accumulated_submission_time': 5924.268723726273, 'accumulated_eval_time': 35511.42207694054, 'accumulated_logging_time': 1.1195969581604004}
I0307 00:38:06.339955 139711578363648 logging_writer.py:48] [6159] accumulated_eval_time=35511.4, accumulated_logging_time=1.1196, accumulated_submission_time=5924.27, global_step=6159, preemption_count=0, score=5924.27, test/loss=0.126561, test/num_examples=95000000, total_duration=41437.1, train/loss=0.124227, validation/loss=0.124284, validation/num_examples=83274637
I0307 00:38:25.752061 139711569970944 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.007112087681889534, loss=0.11844165623188019
I0307 00:40:08.124749 139865041368256 spec.py:321] Evaluating on the training split.
I0307 00:41:08.601083 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 00:45:23.689112 139865041368256 spec.py:349] Evaluating on the test split.
I0307 00:51:00.863279 139865041368256 submission_runner.py:469] Time since start: 42211.68s, 	Step: 6286, 	{'train/loss': 0.12274382081843398, 'validation/loss': 0.12426158376123235, 'validation/num_examples': 83274637, 'test/loss': 0.12665356061883223, 'test/num_examples': 95000000, 'score': 6046.040119171143, 'total_duration': 42211.679231882095, 'accumulated_submission_time': 6046.040119171143, 'accumulated_eval_time': 36164.16054081917, 'accumulated_logging_time': 1.1359503269195557}
I0307 00:51:00.873331 139711578363648 logging_writer.py:48] [6286] accumulated_eval_time=36164.2, accumulated_logging_time=1.13595, accumulated_submission_time=6046.04, global_step=6286, preemption_count=0, score=6046.04, test/loss=0.126654, test/num_examples=95000000, total_duration=42211.7, train/loss=0.122744, validation/loss=0.124262, validation/num_examples=83274637
I0307 00:51:02.472472 139711569970944 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.008261287584900856, loss=0.12198033928871155
I0307 00:52:47.437569 139711578363648 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.008551143109798431, loss=0.12435906380414963
I0307 00:53:01.451803 139865041368256 spec.py:321] Evaluating on the training split.
I0307 00:54:02.483074 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 00:58:19.439242 139865041368256 spec.py:349] Evaluating on the test split.
I0307 01:04:06.238980 139865041368256 submission_runner.py:469] Time since start: 42997.05s, 	Step: 6413, 	{'train/loss': 0.123363839204675, 'validation/loss': 0.1241623913045866, 'validation/num_examples': 83274637, 'test/loss': 0.12648813510485196, 'test/num_examples': 95000000, 'score': 6166.605379104614, 'total_duration': 42997.054936885834, 'accumulated_submission_time': 6166.605379104614, 'accumulated_eval_time': 36828.94765996933, 'accumulated_logging_time': 1.15232253074646}
I0307 01:04:06.249041 139711569970944 logging_writer.py:48] [6413] accumulated_eval_time=36828.9, accumulated_logging_time=1.15232, accumulated_submission_time=6166.61, global_step=6413, preemption_count=0, score=6166.61, test/loss=0.126488, test/num_examples=95000000, total_duration=42997.1, train/loss=0.123364, validation/loss=0.124162, validation/num_examples=83274637
I0307 01:05:20.963225 139711578363648 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.00894173700362444, loss=0.1286095231771469
I0307 01:06:07.002144 139865041368256 spec.py:321] Evaluating on the training split.
I0307 01:07:03.771223 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 01:11:26.598116 139865041368256 spec.py:349] Evaluating on the test split.
I0307 01:16:57.555781 139865041368256 submission_runner.py:469] Time since start: 43768.37s, 	Step: 6538, 	{'train/loss': 0.12157355654258398, 'validation/loss': 0.12410011287785619, 'validation/num_examples': 83274637, 'test/loss': 0.1264757349712171, 'test/num_examples': 95000000, 'score': 6287.344458818436, 'total_duration': 43768.371727705, 'accumulated_submission_time': 6287.344458818436, 'accumulated_eval_time': 37479.50123167038, 'accumulated_logging_time': 1.1698594093322754}
I0307 01:16:57.565612 139711569970944 logging_writer.py:48] [6538] accumulated_eval_time=37479.5, accumulated_logging_time=1.16986, accumulated_submission_time=6287.34, global_step=6538, preemption_count=0, score=6287.34, test/loss=0.126476, test/num_examples=95000000, total_duration=43768.4, train/loss=0.121574, validation/loss=0.1241, validation/num_examples=83274637
I0307 01:17:41.535744 139711578363648 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.00817040354013443, loss=0.11600065231323242
I0307 01:18:57.649439 139865041368256 spec.py:321] Evaluating on the training split.
I0307 01:19:56.035323 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 01:24:17.279830 139865041368256 spec.py:349] Evaluating on the test split.
I0307 01:29:44.707912 139865041368256 submission_runner.py:469] Time since start: 44535.52s, 	Step: 6664, 	{'train/loss': 0.12499148651676358, 'validation/loss': 0.12421684171760859, 'validation/num_examples': 83274637, 'test/loss': 0.12666974700863487, 'test/num_examples': 95000000, 'score': 6407.414861679077, 'total_duration': 44535.52385735512, 'accumulated_submission_time': 6407.414861679077, 'accumulated_eval_time': 38126.55963182449, 'accumulated_logging_time': 1.186309576034546}
I0307 01:29:44.718658 139711569970944 logging_writer.py:48] [6664] accumulated_eval_time=38126.6, accumulated_logging_time=1.18631, accumulated_submission_time=6407.41, global_step=6664, preemption_count=0, score=6407.41, test/loss=0.12667, test/num_examples=95000000, total_duration=44535.5, train/loss=0.124991, validation/loss=0.124217, validation/num_examples=83274637
I0307 01:29:58.659871 139711578363648 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.005704182665795088, loss=0.11909270286560059
I0307 01:31:44.734262 139865041368256 spec.py:321] Evaluating on the training split.
I0307 01:32:38.845394 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 01:36:54.392101 139865041368256 spec.py:349] Evaluating on the test split.
I0307 01:42:59.386127 139865041368256 submission_runner.py:469] Time since start: 45330.20s, 	Step: 6788, 	{'train/loss': 0.1222525186860149, 'validation/loss': 0.12424062695525845, 'validation/num_examples': 83274637, 'test/loss': 0.12661233439555922, 'test/num_examples': 95000000, 'score': 6527.345878362656, 'total_duration': 45330.2020945549, 'accumulated_submission_time': 6527.345878362656, 'accumulated_eval_time': 38801.211453676224, 'accumulated_logging_time': 1.2748687267303467}
I0307 01:42:59.396634 139711569970944 logging_writer.py:48] [6788] accumulated_eval_time=38801.2, accumulated_logging_time=1.27487, accumulated_submission_time=6527.35, global_step=6788, preemption_count=0, score=6527.35, test/loss=0.126612, test/num_examples=95000000, total_duration=45330.2, train/loss=0.122253, validation/loss=0.124241, validation/num_examples=83274637
I0307 01:43:00.787341 139711578363648 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.021186482161283493, loss=0.12792688608169556
I0307 01:44:40.475894 139711569970944 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.0067345937713980675, loss=0.12087274342775345
I0307 01:45:00.198158 139865041368256 spec.py:321] Evaluating on the training split.
I0307 01:45:57.235199 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 01:50:22.940425 139865041368256 spec.py:349] Evaluating on the test split.
I0307 01:56:11.469119 139865041368256 submission_runner.py:469] Time since start: 46122.29s, 	Step: 6917, 	{'train/loss': 0.12363491481486356, 'validation/loss': 0.12408830923185607, 'validation/num_examples': 83274637, 'test/loss': 0.12646368057154606, 'test/num_examples': 95000000, 'score': 6648.133413314819, 'total_duration': 46122.28507947922, 'accumulated_submission_time': 6648.133413314819, 'accumulated_eval_time': 39472.482355594635, 'accumulated_logging_time': 1.2916154861450195}
I0307 01:56:11.479345 139711578363648 logging_writer.py:48] [6917] accumulated_eval_time=39472.5, accumulated_logging_time=1.29162, accumulated_submission_time=6648.13, global_step=6917, preemption_count=0, score=6648.13, test/loss=0.126464, test/num_examples=95000000, total_duration=46122.3, train/loss=0.123635, validation/loss=0.124088, validation/num_examples=83274637
I0307 01:57:18.940041 139711569970944 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.012285471893846989, loss=0.12512536346912384
I0307 01:58:13.004312 139865041368256 spec.py:321] Evaluating on the training split.
I0307 01:59:15.105737 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 02:03:33.539052 139865041368256 spec.py:349] Evaluating on the test split.
I0307 02:09:20.638216 139865041368256 submission_runner.py:469] Time since start: 46911.45s, 	Step: 7043, 	{'train/loss': 0.12138971070167404, 'validation/loss': 0.12381238517606057, 'validation/num_examples': 83274637, 'test/loss': 0.12613596762952303, 'test/num_examples': 95000000, 'score': 6769.644779205322, 'total_duration': 46911.45415663719, 'accumulated_submission_time': 6769.644779205322, 'accumulated_eval_time': 40140.11620569229, 'accumulated_logging_time': 1.3090593814849854}
I0307 02:09:20.648621 139711578363648 logging_writer.py:48] [7043] accumulated_eval_time=40140.1, accumulated_logging_time=1.30906, accumulated_submission_time=6769.64, global_step=7043, preemption_count=0, score=6769.64, test/loss=0.126136, test/num_examples=95000000, total_duration=46911.5, train/loss=0.12139, validation/loss=0.123812, validation/num_examples=83274637
I0307 02:09:59.354623 139711569970944 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.008559975773096085, loss=0.12050130218267441
I0307 02:11:21.018646 139865041368256 spec.py:321] Evaluating on the training split.
I0307 02:12:16.826091 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 02:16:31.146967 139865041368256 spec.py:349] Evaluating on the test split.
I0307 02:22:10.807827 139865041368256 submission_runner.py:469] Time since start: 47681.62s, 	Step: 7169, 	{'train/loss': 0.12177030388382995, 'validation/loss': 0.12385254436281534, 'validation/num_examples': 83274637, 'test/loss': 0.12615895728824014, 'test/num_examples': 95000000, 'score': 6890.001515388489, 'total_duration': 47681.62378334999, 'accumulated_submission_time': 6890.001515388489, 'accumulated_eval_time': 40789.905323028564, 'accumulated_logging_time': 1.3260564804077148}
I0307 02:22:10.817981 139711578363648 logging_writer.py:48] [7169] accumulated_eval_time=40789.9, accumulated_logging_time=1.32606, accumulated_submission_time=6890, global_step=7169, preemption_count=0, score=6890, test/loss=0.126159, test/num_examples=95000000, total_duration=47681.6, train/loss=0.12177, validation/loss=0.123853, validation/num_examples=83274637
I0307 02:22:18.133295 139711569970944 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.006061197258532047, loss=0.12304963171482086
I0307 02:24:11.828076 139865041368256 spec.py:321] Evaluating on the training split.
I0307 02:25:10.012331 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 02:29:25.592209 139865041368256 spec.py:349] Evaluating on the test split.
I0307 02:35:03.010323 139865041368256 submission_runner.py:469] Time since start: 48453.83s, 	Step: 7291, 	{'train/loss': 0.12300953145999953, 'validation/loss': 0.12391244471609796, 'validation/num_examples': 83274637, 'test/loss': 0.12622773505345394, 'test/num_examples': 95000000, 'score': 7010.998081684113, 'total_duration': 48453.82627415657, 'accumulated_submission_time': 7010.998081684113, 'accumulated_eval_time': 41441.08750271797, 'accumulated_logging_time': 1.3426883220672607}
I0307 02:35:03.020813 139711578363648 logging_writer.py:48] [7291] accumulated_eval_time=41441.1, accumulated_logging_time=1.34269, accumulated_submission_time=7011, global_step=7291, preemption_count=0, score=7011, test/loss=0.126228, test/num_examples=95000000, total_duration=48453.8, train/loss=0.12301, validation/loss=0.123912, validation/num_examples=83274637
I0307 02:35:04.103140 139711569970944 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.008146548643708229, loss=0.12474864721298218
I0307 02:36:45.876692 139711578363648 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.0065522463992238045, loss=0.12465302646160126
I0307 02:37:03.498850 139865041368256 spec.py:321] Evaluating on the training split.
I0307 02:37:59.563980 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 02:42:14.021772 139865041368256 spec.py:349] Evaluating on the test split.
I0307 02:48:06.319464 139865041368256 submission_runner.py:469] Time since start: 49237.14s, 	Step: 7416, 	{'train/loss': 0.12327715087939733, 'validation/loss': 0.12386703994395865, 'validation/num_examples': 83274637, 'test/loss': 0.12621523718133223, 'test/num_examples': 95000000, 'score': 7131.463647603989, 'total_duration': 49237.13542175293, 'accumulated_submission_time': 7131.463647603989, 'accumulated_eval_time': 42103.9080517292, 'accumulated_logging_time': 1.3594460487365723}
I0307 02:48:06.329778 139711569970944 logging_writer.py:48] [7416] accumulated_eval_time=42103.9, accumulated_logging_time=1.35945, accumulated_submission_time=7131.46, global_step=7416, preemption_count=0, score=7131.46, test/loss=0.126215, test/num_examples=95000000, total_duration=49237.1, train/loss=0.123277, validation/loss=0.123867, validation/num_examples=83274637
I0307 02:49:21.374663 139711578363648 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.008624142035841942, loss=0.12418178468942642
I0307 02:50:07.087404 139865041368256 spec.py:321] Evaluating on the training split.
I0307 02:51:03.838880 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 02:55:19.541920 139865041368256 spec.py:349] Evaluating on the test split.
I0307 03:01:11.072062 139865041368256 submission_runner.py:469] Time since start: 50021.89s, 	Step: 7539, 	{'train/loss': 0.12214070819786885, 'validation/loss': 0.12397056804623928, 'validation/num_examples': 83274637, 'test/loss': 0.12639074190995067, 'test/num_examples': 95000000, 'score': 7252.208505868912, 'total_duration': 50021.88802719116, 'accumulated_submission_time': 7252.208505868912, 'accumulated_eval_time': 42767.89265561104, 'accumulated_logging_time': 1.3762896060943604}
I0307 03:01:11.082232 139711569970944 logging_writer.py:48] [7539] accumulated_eval_time=42767.9, accumulated_logging_time=1.37629, accumulated_submission_time=7252.21, global_step=7539, preemption_count=0, score=7252.21, test/loss=0.126391, test/num_examples=95000000, total_duration=50021.9, train/loss=0.122141, validation/loss=0.123971, validation/num_examples=83274637
I0307 03:01:57.154429 139711578363648 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.00656951405107975, loss=0.11348503828048706
I0307 03:03:11.233676 139865041368256 spec.py:321] Evaluating on the training split.
I0307 03:04:03.734164 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 03:08:19.574971 139865041368256 spec.py:349] Evaluating on the test split.
I0307 03:14:03.552414 139865041368256 submission_runner.py:469] Time since start: 50794.37s, 	Step: 7666, 	{'train/loss': 0.12399919899239105, 'validation/loss': 0.1239440179079901, 'validation/num_examples': 83274637, 'test/loss': 0.1263071380653783, 'test/num_examples': 95000000, 'score': 7372.308820009232, 'total_duration': 50794.36833739281, 'accumulated_submission_time': 7372.308820009232, 'accumulated_eval_time': 43420.21129465103, 'accumulated_logging_time': 1.4311671257019043}
I0307 03:14:03.562617 139711569970944 logging_writer.py:48] [7666] accumulated_eval_time=43420.2, accumulated_logging_time=1.43117, accumulated_submission_time=7372.31, global_step=7666, preemption_count=0, score=7372.31, test/loss=0.126307, test/num_examples=95000000, total_duration=50794.4, train/loss=0.123999, validation/loss=0.123944, validation/num_examples=83274637
I0307 03:14:15.066231 139711578363648 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.011235360987484455, loss=0.12412330508232117
I0307 03:16:03.886260 139865041368256 spec.py:321] Evaluating on the training split.
I0307 03:17:04.242481 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 03:21:25.561676 139865041368256 spec.py:349] Evaluating on the test split.
I0307 03:27:14.572435 139865041368256 submission_runner.py:469] Time since start: 51585.39s, 	Step: 7793, 	{'train/loss': 0.12270960998985003, 'validation/loss': 0.12388461540146259, 'validation/num_examples': 83274637, 'test/loss': 0.12622123579358552, 'test/num_examples': 95000000, 'score': 7492.619068861008, 'total_duration': 51585.38837480545, 'accumulated_submission_time': 7492.619068861008, 'accumulated_eval_time': 44090.89740109444, 'accumulated_logging_time': 1.4480314254760742}
I0307 03:27:14.583028 139711569970944 logging_writer.py:48] [7793] accumulated_eval_time=44090.9, accumulated_logging_time=1.44803, accumulated_submission_time=7492.62, global_step=7793, preemption_count=0, score=7492.62, test/loss=0.126221, test/num_examples=95000000, total_duration=51585.4, train/loss=0.12271, validation/loss=0.123885, validation/num_examples=83274637
I0307 03:27:15.522249 139711578363648 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.005888002458959818, loss=0.12343353778123856
I0307 03:28:49.084607 139711569970944 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.00690413685515523, loss=0.11911838501691818
I0307 03:29:15.785284 139865041368256 spec.py:321] Evaluating on the training split.
I0307 03:30:13.738567 139865041368256 spec.py:333] Evaluating on the validation split.
I0307 03:34:34.400542 139865041368256 spec.py:349] Evaluating on the test split.
I0307 03:40:11.274837 139865041368256 submission_runner.py:469] Time since start: 52362.09s, 	Step: 7924, 	{'train/loss': 0.12359859908011349, 'validation/loss': 0.12395847563434516, 'validation/num_examples': 83274637, 'test/loss': 0.1263160644736842, 'test/num_examples': 95000000, 'score': 7613.8084762096405, 'total_duration': 52362.09078860283, 'accumulated_submission_time': 7613.8084762096405, 'accumulated_eval_time': 44746.38688278198, 'accumulated_logging_time': 1.4650804996490479}
I0307 03:40:11.286675 139711578363648 logging_writer.py:48] [7924] accumulated_eval_time=44746.4, accumulated_logging_time=1.46508, accumulated_submission_time=7613.81, global_step=7924, preemption_count=0, score=7613.81, test/loss=0.126316, test/num_examples=95000000, total_duration=52362.1, train/loss=0.123599, validation/loss=0.123958, validation/num_examples=83274637
I0307 03:41:16.507105 139711569970944 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.015265429392457008, loss=0.11660339683294296
I0307 03:42:11.558042 139711578363648 logging_writer.py:48] [8046] global_step=8046, preemption_count=0, score=7734.06
I0307 03:42:14.682387 139865041368256 submission_runner.py:646] Tuning trial 5/5
I0307 03:42:14.721976 139865041368256 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.1, label_smoothing=0.0, learning_rate=0.0017486387539278373, one_minus_beta1=0.06733926164, beta2=0.9955159689799007, weight_decay=0.08121616522670176, warmup_factor=0.02)
I0307 03:42:14.723415 139865041368256 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/loss': 1.972592979857007, 'validation/loss': 1.972452149975298, 'validation/num_examples': 83274637, 'test/loss': 1.970119709868421, 'test/num_examples': 95000000, 'score': 17.36156940460205, 'total_duration': 1184.376938343048, 'accumulated_submission_time': 17.36156940460205, 'accumulated_eval_time': 1167.0152463912964, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (125, {'train/loss': 0.13147800447384142, 'validation/loss': 0.13101069102566307, 'validation/num_examples': 83274637, 'test/loss': 0.13394166224300988, 'test/num_examples': 95000000, 'score': 137.88437604904175, 'total_duration': 2328.031477689743, 'accumulated_submission_time': 137.88437604904175, 'accumulated_eval_time': 2190.042842388153, 'accumulated_logging_time': 0.0967247486114502, 'global_step': 125, 'preemption_count': 0}), (250, {'train/loss': 0.1291446589730071, 'validation/loss': 0.12996908323405915, 'validation/num_examples': 83274637, 'test/loss': 0.13300554146792762, 'test/num_examples': 95000000, 'score': 258.1208851337433, 'total_duration': 3466.6380219459534, 'accumulated_submission_time': 258.1208851337433, 'accumulated_eval_time': 3208.388557434082, 'accumulated_logging_time': 0.1134030818939209, 'global_step': 250, 'preemption_count': 0}), (369, {'train/loss': 0.12793116676826147, 'validation/loss': 0.12748181834145222, 'validation/num_examples': 83274637, 'test/loss': 0.12988641227384867, 'test/num_examples': 95000000, 'score': 378.49212741851807, 'total_duration': 4638.4382202625275, 'accumulated_submission_time': 378.49212741851807, 'accumulated_eval_time': 4259.752856492996, 'accumulated_logging_time': 0.17062592506408691, 'global_step': 369, 'preemption_count': 0}), (496, {'train/loss': 0.12582093169151237, 'validation/loss': 0.1272729076920297, 'validation/num_examples': 83274637, 'test/loss': 0.12986079280427631, 'test/num_examples': 95000000, 'score': 499.56796288490295, 'total_duration': 5762.051439285278, 'accumulated_submission_time': 499.56796288490295, 'accumulated_eval_time': 5262.250036716461, 'accumulated_logging_time': 0.20361781120300293, 'global_step': 496, 'preemption_count': 0}), (620, {'train/loss': 0.1254835638610072, 'validation/loss': 0.12684869159013867, 'validation/num_examples': 83274637, 'test/loss': 0.12935885636307565, 'test/num_examples': 95000000, 'score': 619.8424777984619, 'total_duration': 6855.52321767807, 'accumulated_submission_time': 619.8424777984619, 'accumulated_eval_time': 6235.426440000534, 'accumulated_logging_time': 0.21775031089782715, 'global_step': 620, 'preemption_count': 0}), (752, {'train/loss': 0.12539261540854876, 'validation/loss': 0.12695798438562805, 'validation/num_examples': 83274637, 'test/loss': 0.1293796773745888, 'test/num_examples': 95000000, 'score': 740.7667157649994, 'total_duration': 7927.455089092255, 'accumulated_submission_time': 740.7667157649994, 'accumulated_eval_time': 7186.4120190143585, 'accumulated_logging_time': 0.23239994049072266, 'global_step': 752, 'preemption_count': 0}), (875, {'train/loss': 0.12566207868263782, 'validation/loss': 0.12653363627278555, 'validation/num_examples': 83274637, 'test/loss': 0.12899452788856908, 'test/num_examples': 95000000, 'score': 860.8952717781067, 'total_duration': 8915.391944885254, 'accumulated_submission_time': 860.8952717781067, 'accumulated_eval_time': 8054.1986429691315, 'accumulated_logging_time': 0.24739480018615723, 'global_step': 875, 'preemption_count': 0}), (1003, {'train/loss': 0.12528002878311295, 'validation/loss': 0.12600059765195976, 'validation/num_examples': 83274637, 'test/loss': 0.12844500265213815, 'test/num_examples': 95000000, 'score': 981.1251287460327, 'total_duration': 9840.12604522705, 'accumulated_submission_time': 981.1251287460327, 'accumulated_eval_time': 8858.681668043137, 'accumulated_logging_time': 0.26180100440979004, 'global_step': 1003, 'preemption_count': 0}), (1131, {'train/loss': 0.12499579486185275, 'validation/loss': 0.1284958704095638, 'validation/num_examples': 83274637, 'test/loss': 0.13098726649876644, 'test/num_examples': 95000000, 'score': 1101.5122396945953, 'total_duration': 10621.871497869492, 'accumulated_submission_time': 1101.5122396945953, 'accumulated_eval_time': 9520.018758296967, 'accumulated_logging_time': 0.27634716033935547, 'global_step': 1131, 'preemption_count': 0}), (1254, {'train/loss': 0.12857875537197544, 'validation/loss': 0.12623873398041463, 'validation/num_examples': 83274637, 'test/loss': 0.12864349541529604, 'test/num_examples': 95000000, 'score': 1221.8905608654022, 'total_duration': 11397.09691977501, 'accumulated_submission_time': 1221.8905608654022, 'accumulated_eval_time': 10174.844587802887, 'accumulated_logging_time': 0.29068994522094727, 'global_step': 1254, 'preemption_count': 0}), (1380, {'train/loss': 0.1238754253787627, 'validation/loss': 0.12624880045751694, 'validation/num_examples': 83274637, 'test/loss': 0.1287062955078125, 'test/num_examples': 95000000, 'score': 1342.039057970047, 'total_duration': 12167.562039136887, 'accumulated_submission_time': 1342.039057970047, 'accumulated_eval_time': 10825.137471914291, 'accumulated_logging_time': 0.30689072608947754, 'global_step': 1380, 'preemption_count': 0}), (1512, {'train/loss': 0.12277510780958259, 'validation/loss': 0.12545797770043493, 'validation/num_examples': 83274637, 'test/loss': 0.12762149575452303, 'test/num_examples': 95000000, 'score': 1463.1147665977478, 'total_duration': 12926.246686458588, 'accumulated_submission_time': 1463.1147665977478, 'accumulated_eval_time': 11462.722916841507, 'accumulated_logging_time': 0.3232078552246094, 'global_step': 1512, 'preemption_count': 0}), (1637, {'train/loss': 0.12469331334409474, 'validation/loss': 0.1260232490343312, 'validation/num_examples': 83274637, 'test/loss': 0.12835216860608553, 'test/num_examples': 95000000, 'score': 1583.622383594513, 'total_duration': 13689.646173715591, 'accumulated_submission_time': 1583.622383594513, 'accumulated_eval_time': 12105.593589782715, 'accumulated_logging_time': 0.3377704620361328, 'global_step': 1637, 'preemption_count': 0}), (1765, {'train/loss': 0.12326435942741686, 'validation/loss': 0.1254087468446988, 'validation/num_examples': 83274637, 'test/loss': 0.12782752257401317, 'test/num_examples': 95000000, 'score': 1703.6552188396454, 'total_duration': 14430.545518875122, 'accumulated_submission_time': 1703.6552188396454, 'accumulated_eval_time': 12726.43807888031, 'accumulated_logging_time': 0.3528621196746826, 'global_step': 1765, 'preemption_count': 0}), (1891, {'train/loss': 0.12580196183385714, 'validation/loss': 0.12626821417074482, 'validation/num_examples': 83274637, 'test/loss': 0.12890123374794407, 'test/num_examples': 95000000, 'score': 1824.8706848621368, 'total_duration': 15197.383055448532, 'accumulated_submission_time': 1824.8706848621368, 'accumulated_eval_time': 13372.037509679794, 'accumulated_logging_time': 0.3685150146484375, 'global_step': 1891, 'preemption_count': 0}), (2017, {'train/loss': 0.12362202993775688, 'validation/loss': 0.12528329007221836, 'validation/num_examples': 83274637, 'test/loss': 0.12763272173108553, 'test/num_examples': 95000000, 'score': 1945.5002789497375, 'total_duration': 15968.62443971634, 'accumulated_submission_time': 1945.5002789497375, 'accumulated_eval_time': 14022.627816200256, 'accumulated_logging_time': 0.383411169052124, 'global_step': 2017, 'preemption_count': 0}), (2146, {'train/loss': 0.1245359933624665, 'validation/loss': 0.1254195780049415, 'validation/num_examples': 83274637, 'test/loss': 0.12775079209498355, 'test/num_examples': 95000000, 'score': 2065.4876477718353, 'total_duration': 16722.116555452347, 'accumulated_submission_time': 2065.4876477718353, 'accumulated_eval_time': 14656.110614538193, 'accumulated_logging_time': 0.39873552322387695, 'global_step': 2146, 'preemption_count': 0}), (2271, {'train/loss': 0.12228986576386967, 'validation/loss': 0.12521852239412193, 'validation/num_examples': 83274637, 'test/loss': 0.12756393913445724, 'test/num_examples': 95000000, 'score': 2185.9515056610107, 'total_duration': 17493.14819931984, 'accumulated_submission_time': 2185.9515056610107, 'accumulated_eval_time': 15306.65669298172, 'accumulated_logging_time': 0.4140334129333496, 'global_step': 2271, 'preemption_count': 0}), (2394, {'train/loss': 0.12281155900197958, 'validation/loss': 0.12506288323554363, 'validation/num_examples': 83274637, 'test/loss': 0.12733497425986842, 'test/num_examples': 95000000, 'score': 2306.419098377228, 'total_duration': 18278.647995233536, 'accumulated_submission_time': 2306.419098377228, 'accumulated_eval_time': 15971.666358709335, 'accumulated_logging_time': 0.42966437339782715, 'global_step': 2394, 'preemption_count': 0}), (2517, {'train/loss': 0.1250451883570578, 'validation/loss': 0.1253004631173745, 'validation/num_examples': 83274637, 'test/loss': 0.12760791852384867, 'test/num_examples': 95000000, 'score': 2427.3290662765503, 'total_duration': 19056.138740062714, 'accumulated_submission_time': 2427.3290662765503, 'accumulated_eval_time': 16628.22469997406, 'accumulated_logging_time': 0.44553327560424805, 'global_step': 2517, 'preemption_count': 0}), (2642, {'train/loss': 0.12467686514481434, 'validation/loss': 0.12483446520926443, 'validation/num_examples': 83274637, 'test/loss': 0.12721343580386513, 'test/num_examples': 95000000, 'score': 2547.735762119293, 'total_duration': 19830.026311159134, 'accumulated_submission_time': 2547.735762119293, 'accumulated_eval_time': 17281.681800842285, 'accumulated_logging_time': 0.46231889724731445, 'global_step': 2642, 'preemption_count': 0}), (2772, {'train/loss': 0.12187498750504833, 'validation/loss': 0.1248254448576788, 'validation/num_examples': 83274637, 'test/loss': 0.12727931628289474, 'test/num_examples': 95000000, 'score': 2668.650507926941, 'total_duration': 20602.80819106102, 'accumulated_submission_time': 2668.650507926941, 'accumulated_eval_time': 17933.495532035828, 'accumulated_logging_time': 0.5086266994476318, 'global_step': 2772, 'preemption_count': 0}), (2896, {'train/loss': 0.1256080889523779, 'validation/loss': 0.12497680612614641, 'validation/num_examples': 83274637, 'test/loss': 0.12736894639185856, 'test/num_examples': 95000000, 'score': 2789.435708999634, 'total_duration': 21364.663791418076, 'accumulated_submission_time': 2789.435708999634, 'accumulated_eval_time': 18574.543964862823, 'accumulated_logging_time': 0.5240743160247803, 'global_step': 2896, 'preemption_count': 0}), (3027, {'train/loss': 0.12278606037392556, 'validation/loss': 0.12520512643125137, 'validation/num_examples': 83274637, 'test/loss': 0.1275594728515625, 'test/num_examples': 95000000, 'score': 2910.146694421768, 'total_duration': 22141.226526498795, 'accumulated_submission_time': 2910.146694421768, 'accumulated_eval_time': 19230.37192630768, 'accumulated_logging_time': 0.5407383441925049, 'global_step': 3027, 'preemption_count': 0}), (3152, {'train/loss': 0.12305885108199509, 'validation/loss': 0.12475046308874184, 'validation/num_examples': 83274637, 'test/loss': 0.12705676150287828, 'test/num_examples': 95000000, 'score': 3030.9786427021027, 'total_duration': 22909.960525751114, 'accumulated_submission_time': 3030.9786427021027, 'accumulated_eval_time': 19878.25231719017, 'accumulated_logging_time': 0.5558595657348633, 'global_step': 3152, 'preemption_count': 0}), (3282, {'train/loss': 0.12317724092482771, 'validation/loss': 0.125401695522589, 'validation/num_examples': 83274637, 'test/loss': 0.12789960460526315, 'test/num_examples': 95000000, 'score': 3151.762377500534, 'total_duration': 23672.65425157547, 'accumulated_submission_time': 3151.762377500534, 'accumulated_eval_time': 20520.139795303345, 'accumulated_logging_time': 0.5720400810241699, 'global_step': 3282, 'preemption_count': 0}), (3408, {'train/loss': 0.12315006217913432, 'validation/loss': 0.12503896775185733, 'validation/num_examples': 83274637, 'test/loss': 0.1275110765830592, 'test/num_examples': 95000000, 'score': 3272.5826694965363, 'total_duration': 24447.401106595993, 'accumulated_submission_time': 3272.5826694965363, 'accumulated_eval_time': 21174.043484210968, 'accumulated_logging_time': 0.5880351066589355, 'global_step': 3408, 'preemption_count': 0}), (3535, {'train/loss': 0.1244228331829017, 'validation/loss': 0.12473789207411601, 'validation/num_examples': 83274637, 'test/loss': 0.12718617180304276, 'test/num_examples': 95000000, 'score': 3392.7539372444153, 'total_duration': 25235.433435440063, 'accumulated_submission_time': 3392.7539372444153, 'accumulated_eval_time': 21841.882022857666, 'accumulated_logging_time': 0.6039283275604248, 'global_step': 3535, 'preemption_count': 0}), (3660, {'train/loss': 0.12164591822140622, 'validation/loss': 0.12475963025076553, 'validation/num_examples': 83274637, 'test/loss': 0.12710908919613487, 'test/num_examples': 95000000, 'score': 3512.822916030884, 'total_duration': 26002.298308610916, 'accumulated_submission_time': 3512.822916030884, 'accumulated_eval_time': 22488.588221549988, 'accumulated_logging_time': 0.6862192153930664, 'global_step': 3660, 'preemption_count': 0}), (3783, {'train/loss': 0.12218525865167942, 'validation/loss': 0.1246299999351093, 'validation/num_examples': 83274637, 'test/loss': 0.1270731060958059, 'test/num_examples': 95000000, 'score': 3632.8586564064026, 'total_duration': 26780.904814958572, 'accumulated_submission_time': 3632.8586564064026, 'accumulated_eval_time': 23147.136930704117, 'accumulated_logging_time': 0.7024886608123779, 'global_step': 3783, 'preemption_count': 0}), (3909, {'train/loss': 0.12370519409155321, 'validation/loss': 0.12478973977108683, 'validation/num_examples': 83274637, 'test/loss': 0.1270896820518092, 'test/num_examples': 95000000, 'score': 3753.4954929351807, 'total_duration': 27538.337899684906, 'accumulated_submission_time': 3753.4954929351807, 'accumulated_eval_time': 23783.90933561325, 'accumulated_logging_time': 0.7199935913085938, 'global_step': 3909, 'preemption_count': 0}), (4029, {'train/loss': 0.12351017204002014, 'validation/loss': 0.12467005927810101, 'validation/num_examples': 83274637, 'test/loss': 0.1271703711040296, 'test/num_examples': 95000000, 'score': 3874.429486989975, 'total_duration': 28305.0885617733, 'accumulated_submission_time': 3874.429486989975, 'accumulated_eval_time': 24429.700989484787, 'accumulated_logging_time': 0.7382345199584961, 'global_step': 4029, 'preemption_count': 0}), (4158, {'train/loss': 0.12411163361895385, 'validation/loss': 0.1246524716538242, 'validation/num_examples': 83274637, 'test/loss': 0.12708525364925988, 'test/num_examples': 95000000, 'score': 3994.628307580948, 'total_duration': 29079.48060965538, 'accumulated_submission_time': 3994.628307580948, 'accumulated_eval_time': 25083.871973514557, 'accumulated_logging_time': 0.7537219524383545, 'global_step': 4158, 'preemption_count': 0}), (4281, {'train/loss': 0.12237459986980231, 'validation/loss': 0.12507064313291452, 'validation/num_examples': 83274637, 'test/loss': 0.12771258269942434, 'test/num_examples': 95000000, 'score': 4114.814796209335, 'total_duration': 29853.75492668152, 'accumulated_submission_time': 4114.814796209335, 'accumulated_eval_time': 25737.937618017197, 'accumulated_logging_time': 0.769340991973877, 'global_step': 4281, 'preemption_count': 0}), (4407, {'train/loss': 0.12289856916656659, 'validation/loss': 0.12461468716313835, 'validation/num_examples': 83274637, 'test/loss': 0.12697791967516447, 'test/num_examples': 95000000, 'score': 4235.856360673904, 'total_duration': 30631.43055677414, 'accumulated_submission_time': 4235.856360673904, 'accumulated_eval_time': 26394.549590349197, 'accumulated_logging_time': 0.7852036952972412, 'global_step': 4407, 'preemption_count': 0}), (4533, {'train/loss': 0.12237647265992449, 'validation/loss': 0.12434284713825142, 'validation/num_examples': 83274637, 'test/loss': 0.1269124599917763, 'test/num_examples': 95000000, 'score': 4356.4244556427, 'total_duration': 31395.365745067596, 'accumulated_submission_time': 4356.4244556427, 'accumulated_eval_time': 27037.860816717148, 'accumulated_logging_time': 0.8345828056335449, 'global_step': 4533, 'preemption_count': 0}), (4661, {'train/loss': 0.12115773723794604, 'validation/loss': 0.12439585083695899, 'validation/num_examples': 83274637, 'test/loss': 0.12683016449424342, 'test/num_examples': 95000000, 'score': 4476.567169904709, 'total_duration': 32170.001632213593, 'accumulated_submission_time': 4476.567169904709, 'accumulated_eval_time': 27692.33120584488, 'accumulated_logging_time': 0.8507177829742432, 'global_step': 4661, 'preemption_count': 0}), (4790, {'train/loss': 0.12397603864002528, 'validation/loss': 0.12433848484298632, 'validation/num_examples': 83274637, 'test/loss': 0.12684073392269737, 'test/num_examples': 95000000, 'score': 4596.780594587326, 'total_duration': 32949.25524020195, 'accumulated_submission_time': 4596.780594587326, 'accumulated_eval_time': 28351.348131656647, 'accumulated_logging_time': 0.866657018661499, 'global_step': 4790, 'preemption_count': 0}), (4920, {'train/loss': 0.12287534676117343, 'validation/loss': 0.12415881947429339, 'validation/num_examples': 83274637, 'test/loss': 0.12655607018914475, 'test/num_examples': 95000000, 'score': 4717.340375423431, 'total_duration': 33719.217500925064, 'accumulated_submission_time': 4717.340375423431, 'accumulated_eval_time': 29000.728383779526, 'accumulated_logging_time': 0.8826417922973633, 'global_step': 4920, 'preemption_count': 0}), (5039, {'train/loss': 0.12229652480228143, 'validation/loss': 0.12433123311800282, 'validation/num_examples': 83274637, 'test/loss': 0.12670037003495066, 'test/num_examples': 95000000, 'score': 4837.363646507263, 'total_duration': 34485.5779876709, 'accumulated_submission_time': 4837.363646507263, 'accumulated_eval_time': 29647.042902469635, 'accumulated_logging_time': 0.8986783027648926, 'global_step': 5039, 'preemption_count': 0}), (5161, {'train/loss': 0.12325363068507528, 'validation/loss': 0.1243437993949166, 'validation/num_examples': 83274637, 'test/loss': 0.12676590653782896, 'test/num_examples': 95000000, 'score': 4958.840138196945, 'total_duration': 35257.97181534767, 'accumulated_submission_time': 4958.840138196945, 'accumulated_eval_time': 30297.93617129326, 'accumulated_logging_time': 0.916257381439209, 'global_step': 5161, 'preemption_count': 0}), (5287, {'train/loss': 0.12214451938070967, 'validation/loss': 0.12448618465748686, 'validation/num_examples': 83274637, 'test/loss': 0.12687910025699012, 'test/num_examples': 95000000, 'score': 5079.091540813446, 'total_duration': 36029.86261796951, 'accumulated_submission_time': 5079.091540813446, 'accumulated_eval_time': 30949.54853796959, 'accumulated_logging_time': 0.9365813732147217, 'global_step': 5287, 'preemption_count': 0}), (5414, {'train/loss': 0.12143726016646661, 'validation/loss': 0.12431993511135592, 'validation/num_examples': 83274637, 'test/loss': 0.1266653302528783, 'test/num_examples': 95000000, 'score': 5200.039031267166, 'total_duration': 36801.459287405014, 'accumulated_submission_time': 5200.039031267166, 'accumulated_eval_time': 31600.15849661827, 'accumulated_logging_time': 0.9690985679626465, 'global_step': 5414, 'preemption_count': 0}), (5538, {'train/loss': 0.12209599489732734, 'validation/loss': 0.12424783817514945, 'validation/num_examples': 83274637, 'test/loss': 0.12655464939350328, 'test/num_examples': 95000000, 'score': 5321.631330728531, 'total_duration': 37574.666451215744, 'accumulated_submission_time': 5321.631330728531, 'accumulated_eval_time': 32251.748555898666, 'accumulated_logging_time': 0.9868378639221191, 'global_step': 5538, 'preemption_count': 0}), (5666, {'train/loss': 0.12163322983579065, 'validation/loss': 0.12453471575667338, 'validation/num_examples': 83274637, 'test/loss': 0.12695514778988487, 'test/num_examples': 95000000, 'score': 5442.332728862762, 'total_duration': 38350.17497897148, 'accumulated_submission_time': 5442.332728862762, 'accumulated_eval_time': 32906.530125141144, 'accumulated_logging_time': 1.0043795108795166, 'global_step': 5666, 'preemption_count': 0}), (5788, {'train/loss': 0.12286142632365227, 'validation/loss': 0.12462021526392056, 'validation/num_examples': 83274637, 'test/loss': 0.12697909620682565, 'test/num_examples': 95000000, 'score': 5563.126938343048, 'total_duration': 39116.718750715256, 'accumulated_submission_time': 5563.126938343048, 'accumulated_eval_time': 33552.25583744049, 'accumulated_logging_time': 1.0215568542480469, 'global_step': 5788, 'preemption_count': 0}), (5910, {'train/loss': 0.1227066037860119, 'validation/loss': 0.12441863638218824, 'validation/num_examples': 83274637, 'test/loss': 0.12667101260279606, 'test/num_examples': 95000000, 'score': 5683.617914915085, 'total_duration': 39901.398755311966, 'accumulated_submission_time': 5683.617914915085, 'accumulated_eval_time': 34216.377111911774, 'accumulated_logging_time': 1.0827691555023193, 'global_step': 5910, 'preemption_count': 0}), (6039, {'train/loss': 0.12196214542776909, 'validation/loss': 0.1242677823244932, 'validation/num_examples': 83274637, 'test/loss': 0.12663335814144736, 'test/num_examples': 95000000, 'score': 5803.99795794487, 'total_duration': 40679.30836939812, 'accumulated_submission_time': 5803.99795794487, 'accumulated_eval_time': 34873.882536649704, 'accumulated_logging_time': 1.0998148918151855, 'global_step': 6039, 'preemption_count': 0}), (6159, {'train/loss': 0.12422683294979656, 'validation/loss': 0.12428363042274317, 'validation/num_examples': 83274637, 'test/loss': 0.12656100262129935, 'test/num_examples': 95000000, 'score': 5924.268723726273, 'total_duration': 41437.14596533775, 'accumulated_submission_time': 5924.268723726273, 'accumulated_eval_time': 35511.42207694054, 'accumulated_logging_time': 1.1195969581604004, 'global_step': 6159, 'preemption_count': 0}), (6286, {'train/loss': 0.12274382081843398, 'validation/loss': 0.12426158376123235, 'validation/num_examples': 83274637, 'test/loss': 0.12665356061883223, 'test/num_examples': 95000000, 'score': 6046.040119171143, 'total_duration': 42211.679231882095, 'accumulated_submission_time': 6046.040119171143, 'accumulated_eval_time': 36164.16054081917, 'accumulated_logging_time': 1.1359503269195557, 'global_step': 6286, 'preemption_count': 0}), (6413, {'train/loss': 0.123363839204675, 'validation/loss': 0.1241623913045866, 'validation/num_examples': 83274637, 'test/loss': 0.12648813510485196, 'test/num_examples': 95000000, 'score': 6166.605379104614, 'total_duration': 42997.054936885834, 'accumulated_submission_time': 6166.605379104614, 'accumulated_eval_time': 36828.94765996933, 'accumulated_logging_time': 1.15232253074646, 'global_step': 6413, 'preemption_count': 0}), (6538, {'train/loss': 0.12157355654258398, 'validation/loss': 0.12410011287785619, 'validation/num_examples': 83274637, 'test/loss': 0.1264757349712171, 'test/num_examples': 95000000, 'score': 6287.344458818436, 'total_duration': 43768.371727705, 'accumulated_submission_time': 6287.344458818436, 'accumulated_eval_time': 37479.50123167038, 'accumulated_logging_time': 1.1698594093322754, 'global_step': 6538, 'preemption_count': 0}), (6664, {'train/loss': 0.12499148651676358, 'validation/loss': 0.12421684171760859, 'validation/num_examples': 83274637, 'test/loss': 0.12666974700863487, 'test/num_examples': 95000000, 'score': 6407.414861679077, 'total_duration': 44535.52385735512, 'accumulated_submission_time': 6407.414861679077, 'accumulated_eval_time': 38126.55963182449, 'accumulated_logging_time': 1.186309576034546, 'global_step': 6664, 'preemption_count': 0}), (6788, {'train/loss': 0.1222525186860149, 'validation/loss': 0.12424062695525845, 'validation/num_examples': 83274637, 'test/loss': 0.12661233439555922, 'test/num_examples': 95000000, 'score': 6527.345878362656, 'total_duration': 45330.2020945549, 'accumulated_submission_time': 6527.345878362656, 'accumulated_eval_time': 38801.211453676224, 'accumulated_logging_time': 1.2748687267303467, 'global_step': 6788, 'preemption_count': 0}), (6917, {'train/loss': 0.12363491481486356, 'validation/loss': 0.12408830923185607, 'validation/num_examples': 83274637, 'test/loss': 0.12646368057154606, 'test/num_examples': 95000000, 'score': 6648.133413314819, 'total_duration': 46122.28507947922, 'accumulated_submission_time': 6648.133413314819, 'accumulated_eval_time': 39472.482355594635, 'accumulated_logging_time': 1.2916154861450195, 'global_step': 6917, 'preemption_count': 0}), (7043, {'train/loss': 0.12138971070167404, 'validation/loss': 0.12381238517606057, 'validation/num_examples': 83274637, 'test/loss': 0.12613596762952303, 'test/num_examples': 95000000, 'score': 6769.644779205322, 'total_duration': 46911.45415663719, 'accumulated_submission_time': 6769.644779205322, 'accumulated_eval_time': 40140.11620569229, 'accumulated_logging_time': 1.3090593814849854, 'global_step': 7043, 'preemption_count': 0}), (7169, {'train/loss': 0.12177030388382995, 'validation/loss': 0.12385254436281534, 'validation/num_examples': 83274637, 'test/loss': 0.12615895728824014, 'test/num_examples': 95000000, 'score': 6890.001515388489, 'total_duration': 47681.62378334999, 'accumulated_submission_time': 6890.001515388489, 'accumulated_eval_time': 40789.905323028564, 'accumulated_logging_time': 1.3260564804077148, 'global_step': 7169, 'preemption_count': 0}), (7291, {'train/loss': 0.12300953145999953, 'validation/loss': 0.12391244471609796, 'validation/num_examples': 83274637, 'test/loss': 0.12622773505345394, 'test/num_examples': 95000000, 'score': 7010.998081684113, 'total_duration': 48453.82627415657, 'accumulated_submission_time': 7010.998081684113, 'accumulated_eval_time': 41441.08750271797, 'accumulated_logging_time': 1.3426883220672607, 'global_step': 7291, 'preemption_count': 0}), (7416, {'train/loss': 0.12327715087939733, 'validation/loss': 0.12386703994395865, 'validation/num_examples': 83274637, 'test/loss': 0.12621523718133223, 'test/num_examples': 95000000, 'score': 7131.463647603989, 'total_duration': 49237.13542175293, 'accumulated_submission_time': 7131.463647603989, 'accumulated_eval_time': 42103.9080517292, 'accumulated_logging_time': 1.3594460487365723, 'global_step': 7416, 'preemption_count': 0}), (7539, {'train/loss': 0.12214070819786885, 'validation/loss': 0.12397056804623928, 'validation/num_examples': 83274637, 'test/loss': 0.12639074190995067, 'test/num_examples': 95000000, 'score': 7252.208505868912, 'total_duration': 50021.88802719116, 'accumulated_submission_time': 7252.208505868912, 'accumulated_eval_time': 42767.89265561104, 'accumulated_logging_time': 1.3762896060943604, 'global_step': 7539, 'preemption_count': 0}), (7666, {'train/loss': 0.12399919899239105, 'validation/loss': 0.1239440179079901, 'validation/num_examples': 83274637, 'test/loss': 0.1263071380653783, 'test/num_examples': 95000000, 'score': 7372.308820009232, 'total_duration': 50794.36833739281, 'accumulated_submission_time': 7372.308820009232, 'accumulated_eval_time': 43420.21129465103, 'accumulated_logging_time': 1.4311671257019043, 'global_step': 7666, 'preemption_count': 0}), (7793, {'train/loss': 0.12270960998985003, 'validation/loss': 0.12388461540146259, 'validation/num_examples': 83274637, 'test/loss': 0.12622123579358552, 'test/num_examples': 95000000, 'score': 7492.619068861008, 'total_duration': 51585.38837480545, 'accumulated_submission_time': 7492.619068861008, 'accumulated_eval_time': 44090.89740109444, 'accumulated_logging_time': 1.4480314254760742, 'global_step': 7793, 'preemption_count': 0}), (7924, {'train/loss': 0.12359859908011349, 'validation/loss': 0.12395847563434516, 'validation/num_examples': 83274637, 'test/loss': 0.1263160644736842, 'test/num_examples': 95000000, 'score': 7613.8084762096405, 'total_duration': 52362.09078860283, 'accumulated_submission_time': 7613.8084762096405, 'accumulated_eval_time': 44746.38688278198, 'accumulated_logging_time': 1.4650804996490479, 'global_step': 7924, 'preemption_count': 0})], 'global_step': 8046}
I0307 03:42:14.723514 139865041368256 submission_runner.py:649] Timing: 7734.059682130814
I0307 03:42:14.723551 139865041368256 submission_runner.py:651] Total number of evals: 64
I0307 03:42:14.723580 139865041368256 submission_runner.py:652] ====================
I0307 03:42:14.723743 139865041368256 submission_runner.py:750] Final criteo1tb score: 4
