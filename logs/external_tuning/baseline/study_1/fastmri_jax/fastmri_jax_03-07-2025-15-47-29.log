python submission_runner.py --framework=jax --workload=fastmri --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/baseline/study_1 --overwrite=True --save_checkpoints=False --rng_seed=981004931 --tuning_ruleset=external --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=3 --hparam_end_index=4 2>&1 | tee -a /logs/fastmri_jax_03-07-2025-15-47-29.log
2025-03-07 15:47:35.507023: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741362455.625254       8 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741362455.637102       8 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
I0307 15:47:54.760143 140166018147520 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/fastmri_jax.
I0307 15:47:55.930721 140166018147520 xla_bridge.py:884] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0307 15:47:55.933996 140166018147520 xla_bridge.py:884] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
I0307 15:47:55.935724 140166018147520 submission_runner.py:606] Using RNG seed 981004931
I0307 15:47:56.635807 140166018147520 submission_runner.py:615] --- Tuning run 4/5 ---
I0307 15:47:56.636022 140166018147520 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/fastmri_jax/trial_4.
I0307 15:47:56.636252 140166018147520 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/fastmri_jax/trial_4/hparams.json.
I0307 15:47:56.879488 140166018147520 submission_runner.py:218] Initializing dataset.
I0307 15:48:02.006349 140166018147520 submission_runner.py:229] Initializing model.
I0307 15:48:12.310292 140166018147520 submission_runner.py:272] Initializing optimizer.
I0307 15:48:12.798482 140166018147520 submission_runner.py:279] Initializing metrics bundle.
I0307 15:48:12.798707 140166018147520 submission_runner.py:301] Initializing checkpoint and logger.
I0307 15:48:12.799511 140166018147520 checkpoints.py:1101] Found no checkpoint files in /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/fastmri_jax/trial_4 with prefix checkpoint_
I0307 15:48:12.799621 140166018147520 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/fastmri_jax/trial_4/meta_data_0.json.
I0307 15:48:12.799798 140166018147520 logger_utils.py:262] Unable to record workload.train_mean information. Continuing without it.
I0307 15:48:12.799848 140166018147520 logger_utils.py:262] Unable to record workload.train_stddev information. Continuing without it.
I0307 15:48:13.145941 140166018147520 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/baseline/study_1/fastmri_jax/trial_4/flags_0.json.
I0307 15:48:13.193355 140166018147520 submission_runner.py:337] Starting training loop.
E0307 15:51:51.836804       8 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:51:52.050303       8 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:51:52.485775       8 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:51:52.698954       8 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:51:54.576809       8 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
E0307 15:51:54.789929       8 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.
I0307 15:52:06.529864 140029313656576 logging_writer.py:48] [0] global_step=0, grad_norm=5.4760966300964355, loss=0.9737001657485962
I0307 15:52:06.587546 140166018147520 spec.py:321] Evaluating on the training split.
I0307 15:53:11.078619 140166018147520 spec.py:333] Evaluating on the validation split.
I0307 15:53:35.721639 140166018147520 spec.py:349] Evaluating on the test split.
I0307 15:53:58.604880 140166018147520 submission_runner.py:469] Time since start: 345.41s, 	Step: 1, 	{'train/ssim': 0.21437570026942662, 'train/loss': 1.0265536989484514, 'validation/ssim': 0.20786135560284186, 'validation/loss': 1.0358130391152574, 'validation/num_examples': 3554, 'test/ssim': 0.22986473886702388, 'test/loss': 1.0333816114999301, 'test/num_examples': 3581, 'score': 233.39404225349426, 'total_duration': 345.4114670753479, 'accumulated_submission_time': 233.39404225349426, 'accumulated_eval_time': 112.01727485656738, 'accumulated_logging_time': 0}
I0307 15:53:58.613896 140010363811584 logging_writer.py:48] [1] accumulated_eval_time=112.017, accumulated_logging_time=0, accumulated_submission_time=233.394, global_step=1, preemption_count=0, score=233.394, test/loss=1.03338, test/num_examples=3581, test/ssim=0.229865, total_duration=345.411, train/loss=1.02655, train/ssim=0.214376, validation/loss=1.03581, validation/num_examples=3554, validation/ssim=0.207861
I0307 15:54:11.610013 140010355418880 logging_writer.py:48] [100] global_step=100, grad_norm=0.407272070646286, loss=0.3292451500892639
I0307 15:54:29.527134 140010363811584 logging_writer.py:48] [200] global_step=200, grad_norm=0.38185179233551025, loss=0.22660504281520844
I0307 15:54:46.576192 140010355418880 logging_writer.py:48] [300] global_step=300, grad_norm=0.36910325288772583, loss=0.3398393988609314
I0307 15:55:05.913539 140010363811584 logging_writer.py:48] [400] global_step=400, grad_norm=0.3700956404209137, loss=0.3404834568500519
I0307 15:55:18.866060 140166018147520 spec.py:321] Evaluating on the training split.
I0307 15:55:20.504748 140166018147520 spec.py:333] Evaluating on the validation split.
I0307 15:55:21.804660 140166018147520 spec.py:349] Evaluating on the test split.
I0307 15:55:23.106076 140166018147520 submission_runner.py:469] Time since start: 429.91s, 	Step: 471, 	{'train/ssim': 0.7108235359191895, 'train/loss': 0.2924417087009975, 'validation/ssim': 0.693803416924592, 'validation/loss': 0.3083846779706844, 'validation/num_examples': 3554, 'test/ssim': 0.710609229374651, 'test/loss': 0.31044058758464815, 'test/num_examples': 3581, 'score': 313.5565273761749, 'total_duration': 429.9126660823822, 'accumulated_submission_time': 313.5565273761749, 'accumulated_eval_time': 116.25725507736206, 'accumulated_logging_time': 0.018039464950561523}
I0307 15:55:23.119307 140010355418880 logging_writer.py:48] [471] accumulated_eval_time=116.257, accumulated_logging_time=0.0180395, accumulated_submission_time=313.557, global_step=471, preemption_count=0, score=313.557, test/loss=0.310441, test/num_examples=3581, test/ssim=0.710609, total_duration=429.913, train/loss=0.292442, train/ssim=0.710824, validation/loss=0.308385, validation/num_examples=3554, validation/ssim=0.693803
I0307 15:55:25.574738 140010363811584 logging_writer.py:48] [500] global_step=500, grad_norm=0.1872798651456833, loss=0.43248867988586426
I0307 15:55:46.738705 140010355418880 logging_writer.py:48] [600] global_step=600, grad_norm=0.24626825749874115, loss=0.2908187806606293
I0307 15:56:06.813715 140010363811584 logging_writer.py:48] [700] global_step=700, grad_norm=0.1707531213760376, loss=0.2411825805902481
I0307 15:56:27.120873 140010355418880 logging_writer.py:48] [800] global_step=800, grad_norm=0.41948583722114563, loss=0.20312316715717316
I0307 15:56:43.177684 140166018147520 spec.py:321] Evaluating on the training split.
I0307 15:56:44.478429 140166018147520 spec.py:333] Evaluating on the validation split.
I0307 15:56:45.804111 140166018147520 spec.py:349] Evaluating on the test split.
I0307 15:56:47.113259 140166018147520 submission_runner.py:469] Time since start: 513.92s, 	Step: 882, 	{'train/ssim': 0.7296473639351981, 'train/loss': 0.28060964175633024, 'validation/ssim': 0.7089810089643711, 'validation/loss': 0.29821588433587154, 'validation/num_examples': 3554, 'test/ssim': 0.7263421530298799, 'test/loss': 0.29981839100897095, 'test/num_examples': 3581, 'score': 393.52272605895996, 'total_duration': 513.9198377132416, 'accumulated_submission_time': 393.52272605895996, 'accumulated_eval_time': 120.19277620315552, 'accumulated_logging_time': 0.043900251388549805}
I0307 15:56:47.123707 140010363811584 logging_writer.py:48] [882] accumulated_eval_time=120.193, accumulated_logging_time=0.0439003, accumulated_submission_time=393.523, global_step=882, preemption_count=0, score=393.523, test/loss=0.299818, test/num_examples=3581, test/ssim=0.726342, total_duration=513.92, train/loss=0.28061, train/ssim=0.729647, validation/loss=0.298216, validation/num_examples=3554, validation/ssim=0.708981
I0307 15:56:48.716105 140010355418880 logging_writer.py:48] [900] global_step=900, grad_norm=0.2494485229253769, loss=0.2759212851524353
I0307 15:57:04.241747 140010363811584 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.2641397714614868, loss=0.2413228303194046
I0307 15:57:12.506721 140010355418880 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.1705283522605896, loss=0.30276334285736084
I0307 15:57:20.739253 140010363811584 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.13050909340381622, loss=0.3166079819202423
I0307 15:57:28.953664 140010355418880 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.22092205286026, loss=0.2218484878540039
I0307 15:57:37.191557 140010363811584 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.10286137461662292, loss=0.2822622060775757
I0307 15:57:45.452965 140010355418880 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.11643905192613602, loss=0.34835898876190186
I0307 15:57:53.680069 140010363811584 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.30058181285858154, loss=0.21579985320568085
I0307 15:58:01.912952 140010355418880 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.13647621870040894, loss=0.29923948645591736
I0307 15:58:07.183398 140166018147520 spec.py:321] Evaluating on the training split.
I0307 15:58:08.485504 140166018147520 spec.py:333] Evaluating on the validation split.
I0307 15:58:09.793169 140166018147520 spec.py:349] Evaluating on the test split.
I0307 15:58:11.115649 140166018147520 submission_runner.py:469] Time since start: 597.92s, 	Step: 1765, 	{'train/ssim': 0.7380094528198242, 'train/loss': 0.27636275972638813, 'validation/ssim': 0.7180587948878024, 'validation/loss': 0.2939740268447524, 'validation/num_examples': 3554, 'test/ssim': 0.7352173908300754, 'test/loss': 0.29559603991770805, 'test/num_examples': 3581, 'score': 473.51234769821167, 'total_duration': 597.9222173690796, 'accumulated_submission_time': 473.51234769821167, 'accumulated_eval_time': 124.1249623298645, 'accumulated_logging_time': 0.06682133674621582}
I0307 15:58:11.126091 140010363811584 logging_writer.py:48] [1765] accumulated_eval_time=124.125, accumulated_logging_time=0.0668213, accumulated_submission_time=473.512, global_step=1765, preemption_count=0, score=473.512, test/loss=0.295596, test/num_examples=3581, test/ssim=0.735217, total_duration=597.922, train/loss=0.276363, train/ssim=0.738009, validation/loss=0.293974, validation/num_examples=3554, validation/ssim=0.718059
I0307 15:58:14.098289 140010355418880 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.24257367849349976, loss=0.249252051115036
I0307 15:58:22.332798 140010363811584 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.21334263682365417, loss=0.3239692449569702
I0307 15:58:30.587091 140010355418880 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.18770062923431396, loss=0.25653108954429626
I0307 15:58:38.824729 140010363811584 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.1735234558582306, loss=0.2965559959411621
I0307 15:58:47.066783 140010355418880 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.12281596660614014, loss=0.25011909008026123
I0307 15:58:55.290392 140010363811584 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.19365517795085907, loss=0.2661277949810028
I0307 15:59:03.532182 140010355418880 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.29811999201774597, loss=0.2442830353975296
I0307 15:59:11.777907 140010363811584 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.22761495411396027, loss=0.3252400755882263
I0307 15:59:20.020996 140010355418880 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.26086336374282837, loss=0.2522740960121155
I0307 15:59:28.237858 140010363811584 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.33646243810653687, loss=0.30610784888267517
I0307 15:59:31.125020 140166018147520 spec.py:321] Evaluating on the training split.
I0307 15:59:32.428580 140166018147520 spec.py:333] Evaluating on the validation split.
I0307 15:59:33.735926 140166018147520 spec.py:349] Evaluating on the test split.
I0307 15:59:35.043750 140166018147520 submission_runner.py:469] Time since start: 681.85s, 	Step: 2736, 	{'train/ssim': 0.7322846140180316, 'train/loss': 0.2750471660069057, 'validation/ssim': 0.7128382797112408, 'validation/loss': 0.29234991465382315, 'validation/num_examples': 3554, 'test/ssim': 0.7303658714177255, 'test/loss': 0.293825048869031, 'test/num_examples': 3581, 'score': 553.4525375366211, 'total_duration': 681.8503429889679, 'accumulated_submission_time': 553.4525375366211, 'accumulated_eval_time': 128.04365730285645, 'accumulated_logging_time': 0.08536815643310547}
I0307 15:59:35.053302 140010355418880 logging_writer.py:48] [2736] accumulated_eval_time=128.044, accumulated_logging_time=0.0853682, accumulated_submission_time=553.453, global_step=2736, preemption_count=0, score=553.453, test/loss=0.293825, test/num_examples=3581, test/ssim=0.730366, total_duration=681.85, train/loss=0.275047, train/ssim=0.732285, validation/loss=0.29235, validation/num_examples=3554, validation/ssim=0.712838
I0307 15:59:40.403902 140010363811584 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.2586077153682709, loss=0.356244832277298
I0307 15:59:48.647963 140010355418880 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.11812538653612137, loss=0.30255937576293945
I0307 15:59:56.866732 140010363811584 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.13813401758670807, loss=0.2446533739566803
I0307 16:00:05.099030 140010355418880 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.11132638901472092, loss=0.2809801697731018
I0307 16:00:13.316712 140010363811584 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.2764773666858673, loss=0.25506511330604553
I0307 16:00:21.553686 140010355418880 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.3863641321659088, loss=0.2838786244392395
I0307 16:00:29.790021 140010363811584 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.12062031030654907, loss=0.23898708820343018
I0307 16:00:38.027470 140010355418880 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.24896082282066345, loss=0.28182825446128845
I0307 16:00:46.253361 140010363811584 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.18436454236507416, loss=0.25946044921875
I0307 16:00:54.470432 140010355418880 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.28432512283325195, loss=0.281281054019928
I0307 16:00:55.053939 140166018147520 spec.py:321] Evaluating on the training split.
I0307 16:00:56.361922 140166018147520 spec.py:333] Evaluating on the validation split.
I0307 16:00:57.669308 140166018147520 spec.py:349] Evaluating on the test split.
I0307 16:00:58.978326 140166018147520 submission_runner.py:469] Time since start: 765.78s, 	Step: 3708, 	{'train/ssim': 0.7373841149466378, 'train/loss': 0.2745167187282017, 'validation/ssim': 0.716757650380733, 'validation/loss': 0.2921939092066158, 'validation/num_examples': 3554, 'test/ssim': 0.7342412373900447, 'test/loss': 0.2936962972436994, 'test/num_examples': 3581, 'score': 633.392215013504, 'total_duration': 765.7849185466766, 'accumulated_submission_time': 633.392215013504, 'accumulated_eval_time': 131.96801352500916, 'accumulated_logging_time': 0.10438728332519531}
I0307 16:00:58.988086 140010363811584 logging_writer.py:48] [3708] accumulated_eval_time=131.968, accumulated_logging_time=0.104387, accumulated_submission_time=633.392, global_step=3708, preemption_count=0, score=633.392, test/loss=0.293696, test/num_examples=3581, test/ssim=0.734241, total_duration=765.785, train/loss=0.274517, train/ssim=0.737384, validation/loss=0.292194, validation/num_examples=3554, validation/ssim=0.716758
I0307 16:01:06.658999 140010355418880 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.11958292871713638, loss=0.280242919921875
I0307 16:01:14.897605 140010363811584 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.38707804679870605, loss=0.28437718749046326
I0307 16:01:23.104803 140010355418880 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.0974881500005722, loss=0.2514454126358032
I0307 16:01:31.324404 140010363811584 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.12598857283592224, loss=0.33615463972091675
I0307 16:01:39.566848 140010355418880 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.11926022917032242, loss=0.22995074093341827
I0307 16:01:47.781094 140010363811584 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.20944920182228088, loss=0.2613058090209961
I0307 16:01:56.001408 140010355418880 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.10379932820796967, loss=0.2730811536312103
I0307 16:02:04.238052 140010363811584 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.11756256967782974, loss=0.2605670094490051
I0307 16:02:12.468113 140010355418880 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.1618136763572693, loss=0.2612290680408478
I0307 16:02:19.048013 140166018147520 spec.py:321] Evaluating on the training split.
I0307 16:02:20.350457 140166018147520 spec.py:333] Evaluating on the validation split.
I0307 16:02:21.657078 140166018147520 spec.py:349] Evaluating on the test split.
I0307 16:02:22.963325 140166018147520 submission_runner.py:469] Time since start: 849.77s, 	Step: 4681, 	{'train/ssim': 0.7371012823922294, 'train/loss': 0.2728183610098703, 'validation/ssim': 0.7170827132500351, 'validation/loss': 0.2903662892493493, 'validation/num_examples': 3554, 'test/ssim': 0.7344531986307945, 'test/loss': 0.2918735941972389, 'test/num_examples': 3581, 'score': 713.3908176422119, 'total_duration': 849.7699213027954, 'accumulated_submission_time': 713.3908176422119, 'accumulated_eval_time': 135.88328075408936, 'accumulated_logging_time': 0.12425923347473145}
I0307 16:02:22.973451 140010363811584 logging_writer.py:48] [4681] accumulated_eval_time=135.883, accumulated_logging_time=0.124259, accumulated_submission_time=713.391, global_step=4681, preemption_count=0, score=713.391, test/loss=0.291874, test/num_examples=3581, test/ssim=0.734453, total_duration=849.77, train/loss=0.272818, train/ssim=0.737101, validation/loss=0.290366, validation/num_examples=3554, validation/ssim=0.717083
I0307 16:02:24.646786 140010355418880 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.0834907591342926, loss=0.24434919655323029
I0307 16:02:32.871126 140010363811584 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.110115647315979, loss=0.2824091613292694
I0307 16:02:41.097403 140010355418880 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.22408196330070496, loss=0.2707381546497345
I0307 16:02:49.355687 140010363811584 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.1308208853006363, loss=0.3250517249107361
I0307 16:02:57.584109 140010355418880 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.2951078712940216, loss=0.27792516350746155
I0307 16:03:05.806953 140010363811584 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.11963434517383575, loss=0.23433920741081238
I0307 16:03:14.027413 140010355418880 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.16624169051647186, loss=0.2901681363582611
I0307 16:03:22.253257 140010363811584 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.3130989074707031, loss=0.22653943300247192
I0307 16:03:30.466745 140010355418880 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.11969355493783951, loss=0.31210535764694214
I0307 16:03:38.685430 140010363811584 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.2601161301136017, loss=0.26239535212516785
I0307 16:03:42.967754 140166018147520 spec.py:321] Evaluating on the training split.
I0307 16:03:44.272963 140166018147520 spec.py:333] Evaluating on the validation split.
I0307 16:03:45.580549 140166018147520 spec.py:349] Evaluating on the test split.
I0307 16:03:46.889253 140166018147520 submission_runner.py:469] Time since start: 933.70s, 	Step: 5653, 	{'train/ssim': 0.7348335811070034, 'train/loss': 0.2736290012087141, 'validation/ssim': 0.7152937683551984, 'validation/loss': 0.29119120840953855, 'validation/num_examples': 3554, 'test/ssim': 0.7323459261990366, 'test/loss': 0.29272334810676137, 'test/num_examples': 3581, 'score': 793.3245630264282, 'total_duration': 933.6958382129669, 'accumulated_submission_time': 793.3245630264282, 'accumulated_eval_time': 139.80472612380981, 'accumulated_logging_time': 0.14273548126220703}
I0307 16:03:46.899219 140010355418880 logging_writer.py:48] [5653] accumulated_eval_time=139.805, accumulated_logging_time=0.142735, accumulated_submission_time=793.325, global_step=5653, preemption_count=0, score=793.325, test/loss=0.292723, test/num_examples=3581, test/ssim=0.732346, total_duration=933.696, train/loss=0.273629, train/ssim=0.734834, validation/loss=0.291191, validation/num_examples=3554, validation/ssim=0.715294
I0307 16:03:50.866152 140010363811584 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.16938406229019165, loss=0.2789956331253052
I0307 16:03:59.090682 140010355418880 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.08893084526062012, loss=0.3472263216972351
I0307 16:04:07.330959 140010363811584 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.26662877202033997, loss=0.2720929682254791
I0307 16:04:15.540242 140010355418880 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.10522539913654327, loss=0.3020946681499481
I0307 16:04:23.766494 140010363811584 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.22200414538383484, loss=0.3704545497894287
I0307 16:04:32.004676 140010355418880 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.31737491488456726, loss=0.2189570814371109
I0307 16:04:40.248090 140010363811584 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.17576251924037933, loss=0.285576730966568
I0307 16:04:48.479865 140010355418880 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.07436877489089966, loss=0.29776960611343384
I0307 16:04:56.693706 140010363811584 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.18739019334316254, loss=0.2221255898475647
I0307 16:05:04.921079 140010355418880 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.1890253722667694, loss=0.28256550431251526
I0307 16:05:06.897264 140166018147520 spec.py:321] Evaluating on the training split.
I0307 16:05:08.199778 140166018147520 spec.py:333] Evaluating on the validation split.
I0307 16:05:09.506872 140166018147520 spec.py:349] Evaluating on the test split.
I0307 16:05:10.814516 140166018147520 submission_runner.py:469] Time since start: 1017.62s, 	Step: 6625, 	{'train/ssim': 0.7453187533787319, 'train/loss': 0.27147594520023893, 'validation/ssim': 0.7243736838113745, 'validation/loss': 0.28991664871447664, 'validation/num_examples': 3554, 'test/ssim': 0.7412834092912245, 'test/loss': 0.2915149849575014, 'test/num_examples': 3581, 'score': 873.2600636482239, 'total_duration': 1017.6211085319519, 'accumulated_submission_time': 873.2600636482239, 'accumulated_eval_time': 143.7219295501709, 'accumulated_logging_time': 0.16209101676940918}
I0307 16:05:10.824772 140010363811584 logging_writer.py:48] [6625] accumulated_eval_time=143.722, accumulated_logging_time=0.162091, accumulated_submission_time=873.26, global_step=6625, preemption_count=0, score=873.26, test/loss=0.291515, test/num_examples=3581, test/ssim=0.741283, total_duration=1017.62, train/loss=0.271476, train/ssim=0.745319, validation/loss=0.289917, validation/num_examples=3554, validation/ssim=0.724374
I0307 16:05:10.837451 140010355418880 logging_writer.py:48] [6625] global_step=6625, preemption_count=0, score=873.26
I0307 16:05:11.680388 140166018147520 submission_runner.py:646] Tuning trial 4/5
I0307 16:05:11.680577 140166018147520 submission_runner.py:647] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.0, learning_rate=0.004958460849689891, one_minus_beta1=0.13625575743, beta2=0.6291854735396584, weight_decay=0.1147386261512052, warmup_factor=0.02)
I0307 16:05:11.681270 140166018147520 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/ssim': 0.21437570026942662, 'train/loss': 1.0265536989484514, 'validation/ssim': 0.20786135560284186, 'validation/loss': 1.0358130391152574, 'validation/num_examples': 3554, 'test/ssim': 0.22986473886702388, 'test/loss': 1.0333816114999301, 'test/num_examples': 3581, 'score': 233.39404225349426, 'total_duration': 345.4114670753479, 'accumulated_submission_time': 233.39404225349426, 'accumulated_eval_time': 112.01727485656738, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (471, {'train/ssim': 0.7108235359191895, 'train/loss': 0.2924417087009975, 'validation/ssim': 0.693803416924592, 'validation/loss': 0.3083846779706844, 'validation/num_examples': 3554, 'test/ssim': 0.710609229374651, 'test/loss': 0.31044058758464815, 'test/num_examples': 3581, 'score': 313.5565273761749, 'total_duration': 429.9126660823822, 'accumulated_submission_time': 313.5565273761749, 'accumulated_eval_time': 116.25725507736206, 'accumulated_logging_time': 0.018039464950561523, 'global_step': 471, 'preemption_count': 0}), (882, {'train/ssim': 0.7296473639351981, 'train/loss': 0.28060964175633024, 'validation/ssim': 0.7089810089643711, 'validation/loss': 0.29821588433587154, 'validation/num_examples': 3554, 'test/ssim': 0.7263421530298799, 'test/loss': 0.29981839100897095, 'test/num_examples': 3581, 'score': 393.52272605895996, 'total_duration': 513.9198377132416, 'accumulated_submission_time': 393.52272605895996, 'accumulated_eval_time': 120.19277620315552, 'accumulated_logging_time': 0.043900251388549805, 'global_step': 882, 'preemption_count': 0}), (1765, {'train/ssim': 0.7380094528198242, 'train/loss': 0.27636275972638813, 'validation/ssim': 0.7180587948878024, 'validation/loss': 0.2939740268447524, 'validation/num_examples': 3554, 'test/ssim': 0.7352173908300754, 'test/loss': 0.29559603991770805, 'test/num_examples': 3581, 'score': 473.51234769821167, 'total_duration': 597.9222173690796, 'accumulated_submission_time': 473.51234769821167, 'accumulated_eval_time': 124.1249623298645, 'accumulated_logging_time': 0.06682133674621582, 'global_step': 1765, 'preemption_count': 0}), (2736, {'train/ssim': 0.7322846140180316, 'train/loss': 0.2750471660069057, 'validation/ssim': 0.7128382797112408, 'validation/loss': 0.29234991465382315, 'validation/num_examples': 3554, 'test/ssim': 0.7303658714177255, 'test/loss': 0.293825048869031, 'test/num_examples': 3581, 'score': 553.4525375366211, 'total_duration': 681.8503429889679, 'accumulated_submission_time': 553.4525375366211, 'accumulated_eval_time': 128.04365730285645, 'accumulated_logging_time': 0.08536815643310547, 'global_step': 2736, 'preemption_count': 0}), (3708, {'train/ssim': 0.7373841149466378, 'train/loss': 0.2745167187282017, 'validation/ssim': 0.716757650380733, 'validation/loss': 0.2921939092066158, 'validation/num_examples': 3554, 'test/ssim': 0.7342412373900447, 'test/loss': 0.2936962972436994, 'test/num_examples': 3581, 'score': 633.392215013504, 'total_duration': 765.7849185466766, 'accumulated_submission_time': 633.392215013504, 'accumulated_eval_time': 131.96801352500916, 'accumulated_logging_time': 0.10438728332519531, 'global_step': 3708, 'preemption_count': 0}), (4681, {'train/ssim': 0.7371012823922294, 'train/loss': 0.2728183610098703, 'validation/ssim': 0.7170827132500351, 'validation/loss': 0.2903662892493493, 'validation/num_examples': 3554, 'test/ssim': 0.7344531986307945, 'test/loss': 0.2918735941972389, 'test/num_examples': 3581, 'score': 713.3908176422119, 'total_duration': 849.7699213027954, 'accumulated_submission_time': 713.3908176422119, 'accumulated_eval_time': 135.88328075408936, 'accumulated_logging_time': 0.12425923347473145, 'global_step': 4681, 'preemption_count': 0}), (5653, {'train/ssim': 0.7348335811070034, 'train/loss': 0.2736290012087141, 'validation/ssim': 0.7152937683551984, 'validation/loss': 0.29119120840953855, 'validation/num_examples': 3554, 'test/ssim': 0.7323459261990366, 'test/loss': 0.29272334810676137, 'test/num_examples': 3581, 'score': 793.3245630264282, 'total_duration': 933.6958382129669, 'accumulated_submission_time': 793.3245630264282, 'accumulated_eval_time': 139.80472612380981, 'accumulated_logging_time': 0.14273548126220703, 'global_step': 5653, 'preemption_count': 0}), (6625, {'train/ssim': 0.7453187533787319, 'train/loss': 0.27147594520023893, 'validation/ssim': 0.7243736838113745, 'validation/loss': 0.28991664871447664, 'validation/num_examples': 3554, 'test/ssim': 0.7412834092912245, 'test/loss': 0.2915149849575014, 'test/num_examples': 3581, 'score': 873.2600636482239, 'total_duration': 1017.6211085319519, 'accumulated_submission_time': 873.2600636482239, 'accumulated_eval_time': 143.7219295501709, 'accumulated_logging_time': 0.16209101676940918, 'global_step': 6625, 'preemption_count': 0})], 'global_step': 6625}
I0307 16:05:11.681364 140166018147520 submission_runner.py:649] Timing: 873.2600636482239
I0307 16:05:11.681399 140166018147520 submission_runner.py:651] Total number of evals: 9
I0307 16:05:11.681436 140166018147520 submission_runner.py:652] ====================
I0307 16:05:11.681554 140166018147520 submission_runner.py:750] Final fastmri score: 3
