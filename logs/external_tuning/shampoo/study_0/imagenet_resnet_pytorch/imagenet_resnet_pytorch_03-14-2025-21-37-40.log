torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=imagenet_resnet --submission_path=submissions_algorithms/leaderboard/external_tuning/shampoo_submission/submission.py --data_dir=/data/imagenet/pytorch --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/shampoo/study_0 --overwrite=True --save_checkpoints=False --rng_seed=-1332808110 --imagenet_v2_data_dir=/data/imagenet/pytorch --torch_compile=true --tuning_ruleset=external --tuning_search_space=submissions_algorithms/leaderboard/external_tuning/shampoo_submission/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=2 --hparam_end_index=3 2>&1 | tee -a /logs/imagenet_resnet_pytorch_03-14-2025-21-37-40.log
W0314 21:37:42.412000 9 site-packages/torch/distributed/run.py:793] 
W0314 21:37:42.412000 9 site-packages/torch/distributed/run.py:793] *****************************************
W0314 21:37:42.412000 9 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0314 21:37:42.412000 9 site-packages/torch/distributed/run.py:793] *****************************************
2025-03-14 21:37:43.598257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-14 21:37:43.598265: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-14 21:37:43.598271: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-14 21:37:43.598257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-14 21:37:43.598272: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-14 21:37:43.598257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-14 21:37:43.598257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-14 21:37:43.598258: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741988263.618521      46 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741988263.618518      45 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741988263.618517      44 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741988263.618519      49 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741988263.618517      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741988263.618518      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741988263.618569      51 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741988263.618571      50 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741988263.624787      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1741988263.624787      49 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1741988263.624791      51 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1741988263.624790      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1741988263.624796      50 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1741988263.624801      45 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1741988263.624805      46 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1741988263.624808      44 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
[rank0]:[W314 21:37:51.950200332 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank3]:[W314 21:37:52.259329973 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank6]:[W314 21:37:52.307205607 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank2]:[W314 21:37:52.373833459 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank4]:[W314 21:37:52.381306120 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank7]:[W314 21:37:52.386739132 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank5]:[W314 21:37:52.390212937 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank1]:[W314 21:37:52.403605589 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
I0314 21:37:53.945338 140083172709568 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch.
I0314 21:37:53.945337 140602519192768 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch.
I0314 21:37:53.945337 139848171250880 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch.
I0314 21:37:53.945336 139673129641152 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch.
I0314 21:37:53.945338 140718679155904 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch.
I0314 21:37:53.945342 140540452091072 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch.
I0314 21:37:53.945361 140498825811136 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch.
I0314 21:37:53.945472 140547962021056 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch.
I0314 21:37:54.036276 140547962021056 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:54.037933 140498825811136 submission_runner.py:606] Using RNG seed -1332808110
I0314 21:37:54.039240 140498825811136 submission_runner.py:615] --- Tuning run 3/5 ---
I0314 21:37:54.038976 139673129641152 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:54.039384 140498825811136 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch/trial_3.
I0314 21:37:54.039616 140498825811136 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:54.040092 139848171250880 logger_utils.py:91] Loading hparams from /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:54.040309 140602519192768 logger_utils.py:91] Loading hparams from /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:54.041321 140083172709568 logger_utils.py:91] Loading hparams from /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:54.041948 140718679155904 logger_utils.py:91] Loading hparams from /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:54.041962 140540452091072 logger_utils.py:91] Loading hparams from /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:54.377857 140498825811136 submission_runner.py:218] Initializing dataset.
I0314 21:38:05.751691 140498825811136 submission_runner.py:229] Initializing model.
I0314 21:38:06.254074 140498825811136 submission_runner.py:268] Performing `torch.compile`.
W0314 21:38:07.239656 139673129641152 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
W0314 21:38:07.242938 140547962021056 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
W0314 21:38:07.243556 140718679155904 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
W0314 21:38:07.244418 140540452091072 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
I0314 21:38:07.245877 140498825811136 submission_runner.py:272] Initializing optimizer.
I0314 21:38:07.247018 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
I0314 21:38:07.247238 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([0])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.247385 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([0])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.247556 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:07.247678 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([0])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.247795 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([0])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.247924 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.248030 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([0])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.248140 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([0])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.248266 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.248380 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([0])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.248472 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([0])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.248725 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([256, 256]), torch.Size([64, 64])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.248843 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([0])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.248937 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([0])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.249057 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.249150 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([0])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.249241 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([0])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.249358 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.249462 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([0])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.249584 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([0])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.249719 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
W0314 21:38:07.249963 140498825811136 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
I0314 21:38:07.250967 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
I0314 21:38:07.251191 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([0])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.251432 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([64, 64])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.251629 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:07.249814 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([0])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.251754 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([0])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.251872 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([0])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.251869 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([0])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.251810 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([192, 192]), torch.Size([49, 49])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
I0314 21:38:07.252003 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.252004 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.252015 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([0])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.252093 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([0])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.252140 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([0])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.252190 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([0])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.252184 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([64, 64])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.252308 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([0])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.252328 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.252334 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:07.252417 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([0])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.252523 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([0])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.252529 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([64, 64])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.252673 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([0])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.252821 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.252815 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
I0314 21:38:07.252932 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([0])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.253022 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([0])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.253011 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([256, 256]), torch.Size([64, 64])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.253068 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([0])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.253139 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([0])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.253144 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.253227 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([0])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.253244 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([0])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.253244 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([0])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.253238 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([256, 256]), torch.Size([64, 64])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.253348 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([0])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.253379 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.253386 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([0])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.253470 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.253485 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([0])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.253478 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([0])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.253573 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([0])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.253575 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([0])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.253617 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:07.253602 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([64, 64]), torch.Size([64, 64])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:07.253661 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([0])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.253695 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.253726 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([0])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.253773 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([0])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.253796 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([0])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.253819 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([0])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.253882 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([0])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.253932 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([0])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.254025 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.254102 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([128, 128]), torch.Size([384, 384]), torch.Size([3, 3])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.254098 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.254131 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([0])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.254219 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([0])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.254218 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([0])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.254238 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([0])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.254306 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([0])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.254303 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([64, 64]), torch.Size([256, 256])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.254371 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([0])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.254439 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([0])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.254438 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([256, 256]), torch.Size([64, 64])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.254545 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
W0314 21:38:07.254470 140083172709568 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
I0314 21:38:07.254609 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([64, 64])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.254665 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([0])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.254767 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.254779 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([0])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.254868 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([0])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.254927 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.254917 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([512, 512]), torch.Size([128, 128])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.254961 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([0])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.255033 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([0])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.255088 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.255119 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([256, 256])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.255160 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([0])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.255262 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([0])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.255300 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:07.255409 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([0])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.255440 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.255514 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([0])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.255563 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([0])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.255639 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.255676 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([0])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.255745 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([0])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.255831 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.255852 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([0])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.256011 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.256109 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([0])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.256201 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([0])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.256342 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.256444 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([0])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.256445 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([64, 64])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.256548 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([0])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.254598 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([256, 256])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.256622 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([0])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.256683 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.256744 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([0])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.256775 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([0])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.256795 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.256795 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
I0314 21:38:07.256861 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([0])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.256895 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.256989 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([0])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.257011 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.257069 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([64, 64])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.257097 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([0])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.257118 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([0])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.255192 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([0])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.257182 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([0])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.257187 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([0])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.257262 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:07.257310 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.257365 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([0])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.257362 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([256, 256])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.257410 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([0])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.257481 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([0])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.257534 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([0])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.257533 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.257612 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.257629 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([0])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.257658 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.257718 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([0])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.257720 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([0])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.257756 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([0])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.257781 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([512, 512]), torch.Size([128, 128])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.257825 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([0])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.257854 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([0])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.257855 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.257922 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([0])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.257939 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.257946 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([0])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.257977 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:07.258020 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([0])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.258024 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([0])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.258068 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([0])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.258092 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([64, 64])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.258151 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.258158 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([0])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.258204 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([256, 256])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.258244 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.258296 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.258322 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([0])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.258342 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([0])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.258346 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.258427 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([0])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.258442 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([0])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.258449 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([0])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.258454 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([128, 128])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.258534 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([0])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.258558 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:07.258585 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([0])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.258589 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.258646 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([0])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.258665 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.258672 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([0])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.258708 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.258737 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([0])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.258753 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([0])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.258800 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([0])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.258832 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([64, 64])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.258859 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.256911 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([0])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.258895 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.258960 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([0])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.258971 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([0])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.259007 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([0])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.259057 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([0])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.259047 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([0])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.259110 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([0])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.259163 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([64, 64]), torch.Size([576, 576])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.259178 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:07.259215 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.259244 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.259275 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([0])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.259290 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([0])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.259342 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([0])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.259351 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([0])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.259369 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([0])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.259380 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([0])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.259399 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([512, 512])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.259450 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([0])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.259474 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([0])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.259504 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.259536 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.259576 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:07.259589 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:07.259634 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([0])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.259633 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.259684 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([0])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.259611 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([0])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.259725 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([0])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.259739 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([0])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.259791 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([0])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.259824 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([0])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.259842 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([0])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.259851 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.259917 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.259946 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([0])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.259964 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.259985 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.260012 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([0])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.260038 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([0])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.260063 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([0])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.260098 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([0])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.260156 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.260157 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([0])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.260158 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([512, 512])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.260170 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([128, 128])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.260217 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([0])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.260248 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([0])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.260287 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.260309 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([0])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.260353 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.260358 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([0])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.260442 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.260456 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([0])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.260530 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([128, 128]), torch.Size([256, 256])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:07.260549 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([0])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.260555 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([0])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.260637 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([0])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.260671 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.260746 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([128, 128])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.260808 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.260872 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([0])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.260983 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([128, 128])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.261011 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([64, 64])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.261060 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.261095 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([0])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.261158 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([0])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.261167 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([0])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.261215 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.261212 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([256, 256]), torch.Size([1024, 1024])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.261286 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.261321 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([0])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.261323 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([128, 128])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.261357 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([0])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.261353 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([512, 512])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.261390 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([0])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.261461 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([0])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.261483 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.261492 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([0])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.261469 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
I0314 21:38:07.261548 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([256, 256])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.261620 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.261627 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.261698 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:07.261725 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([0])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.261717 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([0])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.261735 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([64, 64])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.261792 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([0])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.261809 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([0])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.261815 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([0])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.261881 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([0])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.261890 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([0])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.261893 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([512, 512])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.261923 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.261972 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.262014 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([0])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.262021 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:07.262038 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.262040 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.262066 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([0])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.262104 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([0])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.262127 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([0])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.262128 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([0])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.262139 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([0])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.262165 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([512, 512])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.262217 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([0])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.262227 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([0])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.262223 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([128, 128])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.262289 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([64, 64])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.262322 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([0])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.262346 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.262349 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.262361 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.262435 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([0])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.262439 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([0])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.262444 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([0])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.262503 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([64, 64]), torch.Size([576, 576])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.262535 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([0])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.262532 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([0])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.262538 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([0])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.262632 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([0])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.262666 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.262687 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.262683 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:07.262723 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([0])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.262706 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([256, 256]), torch.Size([1024, 1024])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.262765 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([0])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.262788 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([0])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.262822 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([0])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.262833 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.262872 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([0])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.262882 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([0])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.262885 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([0])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.262910 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([0])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.262925 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([0])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.262984 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([0])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.262993 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([0])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.262980 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([512, 512]), torch.Size([256, 256])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:07.263011 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.263063 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.263089 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.263102 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([0])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.263117 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([0])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.263134 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.263158 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([0])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.263171 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([0])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.263187 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([0])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.263236 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([0])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.263272 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([0])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.263333 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([0])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.263345 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.263405 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.263435 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([0])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.263460 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.263512 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([0])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.263520 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([0])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.263540 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([128, 128]), torch.Size([512, 512])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.263580 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([0])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.263608 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([0])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.263641 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.263730 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.263737 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([0])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.263804 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([128, 128])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.263823 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([0])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.263824 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([0])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.263831 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([512, 512])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.263908 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([0])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.263936 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([0])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.263951 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.264024 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.264024 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([256, 256])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.264053 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.264141 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([0])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.264127 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([128, 128])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.264163 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.264194 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([512, 512])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.264222 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([0])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.264246 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([0])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.264257 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([0])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.264285 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([0])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.264343 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([0])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.264357 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([0])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.264421 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.264469 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.264475 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.264518 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([0])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.264514 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.264560 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([0])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.264574 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([0])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.264581 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([128, 128]), torch.Size([384, 384]), torch.Size([3, 3])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.264621 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([0])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.264623 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([0])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.264659 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([0])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.264708 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([64, 64])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.264721 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([0])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.264725 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([0])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.264740 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.264780 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.264817 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([0])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.264827 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([0])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
W0314 21:38:07.264736 139848171250880 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
I0314 21:38:07.264818 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([256, 256]), torch.Size([512, 512])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:07.264837 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.264871 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.264887 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([0])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.264935 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([0])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.264960 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.264972 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([0])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.264987 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([0])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.265038 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([0])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.265062 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([0])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.265099 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([0])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.265121 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.265158 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([0])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.265230 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([0])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.265280 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:07.265375 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([0])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.265325 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([0])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.265425 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([512, 512])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.265480 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([0])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.265599 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.265654 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.265669 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.265752 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([0])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.265819 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([0])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.265908 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([256, 256]), torch.Size([768, 768]), torch.Size([3, 3])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.265929 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([0])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.265928 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([256, 256])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.265923 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([128, 128]), torch.Size([512, 512])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.266053 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.266059 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([0])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.266063 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.266081 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([256, 256])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.266151 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([0])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.266151 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([0])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.266193 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([0])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.266221 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([128, 128])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.266241 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([0])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.266248 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([0])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.264913 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([0])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.266335 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.266363 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.266405 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.266446 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([0])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.266467 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([0])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.266471 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.266506 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([1024, 1024])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.266540 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([0])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.266558 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([0])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.266582 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([0])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.266640 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([0])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.266666 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([64, 64]), torch.Size([256, 256])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.266685 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.266695 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([0])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.266762 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.266775 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([0])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.266788 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([0])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.266855 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([0])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.266852 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.266859 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([0])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.266893 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([0])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.266949 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([0])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.266952 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([0])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.266962 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.266993 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([1024, 1024])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.267037 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([0])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.267046 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.267051 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([0])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.267111 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.267134 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([0])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.267154 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([0])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.267220 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.267231 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([0])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.267239 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([0])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.267249 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.267318 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([0])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.267337 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([0])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.267350 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.267420 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([0])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.267413 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([0])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.267446 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([0])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.267464 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.267535 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:07.267541 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([0])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.267557 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([0])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.267567 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([0])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.267578 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([1024, 1024]), torch.Size([512, 512])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.267617 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([0])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.267655 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([0])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.267623 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([0])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.267678 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.267741 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.267753 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([128, 128])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.267764 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([0])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.267780 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.267807 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([0])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.267858 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([0])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.267886 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.267917 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.267913 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([256, 256])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.267972 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([0])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.267989 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.268026 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.268054 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([0])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.268050 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([128, 128])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.268084 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.268122 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.268160 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.268184 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([0])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.268178 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([128, 128])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.268212 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.268215 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.268249 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([0])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.268230 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([1024, 1024])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.268305 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([0])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.268313 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([0])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.268328 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.268367 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([0])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.268460 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.268466 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.268450 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([1024, 1024])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.268463 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:07.268491 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:07.268566 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([0])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.268580 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([0])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.268590 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:07.268597 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([0])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.268617 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.268667 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([0])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.268671 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([0])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.268677 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.268694 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([0])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.268730 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([0])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.268764 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.268784 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.268792 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:07.268809 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.268833 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([0])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.268870 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([0])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.268862 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.268878 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([0])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.268875 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([512, 512])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.268963 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([0])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.268964 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([0])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.268958 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([128, 128])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.268966 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.269025 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([0])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.269050 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([0])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.269082 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.269102 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.269102 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([256, 256]), torch.Size([768, 768]), torch.Size([3, 3])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.269125 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.269196 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.269197 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:07.269227 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([0])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.269219 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([0])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.269268 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([0])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.269286 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([0])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.269291 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.269324 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([0])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.269326 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([0])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.269371 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([0])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.269404 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([0])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.269449 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.269451 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.269554 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([0])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.269558 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([0])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.269562 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([0])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.269659 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([0])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.269665 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([0])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.269721 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.269779 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.269802 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.269825 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([0])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.269838 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([256, 256])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.269873 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([0])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.269919 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([0])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.269958 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([0])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.269960 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([256, 256])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.269989 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([0])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.270042 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.270061 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([0])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.270056 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([256, 256])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.270093 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.270163 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.270185 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.270203 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([0])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.270216 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.270210 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([512, 512]), torch.Size([128, 128])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.270256 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.270287 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([1024, 1024]), torch.Size([256, 256])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.270318 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([0])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.270306 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([0])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.270319 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([0])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.270348 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.270360 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([256, 256])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.270408 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([0])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.270408 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([0])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.270421 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([0])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.270427 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([0])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.270441 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.270498 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([0])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.270531 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.270540 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.270540 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.270551 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.270590 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.270622 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([0])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.270640 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([0])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.270639 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.270643 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([0])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.270670 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.270716 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([0])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.270716 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([0])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.270738 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([0])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.270740 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([0])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.270795 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([1024, 1024])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.270804 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.270823 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([0])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.270852 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.270855 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([0])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.270890 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([0])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.270931 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.270969 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.271000 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([0])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.271032 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([1024, 1024])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.271048 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([0])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.271101 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([0])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.271138 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([0])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.271133 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([256, 256]), torch.Size([768, 768]), torch.Size([3, 3])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.271157 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([0])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.271212 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([0])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.271242 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([0])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.271283 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.271288 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.271342 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([0])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.271327 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([128, 128]), torch.Size([384, 384]), torch.Size([3, 3])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.271365 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.271376 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([0])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.271461 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([0])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.271465 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.271493 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([128, 128])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.271503 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([0])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.271562 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([0])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.271614 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([0])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.271614 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.271619 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([0])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.271589 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
I0314 21:38:07.271656 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([0])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.271703 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([0])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.271727 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.271744 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([0])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.271776 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.271812 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([0])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.271812 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.271861 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([0])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.271871 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([256, 256])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.271877 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([0])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.271895 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([0])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.272002 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.272000 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([256, 256])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272005 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:07.272013 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.272026 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([256, 256])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272045 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([256, 256])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272102 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([0])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.272098 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([0])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.272121 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([0])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272167 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([0])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.272193 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([0])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.272195 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([0])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.272192 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.272202 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([0])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272178 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([512, 512]), torch.Size([512, 512]), torch.Size([9, 9])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.272288 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([0])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.272306 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.272320 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([0])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272330 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.272319 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.272346 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([0])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.272366 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.272418 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([0])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272426 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([0])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.272424 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([0])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.272427 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([0])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272432 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.272463 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([0])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.272470 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([0])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.272504 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([0])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.272510 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([0])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272515 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([0])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.272541 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([0])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.272551 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.272569 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([0])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.272590 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([0])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.272614 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.272621 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.272641 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([0])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.272666 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.272686 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.272695 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.272699 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([0])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272711 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.272731 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([0])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.272744 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.272765 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([0])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.272778 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([0])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272790 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([0])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272814 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([0])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272834 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.272849 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([0])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.272863 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([0])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272866 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.272874 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.272886 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([0])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272920 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.272926 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([0])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272963 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([0])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.272974 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:07.272976 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([0])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.273015 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.273041 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.273052 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([0])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.273053 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([0])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.273092 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.273108 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.273116 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.273138 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([0])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.273154 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.273201 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([256, 256])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.273210 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([0])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.273232 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:07.273245 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([0])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.273251 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([0])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.273317 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([0])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.273328 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([0])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.273369 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:07.273380 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.273388 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([512, 512])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.273455 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.273474 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([0])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.273478 139673129641152 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([0])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:07.273510 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.273526 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([0])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.273540 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([0])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.273552 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([0])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.273616 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([0])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.273671 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.273675 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.273702 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([1024, 1024])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.273734 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.273758 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([0])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.273762 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([0])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.273755 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([1024, 1024])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.273835 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([0])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.273846 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([0])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.273848 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([0])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.273874 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([0])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.273863 139673129641152 shampoo_preconditioner_list.py:612] Rank 2: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:07.273954 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.273959 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.273973 139673129641152 shampoo_preconditioner_list.py:615] Rank 2: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768)
I0314 21:38:07.273989 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.274003 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.273998 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([1024, 1024]), torch.Size([256, 256])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.274026 139673129641152 shampoo_preconditioner_list.py:618] Rank 2: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:07.274041 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([0])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.274064 139673129641152 shampoo_preconditioner_list.py:621] Rank 2: ShampooPreconditionerList Total Bytes: 3230472
I0314 21:38:07.274089 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([0])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.274136 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([0])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.274145 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([0])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.274151 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([256, 256])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.274239 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.274266 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([0])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.274293 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([1024, 1024])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.274333 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([0])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.274422 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([0])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.274436 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.274471 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.274585 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.274611 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([256, 256])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.274672 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([0])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.274685 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([0])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.274721 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([0])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
W0314 21:38:07.274614 140602519192768 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
I0314 21:38:07.274741 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([256, 256])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.274800 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([0])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.274826 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([256, 256])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.274884 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.274941 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.274955 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.274959 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.274982 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([0])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.274985 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([1024, 1024]), torch.Size([512, 512])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.275035 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([0])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.275043 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([0])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.275062 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([0])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.275087 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([0])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.275117 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.275130 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([0])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.275129 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([0])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.275170 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([0])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.275209 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.275213 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.275240 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.275242 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.273814 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([0])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.275304 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([0])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.275306 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.275328 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([0])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.275338 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([0])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.275388 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.275393 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([0])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.275423 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([0])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.275422 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([0])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.275550 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.275521 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([0])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.275554 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.275636 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([0])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.275645 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([0])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.275638 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([256, 256]), torch.Size([1024, 1024])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.275680 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.275738 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([0])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.275740 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([0])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.275756 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([0])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.275791 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([0])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.275846 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.275851 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([0])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.275875 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.275879 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([0])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.275930 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([0])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.275970 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([0])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.275979 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.275985 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.276009 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([0])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.276015 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([256, 256]), torch.Size([1024, 1024])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.276062 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([0])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.276064 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([0])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.276068 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([0])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.276139 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([0])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.276165 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([0])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.276180 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.276161 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([1024, 1024]), torch.Size([1024, 1024])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:07.276206 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([256, 256])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.276251 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.276299 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([0])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.276319 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.276325 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:07.276359 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.276360 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([0])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.276417 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.276420 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.276443 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([0])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.276503 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.276528 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.276545 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:07.276556 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([256, 256]), torch.Size([1024, 1024])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.276618 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.276628 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([0])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.276670 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([0])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.276707 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([0])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.276707 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.276805 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([256, 256])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.276825 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.276833 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.276905 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([0])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.276983 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([0])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.277019 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.277034 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([256, 256]), torch.Size([768, 768]), torch.Size([3, 3])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.277087 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.277128 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([0])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.277167 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([0])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.277198 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([0])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.277249 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([0])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.277258 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([1024, 1024])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.277306 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([0])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.277372 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:07.277384 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([1024, 1024])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.277410 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([0])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.277427 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.277457 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([0])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.277513 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([0])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.277524 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.277544 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([0])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.277532 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.277519 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([256, 256])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.277594 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([0])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.277628 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.277660 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([0])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.277667 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([0])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.277697 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.277752 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:07.277737 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([512, 512])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.277763 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([0])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.277777 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([0])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.277819 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.277850 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([0])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.277871 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:07.277910 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.277956 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.277982 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.278002 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([1024, 1024])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.278017 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([0])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.278064 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([0])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.278102 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([0])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.278129 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([0])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.278131 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([1024, 1024])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.278182 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([128, 128]), torch.Size([512, 512])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.278214 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([256, 256])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.278222 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.278233 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.278280 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.278305 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([0])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.278326 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.278332 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.278341 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.278388 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([0])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.278398 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([0])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.278415 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.278418 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([0])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.278463 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.278493 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([0])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.278506 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([0])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.278504 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.278589 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.278597 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.278671 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([0])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.278684 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.278753 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([0])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.278836 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([256, 256]), torch.Size([768, 768]), torch.Size([3, 3])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.278886 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.278969 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([0])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.278970 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([0])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.279048 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([0])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.279074 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([0])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.279152 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.279204 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([512, 512]), torch.Size([512, 512]), torch.Size([9, 9])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.279225 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.279233 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([0])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.279313 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([0])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.279325 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([0])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.279436 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.279436 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([0])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.279542 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([0])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.279582 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([128, 128]), torch.Size([384, 384]), torch.Size([3, 3])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.279622 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.279632 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([0])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.279678 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([512, 512]), torch.Size([1024, 1024])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.279710 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([0])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.279727 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([0])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.279759 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.279795 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([0])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.279779 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([512, 512]), torch.Size([1024, 1024])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.279844 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([0])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.279846 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([0])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.279915 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.279923 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.279931 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([0])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.279926 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([512, 512])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.280010 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([0])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.280017 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([0])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.280032 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.280058 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([0])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.280096 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([0])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.280106 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([0])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.280145 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([0])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.280207 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.280203 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.280244 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.280313 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([0])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.280338 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.280325 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([512, 512])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.280369 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([0])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.280421 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([0])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.280428 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.280479 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([0])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.280512 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.280562 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.280659 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([0])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.280653 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.280679 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([1024, 1024])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.280738 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([0])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.280748 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([0])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.280792 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.280837 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([0])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.280841 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.280914 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([0])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.280915 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:07.280962 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.280992 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([0])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.281041 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:07.281084 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.281065 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([512, 512])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.281104 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.281140 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.281178 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.281224 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([512, 512])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.281242 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.281246 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([0])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.281246 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.281279 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([1024, 1024]), torch.Size([512, 512])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.281336 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([0])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.281383 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.281390 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([1024, 1024])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.281404 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.281446 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.281464 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.281487 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.281510 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.281540 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.281545 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([0])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.281616 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.281618 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([0])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.281620 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.281621 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.281697 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.281708 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.281710 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([1024, 1024])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.281778 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.281826 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.281840 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.281854 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([1024, 1024])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.281882 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:07.281940 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([0])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.281966 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.281971 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.281984 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:07.282047 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([0])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.282057 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.282092 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.282076 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([1024, 1024])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.282105 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:07.282135 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.282198 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.282212 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.282211 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.282219 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:07.282218 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.282186 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
I0314 21:38:07.282260 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([512, 512]), torch.Size([128, 128])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.282290 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([0])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.282296 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.282296 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([0])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.282302 140540452091072 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([0])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:07.282314 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.282378 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([0])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.282380 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([0])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.282397 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.282429 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.282416 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([0])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.282459 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([0])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.282529 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.282557 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:07.282576 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.282568 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([0])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.282591 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:07.282590 140540452091072 shampoo_preconditioner_list.py:612] Rank 3: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:07.282641 140540452091072 shampoo_preconditioner_list.py:615] Rank 3: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056)
I0314 21:38:07.282663 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([0])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.282689 140540452091072 shampoo_preconditioner_list.py:618] Rank 3: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:07.282677 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([0])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.282726 140540452091072 shampoo_preconditioner_list.py:621] Rank 3: ShampooPreconditionerList Total Bytes: 12012296
I0314 21:38:07.282740 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([0])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.282732 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:07.282774 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([0])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.282792 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([512, 512])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.282839 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([0])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.282857 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([1024, 1024]), torch.Size([1024, 1024])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:07.282880 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.282936 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.282940 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.282960 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([0])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.282954 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([0])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.283027 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([0])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.283037 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([0])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.283053 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.283062 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([512, 512])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.283087 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.283113 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([0])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.283143 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.283147 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.283201 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([0])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.283198 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([0])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.283223 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.283229 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([0])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.283231 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.283305 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([0])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.283392 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([64, 64])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.283423 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.283453 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([1024, 1024])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.283503 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([0])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.283538 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.283588 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([0])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.283611 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.283694 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.283701 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([256, 256])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.283729 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.283784 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([0])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.283820 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([0])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.283874 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([0])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.283872 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.283949 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.284013 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.284045 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([0])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.284095 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([0])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.284138 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([0])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.284128 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([1024, 1024]), torch.Size([512, 512])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.284175 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([0])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.284163 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([1024, 1024]), torch.Size([512, 512])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.284235 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([1024, 1024])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.284259 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.284265 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.284295 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.284274 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.284363 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.284382 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([0])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.284382 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([0])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.284381 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.284391 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.284461 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([0])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.284464 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.284480 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([0])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.284502 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.284554 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.284576 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.284605 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.284594 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([512, 512]), torch.Size([1024, 1024])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.284633 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.284651 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([0])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.284673 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.284713 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([0])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.284722 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([0])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.284731 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([0])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.284781 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.284807 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([0])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.284817 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([0])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.284862 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([0])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.284872 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.284933 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.284954 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([256, 256]), torch.Size([768, 768]), torch.Size([3, 3])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.284966 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.284953 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([1024, 1024])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.285004 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([0])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.285056 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([0])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.285059 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([0])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.285090 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.285135 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([0])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.285136 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([0])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.285148 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([0])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.285204 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.285271 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.285334 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:07.285321 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([512, 512])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.285336 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.285443 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([0])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.285483 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.285461 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:07.285562 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([0])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.285578 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([0])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.285573 140718679155904 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([0])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:07.285661 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([0])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.285726 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.285776 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.285875 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.285880 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.285873 140718679155904 shampoo_preconditioner_list.py:612] Rank 7: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:07.285891 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([1024, 1024]), torch.Size([256, 256])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.285924 140718679155904 shampoo_preconditioner_list.py:615] Rank 7: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 655360, 131072)
I0314 21:38:07.285953 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.285960 140718679155904 shampoo_preconditioner_list.py:618] Rank 7: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:07.285993 140718679155904 shampoo_preconditioner_list.py:621] Rank 7: ShampooPreconditionerList Total Bytes: 17222408
I0314 21:38:07.285999 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([1024, 1024]), torch.Size([512, 512])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.286018 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([0])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.286033 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.286099 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([0])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.286117 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.286125 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.286196 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.286208 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.286217 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.286283 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([0])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.286302 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:07.286315 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.286371 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([0])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.286469 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([1024, 1024])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.286522 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.286619 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.286692 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([0])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.286733 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.286796 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([0])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.286842 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.285026 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([0])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.286923 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.287005 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.287011 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([0])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.287024 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([1000, 1000]), torch.Size([1024, 1024])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:07.287037 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([1024, 1024])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.287043 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([0])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.287088 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([0])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.287146 140083172709568 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([0])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:07.287175 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:07.287196 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.287200 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:07.287267 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([0])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.287282 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([0])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.287313 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:07.287379 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([0])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.287397 140083172709568 shampoo_preconditioner_list.py:612] Rank 6: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:07.287408 140498825811136 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([0])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:07.287452 140083172709568 shampoo_preconditioner_list.py:615] Rank 6: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768)
I0314 21:38:07.287442 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([64, 64])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.287491 140083172709568 shampoo_preconditioner_list.py:618] Rank 6: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:07.287514 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.287528 140083172709568 shampoo_preconditioner_list.py:621] Rank 6: ShampooPreconditionerList Total Bytes: 9849608
I0314 21:38:07.287599 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([0])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.287620 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([512, 512]), torch.Size([1024, 1024])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.287688 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([0])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.287706 140498825811136 shampoo_preconditioner_list.py:612] Rank 0: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:07.287757 140498825811136 shampoo_preconditioner_list.py:615] Rank 0: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288)
I0314 21:38:07.287802 140498825811136 shampoo_preconditioner_list.py:618] Rank 0: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:07.287804 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.287839 140498825811136 shampoo_preconditioner_list.py:621] Rank 0: ShampooPreconditionerList Total Bytes: 11455240
I0314 21:38:07.287883 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([0])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.287962 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([0])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.288064 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.288161 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([0])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.288245 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([0])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.288222 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([64, 64]), torch.Size([576, 576])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:07.288359 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([512, 512])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.288389 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([0])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.288502 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([0])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:07.288536 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([0])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.288658 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:07.288681 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.288740 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.288837 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([0])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.288839 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([256, 256])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.288858 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([0])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.288944 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([0])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.288946 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([0])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.288970 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([0])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.289065 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.289086 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:07.289124 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.289163 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([0])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.289186 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([0])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.289272 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([0])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.289265 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([0])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.289283 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.289421 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.289477 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([1024, 1024])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.289519 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([0])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.289619 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([0])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.289621 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.289729 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.289757 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.289848 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.289853 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([0])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.289958 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([0])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.290006 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:07.290089 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:07.290158 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:07.290183 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([0])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.290277 140547962021056 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([0])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:07.290289 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([0])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.290361 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([512, 512]), torch.Size([1024, 1024])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.290403 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.290486 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([0])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.290498 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([0])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.290586 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([0])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.290585 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([0])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.290591 140547962021056 shampoo_preconditioner_list.py:612] Rank 4: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:07.290662 140547962021056 shampoo_preconditioner_list.py:615] Rank 4: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768)
I0314 21:38:07.290709 140547962021056 shampoo_preconditioner_list.py:618] Rank 4: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:07.290733 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.290750 140547962021056 shampoo_preconditioner_list.py:621] Rank 4: ShampooPreconditionerList Total Bytes: 14830344
I0314 21:38:07.290749 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.290816 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([0])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.290853 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([0])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.290895 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([0])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.291001 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.291016 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([128, 128])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.291110 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.291155 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.291150 140498825811136 submission.py:142] No large parameters detected! Continuing with only Shampoo....
I0314 21:38:07.291195 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.291251 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([0])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.291267 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.291338 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.291358 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([0])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.291404 140498825811136 submission_runner.py:279] Initializing metrics bundle.
I0314 21:38:07.291432 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.291471 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.291528 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:07.291565 140498825811136 submission_runner.py:301] Initializing checkpoint and logger.
I0314 21:38:07.291566 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([0])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.291631 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:07.291678 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([0])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.291710 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.291797 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.291835 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.291897 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.291934 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([0])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.291986 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.291986 140498825811136 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch/trial_3/meta_data_0.json.
I0314 21:38:07.292024 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([0])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.292095 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.292143 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.292309 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.292432 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([0])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.292531 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([0])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.292675 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.292757 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([0])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.292773 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([512, 512])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.292837 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([0])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.292908 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([0])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.293051 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:07.293247 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([0])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.293395 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([1024, 1024]), torch.Size([512, 512])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.293452 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([128, 128])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.293534 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.293619 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.293632 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:07.293699 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.293738 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([0])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.293788 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.293834 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([0])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:07.293867 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.293954 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:07.293976 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.294059 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([0])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.294081 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.294152 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([0])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.294154 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([0])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.294232 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([0])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.294267 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:07.294358 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([0])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.294363 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.294439 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([0])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.294449 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([0])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.294523 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([0])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.294607 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.294631 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.294705 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([0])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.294725 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.294796 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.294796 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([0])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.294880 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.294959 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.295021 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([1024, 1024]), torch.Size([256, 256])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.295044 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.295135 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([0])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.295242 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([0])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.295363 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.295454 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([0])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.295543 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([0])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.295668 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.295837 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([256, 256])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.295949 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([0])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.296113 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.296208 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([0])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.296305 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([1000, 1000]), torch.Size([1024, 1024])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:07.296336 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([0])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.296455 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:07.296543 139848171250880 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([0])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:07.296794 139848171250880 shampoo_preconditioner_list.py:612] Rank 5: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:07.296843 139848171250880 shampoo_preconditioner_list.py:615] Rank 5: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768)
I0314 21:38:07.296882 139848171250880 shampoo_preconditioner_list.py:618] Rank 5: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:07.296916 139848171250880 shampoo_preconditioner_list.py:621] Rank 5: ShampooPreconditionerList Total Bytes: 3230472
I0314 21:38:07.298089 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([1024, 1024]), torch.Size([256, 256])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.298231 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([0])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.298403 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([1024, 1024])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.298563 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.298671 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([0])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.298786 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([0])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.298930 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.299087 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([256, 256])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.299216 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([0])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.299347 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.299445 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([0])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.299556 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([0])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.299683 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.299776 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([0])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.299866 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([0])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.300009 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.300192 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([0])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.300339 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([0])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.300474 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.300572 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([0])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.301276 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([1024, 1024])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.301443 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.301628 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([256, 256])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.301738 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([0])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.301898 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.301991 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([0])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.302094 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([0])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.302211 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.302313 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([0])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.302404 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([0])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.302520 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:07.302617 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([0])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.302710 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([0])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.302884 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:07.303050 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([256, 256])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.303162 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([0])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:07.304438 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([1024, 1024]), torch.Size([256, 256])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:07.304592 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([0])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.304767 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([1024, 1024])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.304942 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.305047 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([0])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.306161 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([512, 512])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.306344 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.306444 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([0])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.306538 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([0])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.306666 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.306802 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.306897 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.306987 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.307075 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.311030 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([1024, 1024])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.311193 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:07.311317 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:07.311411 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.311521 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.311626 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.311798 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([1024, 1024])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.311937 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.312152 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.312257 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([0])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.312416 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([0])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.317407 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([512, 512]), torch.Size([512, 512]), torch.Size([9, 9])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.320992 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([512, 512])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.321149 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([0])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.321272 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.321398 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.321497 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.321621 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.321736 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.324924 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([1024, 1024])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.325111 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:07.325241 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:07.325339 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([0])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.325434 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([0])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.325587 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:07.325696 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([0])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.325798 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([0])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:07.325926 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:07.326040 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:07.326128 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.326214 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.326335 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:07.326433 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:07.326556 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:07.326684 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:07.326852 140602519192768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([1000, 1000])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:07.327160 140602519192768 shampoo_preconditioner_list.py:612] Rank 1: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:07.327219 140602519192768 shampoo_preconditioner_list.py:615] Rank 1: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056)
I0314 21:38:07.327263 140602519192768 shampoo_preconditioner_list.py:618] Rank 1: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:07.327302 140602519192768 shampoo_preconditioner_list.py:621] Rank 1: ShampooPreconditionerList Total Bytes: 12012296
I0314 21:38:07.605069 140498825811136 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_0/imagenet_resnet_pytorch/trial_3/flags_0.json.
I0314 21:38:07.634346 140498825811136 submission_runner.py:337] Starting training loop.
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
[rank2]:W0314 21:38:14.175000 46 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank3]:W0314 21:38:14.268000 47 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank7]:W0314 21:38:14.355000 51 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank4]:W0314 21:38:14.401000 48 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank6]:W0314 21:38:14.500000 50 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank5]:W0314 21:38:14.502000 49 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank1]:W0314 21:38:14.514000 45 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank0]:W0314 21:38:14.602000 44 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
I0314 21:39:54.721577 140479397492480 logging_writer.py:48] [0] global_step=0, grad_norm=0.6042, loss=6.9318
I0314 21:39:54.743053 140498825811136 submission.py:265] 0) loss = 6.932, grad_norm = 0.604
I0314 21:39:55.650429 140498825811136 spec.py:321] Evaluating on the training split.
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
I0314 21:44:40.640382 140498825811136 spec.py:333] Evaluating on the validation split.
I0314 21:46:09.250218 140498825811136 spec.py:349] Evaluating on the test split.
I0314 21:46:09.439577 140498825811136 dataset_info.py:690] Load dataset info from /data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0
I0314 21:46:09.448621 140498825811136 reader.py:261] Creating a tf.data.Dataset reading 16 files located in folders: /data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0.
I0314 21:46:09.505338 140498825811136 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0
I0314 21:46:44.304198 140498825811136 submission_runner.py:469] Time since start: 516.67s, 	Step: 1, 	{'train/accuracy': 0.001016422193877551, 'train/loss': 6.91202467315051, 'validation/accuracy': 0.0009, 'validation/loss': 6.9119425, 'validation/num_examples': 50000, 'test/accuracy': 0.0012, 'test/loss': 6.9129984375, 'test/num_examples': 10000, 'score': 107.10950207710266, 'total_duration': 516.6698548793793, 'accumulated_submission_time': 107.10950207710266, 'accumulated_eval_time': 408.65377712249756, 'accumulated_logging_time': 0}
I0314 21:46:44.313208 140469690414848 logging_writer.py:48] [1] accumulated_eval_time=408.654, accumulated_logging_time=0, accumulated_submission_time=107.11, global_step=1, preemption_count=0, score=107.11, test/accuracy=0.0012, test/loss=6.913, test/num_examples=10000, total_duration=516.67, train/accuracy=0.00101642, train/loss=6.91202, validation/accuracy=0.0009, validation/loss=6.91194, validation/num_examples=50000
I0314 21:46:46.132160 140469682022144 logging_writer.py:48] [1] global_step=1, grad_norm=0.630074, loss=6.92939
I0314 21:46:46.136115 140498825811136 submission.py:265] 1) loss = 6.929, grad_norm = 0.630
I0314 21:46:46.486508 140469690414848 logging_writer.py:48] [2] global_step=2, grad_norm=0.618889, loss=6.92828
I0314 21:46:46.490681 140498825811136 submission.py:265] 2) loss = 6.928, grad_norm = 0.619
I0314 21:46:46.843890 140469682022144 logging_writer.py:48] [3] global_step=3, grad_norm=0.621794, loss=6.93605
I0314 21:46:46.847475 140498825811136 submission.py:265] 3) loss = 6.936, grad_norm = 0.622
I0314 21:46:47.198732 140469690414848 logging_writer.py:48] [4] global_step=4, grad_norm=0.615719, loss=6.94072
I0314 21:46:47.202423 140498825811136 submission.py:265] 4) loss = 6.941, grad_norm = 0.616
I0314 21:46:47.554203 140469682022144 logging_writer.py:48] [5] global_step=5, grad_norm=0.608779, loss=6.92659
I0314 21:46:47.558066 140498825811136 submission.py:265] 5) loss = 6.927, grad_norm = 0.609
I0314 21:46:47.909791 140469690414848 logging_writer.py:48] [6] global_step=6, grad_norm=0.614874, loss=6.92399
I0314 21:46:47.913634 140498825811136 submission.py:265] 6) loss = 6.924, grad_norm = 0.615
I0314 21:46:48.264783 140469682022144 logging_writer.py:48] [7] global_step=7, grad_norm=0.638095, loss=6.92212
I0314 21:46:48.268643 140498825811136 submission.py:265] 7) loss = 6.922, grad_norm = 0.638
I0314 21:46:48.619900 140469690414848 logging_writer.py:48] [8] global_step=8, grad_norm=0.623147, loss=6.92678
I0314 21:46:48.623660 140498825811136 submission.py:265] 8) loss = 6.927, grad_norm = 0.623
I0314 21:46:49.596473 140469682022144 logging_writer.py:48] [9] global_step=9, grad_norm=0.630474, loss=6.9169
I0314 21:46:49.599836 140498825811136 submission.py:265] 9) loss = 6.917, grad_norm = 0.630
I0314 21:46:50.891211 140469690414848 logging_writer.py:48] [10] global_step=10, grad_norm=0.621147, loss=6.93235
I0314 21:46:50.894935 140498825811136 submission.py:265] 10) loss = 6.932, grad_norm = 0.621
I0314 21:46:51.499364 140469682022144 logging_writer.py:48] [11] global_step=11, grad_norm=0.608207, loss=6.92609
I0314 21:46:51.503010 140498825811136 submission.py:265] 11) loss = 6.926, grad_norm = 0.608
I0314 21:46:52.295562 140469690414848 logging_writer.py:48] [12] global_step=12, grad_norm=0.606957, loss=6.92258
I0314 21:46:52.299803 140498825811136 submission.py:265] 12) loss = 6.923, grad_norm = 0.607
I0314 21:46:54.468083 140469682022144 logging_writer.py:48] [13] global_step=13, grad_norm=0.610877, loss=6.92198
I0314 21:46:54.471966 140498825811136 submission.py:265] 13) loss = 6.922, grad_norm = 0.611
I0314 21:46:55.792776 140469690414848 logging_writer.py:48] [14] global_step=14, grad_norm=0.631737, loss=6.93102
I0314 21:46:55.796520 140498825811136 submission.py:265] 14) loss = 6.931, grad_norm = 0.632
I0314 21:46:56.561944 140469682022144 logging_writer.py:48] [15] global_step=15, grad_norm=0.606733, loss=6.92527
I0314 21:46:56.566018 140498825811136 submission.py:265] 15) loss = 6.925, grad_norm = 0.607
I0314 21:46:57.158898 140469690414848 logging_writer.py:48] [16] global_step=16, grad_norm=0.602036, loss=6.9275
I0314 21:46:57.162888 140498825811136 submission.py:265] 16) loss = 6.928, grad_norm = 0.602
I0314 21:46:59.701653 140469682022144 logging_writer.py:48] [17] global_step=17, grad_norm=0.61938, loss=6.93036
I0314 21:46:59.705287 140498825811136 submission.py:265] 17) loss = 6.930, grad_norm = 0.619
I0314 21:47:00.888535 140469690414848 logging_writer.py:48] [18] global_step=18, grad_norm=0.617558, loss=6.92407
I0314 21:47:00.892544 140498825811136 submission.py:265] 18) loss = 6.924, grad_norm = 0.618
I0314 21:47:01.244995 140469682022144 logging_writer.py:48] [19] global_step=19, grad_norm=0.610546, loss=6.9164
I0314 21:47:01.249503 140498825811136 submission.py:265] 19) loss = 6.916, grad_norm = 0.611
I0314 21:47:01.785812 140469690414848 logging_writer.py:48] [20] global_step=20, grad_norm=0.626317, loss=6.92901
I0314 21:47:01.789539 140498825811136 submission.py:265] 20) loss = 6.929, grad_norm = 0.626
I0314 21:47:04.711941 140469682022144 logging_writer.py:48] [21] global_step=21, grad_norm=0.614632, loss=6.93069
I0314 21:47:04.715674 140498825811136 submission.py:265] 21) loss = 6.931, grad_norm = 0.615
I0314 21:47:05.774949 140469690414848 logging_writer.py:48] [22] global_step=22, grad_norm=0.619952, loss=6.93292
I0314 21:47:05.778761 140498825811136 submission.py:265] 22) loss = 6.933, grad_norm = 0.620
I0314 21:47:06.129604 140469682022144 logging_writer.py:48] [23] global_step=23, grad_norm=0.618508, loss=6.93987
I0314 21:47:06.133226 140498825811136 submission.py:265] 23) loss = 6.940, grad_norm = 0.619
I0314 21:47:06.635793 140469690414848 logging_writer.py:48] [24] global_step=24, grad_norm=0.621283, loss=6.91733
I0314 21:47:06.639272 140498825811136 submission.py:265] 24) loss = 6.917, grad_norm = 0.621
I0314 21:47:09.564043 140469682022144 logging_writer.py:48] [25] global_step=25, grad_norm=0.611492, loss=6.92026
I0314 21:47:09.567938 140498825811136 submission.py:265] 25) loss = 6.920, grad_norm = 0.611
I0314 21:47:10.659595 140469690414848 logging_writer.py:48] [26] global_step=26, grad_norm=0.628113, loss=6.92007
I0314 21:47:10.663421 140498825811136 submission.py:265] 26) loss = 6.920, grad_norm = 0.628
I0314 21:47:11.394634 140469682022144 logging_writer.py:48] [27] global_step=27, grad_norm=0.609794, loss=6.92252
I0314 21:47:11.398186 140498825811136 submission.py:265] 27) loss = 6.923, grad_norm = 0.610
I0314 21:47:12.017746 140469690414848 logging_writer.py:48] [28] global_step=28, grad_norm=0.625082, loss=6.92853
I0314 21:47:12.021238 140498825811136 submission.py:265] 28) loss = 6.929, grad_norm = 0.625
I0314 21:47:14.909924 140469682022144 logging_writer.py:48] [29] global_step=29, grad_norm=0.615207, loss=6.92578
I0314 21:47:14.913873 140498825811136 submission.py:265] 29) loss = 6.926, grad_norm = 0.615
I0314 21:47:15.999713 140469690414848 logging_writer.py:48] [30] global_step=30, grad_norm=0.621765, loss=6.92374
I0314 21:47:16.003252 140498825811136 submission.py:265] 30) loss = 6.924, grad_norm = 0.622
I0314 21:47:16.520147 140469682022144 logging_writer.py:48] [31] global_step=31, grad_norm=0.600491, loss=6.93228
I0314 21:47:16.523605 140498825811136 submission.py:265] 31) loss = 6.932, grad_norm = 0.600
I0314 21:47:16.955235 140469690414848 logging_writer.py:48] [32] global_step=32, grad_norm=0.600531, loss=6.92643
I0314 21:47:16.958734 140498825811136 submission.py:265] 32) loss = 6.926, grad_norm = 0.601
I0314 21:47:19.657998 140469682022144 logging_writer.py:48] [33] global_step=33, grad_norm=0.646443, loss=6.93471
I0314 21:47:19.661548 140498825811136 submission.py:265] 33) loss = 6.935, grad_norm = 0.646
I0314 21:47:20.778987 140469690414848 logging_writer.py:48] [34] global_step=34, grad_norm=0.614654, loss=6.9298
I0314 21:47:20.782478 140498825811136 submission.py:265] 34) loss = 6.930, grad_norm = 0.615
I0314 21:47:21.239829 140469682022144 logging_writer.py:48] [35] global_step=35, grad_norm=0.607555, loss=6.92561
I0314 21:47:21.243630 140498825811136 submission.py:265] 35) loss = 6.926, grad_norm = 0.608
I0314 21:47:21.610414 140469690414848 logging_writer.py:48] [36] global_step=36, grad_norm=0.626465, loss=6.92944
I0314 21:47:21.614309 140498825811136 submission.py:265] 36) loss = 6.929, grad_norm = 0.626
I0314 21:47:24.360755 140469682022144 logging_writer.py:48] [37] global_step=37, grad_norm=0.618122, loss=6.92628
I0314 21:47:24.364586 140498825811136 submission.py:265] 37) loss = 6.926, grad_norm = 0.618
I0314 21:47:25.548221 140469690414848 logging_writer.py:48] [38] global_step=38, grad_norm=0.609629, loss=6.92631
I0314 21:47:25.552020 140498825811136 submission.py:265] 38) loss = 6.926, grad_norm = 0.610
I0314 21:47:27.199975 140469682022144 logging_writer.py:48] [39] global_step=39, grad_norm=0.615592, loss=6.91744
I0314 21:47:27.203458 140498825811136 submission.py:265] 39) loss = 6.917, grad_norm = 0.616
I0314 21:47:27.555043 140469690414848 logging_writer.py:48] [40] global_step=40, grad_norm=0.621567, loss=6.91902
I0314 21:47:27.558790 140498825811136 submission.py:265] 40) loss = 6.919, grad_norm = 0.622
I0314 21:47:29.653810 140469682022144 logging_writer.py:48] [41] global_step=41, grad_norm=0.598359, loss=6.92168
I0314 21:47:29.657824 140498825811136 submission.py:265] 41) loss = 6.922, grad_norm = 0.598
I0314 21:47:30.691370 140469690414848 logging_writer.py:48] [42] global_step=42, grad_norm=0.600447, loss=6.91628
I0314 21:47:30.694882 140498825811136 submission.py:265] 42) loss = 6.916, grad_norm = 0.600
I0314 21:47:32.758519 140469682022144 logging_writer.py:48] [43] global_step=43, grad_norm=0.617474, loss=6.92102
I0314 21:47:32.762426 140498825811136 submission.py:265] 43) loss = 6.921, grad_norm = 0.617
I0314 21:47:33.133164 140469690414848 logging_writer.py:48] [44] global_step=44, grad_norm=0.613981, loss=6.91918
I0314 21:47:33.137112 140498825811136 submission.py:265] 44) loss = 6.919, grad_norm = 0.614
I0314 21:47:36.016072 140469682022144 logging_writer.py:48] [45] global_step=45, grad_norm=0.599731, loss=6.92123
I0314 21:47:36.019657 140498825811136 submission.py:265] 45) loss = 6.921, grad_norm = 0.600
I0314 21:47:36.396056 140469690414848 logging_writer.py:48] [46] global_step=46, grad_norm=0.63218, loss=6.91835
I0314 21:47:36.399729 140498825811136 submission.py:265] 46) loss = 6.918, grad_norm = 0.632
I0314 21:47:37.932067 140469682022144 logging_writer.py:48] [47] global_step=47, grad_norm=0.60083, loss=6.90196
I0314 21:47:37.935648 140498825811136 submission.py:265] 47) loss = 6.902, grad_norm = 0.601
I0314 21:47:38.288170 140469690414848 logging_writer.py:48] [48] global_step=48, grad_norm=0.604909, loss=6.90811
I0314 21:47:38.291828 140498825811136 submission.py:265] 48) loss = 6.908, grad_norm = 0.605
I0314 21:47:40.945936 140469682022144 logging_writer.py:48] [49] global_step=49, grad_norm=0.625135, loss=6.9202
I0314 21:47:40.949723 140498825811136 submission.py:265] 49) loss = 6.920, grad_norm = 0.625
I0314 21:47:41.301397 140469690414848 logging_writer.py:48] [50] global_step=50, grad_norm=0.604466, loss=6.90808
I0314 21:47:41.304899 140498825811136 submission.py:265] 50) loss = 6.908, grad_norm = 0.604
I0314 21:47:42.762319 140469682022144 logging_writer.py:48] [51] global_step=51, grad_norm=0.609776, loss=6.91677
I0314 21:47:42.766081 140498825811136 submission.py:265] 51) loss = 6.917, grad_norm = 0.610
I0314 21:47:43.117277 140469690414848 logging_writer.py:48] [52] global_step=52, grad_norm=0.600207, loss=6.91041
I0314 21:47:43.121134 140498825811136 submission.py:265] 52) loss = 6.910, grad_norm = 0.600
I0314 21:47:45.700082 140469682022144 logging_writer.py:48] [53] global_step=53, grad_norm=0.595917, loss=6.91325
I0314 21:47:45.704000 140498825811136 submission.py:265] 53) loss = 6.913, grad_norm = 0.596
I0314 21:47:46.055593 140469690414848 logging_writer.py:48] [54] global_step=54, grad_norm=0.615658, loss=6.90295
I0314 21:47:46.058995 140498825811136 submission.py:265] 54) loss = 6.903, grad_norm = 0.616
I0314 21:47:47.304908 140469682022144 logging_writer.py:48] [55] global_step=55, grad_norm=0.599298, loss=6.9108
I0314 21:47:47.308408 140498825811136 submission.py:265] 55) loss = 6.911, grad_norm = 0.599
I0314 21:47:47.660148 140469690414848 logging_writer.py:48] [56] global_step=56, grad_norm=0.612399, loss=6.90701
I0314 21:47:47.663733 140498825811136 submission.py:265] 56) loss = 6.907, grad_norm = 0.612
I0314 21:47:50.888780 140469682022144 logging_writer.py:48] [57] global_step=57, grad_norm=0.61311, loss=6.90605
I0314 21:47:50.892318 140498825811136 submission.py:265] 57) loss = 6.906, grad_norm = 0.613
I0314 21:47:51.244028 140469690414848 logging_writer.py:48] [58] global_step=58, grad_norm=0.626758, loss=6.90324
I0314 21:47:51.247518 140498825811136 submission.py:265] 58) loss = 6.903, grad_norm = 0.627
I0314 21:47:52.395321 140469682022144 logging_writer.py:48] [59] global_step=59, grad_norm=0.615952, loss=6.90944
I0314 21:47:52.398793 140498825811136 submission.py:265] 59) loss = 6.909, grad_norm = 0.616
I0314 21:47:52.750571 140469690414848 logging_writer.py:48] [60] global_step=60, grad_norm=0.607162, loss=6.90056
I0314 21:47:52.754361 140498825811136 submission.py:265] 60) loss = 6.901, grad_norm = 0.607
I0314 21:47:55.570688 140469682022144 logging_writer.py:48] [61] global_step=61, grad_norm=0.592478, loss=6.90587
I0314 21:47:55.574366 140498825811136 submission.py:265] 61) loss = 6.906, grad_norm = 0.592
I0314 21:47:55.926196 140469690414848 logging_writer.py:48] [62] global_step=62, grad_norm=0.595526, loss=6.89944
I0314 21:47:55.929739 140498825811136 submission.py:265] 62) loss = 6.899, grad_norm = 0.596
I0314 21:47:57.036996 140469682022144 logging_writer.py:48] [63] global_step=63, grad_norm=0.609934, loss=6.8964
I0314 21:47:57.040516 140498825811136 submission.py:265] 63) loss = 6.896, grad_norm = 0.610
I0314 21:47:57.392400 140469690414848 logging_writer.py:48] [64] global_step=64, grad_norm=0.627634, loss=6.8919
I0314 21:47:57.396217 140498825811136 submission.py:265] 64) loss = 6.892, grad_norm = 0.628
I0314 21:48:00.304453 140469682022144 logging_writer.py:48] [65] global_step=65, grad_norm=0.606697, loss=6.88423
I0314 21:48:00.308276 140498825811136 submission.py:265] 65) loss = 6.884, grad_norm = 0.607
I0314 21:48:00.879553 140469690414848 logging_writer.py:48] [66] global_step=66, grad_norm=0.610387, loss=6.89116
I0314 21:48:00.883332 140498825811136 submission.py:265] 66) loss = 6.891, grad_norm = 0.610
I0314 21:48:01.555198 140469682022144 logging_writer.py:48] [67] global_step=67, grad_norm=0.606226, loss=6.88819
I0314 21:48:01.558698 140498825811136 submission.py:265] 67) loss = 6.888, grad_norm = 0.606
I0314 21:48:02.184918 140469690414848 logging_writer.py:48] [68] global_step=68, grad_norm=0.612466, loss=6.88828
I0314 21:48:02.188833 140498825811136 submission.py:265] 68) loss = 6.888, grad_norm = 0.612
I0314 21:48:04.816003 140469682022144 logging_writer.py:48] [69] global_step=69, grad_norm=0.58953, loss=6.9021
I0314 21:48:04.819811 140498825811136 submission.py:265] 69) loss = 6.902, grad_norm = 0.590
I0314 21:48:05.968968 140469690414848 logging_writer.py:48] [70] global_step=70, grad_norm=0.617164, loss=6.8949
I0314 21:48:05.973192 140498825811136 submission.py:265] 70) loss = 6.895, grad_norm = 0.617
I0314 21:48:06.729497 140469682022144 logging_writer.py:48] [71] global_step=71, grad_norm=0.608429, loss=6.89766
I0314 21:48:06.733071 140498825811136 submission.py:265] 71) loss = 6.898, grad_norm = 0.608
I0314 21:48:07.913020 140469690414848 logging_writer.py:48] [72] global_step=72, grad_norm=0.610731, loss=6.89115
I0314 21:48:07.916838 140498825811136 submission.py:265] 72) loss = 6.891, grad_norm = 0.611
I0314 21:48:09.905616 140469682022144 logging_writer.py:48] [73] global_step=73, grad_norm=0.621258, loss=6.89323
I0314 21:48:09.909698 140498825811136 submission.py:265] 73) loss = 6.893, grad_norm = 0.621
I0314 21:48:10.976511 140469690414848 logging_writer.py:48] [74] global_step=74, grad_norm=0.582559, loss=6.89171
I0314 21:48:10.980195 140498825811136 submission.py:265] 74) loss = 6.892, grad_norm = 0.583
I0314 21:48:11.859369 140469682022144 logging_writer.py:48] [75] global_step=75, grad_norm=0.598135, loss=6.88558
I0314 21:48:11.863229 140498825811136 submission.py:265] 75) loss = 6.886, grad_norm = 0.598
I0314 21:48:12.669318 140469690414848 logging_writer.py:48] [76] global_step=76, grad_norm=0.600388, loss=6.88996
I0314 21:48:12.672756 140498825811136 submission.py:265] 76) loss = 6.890, grad_norm = 0.600
I0314 21:48:14.669294 140469682022144 logging_writer.py:48] [77] global_step=77, grad_norm=0.608983, loss=6.88307
I0314 21:48:14.673336 140498825811136 submission.py:265] 77) loss = 6.883, grad_norm = 0.609
I0314 21:48:16.020061 140469690414848 logging_writer.py:48] [78] global_step=78, grad_norm=0.610667, loss=6.8842
I0314 21:48:16.023443 140498825811136 submission.py:265] 78) loss = 6.884, grad_norm = 0.611
I0314 21:48:16.852182 140469682022144 logging_writer.py:48] [79] global_step=79, grad_norm=0.623994, loss=6.89041
I0314 21:48:16.856121 140498825811136 submission.py:265] 79) loss = 6.890, grad_norm = 0.624
I0314 21:48:17.871883 140469690414848 logging_writer.py:48] [80] global_step=80, grad_norm=0.59171, loss=6.88283
I0314 21:48:17.875814 140498825811136 submission.py:265] 80) loss = 6.883, grad_norm = 0.592
I0314 21:48:19.960142 140469682022144 logging_writer.py:48] [81] global_step=81, grad_norm=0.60335, loss=6.88309
I0314 21:48:19.963832 140498825811136 submission.py:265] 81) loss = 6.883, grad_norm = 0.603
I0314 21:48:21.605561 140469690414848 logging_writer.py:48] [82] global_step=82, grad_norm=0.602942, loss=6.86941
I0314 21:48:21.609395 140498825811136 submission.py:265] 82) loss = 6.869, grad_norm = 0.603
I0314 21:48:22.404511 140469682022144 logging_writer.py:48] [83] global_step=83, grad_norm=0.615298, loss=6.87852
I0314 21:48:22.408147 140498825811136 submission.py:265] 83) loss = 6.879, grad_norm = 0.615
I0314 21:48:23.481213 140469690414848 logging_writer.py:48] [84] global_step=84, grad_norm=0.606485, loss=6.88588
I0314 21:48:23.484690 140498825811136 submission.py:265] 84) loss = 6.886, grad_norm = 0.606
I0314 21:48:25.751010 140469682022144 logging_writer.py:48] [85] global_step=85, grad_norm=0.595097, loss=6.87092
I0314 21:48:25.754714 140498825811136 submission.py:265] 85) loss = 6.871, grad_norm = 0.595
I0314 21:48:27.160067 140469690414848 logging_writer.py:48] [86] global_step=86, grad_norm=0.626061, loss=6.87285
I0314 21:48:27.163471 140498825811136 submission.py:265] 86) loss = 6.873, grad_norm = 0.626
I0314 21:48:27.515245 140469682022144 logging_writer.py:48] [87] global_step=87, grad_norm=0.609661, loss=6.87166
I0314 21:48:27.518908 140498825811136 submission.py:265] 87) loss = 6.872, grad_norm = 0.610
I0314 21:48:28.350927 140469690414848 logging_writer.py:48] [88] global_step=88, grad_norm=0.613203, loss=6.86948
I0314 21:48:28.354989 140498825811136 submission.py:265] 88) loss = 6.869, grad_norm = 0.613
I0314 21:48:30.428406 140469682022144 logging_writer.py:48] [89] global_step=89, grad_norm=0.607956, loss=6.8602
I0314 21:48:30.432157 140498825811136 submission.py:265] 89) loss = 6.860, grad_norm = 0.608
I0314 21:48:32.522220 140469690414848 logging_writer.py:48] [90] global_step=90, grad_norm=0.621933, loss=6.87954
I0314 21:48:32.525942 140498825811136 submission.py:265] 90) loss = 6.880, grad_norm = 0.622
I0314 21:48:32.878675 140469682022144 logging_writer.py:48] [91] global_step=91, grad_norm=0.60832, loss=6.87337
I0314 21:48:32.882734 140498825811136 submission.py:265] 91) loss = 6.873, grad_norm = 0.608
I0314 21:48:33.425377 140469690414848 logging_writer.py:48] [92] global_step=92, grad_norm=0.619842, loss=6.86374
I0314 21:48:33.429496 140498825811136 submission.py:265] 92) loss = 6.864, grad_norm = 0.620
I0314 21:48:35.167090 140469682022144 logging_writer.py:48] [93] global_step=93, grad_norm=0.605205, loss=6.86223
I0314 21:48:35.170950 140498825811136 submission.py:265] 93) loss = 6.862, grad_norm = 0.605
I0314 21:48:37.499622 140469690414848 logging_writer.py:48] [94] global_step=94, grad_norm=0.603353, loss=6.86931
I0314 21:48:37.503183 140498825811136 submission.py:265] 94) loss = 6.869, grad_norm = 0.603
I0314 21:48:37.855315 140469682022144 logging_writer.py:48] [95] global_step=95, grad_norm=0.605884, loss=6.87005
I0314 21:48:37.858922 140498825811136 submission.py:265] 95) loss = 6.870, grad_norm = 0.606
I0314 21:48:38.212084 140469690414848 logging_writer.py:48] [96] global_step=96, grad_norm=0.607452, loss=6.865
I0314 21:48:38.216335 140498825811136 submission.py:265] 96) loss = 6.865, grad_norm = 0.607
I0314 21:48:39.801855 140469682022144 logging_writer.py:48] [97] global_step=97, grad_norm=0.614317, loss=6.85311
I0314 21:48:39.805756 140498825811136 submission.py:265] 97) loss = 6.853, grad_norm = 0.614
I0314 21:48:43.533385 140469690414848 logging_writer.py:48] [98] global_step=98, grad_norm=0.613036, loss=6.86031
I0314 21:48:43.537448 140498825811136 submission.py:265] 98) loss = 6.860, grad_norm = 0.613
I0314 21:48:44.644239 140469682022144 logging_writer.py:48] [99] global_step=99, grad_norm=0.618616, loss=6.86914
I0314 21:48:44.648354 140498825811136 submission.py:265] 99) loss = 6.869, grad_norm = 0.619
I0314 21:48:45.000420 140469690414848 logging_writer.py:48] [100] global_step=100, grad_norm=0.610829, loss=6.86546
I0314 21:48:45.004129 140498825811136 submission.py:265] 100) loss = 6.865, grad_norm = 0.611
I0314 21:55:18.527137 140498825811136 spec.py:321] Evaluating on the training split.
I0314 21:55:59.506540 140498825811136 spec.py:333] Evaluating on the validation split.
I0314 21:56:40.006778 140498825811136 spec.py:349] Evaluating on the test split.
I0314 21:56:41.139926 140498825811136 submission_runner.py:469] Time since start: 1113.51s, 	Step: 433, 	{'train/accuracy': 0.03077168367346939, 'train/loss': 6.195235894650829, 'validation/accuracy': 0.03022, 'validation/loss': 6.232455, 'validation/num_examples': 50000, 'test/accuracy': 0.0175, 'test/loss': 6.366544140625, 'test/num_examples': 10000, 'score': 618.1501262187958, 'total_duration': 1113.5057480335236, 'accumulated_submission_time': 618.1501262187958, 'accumulated_eval_time': 491.2667407989502, 'accumulated_logging_time': 0.0179290771484375}
I0314 21:56:41.150056 140469698807552 logging_writer.py:48] [433] accumulated_eval_time=491.267, accumulated_logging_time=0.0179291, accumulated_submission_time=618.15, global_step=433, preemption_count=0, score=618.15, test/accuracy=0.0175, test/loss=6.36654, test/num_examples=10000, total_duration=1113.51, train/accuracy=0.0307717, train/loss=6.19524, validation/accuracy=0.03022, validation/loss=6.23245, validation/num_examples=50000
I0314 21:57:51.249500 140469707200256 logging_writer.py:48] [500] global_step=500, grad_norm=0.857426, loss=6.29538
I0314 21:57:51.254126 140498825811136 submission.py:265] 500) loss = 6.295, grad_norm = 0.857
I0314 22:05:14.467465 140498825811136 spec.py:321] Evaluating on the training split.
I0314 22:05:53.463867 140498825811136 spec.py:333] Evaluating on the validation split.
I0314 22:06:33.790586 140498825811136 spec.py:349] Evaluating on the test split.
I0314 22:06:34.928989 140498825811136 submission_runner.py:469] Time since start: 1707.29s, 	Step: 871, 	{'train/accuracy': 0.08302774234693877, 'train/loss': 5.374753368144133, 'validation/accuracy': 0.07748, 'validation/loss': 5.459123125, 'validation/num_examples': 50000, 'test/accuracy': 0.05, 'test/loss': 5.750669140625, 'test/num_examples': 10000, 'score': 1128.4965028762817, 'total_duration': 1707.294766664505, 'accumulated_submission_time': 1128.4965028762817, 'accumulated_eval_time': 571.728408575058, 'accumulated_logging_time': 0.03631782531738281}
I0314 22:06:34.939378 140469698807552 logging_writer.py:48] [871] accumulated_eval_time=571.728, accumulated_logging_time=0.0363178, accumulated_submission_time=1128.5, global_step=871, preemption_count=0, score=1128.5, test/accuracy=0.05, test/loss=5.75067, test/num_examples=10000, total_duration=1707.29, train/accuracy=0.0830277, train/loss=5.37475, validation/accuracy=0.07748, validation/loss=5.45912, validation/num_examples=50000
I0314 22:09:05.893167 140469707200256 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.31328, loss=5.63212
I0314 22:09:05.942853 140498825811136 submission.py:265] 1000) loss = 5.632, grad_norm = 1.313
I0314 22:15:07.417559 140498825811136 spec.py:321] Evaluating on the training split.
I0314 22:15:46.841064 140498825811136 spec.py:333] Evaluating on the validation split.
I0314 22:16:27.488590 140498825811136 spec.py:349] Evaluating on the test split.
I0314 22:16:28.631581 140498825811136 submission_runner.py:469] Time since start: 2301.00s, 	Step: 1379, 	{'train/accuracy': 0.1466438137755102, 'train/loss': 4.571158895687181, 'validation/accuracy': 0.13178, 'validation/loss': 4.69486625, 'validation/num_examples': 50000, 'test/accuracy': 0.0911, 'test/loss': 5.147365625, 'test/num_examples': 10000, 'score': 1637.8483209609985, 'total_duration': 2300.9973809719086, 'accumulated_submission_time': 1637.8483209609985, 'accumulated_eval_time': 652.9425506591797, 'accumulated_logging_time': 0.05721259117126465}
I0314 22:16:28.682633 140469698807552 logging_writer.py:48] [1379] accumulated_eval_time=652.943, accumulated_logging_time=0.0572126, accumulated_submission_time=1637.85, global_step=1379, preemption_count=0, score=1637.85, test/accuracy=0.0911, test/loss=5.14737, test/num_examples=10000, total_duration=2301, train/accuracy=0.146644, train/loss=4.57116, validation/accuracy=0.13178, validation/loss=4.69487, validation/num_examples=50000
I0314 22:17:30.288958 140469707200256 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.21848, loss=5.01387
I0314 22:17:30.292973 140498825811136 submission.py:265] 1500) loss = 5.014, grad_norm = 1.218
I0314 22:21:58.262111 140469698807552 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.10309, loss=4.57436
I0314 22:21:58.266607 140498825811136 submission.py:265] 2000) loss = 4.574, grad_norm = 1.103
I0314 22:25:00.103602 140498825811136 spec.py:321] Evaluating on the training split.
I0314 22:25:40.849309 140498825811136 spec.py:333] Evaluating on the validation split.
I0314 22:26:23.315283 140498825811136 spec.py:349] Evaluating on the test split.
I0314 22:26:24.455617 140498825811136 submission_runner.py:469] Time since start: 2896.82s, 	Step: 2236, 	{'train/accuracy': 0.298030931122449, 'train/loss': 3.4236001773756377, 'validation/accuracy': 0.27212, 'validation/loss': 3.5646621875, 'validation/num_examples': 50000, 'test/accuracy': 0.1853, 'test/loss': 4.224787109375, 'test/num_examples': 10000, 'score': 2145.9948003292084, 'total_duration': 2896.821388244629, 'accumulated_submission_time': 2145.9948003292084, 'accumulated_eval_time': 737.2947862148285, 'accumulated_logging_time': 0.11806011199951172}
I0314 22:26:24.465745 140469707200256 logging_writer.py:48] [2236] accumulated_eval_time=737.295, accumulated_logging_time=0.11806, accumulated_submission_time=2145.99, global_step=2236, preemption_count=0, score=2145.99, test/accuracy=0.1853, test/loss=4.22479, test/num_examples=10000, total_duration=2896.82, train/accuracy=0.298031, train/loss=3.4236, validation/accuracy=0.27212, validation/loss=3.56466, validation/num_examples=50000
I0314 22:31:08.527901 140469698807552 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.09328, loss=4.22497
I0314 22:31:08.583212 140498825811136 submission.py:265] 2500) loss = 4.225, grad_norm = 1.093
I0314 22:34:56.415282 140498825811136 spec.py:321] Evaluating on the training split.
I0314 22:35:35.564110 140498825811136 spec.py:333] Evaluating on the validation split.
I0314 22:36:16.804370 140498825811136 spec.py:349] Evaluating on the test split.
I0314 22:36:17.940079 140498825811136 submission_runner.py:469] Time since start: 3490.31s, 	Step: 3000, 	{'train/accuracy': 0.40708705357142855, 'train/loss': 2.8126083685427297, 'validation/accuracy': 0.37536, 'validation/loss': 2.9731296875, 'validation/num_examples': 50000, 'test/accuracy': 0.2587, 'test/loss': 3.73683125, 'test/num_examples': 10000, 'score': 2654.7711610794067, 'total_duration': 3490.305849790573, 'accumulated_submission_time': 2654.7711610794067, 'accumulated_eval_time': 818.8198070526123, 'accumulated_logging_time': 0.13681578636169434}
I0314 22:36:17.950123 140469707200256 logging_writer.py:48] [3000] accumulated_eval_time=818.82, accumulated_logging_time=0.136816, accumulated_submission_time=2654.77, global_step=3000, preemption_count=0, score=2654.77, test/accuracy=0.2587, test/loss=3.73683, test/num_examples=10000, total_duration=3490.31, train/accuracy=0.407087, train/loss=2.81261, validation/accuracy=0.37536, validation/loss=2.97313, validation/num_examples=50000
I0314 22:36:19.599993 140469698807552 logging_writer.py:48] [3000] global_step=3000, grad_norm=1.0742, loss=3.86238
I0314 22:36:19.603389 140498825811136 submission.py:265] 3000) loss = 3.862, grad_norm = 1.074
I0314 22:40:51.578431 140469707200256 logging_writer.py:48] [3500] global_step=3500, grad_norm=1.02905, loss=3.56744
I0314 22:40:51.582974 140498825811136 submission.py:265] 3500) loss = 3.567, grad_norm = 1.029
I0314 22:44:50.319311 140498825811136 spec.py:321] Evaluating on the training split.
I0314 22:45:30.731117 140498825811136 spec.py:333] Evaluating on the validation split.
I0314 22:46:12.081135 140498825811136 spec.py:349] Evaluating on the test split.
I0314 22:46:13.217717 140498825811136 submission_runner.py:469] Time since start: 4085.58s, 	Step: 3740, 	{'train/accuracy': 0.4516103316326531, 'train/loss': 2.5264626327826054, 'validation/accuracy': 0.41548, 'validation/loss': 2.7033590625, 'validation/num_examples': 50000, 'test/accuracy': 0.2952, 'test/loss': 3.481933984375, 'test/num_examples': 10000, 'score': 3163.9997503757477, 'total_duration': 4085.5834527015686, 'accumulated_submission_time': 3163.9997503757477, 'accumulated_eval_time': 901.7183556556702, 'accumulated_logging_time': 0.15584373474121094}
I0314 22:46:13.264348 140469698807552 logging_writer.py:48] [3740] accumulated_eval_time=901.718, accumulated_logging_time=0.155844, accumulated_submission_time=3164, global_step=3740, preemption_count=0, score=3164, test/accuracy=0.2952, test/loss=3.48193, test/num_examples=10000, total_duration=4085.58, train/accuracy=0.45161, train/loss=2.52646, validation/accuracy=0.41548, validation/loss=2.70336, validation/num_examples=50000
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
I0314 22:48:10.800995 140469707200256 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.973105, loss=3.54806
I0314 22:48:10.805627 140498825811136 submission.py:265] 4000) loss = 3.548, grad_norm = 0.973
I0314 22:52:37.012590 140469698807552 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.951605, loss=3.31763
I0314 22:52:37.016852 140498825811136 submission.py:265] 4500) loss = 3.318, grad_norm = 0.952
I0314 22:54:47.141425 140498825811136 spec.py:321] Evaluating on the training split.
I0314 22:55:27.277117 140498825811136 spec.py:333] Evaluating on the validation split.
I0314 22:56:08.119717 140498825811136 spec.py:349] Evaluating on the test split.
I0314 22:56:09.255786 140498825811136 submission_runner.py:469] Time since start: 4681.62s, 	Step: 4678, 	{'train/accuracy': 0.5200693558673469, 'train/loss': 2.1601232411910076, 'validation/accuracy': 0.48154, 'validation/loss': 2.34627859375, 'validation/num_examples': 50000, 'test/accuracy': 0.3521, 'test/loss': 3.1220181640625, 'test/num_examples': 10000, 'score': 3674.542419195175, 'total_duration': 4681.621529579163, 'accumulated_submission_time': 3674.542419195175, 'accumulated_eval_time': 983.8328664302826, 'accumulated_logging_time': 0.23341703414916992}
I0314 22:56:09.265852 140469707200256 logging_writer.py:48] [4678] accumulated_eval_time=983.833, accumulated_logging_time=0.233417, accumulated_submission_time=3674.54, global_step=4678, preemption_count=0, score=3674.54, test/accuracy=0.3521, test/loss=3.12202, test/num_examples=10000, total_duration=4681.62, train/accuracy=0.520069, train/loss=2.16012, validation/accuracy=0.48154, validation/loss=2.34628, validation/num_examples=50000
I0314 23:01:42.058786 140469698807552 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.960074, loss=3.29569
I0314 23:01:42.075807 140498825811136 submission.py:265] 5000) loss = 3.296, grad_norm = 0.960
I0314 23:04:40.768042 140498825811136 spec.py:321] Evaluating on the training split.
I0314 23:05:22.062907 140498825811136 spec.py:333] Evaluating on the validation split.
I0314 23:06:04.053271 140498825811136 spec.py:349] Evaluating on the test split.
I0314 23:06:05.180681 140498825811136 submission_runner.py:469] Time since start: 5277.55s, 	Step: 5405, 	{'train/accuracy': 0.5469347895408163, 'train/loss': 2.0122524962133292, 'validation/accuracy': 0.50722, 'validation/loss': 2.221385, 'validation/num_examples': 50000, 'test/accuracy': 0.3721, 'test/loss': 3.0044435546875, 'test/num_examples': 10000, 'score': 4182.806913137436, 'total_duration': 5277.5464787483215, 'accumulated_submission_time': 4182.806913137436, 'accumulated_eval_time': 1068.2456591129303, 'accumulated_logging_time': 0.2519814968109131}
I0314 23:06:05.190499 140469707200256 logging_writer.py:48] [5405] accumulated_eval_time=1068.25, accumulated_logging_time=0.251981, accumulated_submission_time=4182.81, global_step=5405, preemption_count=0, score=4182.81, test/accuracy=0.3721, test/loss=3.00444, test/num_examples=10000, total_duration=5277.55, train/accuracy=0.546935, train/loss=2.01225, validation/accuracy=0.50722, validation/loss=2.22139, validation/num_examples=50000
I0314 23:06:50.091012 140469698807552 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.958571, loss=3.32999
I0314 23:06:50.095141 140498825811136 submission.py:265] 5500) loss = 3.330, grad_norm = 0.959
I0314 23:12:18.036505 140469707200256 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.969925, loss=3.18495
I0314 23:12:18.085755 140498825811136 submission.py:265] 6000) loss = 3.185, grad_norm = 0.970
I0314 23:14:39.881596 140498825811136 spec.py:321] Evaluating on the training split.
I0314 23:15:19.544659 140498825811136 spec.py:333] Evaluating on the validation split.
I0314 23:16:01.045788 140498825811136 spec.py:349] Evaluating on the test split.
I0314 23:16:02.184270 140498825811136 submission_runner.py:469] Time since start: 5874.55s, 	Step: 6142, 	{'train/accuracy': 0.5642737563775511, 'train/loss': 1.9611919169523278, 'validation/accuracy': 0.52344, 'validation/loss': 2.1668059375, 'validation/num_examples': 50000, 'test/accuracy': 0.378, 'test/loss': 2.947890625, 'test/num_examples': 10000, 'score': 4694.277507781982, 'total_duration': 5874.550024986267, 'accumulated_submission_time': 4694.277507781982, 'accumulated_eval_time': 1150.5484170913696, 'accumulated_logging_time': 0.26991796493530273}
I0314 23:16:02.211189 140469698807552 logging_writer.py:48] [6142] accumulated_eval_time=1150.55, accumulated_logging_time=0.269918, accumulated_submission_time=4694.28, global_step=6142, preemption_count=0, score=4694.28, test/accuracy=0.378, test/loss=2.94789, test/num_examples=10000, total_duration=5874.55, train/accuracy=0.564274, train/loss=1.96119, validation/accuracy=0.52344, validation/loss=2.16681, validation/num_examples=50000
I0314 23:19:44.714631 140469707200256 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.978686, loss=3.18759
I0314 23:19:44.719131 140498825811136 submission.py:265] 6500) loss = 3.188, grad_norm = 0.979
I0314 23:23:51.186269 140469698807552 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.995096, loss=3.0949
I0314 23:23:51.190446 140498825811136 submission.py:265] 7000) loss = 3.095, grad_norm = 0.995
I0314 23:24:33.749119 140498825811136 spec.py:321] Evaluating on the training split.
I0314 23:25:13.783222 140498825811136 spec.py:333] Evaluating on the validation split.
I0314 23:25:54.698076 140498825811136 spec.py:349] Evaluating on the test split.
I0314 23:25:55.836800 140498825811136 submission_runner.py:469] Time since start: 6468.20s, 	Step: 7065, 	{'train/accuracy': 0.589225924744898, 'train/loss': 1.8145524628308354, 'validation/accuracy': 0.54478, 'validation/loss': 2.03369953125, 'validation/num_examples': 50000, 'test/accuracy': 0.4079, 'test/loss': 2.771328515625, 'test/num_examples': 10000, 'score': 5202.502809047699, 'total_duration': 6468.202593564987, 'accumulated_submission_time': 5202.502809047699, 'accumulated_eval_time': 1232.6363155841827, 'accumulated_logging_time': 0.30586719512939453}
I0314 23:25:55.846707 140469707200256 logging_writer.py:48] [7065] accumulated_eval_time=1232.64, accumulated_logging_time=0.305867, accumulated_submission_time=5202.5, global_step=7065, preemption_count=0, score=5202.5, test/accuracy=0.4079, test/loss=2.77133, test/num_examples=10000, total_duration=6468.2, train/accuracy=0.589226, train/loss=1.81455, validation/accuracy=0.54478, validation/loss=2.0337, validation/num_examples=50000
I0314 23:32:35.019062 140469698807552 logging_writer.py:48] [7500] global_step=7500, grad_norm=1.01506, loss=3.12265
I0314 23:32:35.037191 140498825811136 submission.py:265] 7500) loss = 3.123, grad_norm = 1.015
I0314 23:34:27.586767 140498825811136 spec.py:321] Evaluating on the training split.
I0314 23:35:08.280982 140498825811136 spec.py:333] Evaluating on the validation split.
I0314 23:35:49.425672 140498825811136 spec.py:349] Evaluating on the test split.
I0314 23:35:50.546367 140498825811136 submission_runner.py:469] Time since start: 7062.91s, 	Step: 7751, 	{'train/accuracy': 0.5987125318877551, 'train/loss': 1.7709064094387754, 'validation/accuracy': 0.55386, 'validation/loss': 1.9840478125, 'validation/num_examples': 50000, 'test/accuracy': 0.4094, 'test/loss': 2.776784765625, 'test/num_examples': 10000, 'score': 5711.111362695694, 'total_duration': 7062.912135601044, 'accumulated_submission_time': 5711.111362695694, 'accumulated_eval_time': 1315.596096754074, 'accumulated_logging_time': 0.3243408203125}
I0314 23:35:50.574650 140469707200256 logging_writer.py:48] [7751] accumulated_eval_time=1315.6, accumulated_logging_time=0.324341, accumulated_submission_time=5711.11, global_step=7751, preemption_count=0, score=5711.11, test/accuracy=0.4094, test/loss=2.77678, test/num_examples=10000, total_duration=7062.91, train/accuracy=0.598713, train/loss=1.77091, validation/accuracy=0.55386, validation/loss=1.98405, validation/num_examples=50000
I0314 23:37:45.810381 140469698807552 logging_writer.py:48] [8000] global_step=8000, grad_norm=1.03893, loss=2.99972
I0314 23:37:45.814496 140498825811136 submission.py:265] 8000) loss = 3.000, grad_norm = 1.039
I0314 23:43:11.581277 140469707200256 logging_writer.py:48] [8500] global_step=8500, grad_norm=1.02584, loss=2.9365
I0314 23:43:11.601663 140498825811136 submission.py:265] 8500) loss = 2.936, grad_norm = 1.026
I0314 23:44:23.220593 140498825811136 spec.py:321] Evaluating on the training split.
I0314 23:45:03.681640 140498825811136 spec.py:333] Evaluating on the validation split.
I0314 23:45:44.784204 140498825811136 spec.py:349] Evaluating on the test split.
I0314 23:45:45.913675 140498825811136 submission_runner.py:469] Time since start: 7658.28s, 	Step: 8571, 	{'train/accuracy': 0.6064453125, 'train/loss': 1.745419249242666, 'validation/accuracy': 0.55786, 'validation/loss': 1.96768546875, 'validation/num_examples': 50000, 'test/accuracy': 0.4171, 'test/loss': 2.7391240234375, 'test/num_examples': 10000, 'score': 6220.486655473709, 'total_duration': 7658.279411315918, 'accumulated_submission_time': 6220.486655473709, 'accumulated_eval_time': 1398.289455652237, 'accumulated_logging_time': 0.36058902740478516}
I0314 23:45:45.945865 140469698807552 logging_writer.py:48] [8571] accumulated_eval_time=1398.29, accumulated_logging_time=0.360589, accumulated_submission_time=6220.49, global_step=8571, preemption_count=0, score=6220.49, test/accuracy=0.4171, test/loss=2.73912, test/num_examples=10000, total_duration=7658.28, train/accuracy=0.606445, train/loss=1.74542, validation/accuracy=0.55786, validation/loss=1.96769, validation/num_examples=50000
I0314 23:50:44.051471 140469707200256 logging_writer.py:48] [9000] global_step=9000, grad_norm=1.01077, loss=2.96698
I0314 23:50:44.056330 140498825811136 submission.py:265] 9000) loss = 2.967, grad_norm = 1.011
I0314 23:54:17.548058 140498825811136 spec.py:321] Evaluating on the training split.
I0314 23:54:57.454432 140498825811136 spec.py:333] Evaluating on the validation split.
I0314 23:55:38.149084 140498825811136 spec.py:349] Evaluating on the test split.
I0314 23:55:39.280642 140498825811136 submission_runner.py:469] Time since start: 8251.65s, 	Step: 9473, 	{'train/accuracy': 0.6228475765306123, 'train/loss': 1.666953417719627, 'validation/accuracy': 0.5759, 'validation/loss': 1.894779375, 'validation/num_examples': 50000, 'test/accuracy': 0.4365, 'test/loss': 2.6209654296875, 'test/num_examples': 10000, 'score': 6728.717941045761, 'total_duration': 8251.646416664124, 'accumulated_submission_time': 6728.717941045761, 'accumulated_eval_time': 1480.0222208499908, 'accumulated_logging_time': 0.40282273292541504}
I0314 23:55:39.290609 140469698807552 logging_writer.py:48] [9473] accumulated_eval_time=1480.02, accumulated_logging_time=0.402823, accumulated_submission_time=6728.72, global_step=9473, preemption_count=0, score=6728.72, test/accuracy=0.4365, test/loss=2.62097, test/num_examples=10000, total_duration=8251.65, train/accuracy=0.622848, train/loss=1.66695, validation/accuracy=0.5759, validation/loss=1.89478, validation/num_examples=50000
I0314 23:55:56.503419 140469707200256 logging_writer.py:48] [9500] global_step=9500, grad_norm=1.00079, loss=2.98316
I0314 23:55:56.508997 140498825811136 submission.py:265] 9500) loss = 2.983, grad_norm = 1.001
I0315 00:02:44.015847 140469698807552 logging_writer.py:48] [10000] global_step=10000, grad_norm=1.0435, loss=3.01897
I0315 00:02:44.051060 140498825811136 submission.py:265] 10000) loss = 3.019, grad_norm = 1.044
I0315 00:04:11.079464 140498825811136 spec.py:321] Evaluating on the training split.
I0315 00:04:51.175387 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 00:05:32.978334 140498825811136 spec.py:349] Evaluating on the test split.
I0315 00:05:34.103963 140498825811136 submission_runner.py:469] Time since start: 8846.47s, 	Step: 10206, 	{'train/accuracy': 0.6249003507653061, 'train/loss': 1.6324669974190849, 'validation/accuracy': 0.5776, 'validation/loss': 1.86240484375, 'validation/num_examples': 50000, 'test/accuracy': 0.44, 'test/loss': 2.623902734375, 'test/num_examples': 10000, 'score': 7237.305422306061, 'total_duration': 8846.469753980637, 'accumulated_submission_time': 7237.305422306061, 'accumulated_eval_time': 1563.0469081401825, 'accumulated_logging_time': 0.42098569869995117}
I0315 00:05:34.141764 140469707200256 logging_writer.py:48] [10206] accumulated_eval_time=1563.05, accumulated_logging_time=0.420986, accumulated_submission_time=7237.31, global_step=10206, preemption_count=0, score=7237.31, test/accuracy=0.44, test/loss=2.6239, test/num_examples=10000, total_duration=8846.47, train/accuracy=0.6249, train/loss=1.63247, validation/accuracy=0.5776, validation/loss=1.8624, validation/num_examples=50000
I0315 00:07:41.673672 140469698807552 logging_writer.py:48] [10500] global_step=10500, grad_norm=1.06099, loss=2.99112
I0315 00:07:41.678021 140498825811136 submission.py:265] 10500) loss = 2.991, grad_norm = 1.061
I0315 00:12:31.011956 140469707200256 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.976312, loss=2.78923
I0315 00:12:31.016157 140498825811136 submission.py:265] 11000) loss = 2.789, grad_norm = 0.976
I0315 00:14:06.108670 140498825811136 spec.py:321] Evaluating on the training split.
I0315 00:14:48.126262 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 00:15:29.723976 140498825811136 spec.py:349] Evaluating on the test split.
I0315 00:15:30.858082 140498825811136 submission_runner.py:469] Time since start: 9443.22s, 	Step: 11105, 	{'train/accuracy': 0.6355827487244898, 'train/loss': 1.5829047378228636, 'validation/accuracy': 0.58272, 'validation/loss': 1.8143053125, 'validation/num_examples': 50000, 'test/accuracy': 0.4452, 'test/loss': 2.5451052734375, 'test/num_examples': 10000, 'score': 7745.894095182419, 'total_duration': 9443.223860263824, 'accumulated_submission_time': 7745.894095182419, 'accumulated_eval_time': 1647.7964024543762, 'accumulated_logging_time': 0.4670698642730713}
I0315 00:15:30.918775 140469698807552 logging_writer.py:48] [11105] accumulated_eval_time=1647.8, accumulated_logging_time=0.46707, accumulated_submission_time=7745.89, global_step=11105, preemption_count=0, score=7745.89, test/accuracy=0.4452, test/loss=2.54511, test/num_examples=10000, total_duration=9443.22, train/accuracy=0.635583, train/loss=1.5829, validation/accuracy=0.58272, validation/loss=1.81431, validation/num_examples=50000
I0315 00:19:34.705826 140469707200256 logging_writer.py:48] [11500] global_step=11500, grad_norm=1.01209, loss=2.82481
I0315 00:19:34.754202 140498825811136 submission.py:265] 11500) loss = 2.825, grad_norm = 1.012
I0315 00:23:19.880113 140469698807552 logging_writer.py:48] [12000] global_step=12000, grad_norm=1.04625, loss=2.86951
I0315 00:23:19.884447 140498825811136 submission.py:265] 12000) loss = 2.870, grad_norm = 1.046
I0315 00:24:02.383975 140498825811136 spec.py:321] Evaluating on the training split.
I0315 00:24:42.045435 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 00:25:24.048024 140498825811136 spec.py:349] Evaluating on the test split.
I0315 00:25:25.187209 140498825811136 submission_runner.py:469] Time since start: 10037.55s, 	Step: 12069, 	{'train/accuracy': 0.6371771364795918, 'train/loss': 1.5758514404296875, 'validation/accuracy': 0.58716, 'validation/loss': 1.80757296875, 'validation/num_examples': 50000, 'test/accuracy': 0.4485, 'test/loss': 2.568693359375, 'test/num_examples': 10000, 'score': 8253.957944393158, 'total_duration': 10037.552994728088, 'accumulated_submission_time': 8253.957944393158, 'accumulated_eval_time': 1730.5997998714447, 'accumulated_logging_time': 0.5368022918701172}
I0315 00:25:25.223584 140469707200256 logging_writer.py:48] [12069] accumulated_eval_time=1730.6, accumulated_logging_time=0.536802, accumulated_submission_time=8253.96, global_step=12069, preemption_count=0, score=8253.96, test/accuracy=0.4485, test/loss=2.56869, test/num_examples=10000, total_duration=10037.6, train/accuracy=0.637177, train/loss=1.57585, validation/accuracy=0.58716, validation/loss=1.80757, validation/num_examples=50000
I0315 00:31:26.127431 140469698807552 logging_writer.py:48] [12500] global_step=12500, grad_norm=1.01733, loss=2.90355
I0315 00:31:26.156876 140498825811136 submission.py:265] 12500) loss = 2.904, grad_norm = 1.017
I0315 00:33:56.753233 140498825811136 spec.py:321] Evaluating on the training split.
I0315 00:34:36.969775 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 00:35:18.107670 140498825811136 spec.py:349] Evaluating on the test split.
I0315 00:35:19.241353 140498825811136 submission_runner.py:469] Time since start: 10631.61s, 	Step: 12862, 	{'train/accuracy': 0.6376355229591837, 'train/loss': 1.565310575524155, 'validation/accuracy': 0.59232, 'validation/loss': 1.7948803125, 'validation/num_examples': 50000, 'test/accuracy': 0.4439, 'test/loss': 2.59265859375, 'test/num_examples': 10000, 'score': 8762.27849650383, 'total_duration': 10631.607153177261, 'accumulated_submission_time': 8762.27849650383, 'accumulated_eval_time': 1813.0880572795868, 'accumulated_logging_time': 0.5809571743011475}
I0315 00:35:19.251731 140469707200256 logging_writer.py:48] [12862] accumulated_eval_time=1813.09, accumulated_logging_time=0.580957, accumulated_submission_time=8762.28, global_step=12862, preemption_count=0, score=8762.28, test/accuracy=0.4439, test/loss=2.59266, test/num_examples=10000, total_duration=10631.6, train/accuracy=0.637636, train/loss=1.56531, validation/accuracy=0.59232, validation/loss=1.79488, validation/num_examples=50000
I0315 00:36:23.190409 140469698807552 logging_writer.py:48] [13000] global_step=13000, grad_norm=1.03055, loss=2.82339
I0315 00:36:23.194064 140498825811136 submission.py:265] 13000) loss = 2.823, grad_norm = 1.031
I0315 00:41:18.717259 140469707200256 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.966243, loss=2.84129
I0315 00:41:18.721410 140498825811136 submission.py:265] 13500) loss = 2.841, grad_norm = 0.966
I0315 00:43:51.229255 140498825811136 spec.py:321] Evaluating on the training split.
I0315 00:44:32.247889 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 00:45:13.379321 140498825811136 spec.py:349] Evaluating on the test split.
I0315 00:45:14.520325 140498825811136 submission_runner.py:469] Time since start: 11226.89s, 	Step: 13670, 	{'train/accuracy': 0.6405253507653061, 'train/loss': 1.5644222960180165, 'validation/accuracy': 0.594, 'validation/loss': 1.792005, 'validation/num_examples': 50000, 'test/accuracy': 0.4623, 'test/loss': 2.5011990234375, 'test/num_examples': 10000, 'score': 9271.093402862549, 'total_duration': 11226.886065006256, 'accumulated_submission_time': 9271.093402862549, 'accumulated_eval_time': 1896.3792967796326, 'accumulated_logging_time': 0.5998821258544922}
I0315 00:45:14.556501 140469698807552 logging_writer.py:48] [13670] accumulated_eval_time=1896.38, accumulated_logging_time=0.599882, accumulated_submission_time=9271.09, global_step=13670, preemption_count=0, score=9271.09, test/accuracy=0.4623, test/loss=2.5012, test/num_examples=10000, total_duration=11226.9, train/accuracy=0.640525, train/loss=1.56442, validation/accuracy=0.594, validation/loss=1.79201, validation/num_examples=50000
I0315 00:48:22.612120 140469707200256 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.992499, loss=2.72574
I0315 00:48:22.616098 140498825811136 submission.py:265] 14000) loss = 2.726, grad_norm = 0.992
I0315 00:52:16.089344 140469698807552 logging_writer.py:48] [14500] global_step=14500, grad_norm=1.00401, loss=2.79593
I0315 00:52:16.093513 140498825811136 submission.py:265] 14500) loss = 2.796, grad_norm = 1.004
I0315 00:53:46.151786 140498825811136 spec.py:321] Evaluating on the training split.
I0315 00:54:27.160995 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 00:55:08.507492 140498825811136 spec.py:349] Evaluating on the test split.
I0315 00:55:09.621187 140498825811136 submission_runner.py:469] Time since start: 11821.99s, 	Step: 14642, 	{'train/accuracy': 0.6482780612244898, 'train/loss': 1.5432155375577965, 'validation/accuracy': 0.59948, 'validation/loss': 1.76803859375, 'validation/num_examples': 50000, 'test/accuracy': 0.45, 'test/loss': 2.5557091796875, 'test/num_examples': 10000, 'score': 9779.372640132904, 'total_duration': 11821.986961841583, 'accumulated_submission_time': 9779.372640132904, 'accumulated_eval_time': 1979.8489379882812, 'accumulated_logging_time': 0.665999174118042}
I0315 00:55:09.632333 140469707200256 logging_writer.py:48] [14642] accumulated_eval_time=1979.85, accumulated_logging_time=0.665999, accumulated_submission_time=9779.37, global_step=14642, preemption_count=0, score=9779.37, test/accuracy=0.45, test/loss=2.55571, test/num_examples=10000, total_duration=11822, train/accuracy=0.648278, train/loss=1.54322, validation/accuracy=0.59948, validation/loss=1.76804, validation/num_examples=50000
I0315 01:00:37.476019 140469698807552 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.995427, loss=2.79411
I0315 01:00:37.487524 140498825811136 submission.py:265] 15000) loss = 2.794, grad_norm = 0.995
I0315 01:03:41.504216 140498825811136 spec.py:321] Evaluating on the training split.
I0315 01:04:21.269449 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 01:05:03.110624 140498825811136 spec.py:349] Evaluating on the test split.
I0315 01:05:04.231281 140498825811136 submission_runner.py:469] Time since start: 12416.60s, 	Step: 15434, 	{'train/accuracy': 0.6485172193877551, 'train/loss': 1.5096701797173948, 'validation/accuracy': 0.59996, 'validation/loss': 1.7494190625, 'validation/num_examples': 50000, 'test/accuracy': 0.4629, 'test/loss': 2.474128515625, 'test/num_examples': 10000, 'score': 10288.00061416626, 'total_duration': 12416.597063779831, 'accumulated_submission_time': 10288.00061416626, 'accumulated_eval_time': 2062.576160430908, 'accumulated_logging_time': 0.6855707168579102}
I0315 01:05:04.242482 140469707200256 logging_writer.py:48] [15434] accumulated_eval_time=2062.58, accumulated_logging_time=0.685571, accumulated_submission_time=10288, global_step=15434, preemption_count=0, score=10288, test/accuracy=0.4629, test/loss=2.47413, test/num_examples=10000, total_duration=12416.6, train/accuracy=0.648517, train/loss=1.50967, validation/accuracy=0.59996, validation/loss=1.74942, validation/num_examples=50000
I0315 01:05:38.588995 140469698807552 logging_writer.py:48] [15500] global_step=15500, grad_norm=1.06039, loss=2.73589
I0315 01:05:38.592805 140498825811136 submission.py:265] 15500) loss = 2.736, grad_norm = 1.060
I0315 01:10:36.983078 140469707200256 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.973099, loss=2.71616
I0315 01:10:36.987371 140498825811136 submission.py:265] 16000) loss = 2.716, grad_norm = 0.973
I0315 01:13:35.701906 140498825811136 spec.py:321] Evaluating on the training split.
I0315 01:14:16.453399 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 01:14:57.165189 140498825811136 spec.py:349] Evaluating on the test split.
I0315 01:14:58.283715 140498825811136 submission_runner.py:469] Time since start: 13010.65s, 	Step: 16190, 	{'train/accuracy': 0.6552335778061225, 'train/loss': 1.4798185387436225, 'validation/accuracy': 0.60214, 'validation/loss': 1.7157496875, 'validation/num_examples': 50000, 'test/accuracy': 0.4691, 'test/loss': 2.4246767578125, 'test/num_examples': 10000, 'score': 10796.242122650146, 'total_duration': 13010.649475812912, 'accumulated_submission_time': 10796.242122650146, 'accumulated_eval_time': 2145.1582510471344, 'accumulated_logging_time': 0.7050795555114746}
I0315 01:14:58.397099 140469698807552 logging_writer.py:48] [16190] accumulated_eval_time=2145.16, accumulated_logging_time=0.70508, accumulated_submission_time=10796.2, global_step=16190, preemption_count=0, score=10796.2, test/accuracy=0.4691, test/loss=2.42468, test/num_examples=10000, total_duration=13010.6, train/accuracy=0.655234, train/loss=1.47982, validation/accuracy=0.60214, validation/loss=1.71575, validation/num_examples=50000
I0315 01:17:50.278829 140469707200256 logging_writer.py:48] [16500] global_step=16500, grad_norm=1.0268, loss=2.84369
I0315 01:17:50.283340 140498825811136 submission.py:265] 16500) loss = 2.844, grad_norm = 1.027
I0315 01:21:38.656884 140469698807552 logging_writer.py:48] [17000] global_step=17000, grad_norm=1.06601, loss=2.83244
I0315 01:21:38.661420 140498825811136 submission.py:265] 17000) loss = 2.832, grad_norm = 1.066
I0315 01:23:29.890309 140498825811136 spec.py:321] Evaluating on the training split.
I0315 01:24:08.997466 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 01:24:49.625274 140498825811136 spec.py:349] Evaluating on the test split.
I0315 01:24:50.760256 140498825811136 submission_runner.py:469] Time since start: 13603.13s, 	Step: 17169, 	{'train/accuracy': 0.6622887436224489, 'train/loss': 1.4655115555743783, 'validation/accuracy': 0.6116, 'validation/loss': 1.69697125, 'validation/num_examples': 50000, 'test/accuracy': 0.4684, 'test/loss': 2.482653125, 'test/num_examples': 10000, 'score': 11304.382072210312, 'total_duration': 13603.126015901566, 'accumulated_submission_time': 11304.382072210312, 'accumulated_eval_time': 2226.0283443927765, 'accumulated_logging_time': 0.8276746273040771}
I0315 01:24:50.787746 140469707200256 logging_writer.py:48] [17169] accumulated_eval_time=2226.03, accumulated_logging_time=0.827675, accumulated_submission_time=11304.4, global_step=17169, preemption_count=0, score=11304.4, test/accuracy=0.4684, test/loss=2.48265, test/num_examples=10000, total_duration=13603.1, train/accuracy=0.662289, train/loss=1.46551, validation/accuracy=0.6116, validation/loss=1.69697, validation/num_examples=50000
I0315 01:30:02.028050 140469698807552 logging_writer.py:48] [17500] global_step=17500, grad_norm=1.00664, loss=2.80949
I0315 01:30:02.051731 140498825811136 submission.py:265] 17500) loss = 2.809, grad_norm = 1.007
I0315 01:33:22.314110 140498825811136 spec.py:321] Evaluating on the training split.
I0315 01:34:02.584839 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 01:34:43.442701 140498825811136 spec.py:349] Evaluating on the test split.
I0315 01:34:44.573448 140498825811136 submission_runner.py:469] Time since start: 14196.94s, 	Step: 17958, 	{'train/accuracy': 0.6540377869897959, 'train/loss': 1.519357019541215, 'validation/accuracy': 0.60116, 'validation/loss': 1.76038296875, 'validation/num_examples': 50000, 'test/accuracy': 0.4509, 'test/loss': 2.5470642578125, 'test/num_examples': 10000, 'score': 11812.686482429504, 'total_duration': 14196.939190387726, 'accumulated_submission_time': 11812.686482429504, 'accumulated_eval_time': 2308.2878658771515, 'accumulated_logging_time': 0.8636391162872314}
I0315 01:34:44.585752 140469707200256 logging_writer.py:48] [17958] accumulated_eval_time=2308.29, accumulated_logging_time=0.863639, accumulated_submission_time=11812.7, global_step=17958, preemption_count=0, score=11812.7, test/accuracy=0.4509, test/loss=2.54706, test/num_examples=10000, total_duration=14196.9, train/accuracy=0.654038, train/loss=1.51936, validation/accuracy=0.60116, validation/loss=1.76038, validation/num_examples=50000
I0315 01:35:06.138509 140469698807552 logging_writer.py:48] [18000] global_step=18000, grad_norm=1.09226, loss=2.81007
I0315 01:35:06.142590 140498825811136 submission.py:265] 18000) loss = 2.810, grad_norm = 1.092
I0315 01:40:18.632555 140469707200256 logging_writer.py:48] [18500] global_step=18500, grad_norm=1.04019, loss=2.82791
I0315 01:40:18.636704 140498825811136 submission.py:265] 18500) loss = 2.828, grad_norm = 1.040
I0315 01:43:16.693202 140498825811136 spec.py:321] Evaluating on the training split.
I0315 01:43:57.804636 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 01:44:38.622483 140498825811136 spec.py:349] Evaluating on the test split.
I0315 01:44:39.755660 140498825811136 submission_runner.py:469] Time since start: 14792.12s, 	Step: 18690, 	{'train/accuracy': 0.6618104272959183, 'train/loss': 1.4921854758749202, 'validation/accuracy': 0.60656, 'validation/loss': 1.737459375, 'validation/num_examples': 50000, 'test/accuracy': 0.4587, 'test/loss': 2.51851328125, 'test/num_examples': 10000, 'score': 12321.603185415268, 'total_duration': 14792.121434926987, 'accumulated_submission_time': 12321.603185415268, 'accumulated_eval_time': 2391.3504645824432, 'accumulated_logging_time': 0.8848352432250977}
I0315 01:44:39.774662 140469698807552 logging_writer.py:48] [18690] accumulated_eval_time=2391.35, accumulated_logging_time=0.884835, accumulated_submission_time=12321.6, global_step=18690, preemption_count=0, score=12321.6, test/accuracy=0.4587, test/loss=2.51851, test/num_examples=10000, total_duration=14792.1, train/accuracy=0.66181, train/loss=1.49219, validation/accuracy=0.60656, validation/loss=1.73746, validation/num_examples=50000
I0315 01:47:34.784557 140469707200256 logging_writer.py:48] [19000] global_step=19000, grad_norm=1.00294, loss=2.69401
I0315 01:47:34.804506 140498825811136 submission.py:265] 19000) loss = 2.694, grad_norm = 1.003
I0315 01:51:34.895606 140469698807552 logging_writer.py:48] [19500] global_step=19500, grad_norm=1.00409, loss=2.72856
I0315 01:51:34.900011 140498825811136 submission.py:265] 19500) loss = 2.729, grad_norm = 1.004
I0315 01:53:12.648238 140498825811136 spec.py:321] Evaluating on the training split.
I0315 01:53:52.325028 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 01:54:33.494996 140498825811136 spec.py:349] Evaluating on the test split.
I0315 01:54:34.616200 140498825811136 submission_runner.py:469] Time since start: 15386.98s, 	Step: 19648, 	{'train/accuracy': 0.6584821428571429, 'train/loss': 1.4843502433932558, 'validation/accuracy': 0.60516, 'validation/loss': 1.7232921875, 'validation/num_examples': 50000, 'test/accuracy': 0.464, 'test/loss': 2.4990232421875, 'test/num_examples': 10000, 'score': 12831.057042837143, 'total_duration': 15386.98199224472, 'accumulated_submission_time': 12831.057042837143, 'accumulated_eval_time': 2473.3185799121857, 'accumulated_logging_time': 0.9682323932647705}
I0315 01:54:34.627060 140469707200256 logging_writer.py:48] [19648] accumulated_eval_time=2473.32, accumulated_logging_time=0.968232, accumulated_submission_time=12831.1, global_step=19648, preemption_count=0, score=12831.1, test/accuracy=0.464, test/loss=2.49902, test/num_examples=10000, total_duration=15387, train/accuracy=0.658482, train/loss=1.48435, validation/accuracy=0.60516, validation/loss=1.72329, validation/num_examples=50000
I0315 02:00:02.391822 140469698807552 logging_writer.py:48] [20000] global_step=20000, grad_norm=1.03239, loss=2.73539
I0315 02:00:02.402963 140498825811136 submission.py:265] 20000) loss = 2.735, grad_norm = 1.032
I0315 02:03:06.318856 140498825811136 spec.py:321] Evaluating on the training split.
I0315 02:03:45.965885 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 02:04:26.934256 140498825811136 spec.py:349] Evaluating on the test split.
I0315 02:04:28.061115 140498825811136 submission_runner.py:469] Time since start: 15980.43s, 	Step: 20422, 	{'train/accuracy': 0.6583824936224489, 'train/loss': 1.4949622640804368, 'validation/accuracy': 0.60388, 'validation/loss': 1.73942078125, 'validation/num_examples': 50000, 'test/accuracy': 0.4627, 'test/loss': 2.5099642578125, 'test/num_examples': 10000, 'score': 13339.496413469315, 'total_duration': 15980.42686533928, 'accumulated_submission_time': 13339.496413469315, 'accumulated_eval_time': 2555.0610501766205, 'accumulated_logging_time': 0.9875450134277344}
I0315 02:04:28.071959 140469707200256 logging_writer.py:48] [20422] accumulated_eval_time=2555.06, accumulated_logging_time=0.987545, accumulated_submission_time=13339.5, global_step=20422, preemption_count=0, score=13339.5, test/accuracy=0.4627, test/loss=2.50996, test/num_examples=10000, total_duration=15980.4, train/accuracy=0.658382, train/loss=1.49496, validation/accuracy=0.60388, validation/loss=1.73942, validation/num_examples=50000
I0315 02:05:08.036706 140469698807552 logging_writer.py:48] [20500] global_step=20500, grad_norm=1.00124, loss=2.73742
I0315 02:05:08.040979 140498825811136 submission.py:265] 20500) loss = 2.737, grad_norm = 1.001
I0315 02:10:07.776728 140469707200256 logging_writer.py:48] [21000] global_step=21000, grad_norm=1.11379, loss=2.76418
I0315 02:10:07.831782 140498825811136 submission.py:265] 21000) loss = 2.764, grad_norm = 1.114
I0315 02:12:59.692028 140498825811136 spec.py:321] Evaluating on the training split.
I0315 02:13:40.160627 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 02:14:21.261646 140498825811136 spec.py:349] Evaluating on the test split.
I0315 02:14:22.388237 140498825811136 submission_runner.py:469] Time since start: 16574.75s, 	Step: 21180, 	{'train/accuracy': 0.6651985012755102, 'train/loss': 1.4406674443459024, 'validation/accuracy': 0.61306, 'validation/loss': 1.69074859375, 'validation/num_examples': 50000, 'test/accuracy': 0.4702, 'test/loss': 2.4636744140625, 'test/num_examples': 10000, 'score': 13847.956590414047, 'total_duration': 16574.753980398178, 'accumulated_submission_time': 13847.956590414047, 'accumulated_eval_time': 2637.7575104236603, 'accumulated_logging_time': 1.006631851196289}
I0315 02:14:22.448558 140469698807552 logging_writer.py:48] [21180] accumulated_eval_time=2637.76, accumulated_logging_time=1.00663, accumulated_submission_time=13848, global_step=21180, preemption_count=0, score=13848, test/accuracy=0.4702, test/loss=2.46367, test/num_examples=10000, total_duration=16574.8, train/accuracy=0.665199, train/loss=1.44067, validation/accuracy=0.61306, validation/loss=1.69075, validation/num_examples=50000
I0315 02:17:31.416577 140469707200256 logging_writer.py:48] [21500] global_step=21500, grad_norm=1.0641, loss=2.73382
I0315 02:17:31.420788 140498825811136 submission.py:265] 21500) loss = 2.734, grad_norm = 1.064
I0315 02:21:30.748046 140469698807552 logging_writer.py:48] [22000] global_step=22000, grad_norm=1.08108, loss=2.78243
I0315 02:21:30.752151 140498825811136 submission.py:265] 22000) loss = 2.782, grad_norm = 1.081
I0315 02:22:54.545140 140498825811136 spec.py:321] Evaluating on the training split.
I0315 02:23:34.762369 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 02:24:15.152434 140498825811136 spec.py:349] Evaluating on the test split.
I0315 02:24:16.293178 140498825811136 submission_runner.py:469] Time since start: 17168.66s, 	Step: 22118, 	{'train/accuracy': 0.6575055803571429, 'train/loss': 1.491804940359933, 'validation/accuracy': 0.60544, 'validation/loss': 1.73799515625, 'validation/num_examples': 50000, 'test/accuracy': 0.4586, 'test/loss': 2.5184923828125, 'test/num_examples': 10000, 'score': 14356.709750652313, 'total_duration': 17168.658967494965, 'accumulated_submission_time': 14356.709750652313, 'accumulated_eval_time': 2719.505704164505, 'accumulated_logging_time': 1.0749948024749756}
I0315 02:24:16.303957 140469707200256 logging_writer.py:48] [22118] accumulated_eval_time=2719.51, accumulated_logging_time=1.07499, accumulated_submission_time=14356.7, global_step=22118, preemption_count=0, score=14356.7, test/accuracy=0.4586, test/loss=2.51849, test/num_examples=10000, total_duration=17168.7, train/accuracy=0.657506, train/loss=1.4918, validation/accuracy=0.60544, validation/loss=1.738, validation/num_examples=50000
I0315 02:29:59.939303 140469698807552 logging_writer.py:48] [22500] global_step=22500, grad_norm=1.04871, loss=2.75896
I0315 02:29:59.943997 140498825811136 submission.py:265] 22500) loss = 2.759, grad_norm = 1.049
I0315 02:32:48.232785 140498825811136 spec.py:321] Evaluating on the training split.
I0315 02:33:31.173485 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 02:34:12.208283 140498825811136 spec.py:349] Evaluating on the test split.
I0315 02:34:13.334121 140498825811136 submission_runner.py:469] Time since start: 17765.70s, 	Step: 22877, 	{'train/accuracy': 0.6690051020408163, 'train/loss': 1.4153140321069835, 'validation/accuracy': 0.61778, 'validation/loss': 1.65129203125, 'validation/num_examples': 50000, 'test/accuracy': 0.4819, 'test/loss': 2.4001310546875, 'test/num_examples': 10000, 'score': 14865.333568572998, 'total_duration': 17765.699872016907, 'accumulated_submission_time': 14865.333568572998, 'accumulated_eval_time': 2804.6072981357574, 'accumulated_logging_time': 1.1302120685577393}
I0315 02:34:13.372226 140469707200256 logging_writer.py:48] [22877] accumulated_eval_time=2804.61, accumulated_logging_time=1.13021, accumulated_submission_time=14865.3, global_step=22877, preemption_count=0, score=14865.3, test/accuracy=0.4819, test/loss=2.40013, test/num_examples=10000, total_duration=17765.7, train/accuracy=0.669005, train/loss=1.41531, validation/accuracy=0.61778, validation/loss=1.65129, validation/num_examples=50000
I0315 02:35:10.201616 140469698807552 logging_writer.py:48] [23000] global_step=23000, grad_norm=1.04497, loss=2.83009
I0315 02:35:10.206038 140498825811136 submission.py:265] 23000) loss = 2.830, grad_norm = 1.045
I0315 02:40:26.905144 140469707200256 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.992977, loss=2.74234
I0315 02:40:26.941277 140498825811136 submission.py:265] 23500) loss = 2.742, grad_norm = 0.993
I0315 02:42:46.761789 140498825811136 spec.py:321] Evaluating on the training split.
I0315 02:43:26.994511 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 02:44:08.625210 140498825811136 spec.py:349] Evaluating on the test split.
I0315 02:44:09.768289 140498825811136 submission_runner.py:469] Time since start: 18362.13s, 	Step: 23648, 	{'train/accuracy': 0.6658561862244898, 'train/loss': 1.4655758604711415, 'validation/accuracy': 0.61444, 'validation/loss': 1.69396390625, 'validation/num_examples': 50000, 'test/accuracy': 0.47, 'test/loss': 2.4852849609375, 'test/num_examples': 10000, 'score': 15375.455873250961, 'total_duration': 18362.134083271027, 'accumulated_submission_time': 15375.455873250961, 'accumulated_eval_time': 2887.6139566898346, 'accumulated_logging_time': 1.17726731300354}
I0315 02:44:09.821775 140469698807552 logging_writer.py:48] [23648] accumulated_eval_time=2887.61, accumulated_logging_time=1.17727, accumulated_submission_time=15375.5, global_step=23648, preemption_count=0, score=15375.5, test/accuracy=0.47, test/loss=2.48528, test/num_examples=10000, total_duration=18362.1, train/accuracy=0.665856, train/loss=1.46558, validation/accuracy=0.61444, validation/loss=1.69396, validation/num_examples=50000
I0315 02:47:49.663919 140469707200256 logging_writer.py:48] [24000] global_step=24000, grad_norm=1.05836, loss=2.70172
I0315 02:47:49.668358 140498825811136 submission.py:265] 24000) loss = 2.702, grad_norm = 1.058
I0315 02:51:54.259118 140469698807552 logging_writer.py:48] [24500] global_step=24500, grad_norm=1.07417, loss=2.70584
I0315 02:51:54.263717 140498825811136 submission.py:265] 24500) loss = 2.706, grad_norm = 1.074
I0315 02:52:42.493033 140498825811136 spec.py:321] Evaluating on the training split.
I0315 02:53:22.376377 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 02:54:03.858439 140498825811136 spec.py:349] Evaluating on the test split.
I0315 02:54:04.993218 140498825811136 submission_runner.py:469] Time since start: 18957.36s, 	Step: 24570, 	{'train/accuracy': 0.671516262755102, 'train/loss': 1.3860895585040658, 'validation/accuracy': 0.61844, 'validation/loss': 1.62911296875, 'validation/num_examples': 50000, 'test/accuracy': 0.4714, 'test/loss': 2.41489765625, 'test/num_examples': 10000, 'score': 15884.773327350616, 'total_duration': 18957.359013795853, 'accumulated_submission_time': 15884.773327350616, 'accumulated_eval_time': 2970.1142847537994, 'accumulated_logging_time': 1.2386932373046875}
I0315 02:54:05.005357 140469707200256 logging_writer.py:48] [24570] accumulated_eval_time=2970.11, accumulated_logging_time=1.23869, accumulated_submission_time=15884.8, global_step=24570, preemption_count=0, score=15884.8, test/accuracy=0.4714, test/loss=2.4149, test/num_examples=10000, total_duration=18957.4, train/accuracy=0.671516, train/loss=1.38609, validation/accuracy=0.61844, validation/loss=1.62911, validation/num_examples=50000
I0315 03:00:34.250854 140469698807552 logging_writer.py:48] [25000] global_step=25000, grad_norm=1.0794, loss=2.79759
I0315 03:00:34.254958 140498825811136 submission.py:265] 25000) loss = 2.798, grad_norm = 1.079
I0315 03:02:36.855461 140498825811136 spec.py:321] Evaluating on the training split.
I0315 03:03:17.276041 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 03:03:57.951173 140498825811136 spec.py:349] Evaluating on the test split.
I0315 03:03:59.087926 140498825811136 submission_runner.py:469] Time since start: 19551.45s, 	Step: 25262, 	{'train/accuracy': 0.6739078443877551, 'train/loss': 1.4024239364935427, 'validation/accuracy': 0.62012, 'validation/loss': 1.649681875, 'validation/num_examples': 50000, 'test/accuracy': 0.4814, 'test/loss': 2.384304296875, 'test/num_examples': 10000, 'score': 16393.414318561554, 'total_duration': 19551.45368695259, 'accumulated_submission_time': 16393.414318561554, 'accumulated_eval_time': 3052.3468840122223, 'accumulated_logging_time': 1.279970407485962}
I0315 03:03:59.120334 140469707200256 logging_writer.py:48] [25262] accumulated_eval_time=3052.35, accumulated_logging_time=1.27997, accumulated_submission_time=16393.4, global_step=25262, preemption_count=0, score=16393.4, test/accuracy=0.4814, test/loss=2.3843, test/num_examples=10000, total_duration=19551.5, train/accuracy=0.673908, train/loss=1.40242, validation/accuracy=0.62012, validation/loss=1.64968, validation/num_examples=50000
I0315 03:05:50.272409 140469698807552 logging_writer.py:48] [25500] global_step=25500, grad_norm=1.06102, loss=2.73814
I0315 03:05:50.276728 140498825811136 submission.py:265] 25500) loss = 2.738, grad_norm = 1.061
I0315 03:11:05.448252 140469707200256 logging_writer.py:48] [26000] global_step=26000, grad_norm=1.00836, loss=2.64968
I0315 03:11:05.468168 140498825811136 submission.py:265] 26000) loss = 2.650, grad_norm = 1.008
I0315 03:12:30.903906 140498825811136 spec.py:321] Evaluating on the training split.
I0315 03:13:14.216887 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 03:13:55.742975 140498825811136 spec.py:349] Evaluating on the test split.
I0315 03:13:56.873686 140498825811136 submission_runner.py:469] Time since start: 20149.24s, 	Step: 26085, 	{'train/accuracy': 0.6746452487244898, 'train/loss': 1.3851776123046875, 'validation/accuracy': 0.61556, 'validation/loss': 1.6445059375, 'validation/num_examples': 50000, 'test/accuracy': 0.4892, 'test/loss': 2.33088359375, 'test/num_examples': 10000, 'score': 16901.973237752914, 'total_duration': 20149.239444971085, 'accumulated_submission_time': 16901.973237752914, 'accumulated_eval_time': 3138.316793203354, 'accumulated_logging_time': 1.3203949928283691}
I0315 03:13:56.922528 140469698807552 logging_writer.py:48] [26085] accumulated_eval_time=3138.32, accumulated_logging_time=1.32039, accumulated_submission_time=16902, global_step=26085, preemption_count=0, score=16902, test/accuracy=0.4892, test/loss=2.33088, test/num_examples=10000, total_duration=20149.2, train/accuracy=0.674645, train/loss=1.38518, validation/accuracy=0.61556, validation/loss=1.64451, validation/num_examples=50000
I0315 03:18:34.312095 140469707200256 logging_writer.py:48] [26500] global_step=26500, grad_norm=1.07251, loss=2.78003
I0315 03:18:34.317094 140498825811136 submission.py:265] 26500) loss = 2.780, grad_norm = 1.073
I0315 03:22:29.526124 140498825811136 spec.py:321] Evaluating on the training split.
I0315 03:23:09.844673 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 03:23:50.259716 140498825811136 spec.py:349] Evaluating on the test split.
I0315 03:23:51.385184 140498825811136 submission_runner.py:469] Time since start: 20743.75s, 	Step: 26978, 	{'train/accuracy': 0.6806640625, 'train/loss': 1.3638934699856504, 'validation/accuracy': 0.6257, 'validation/loss': 1.6159971875, 'validation/num_examples': 50000, 'test/accuracy': 0.489, 'test/loss': 2.339446484375, 'test/num_examples': 10000, 'score': 17411.281683683395, 'total_duration': 20743.750941991806, 'accumulated_submission_time': 17411.281683683395, 'accumulated_eval_time': 3220.1760029792786, 'accumulated_logging_time': 1.3773982524871826}
I0315 03:23:51.396946 140469698807552 logging_writer.py:48] [26978] accumulated_eval_time=3220.18, accumulated_logging_time=1.3774, accumulated_submission_time=17411.3, global_step=26978, preemption_count=0, score=17411.3, test/accuracy=0.489, test/loss=2.33945, test/num_examples=10000, total_duration=20743.8, train/accuracy=0.680664, train/loss=1.36389, validation/accuracy=0.6257, validation/loss=1.616, validation/num_examples=50000
I0315 03:24:03.477300 140469707200256 logging_writer.py:48] [27000] global_step=27000, grad_norm=1.03094, loss=2.70874
I0315 03:24:03.481278 140498825811136 submission.py:265] 27000) loss = 2.709, grad_norm = 1.031
I0315 03:31:09.223623 140469698807552 logging_writer.py:48] [27500] global_step=27500, grad_norm=1.00602, loss=2.68641
I0315 03:31:09.227840 140498825811136 submission.py:265] 27500) loss = 2.686, grad_norm = 1.006
I0315 03:32:23.050096 140498825811136 spec.py:321] Evaluating on the training split.
I0315 03:33:04.107289 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 03:33:45.824831 140498825811136 spec.py:349] Evaluating on the test split.
I0315 03:33:46.948107 140498825811136 submission_runner.py:469] Time since start: 21339.31s, 	Step: 27638, 	{'train/accuracy': 0.6592992665816326, 'train/loss': 1.4719546571069835, 'validation/accuracy': 0.60788, 'validation/loss': 1.7058434375, 'validation/num_examples': 50000, 'test/accuracy': 0.4549, 'test/loss': 2.553552734375, 'test/num_examples': 10000, 'score': 17919.73151087761, 'total_duration': 21339.31384921074, 'accumulated_submission_time': 17919.73151087761, 'accumulated_eval_time': 3304.074120759964, 'accumulated_logging_time': 1.3972454071044922}
I0315 03:33:46.995908 140469707200256 logging_writer.py:48] [27638] accumulated_eval_time=3304.07, accumulated_logging_time=1.39725, accumulated_submission_time=17919.7, global_step=27638, preemption_count=0, score=17919.7, test/accuracy=0.4549, test/loss=2.55355, test/num_examples=10000, total_duration=21339.3, train/accuracy=0.659299, train/loss=1.47195, validation/accuracy=0.60788, validation/loss=1.70584, validation/num_examples=50000
I0315 03:36:25.839654 140469698807552 logging_writer.py:48] [28000] global_step=28000, grad_norm=1.06399, loss=2.73922
I0315 03:36:25.843426 140498825811136 submission.py:265] 28000) loss = 2.739, grad_norm = 1.064
I0315 03:41:41.508490 140469707200256 logging_writer.py:48] [28500] global_step=28500, grad_norm=1.04523, loss=2.76737
I0315 03:41:41.513056 140498825811136 submission.py:265] 28500) loss = 2.767, grad_norm = 1.045
I0315 03:42:18.584738 140498825811136 spec.py:321] Evaluating on the training split.
I0315 03:42:59.444606 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 03:43:41.423091 140498825811136 spec.py:349] Evaluating on the test split.
I0315 03:43:42.540089 140498825811136 submission_runner.py:469] Time since start: 21934.91s, 	Step: 28535, 	{'train/accuracy': 0.6733697385204082, 'train/loss': 1.4034285253408003, 'validation/accuracy': 0.61962, 'validation/loss': 1.6477103125, 'validation/num_examples': 50000, 'test/accuracy': 0.4775, 'test/loss': 2.4441453125, 'test/num_examples': 10000, 'score': 18427.966715097427, 'total_duration': 21934.905863523483, 'accumulated_submission_time': 18427.966715097427, 'accumulated_eval_time': 3388.0296330451965, 'accumulated_logging_time': 1.4611072540283203}
I0315 03:43:42.592494 140469698807552 logging_writer.py:48] [28535] accumulated_eval_time=3388.03, accumulated_logging_time=1.46111, accumulated_submission_time=18428, global_step=28535, preemption_count=0, score=18428, test/accuracy=0.4775, test/loss=2.44415, test/num_examples=10000, total_duration=21934.9, train/accuracy=0.67337, train/loss=1.40343, validation/accuracy=0.61962, validation/loss=1.64771, validation/num_examples=50000
I0315 03:49:01.846592 140469707200256 logging_writer.py:48] [29000] global_step=29000, grad_norm=1.01378, loss=2.62848
I0315 03:49:01.880619 140498825811136 submission.py:265] 29000) loss = 2.628, grad_norm = 1.014
I0315 03:52:14.566982 140498825811136 spec.py:321] Evaluating on the training split.
I0315 03:52:54.157333 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 03:53:34.680866 140498825811136 spec.py:349] Evaluating on the test split.
I0315 03:53:35.808404 140498825811136 submission_runner.py:469] Time since start: 22528.17s, 	Step: 29420, 	{'train/accuracy': 0.6741669323979592, 'train/loss': 1.4036005759725765, 'validation/accuracy': 0.61848, 'validation/loss': 1.64650765625, 'validation/num_examples': 50000, 'test/accuracy': 0.4705, 'test/loss': 2.435341015625, 'test/num_examples': 10000, 'score': 18936.553476333618, 'total_duration': 22528.17417573929, 'accumulated_submission_time': 18936.553476333618, 'accumulated_eval_time': 3469.2712552547455, 'accumulated_logging_time': 1.5221326351165771}
I0315 03:53:35.821290 140469698807552 logging_writer.py:48] [29420] accumulated_eval_time=3469.27, accumulated_logging_time=1.52213, accumulated_submission_time=18936.6, global_step=29420, preemption_count=0, score=18936.6, test/accuracy=0.4705, test/loss=2.43534, test/num_examples=10000, total_duration=22528.2, train/accuracy=0.674167, train/loss=1.4036, validation/accuracy=0.61848, validation/loss=1.64651, validation/num_examples=50000
I0315 03:54:25.062327 140469707200256 logging_writer.py:48] [29500] global_step=29500, grad_norm=1.0094, loss=2.57365
I0315 03:54:25.066300 140498825811136 submission.py:265] 29500) loss = 2.574, grad_norm = 1.009
I0315 04:01:02.486735 140469698807552 logging_writer.py:48] [30000] global_step=30000, grad_norm=1.01982, loss=2.5844
I0315 04:01:02.491625 140498825811136 submission.py:265] 30000) loss = 2.584, grad_norm = 1.020
I0315 04:02:07.287114 140498825811136 spec.py:321] Evaluating on the training split.
I0315 04:02:47.929105 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 04:03:28.997016 140498825811136 spec.py:349] Evaluating on the test split.
I0315 04:03:30.109185 140498825811136 submission_runner.py:469] Time since start: 23122.47s, 	Step: 30112, 	{'train/accuracy': 0.6864835778061225, 'train/loss': 1.3688983527981504, 'validation/accuracy': 0.63362, 'validation/loss': 1.6107109375, 'validation/num_examples': 50000, 'test/accuracy': 0.4937, 'test/loss': 2.3251962890625, 'test/num_examples': 10000, 'score': 19444.809466838837, 'total_duration': 23122.474955797195, 'accumulated_submission_time': 19444.809466838837, 'accumulated_eval_time': 3552.093462228775, 'accumulated_logging_time': 1.5438423156738281}
I0315 04:03:30.174568 140469707200256 logging_writer.py:48] [30112] accumulated_eval_time=3552.09, accumulated_logging_time=1.54384, accumulated_submission_time=19444.8, global_step=30112, preemption_count=0, score=19444.8, test/accuracy=0.4937, test/loss=2.3252, test/num_examples=10000, total_duration=23122.5, train/accuracy=0.686484, train/loss=1.3689, validation/accuracy=0.63362, validation/loss=1.61071, validation/num_examples=50000
I0315 04:06:13.971925 140469698807552 logging_writer.py:48] [30500] global_step=30500, grad_norm=1.03564, loss=2.75862
I0315 04:06:13.976011 140498825811136 submission.py:265] 30500) loss = 2.759, grad_norm = 1.036
I0315 04:11:12.449862 140469707200256 logging_writer.py:48] [31000] global_step=31000, grad_norm=1.04307, loss=2.70113
I0315 04:11:12.454273 140498825811136 submission.py:265] 31000) loss = 2.701, grad_norm = 1.043
I0315 04:12:03.767102 140498825811136 spec.py:321] Evaluating on the training split.
I0315 04:12:45.467834 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 04:13:27.538434 140498825811136 spec.py:349] Evaluating on the test split.
I0315 04:13:28.678317 140498825811136 submission_runner.py:469] Time since start: 23721.04s, 	Step: 31049, 	{'train/accuracy': 0.678352200255102, 'train/loss': 1.3651959166234853, 'validation/accuracy': 0.62532, 'validation/loss': 1.61416890625, 'validation/num_examples': 50000, 'test/accuracy': 0.4928, 'test/loss': 2.3249451171875, 'test/num_examples': 10000, 'score': 19955.038588047028, 'total_duration': 23721.04411172867, 'accumulated_submission_time': 19955.038588047028, 'accumulated_eval_time': 3637.0048472881317, 'accumulated_logging_time': 1.6243822574615479}
I0315 04:13:28.761760 140469698807552 logging_writer.py:48] [31049] accumulated_eval_time=3637, accumulated_logging_time=1.62438, accumulated_submission_time=19955, global_step=31049, preemption_count=0, score=19955, test/accuracy=0.4928, test/loss=2.32495, test/num_examples=10000, total_duration=23721, train/accuracy=0.678352, train/loss=1.3652, validation/accuracy=0.62532, validation/loss=1.61417, validation/num_examples=50000
I0315 04:18:30.690697 140469707200256 logging_writer.py:48] [31500] global_step=31500, grad_norm=1.02964, loss=2.68977
I0315 04:18:30.697323 140498825811136 submission.py:265] 31500) loss = 2.690, grad_norm = 1.030
I0315 04:22:00.344858 140498825811136 spec.py:321] Evaluating on the training split.
I0315 04:22:40.274854 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 04:23:21.647867 140498825811136 spec.py:349] Evaluating on the test split.
I0315 04:23:22.782083 140498825811136 submission_runner.py:469] Time since start: 24315.15s, 	Step: 31941, 	{'train/accuracy': 0.6797672193877551, 'train/loss': 1.3584562029157365, 'validation/accuracy': 0.6256, 'validation/loss': 1.60840359375, 'validation/num_examples': 50000, 'test/accuracy': 0.4923, 'test/loss': 2.286796875, 'test/num_examples': 10000, 'score': 20463.305315732956, 'total_duration': 24315.14782857895, 'accumulated_submission_time': 20463.305315732956, 'accumulated_eval_time': 3719.4422886371613, 'accumulated_logging_time': 1.729114055633545}
I0315 04:23:22.793706 140469698807552 logging_writer.py:48] [31941] accumulated_eval_time=3719.44, accumulated_logging_time=1.72911, accumulated_submission_time=20463.3, global_step=31941, preemption_count=0, score=20463.3, test/accuracy=0.4923, test/loss=2.2868, test/num_examples=10000, total_duration=24315.1, train/accuracy=0.679767, train/loss=1.35846, validation/accuracy=0.6256, validation/loss=1.6084, validation/num_examples=50000
I0315 04:23:57.899144 140469707200256 logging_writer.py:48] [32000] global_step=32000, grad_norm=1.02599, loss=2.675
I0315 04:23:57.903084 140498825811136 submission.py:265] 32000) loss = 2.675, grad_norm = 1.026
I0315 04:30:34.455193 140469698807552 logging_writer.py:48] [32500] global_step=32500, grad_norm=1.06533, loss=2.80853
I0315 04:30:34.467760 140498825811136 submission.py:265] 32500) loss = 2.809, grad_norm = 1.065
I0315 04:31:54.565854 140498825811136 spec.py:321] Evaluating on the training split.
I0315 04:32:36.727162 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 04:33:19.414223 140498825811136 spec.py:349] Evaluating on the test split.
I0315 04:33:20.550840 140498825811136 submission_runner.py:469] Time since start: 24912.92s, 	Step: 32651, 	{'train/accuracy': 0.6852877869897959, 'train/loss': 1.3629454009386959, 'validation/accuracy': 0.62848, 'validation/loss': 1.61762765625, 'validation/num_examples': 50000, 'test/accuracy': 0.4883, 'test/loss': 2.3384326171875, 'test/num_examples': 10000, 'score': 20971.90588283539, 'total_duration': 24912.91662287712, 'accumulated_submission_time': 20971.90588283539, 'accumulated_eval_time': 3805.427412033081, 'accumulated_logging_time': 1.7495570182800293}
I0315 04:33:20.607043 140469707200256 logging_writer.py:48] [32651] accumulated_eval_time=3805.43, accumulated_logging_time=1.74956, accumulated_submission_time=20971.9, global_step=32651, preemption_count=0, score=20971.9, test/accuracy=0.4883, test/loss=2.33843, test/num_examples=10000, total_duration=24912.9, train/accuracy=0.685288, train/loss=1.36295, validation/accuracy=0.62848, validation/loss=1.61763, validation/num_examples=50000
I0315 04:35:49.211485 140469698807552 logging_writer.py:48] [33000] global_step=33000, grad_norm=1.07646, loss=2.66363
I0315 04:35:49.215481 140498825811136 submission.py:265] 33000) loss = 2.664, grad_norm = 1.076
I0315 04:40:51.968561 140469707200256 logging_writer.py:48] [33500] global_step=33500, grad_norm=1.02479, loss=2.74959
I0315 04:40:51.981534 140498825811136 submission.py:265] 33500) loss = 2.750, grad_norm = 1.025
I0315 04:41:53.355963 140498825811136 spec.py:321] Evaluating on the training split.
I0315 04:42:34.480131 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 04:43:17.299265 140498825811136 spec.py:349] Evaluating on the test split.
I0315 04:43:18.438171 140498825811136 submission_runner.py:469] Time since start: 25510.80s, 	Step: 33564, 	{'train/accuracy': 0.6807437818877551, 'train/loss': 1.3970400751853476, 'validation/accuracy': 0.62672, 'validation/loss': 1.64211703125, 'validation/num_examples': 50000, 'test/accuracy': 0.4946, 'test/loss': 2.355875390625, 'test/num_examples': 10000, 'score': 21481.290788173676, 'total_duration': 25510.803968906403, 'accumulated_submission_time': 21481.290788173676, 'accumulated_eval_time': 3890.509779691696, 'accumulated_logging_time': 1.8141224384307861}
I0315 04:43:18.539022 140469698807552 logging_writer.py:48] [33564] accumulated_eval_time=3890.51, accumulated_logging_time=1.81412, accumulated_submission_time=21481.3, global_step=33564, preemption_count=0, score=21481.3, test/accuracy=0.4946, test/loss=2.35588, test/num_examples=10000, total_duration=25510.8, train/accuracy=0.680744, train/loss=1.39704, validation/accuracy=0.62672, validation/loss=1.64212, validation/num_examples=50000
I0315 04:48:21.651345 140469707200256 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.994125, loss=2.61868
I0315 04:48:21.655859 140498825811136 submission.py:265] 34000) loss = 2.619, grad_norm = 0.994
I0315 04:51:50.816858 140498825811136 spec.py:321] Evaluating on the training split.
I0315 04:52:29.834476 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 04:53:10.759528 140498825811136 spec.py:349] Evaluating on the test split.
I0315 04:53:11.880984 140498825811136 submission_runner.py:469] Time since start: 26104.25s, 	Step: 34444, 	{'train/accuracy': 0.6874003507653061, 'train/loss': 1.355239401058275, 'validation/accuracy': 0.62932, 'validation/loss': 1.613869375, 'validation/num_examples': 50000, 'test/accuracy': 0.4886, 'test/loss': 2.36275390625, 'test/num_examples': 10000, 'score': 21990.251036643982, 'total_duration': 26104.246784687042, 'accumulated_submission_time': 21990.251036643982, 'accumulated_eval_time': 3971.574115037918, 'accumulated_logging_time': 1.923140287399292}
I0315 04:53:11.892466 140469698807552 logging_writer.py:48] [34444] accumulated_eval_time=3971.57, accumulated_logging_time=1.92314, accumulated_submission_time=21990.3, global_step=34444, preemption_count=0, score=21990.3, test/accuracy=0.4886, test/loss=2.36275, test/num_examples=10000, total_duration=26104.2, train/accuracy=0.6874, train/loss=1.35524, validation/accuracy=0.62932, validation/loss=1.61387, validation/num_examples=50000
I0315 04:53:46.907577 140469707200256 logging_writer.py:48] [34500] global_step=34500, grad_norm=1.06148, loss=2.6734
I0315 04:53:46.911740 140498825811136 submission.py:265] 34500) loss = 2.673, grad_norm = 1.061
I0315 05:00:32.322572 140469698807552 logging_writer.py:48] [35000] global_step=35000, grad_norm=1.02851, loss=2.59887
I0315 05:00:32.358231 140498825811136 submission.py:265] 35000) loss = 2.599, grad_norm = 1.029
I0315 05:01:43.682925 140498825811136 spec.py:321] Evaluating on the training split.
I0315 05:02:23.090530 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 05:03:03.848068 140498825811136 spec.py:349] Evaluating on the test split.
I0315 05:03:04.965030 140498825811136 submission_runner.py:469] Time since start: 26697.33s, 	Step: 35113, 	{'train/accuracy': 0.6856465242346939, 'train/loss': 1.3333506681481186, 'validation/accuracy': 0.63072, 'validation/loss': 1.59338953125, 'validation/num_examples': 50000, 'test/accuracy': 0.4856, 'test/loss': 2.378709765625, 'test/num_examples': 10000, 'score': 22498.79735827446, 'total_duration': 26697.330793380737, 'accumulated_submission_time': 22498.79735827446, 'accumulated_eval_time': 4052.8564648628235, 'accumulated_logging_time': 1.9428296089172363}
I0315 05:03:05.006082 140469707200256 logging_writer.py:48] [35113] accumulated_eval_time=4052.86, accumulated_logging_time=1.94283, accumulated_submission_time=22498.8, global_step=35113, preemption_count=0, score=22498.8, test/accuracy=0.4856, test/loss=2.37871, test/num_examples=10000, total_duration=26697.3, train/accuracy=0.685647, train/loss=1.33335, validation/accuracy=0.63072, validation/loss=1.59339, validation/num_examples=50000
I0315 05:05:51.116111 140469698807552 logging_writer.py:48] [35500] global_step=35500, grad_norm=1.06249, loss=2.69322
I0315 05:05:51.120600 140498825811136 submission.py:265] 35500) loss = 2.693, grad_norm = 1.062
I0315 05:10:51.646156 140469707200256 logging_writer.py:48] [36000] global_step=36000, grad_norm=1.01478, loss=2.66464
I0315 05:10:51.708526 140498825811136 submission.py:265] 36000) loss = 2.665, grad_norm = 1.015
I0315 05:11:38.157787 140498825811136 spec.py:321] Evaluating on the training split.
I0315 05:12:21.083076 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 05:13:03.178871 140498825811136 spec.py:349] Evaluating on the test split.
I0315 05:13:04.300243 140498825811136 submission_runner.py:469] Time since start: 27296.67s, 	Step: 36045, 	{'train/accuracy': 0.688835299744898, 'train/loss': 1.3443827726403061, 'validation/accuracy': 0.63008, 'validation/loss': 1.5989709375, 'validation/num_examples': 50000, 'test/accuracy': 0.4947, 'test/loss': 2.34717421875, 'test/num_examples': 10000, 'score': 23008.64829659462, 'total_duration': 27296.66603755951, 'accumulated_submission_time': 23008.64829659462, 'accumulated_eval_time': 4138.999138593674, 'accumulated_logging_time': 1.99222731590271}
I0315 05:13:04.380470 140469698807552 logging_writer.py:48] [36045] accumulated_eval_time=4139, accumulated_logging_time=1.99223, accumulated_submission_time=23008.6, global_step=36045, preemption_count=0, score=23008.6, test/accuracy=0.4947, test/loss=2.34717, test/num_examples=10000, total_duration=27296.7, train/accuracy=0.688835, train/loss=1.34438, validation/accuracy=0.63008, validation/loss=1.59897, validation/num_examples=50000
I0315 05:18:16.961707 140469707200256 logging_writer.py:48] [36500] global_step=36500, grad_norm=1.04351, loss=2.71151
I0315 05:18:16.966154 140498825811136 submission.py:265] 36500) loss = 2.712, grad_norm = 1.044
I0315 05:21:35.986403 140498825811136 spec.py:321] Evaluating on the training split.
I0315 05:22:15.191622 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 05:22:56.277439 140498825811136 spec.py:349] Evaluating on the test split.
I0315 05:22:57.401828 140498825811136 submission_runner.py:469] Time since start: 27889.77s, 	Step: 36952, 	{'train/accuracy': 0.6915457589285714, 'train/loss': 1.3276015301139987, 'validation/accuracy': 0.63266, 'validation/loss': 1.58546359375, 'validation/num_examples': 50000, 'test/accuracy': 0.504, 'test/loss': 2.30903125, 'test/num_examples': 10000, 'score': 23516.921560287476, 'total_duration': 27889.767565011978, 'accumulated_submission_time': 23516.921560287476, 'accumulated_eval_time': 4220.4147255420685, 'accumulated_logging_time': 2.0806312561035156}
I0315 05:22:57.414283 140469698807552 logging_writer.py:48] [36952] accumulated_eval_time=4220.41, accumulated_logging_time=2.08063, accumulated_submission_time=23516.9, global_step=36952, preemption_count=0, score=23516.9, test/accuracy=0.504, test/loss=2.30903, test/num_examples=10000, total_duration=27889.8, train/accuracy=0.691546, train/loss=1.3276, validation/accuracy=0.63266, validation/loss=1.58546, validation/num_examples=50000
I0315 05:23:21.291908 140469707200256 logging_writer.py:48] [37000] global_step=37000, grad_norm=1.00912, loss=2.60818
I0315 05:23:21.296342 140498825811136 submission.py:265] 37000) loss = 2.608, grad_norm = 1.009
I0315 05:29:37.997909 140469698807552 logging_writer.py:48] [37500] global_step=37500, grad_norm=1.03353, loss=2.74858
I0315 05:29:38.035973 140498825811136 submission.py:265] 37500) loss = 2.749, grad_norm = 1.034
I0315 05:31:28.940820 140498825811136 spec.py:321] Evaluating on the training split.
I0315 05:32:08.334040 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 05:32:49.379634 140498825811136 spec.py:349] Evaluating on the test split.
I0315 05:32:50.512570 140498825811136 submission_runner.py:469] Time since start: 28482.88s, 	Step: 37721, 	{'train/accuracy': 0.6964485012755102, 'train/loss': 1.308468565648916, 'validation/accuracy': 0.64022, 'validation/loss': 1.56357234375, 'validation/num_examples': 50000, 'test/accuracy': 0.4962, 'test/loss': 2.322283203125, 'test/num_examples': 10000, 'score': 24025.191588640213, 'total_duration': 28482.878329515457, 'accumulated_submission_time': 24025.191588640213, 'accumulated_eval_time': 4301.986670970917, 'accumulated_logging_time': 2.1012399196624756}
I0315 05:32:50.532358 140469707200256 logging_writer.py:48] [37721] accumulated_eval_time=4301.99, accumulated_logging_time=2.10124, accumulated_submission_time=24025.2, global_step=37721, preemption_count=0, score=24025.2, test/accuracy=0.4962, test/loss=2.32228, test/num_examples=10000, total_duration=28482.9, train/accuracy=0.696449, train/loss=1.30847, validation/accuracy=0.64022, validation/loss=1.56357, validation/num_examples=50000
I0315 05:34:43.204264 140469698807552 logging_writer.py:48] [38000] global_step=38000, grad_norm=1.05095, loss=2.6404
I0315 05:34:43.208842 140498825811136 submission.py:265] 38000) loss = 2.640, grad_norm = 1.051
I0315 05:39:22.447559 140469707200256 logging_writer.py:48] [38500] global_step=38500, grad_norm=1.06549, loss=2.6553
I0315 05:39:22.503809 140498825811136 submission.py:265] 38500) loss = 2.655, grad_norm = 1.065
I0315 05:41:24.491755 140498825811136 spec.py:321] Evaluating on the training split.
I0315 05:42:05.330398 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 05:42:45.977064 140498825811136 spec.py:349] Evaluating on the test split.
I0315 05:42:47.109447 140498825811136 submission_runner.py:469] Time since start: 29079.48s, 	Step: 38634, 	{'train/accuracy': 0.6850884885204082, 'train/loss': 1.3487955210160236, 'validation/accuracy': 0.63268, 'validation/loss': 1.6061584375, 'validation/num_examples': 50000, 'test/accuracy': 0.4964, 'test/loss': 2.3268537109375, 'test/num_examples': 10000, 'score': 24535.890243530273, 'total_duration': 29079.47523522377, 'accumulated_submission_time': 24535.890243530273, 'accumulated_eval_time': 4384.604499578476, 'accumulated_logging_time': 2.1294875144958496}
I0315 05:42:47.206628 140469698807552 logging_writer.py:48] [38634] accumulated_eval_time=4384.6, accumulated_logging_time=2.12949, accumulated_submission_time=24535.9, global_step=38634, preemption_count=0, score=24535.9, test/accuracy=0.4964, test/loss=2.32685, test/num_examples=10000, total_duration=29079.5, train/accuracy=0.685088, train/loss=1.3488, validation/accuracy=0.63268, validation/loss=1.60616, validation/num_examples=50000
I0315 05:47:01.374558 140469707200256 logging_writer.py:48] [39000] global_step=39000, grad_norm=1.02683, loss=2.65144
I0315 05:47:01.378715 140498825811136 submission.py:265] 39000) loss = 2.651, grad_norm = 1.027
I0315 05:51:19.226446 140498825811136 spec.py:321] Evaluating on the training split.
I0315 05:52:02.464926 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 05:52:44.706062 140498825811136 spec.py:349] Evaluating on the test split.
I0315 05:52:45.821254 140498825811136 submission_runner.py:469] Time since start: 29678.19s, 	Step: 39489, 	{'train/accuracy': 0.6890345982142857, 'train/loss': 1.3699955842932876, 'validation/accuracy': 0.63466, 'validation/loss': 1.61291859375, 'validation/num_examples': 50000, 'test/accuracy': 0.4879, 'test/loss': 2.393735546875, 'test/num_examples': 10000, 'score': 25044.58056783676, 'total_duration': 29678.187004327774, 'accumulated_submission_time': 25044.58056783676, 'accumulated_eval_time': 4471.1994071006775, 'accumulated_logging_time': 2.2348995208740234}
I0315 05:52:45.842192 140469698807552 logging_writer.py:48] [39489] accumulated_eval_time=4471.2, accumulated_logging_time=2.2349, accumulated_submission_time=25044.6, global_step=39489, preemption_count=0, score=25044.6, test/accuracy=0.4879, test/loss=2.39374, test/num_examples=10000, total_duration=29678.2, train/accuracy=0.689035, train/loss=1.37, validation/accuracy=0.63466, validation/loss=1.61292, validation/num_examples=50000
I0315 05:52:52.176918 140469707200256 logging_writer.py:48] [39500] global_step=39500, grad_norm=1.03976, loss=2.65848
I0315 05:52:52.180771 140498825811136 submission.py:265] 39500) loss = 2.658, grad_norm = 1.040
I0315 06:00:50.132262 140469698807552 logging_writer.py:48] [40000] global_step=40000, grad_norm=1.0491, loss=2.63647
I0315 06:00:50.216009 140498825811136 submission.py:265] 40000) loss = 2.636, grad_norm = 1.049
I0315 06:01:19.468324 140498825811136 spec.py:321] Evaluating on the training split.
I0315 06:02:01.089708 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 06:02:41.856952 140498825811136 spec.py:349] Evaluating on the test split.
I0315 06:02:42.984457 140498825811136 submission_runner.py:469] Time since start: 30275.35s, 	Step: 40022, 	{'train/accuracy': 0.6891541772959183, 'train/loss': 1.3396358879245058, 'validation/accuracy': 0.63478, 'validation/loss': 1.59013515625, 'validation/num_examples': 50000, 'test/accuracy': 0.4922, 'test/loss': 2.33349609375, 'test/num_examples': 10000, 'score': 25555.04408097267, 'total_duration': 30275.350208997726, 'accumulated_submission_time': 25555.04408097267, 'accumulated_eval_time': 4554.715639829636, 'accumulated_logging_time': 2.264030694961548}
I0315 06:02:43.011451 140469707200256 logging_writer.py:48] [40022] accumulated_eval_time=4554.72, accumulated_logging_time=2.26403, accumulated_submission_time=25555, global_step=40022, preemption_count=0, score=25555, test/accuracy=0.4922, test/loss=2.3335, test/num_examples=10000, total_duration=30275.4, train/accuracy=0.689154, train/loss=1.33964, validation/accuracy=0.63478, validation/loss=1.59014, validation/num_examples=50000
I0315 06:06:25.780798 140469698807552 logging_writer.py:48] [40500] global_step=40500, grad_norm=1.05741, loss=2.6485
I0315 06:06:25.784952 140498825811136 submission.py:265] 40500) loss = 2.649, grad_norm = 1.057
I0315 06:11:14.618058 140498825811136 spec.py:321] Evaluating on the training split.
I0315 06:11:55.722739 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 06:12:37.138520 140498825811136 spec.py:349] Evaluating on the test split.
I0315 06:12:38.261307 140498825811136 submission_runner.py:469] Time since start: 30870.63s, 	Step: 40944, 	{'train/accuracy': 0.6881576849489796, 'train/loss': 1.3547979860889667, 'validation/accuracy': 0.63384, 'validation/loss': 1.60105140625, 'validation/num_examples': 50000, 'test/accuracy': 0.4961, 'test/loss': 2.31831171875, 'test/num_examples': 10000, 'score': 26063.302978277206, 'total_duration': 30870.62711238861, 'accumulated_submission_time': 26063.302978277206, 'accumulated_eval_time': 4638.359055519104, 'accumulated_logging_time': 2.2994790077209473}
I0315 06:12:38.273399 140469707200256 logging_writer.py:48] [40944] accumulated_eval_time=4638.36, accumulated_logging_time=2.29948, accumulated_submission_time=26063.3, global_step=40944, preemption_count=0, score=26063.3, test/accuracy=0.4961, test/loss=2.31831, test/num_examples=10000, total_duration=30870.6, train/accuracy=0.688158, train/loss=1.3548, validation/accuracy=0.63384, validation/loss=1.60105, validation/num_examples=50000
I0315 06:13:33.164802 140469698807552 logging_writer.py:48] [41000] global_step=41000, grad_norm=1.04943, loss=2.70237
I0315 06:13:33.168983 140498825811136 submission.py:265] 41000) loss = 2.702, grad_norm = 1.049
I0315 06:20:33.821733 140469707200256 logging_writer.py:48] [41500] global_step=41500, grad_norm=1.06858, loss=2.67667
I0315 06:20:33.826428 140498825811136 submission.py:265] 41500) loss = 2.677, grad_norm = 1.069
I0315 06:21:09.777882 140498825811136 spec.py:321] Evaluating on the training split.
I0315 06:21:50.347578 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 06:22:32.434072 140498825811136 spec.py:349] Evaluating on the test split.
I0315 06:22:33.569421 140498825811136 submission_runner.py:469] Time since start: 31465.94s, 	Step: 41576, 	{'train/accuracy': 0.6920041454081632, 'train/loss': 1.3322453401526626, 'validation/accuracy': 0.63372, 'validation/loss': 1.593311875, 'validation/num_examples': 50000, 'test/accuracy': 0.4912, 'test/loss': 2.35595546875, 'test/num_examples': 10000, 'score': 26571.651468515396, 'total_duration': 31465.93518781662, 'accumulated_submission_time': 26571.651468515396, 'accumulated_eval_time': 4722.150715351105, 'accumulated_logging_time': 2.3195791244506836}
I0315 06:22:33.582259 140469698807552 logging_writer.py:48] [41576] accumulated_eval_time=4722.15, accumulated_logging_time=2.31958, accumulated_submission_time=26571.7, global_step=41576, preemption_count=0, score=26571.7, test/accuracy=0.4912, test/loss=2.35596, test/num_examples=10000, total_duration=31465.9, train/accuracy=0.692004, train/loss=1.33225, validation/accuracy=0.63372, validation/loss=1.59331, validation/num_examples=50000
I0315 06:26:23.575064 140469707200256 logging_writer.py:48] [42000] global_step=42000, grad_norm=1.07324, loss=2.66499
I0315 06:26:23.579676 140498825811136 submission.py:265] 42000) loss = 2.665, grad_norm = 1.073
I0315 06:31:05.745018 140498825811136 spec.py:321] Evaluating on the training split.
I0315 06:31:46.686986 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 06:32:27.086128 140498825811136 spec.py:349] Evaluating on the test split.
I0315 06:32:28.225179 140498825811136 submission_runner.py:469] Time since start: 32060.59s, 	Step: 42329, 	{'train/accuracy': 0.6904296875, 'train/loss': 1.3020098939233897, 'validation/accuracy': 0.63494, 'validation/loss': 1.56340140625, 'validation/num_examples': 50000, 'test/accuracy': 0.5011, 'test/loss': 2.2755966796875, 'test/num_examples': 10000, 'score': 27080.823556423187, 'total_duration': 32060.590950012207, 'accumulated_submission_time': 27080.823556423187, 'accumulated_eval_time': 4804.631064891815, 'accumulated_logging_time': 2.341977834701538}
I0315 06:32:28.259711 140469698807552 logging_writer.py:48] [42329] accumulated_eval_time=4804.63, accumulated_logging_time=2.34198, accumulated_submission_time=27080.8, global_step=42329, preemption_count=0, score=27080.8, test/accuracy=0.5011, test/loss=2.2756, test/num_examples=10000, total_duration=32060.6, train/accuracy=0.69043, train/loss=1.30201, validation/accuracy=0.63494, validation/loss=1.5634, validation/num_examples=50000
I0315 06:35:50.738252 140469707200256 logging_writer.py:48] [42500] global_step=42500, grad_norm=1.02506, loss=2.64993
I0315 06:35:50.742437 140498825811136 submission.py:265] 42500) loss = 2.650, grad_norm = 1.025
I0315 06:40:06.256390 140469698807552 logging_writer.py:48] [43000] global_step=43000, grad_norm=1.06687, loss=2.64883
I0315 06:40:06.260490 140498825811136 submission.py:265] 43000) loss = 2.649, grad_norm = 1.067
I0315 06:40:59.962246 140498825811136 spec.py:321] Evaluating on the training split.
I0315 06:41:40.248253 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 06:42:21.348359 140498825811136 spec.py:349] Evaluating on the test split.
I0315 06:42:22.464169 140498825811136 submission_runner.py:469] Time since start: 32654.83s, 	Step: 43099, 	{'train/accuracy': 0.6950534119897959, 'train/loss': 1.3223820900430485, 'validation/accuracy': 0.63608, 'validation/loss': 1.57451484375, 'validation/num_examples': 50000, 'test/accuracy': 0.4932, 'test/loss': 2.3397646484375, 'test/num_examples': 10000, 'score': 27589.283241033554, 'total_duration': 32654.829916715622, 'accumulated_submission_time': 27589.283241033554, 'accumulated_eval_time': 4887.133038520813, 'accumulated_logging_time': 2.39498233795166}
I0315 06:42:22.502739 140469707200256 logging_writer.py:48] [43099] accumulated_eval_time=4887.13, accumulated_logging_time=2.39498, accumulated_submission_time=27589.3, global_step=43099, preemption_count=0, score=27589.3, test/accuracy=0.4932, test/loss=2.33976, test/num_examples=10000, total_duration=32654.8, train/accuracy=0.695053, train/loss=1.32238, validation/accuracy=0.63608, validation/loss=1.57451, validation/num_examples=50000
I0315 06:47:12.386357 140469698807552 logging_writer.py:48] [43500] global_step=43500, grad_norm=1.02015, loss=2.65974
I0315 06:47:12.390780 140498825811136 submission.py:265] 43500) loss = 2.660, grad_norm = 1.020
I0315 06:50:53.962676 140498825811136 spec.py:321] Evaluating on the training split.
I0315 06:51:36.798817 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 06:52:18.496947 140498825811136 spec.py:349] Evaluating on the test split.
I0315 06:52:19.619132 140498825811136 submission_runner.py:469] Time since start: 33251.98s, 	Step: 43702, 	{'train/accuracy': 0.6926817602040817, 'train/loss': 1.3233134989835778, 'validation/accuracy': 0.63928, 'validation/loss': 1.57109484375, 'validation/num_examples': 50000, 'test/accuracy': 0.4906, 'test/loss': 2.359754296875, 'test/num_examples': 10000, 'score': 28097.602426290512, 'total_duration': 33251.98486113548, 'accumulated_submission_time': 28097.602426290512, 'accumulated_eval_time': 4972.789545536041, 'accumulated_logging_time': 2.442422866821289}
I0315 06:52:19.633585 140469707200256 logging_writer.py:48] [43702] accumulated_eval_time=4972.79, accumulated_logging_time=2.44242, accumulated_submission_time=28097.6, global_step=43702, preemption_count=0, score=28097.6, test/accuracy=0.4906, test/loss=2.35975, test/num_examples=10000, total_duration=33252, train/accuracy=0.692682, train/loss=1.32331, validation/accuracy=0.63928, validation/loss=1.57109, validation/num_examples=50000
I0315 06:55:28.304779 140469698807552 logging_writer.py:48] [44000] global_step=44000, grad_norm=1.04403, loss=2.52977
I0315 06:55:28.308874 140498825811136 submission.py:265] 44000) loss = 2.530, grad_norm = 1.044
I0315 06:59:49.687055 140469707200256 logging_writer.py:48] [44500] global_step=44500, grad_norm=1.09272, loss=2.69495
I0315 06:59:49.691179 140498825811136 submission.py:265] 44500) loss = 2.695, grad_norm = 1.093
I0315 07:00:51.198813 140498825811136 spec.py:321] Evaluating on the training split.
I0315 07:01:32.247655 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 07:02:13.743465 140498825811136 spec.py:349] Evaluating on the test split.
I0315 07:02:14.864759 140498825811136 submission_runner.py:469] Time since start: 33847.23s, 	Step: 44585, 	{'train/accuracy': 0.6947544642857143, 'train/loss': 1.3269165973274075, 'validation/accuracy': 0.64032, 'validation/loss': 1.57675234375, 'validation/num_examples': 50000, 'test/accuracy': 0.4986, 'test/loss': 2.318326953125, 'test/num_examples': 10000, 'score': 28605.82988333702, 'total_duration': 33847.23049449921, 'accumulated_submission_time': 28605.82988333702, 'accumulated_eval_time': 5056.455642461777, 'accumulated_logging_time': 2.473900318145752}
I0315 07:02:14.911340 140469698807552 logging_writer.py:48] [44585] accumulated_eval_time=5056.46, accumulated_logging_time=2.4739, accumulated_submission_time=28605.8, global_step=44585, preemption_count=0, score=28605.8, test/accuracy=0.4986, test/loss=2.31833, test/num_examples=10000, total_duration=33847.2, train/accuracy=0.694754, train/loss=1.32692, validation/accuracy=0.64032, validation/loss=1.57675, validation/num_examples=50000
I0315 07:09:10.724037 140469707200256 logging_writer.py:48] [45000] global_step=45000, grad_norm=1.02283, loss=2.56994
I0315 07:09:10.728595 140498825811136 submission.py:265] 45000) loss = 2.570, grad_norm = 1.023
I0315 07:10:46.592900 140498825811136 spec.py:321] Evaluating on the training split.
I0315 07:11:29.778695 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 07:12:12.638222 140498825811136 spec.py:349] Evaluating on the test split.
I0315 07:12:13.776714 140498825811136 submission_runner.py:469] Time since start: 34446.14s, 	Step: 45152, 	{'train/accuracy': 0.6934789540816326, 'train/loss': 1.3474890261280292, 'validation/accuracy': 0.63834, 'validation/loss': 1.59560265625, 'validation/num_examples': 50000, 'test/accuracy': 0.5126, 'test/loss': 2.2796935546875, 'test/num_examples': 10000, 'score': 29114.331090450287, 'total_duration': 34446.1423971653, 'accumulated_submission_time': 29114.331090450287, 'accumulated_eval_time': 5143.6395173072815, 'accumulated_logging_time': 2.52937650680542}
I0315 07:12:13.791398 140469698807552 logging_writer.py:48] [45152] accumulated_eval_time=5143.64, accumulated_logging_time=2.52938, accumulated_submission_time=29114.3, global_step=45152, preemption_count=0, score=29114.3, test/accuracy=0.5126, test/loss=2.27969, test/num_examples=10000, total_duration=34446.1, train/accuracy=0.693479, train/loss=1.34749, validation/accuracy=0.63834, validation/loss=1.5956, validation/num_examples=50000
I0315 07:15:00.376513 140469707200256 logging_writer.py:48] [45500] global_step=45500, grad_norm=1.05018, loss=2.62912
I0315 07:15:00.395090 140498825811136 submission.py:265] 45500) loss = 2.629, grad_norm = 1.050
I0315 07:20:36.642158 140469698807552 logging_writer.py:48] [46000] global_step=46000, grad_norm=1.05064, loss=2.66929
I0315 07:20:36.659852 140498825811136 submission.py:265] 46000) loss = 2.669, grad_norm = 1.051
I0315 07:20:46.651451 140498825811136 spec.py:321] Evaluating on the training split.
I0315 07:21:27.687424 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 07:22:08.500757 140498825811136 spec.py:349] Evaluating on the test split.
I0315 07:22:09.629551 140498825811136 submission_runner.py:469] Time since start: 35042.00s, 	Step: 46009, 	{'train/accuracy': 0.6949936224489796, 'train/loss': 1.3204870418626435, 'validation/accuracy': 0.6385, 'validation/loss': 1.570214375, 'validation/num_examples': 50000, 'test/accuracy': 0.494, 'test/loss': 2.3302587890625, 'test/num_examples': 10000, 'score': 29623.896772384644, 'total_duration': 35041.99530720711, 'accumulated_submission_time': 29623.896772384644, 'accumulated_eval_time': 5226.617787837982, 'accumulated_logging_time': 2.552734613418579}
I0315 07:22:09.642243 140469707200256 logging_writer.py:48] [46009] accumulated_eval_time=5226.62, accumulated_logging_time=2.55273, accumulated_submission_time=29623.9, global_step=46009, preemption_count=0, score=29623.9, test/accuracy=0.494, test/loss=2.33026, test/num_examples=10000, total_duration=35042, train/accuracy=0.694994, train/loss=1.32049, validation/accuracy=0.6385, validation/loss=1.57021, validation/num_examples=50000
I0315 07:28:51.275557 140469698807552 logging_writer.py:48] [46500] global_step=46500, grad_norm=1.06894, loss=2.63348
I0315 07:28:51.279973 140498825811136 submission.py:265] 46500) loss = 2.633, grad_norm = 1.069
I0315 07:30:41.234799 140498825811136 spec.py:321] Evaluating on the training split.
I0315 07:31:22.410080 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 07:32:04.379986 140498825811136 spec.py:349] Evaluating on the test split.
I0315 07:32:05.519625 140498825811136 submission_runner.py:469] Time since start: 35637.89s, 	Step: 46727, 	{'train/accuracy': 0.7013512436224489, 'train/loss': 1.2718483282595265, 'validation/accuracy': 0.64738, 'validation/loss': 1.52066984375, 'validation/num_examples': 50000, 'test/accuracy': 0.4989, 'test/loss': 2.28841015625, 'test/num_examples': 10000, 'score': 30132.337628364563, 'total_duration': 35637.88538265228, 'accumulated_submission_time': 30132.337628364563, 'accumulated_eval_time': 5310.9028215408325, 'accumulated_logging_time': 2.573523759841919}
I0315 07:32:05.533706 140469707200256 logging_writer.py:48] [46727] accumulated_eval_time=5310.9, accumulated_logging_time=2.57352, accumulated_submission_time=30132.3, global_step=46727, preemption_count=0, score=30132.3, test/accuracy=0.4989, test/loss=2.28841, test/num_examples=10000, total_duration=35637.9, train/accuracy=0.701351, train/loss=1.27185, validation/accuracy=0.64738, validation/loss=1.52067, validation/num_examples=50000
I0315 07:34:40.124826 140469698807552 logging_writer.py:48] [47000] global_step=47000, grad_norm=1.04202, loss=2.67098
I0315 07:34:40.129324 140498825811136 submission.py:265] 47000) loss = 2.671, grad_norm = 1.042
I0315 07:40:37.157945 140498825811136 spec.py:321] Evaluating on the training split.
I0315 07:41:19.479106 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 07:42:01.481373 140498825811136 spec.py:349] Evaluating on the test split.
I0315 07:42:02.619367 140498825811136 submission_runner.py:469] Time since start: 36234.99s, 	Step: 47408, 	{'train/accuracy': 0.7011320153061225, 'train/loss': 1.2789909985600685, 'validation/accuracy': 0.64502, 'validation/loss': 1.53536671875, 'validation/num_examples': 50000, 'test/accuracy': 0.5112, 'test/loss': 2.242773828125, 'test/num_examples': 10000, 'score': 30640.819804906845, 'total_duration': 36234.985122442245, 'accumulated_submission_time': 30640.819804906845, 'accumulated_eval_time': 5396.364427804947, 'accumulated_logging_time': 2.596203565597534}
I0315 07:42:02.632513 140469707200256 logging_writer.py:48] [47408] accumulated_eval_time=5396.36, accumulated_logging_time=2.5962, accumulated_submission_time=30640.8, global_step=47408, preemption_count=0, score=30640.8, test/accuracy=0.5112, test/loss=2.24277, test/num_examples=10000, total_duration=36235, train/accuracy=0.701132, train/loss=1.27899, validation/accuracy=0.64502, validation/loss=1.53537, validation/num_examples=50000
I0315 07:43:46.796783 140469698807552 logging_writer.py:48] [47500] global_step=47500, grad_norm=1.03114, loss=2.58623
I0315 07:43:46.858143 140498825811136 submission.py:265] 47500) loss = 2.586, grad_norm = 1.031
I0315 07:47:55.062103 140469707200256 logging_writer.py:48] [48000] global_step=48000, grad_norm=1.02587, loss=2.53587
I0315 07:47:55.066434 140498825811136 submission.py:265] 48000) loss = 2.536, grad_norm = 1.026
I0315 07:50:34.642766 140498825811136 spec.py:321] Evaluating on the training split.
I0315 07:51:16.124813 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 07:51:58.298374 140498825811136 spec.py:349] Evaluating on the test split.
I0315 07:51:59.434859 140498825811136 submission_runner.py:469] Time since start: 36831.80s, 	Step: 48281, 	{'train/accuracy': 0.7013512436224489, 'train/loss': 1.2728276155432876, 'validation/accuracy': 0.64494, 'validation/loss': 1.53436859375, 'validation/num_examples': 50000, 'test/accuracy': 0.4959, 'test/loss': 2.314810546875, 'test/num_examples': 10000, 'score': 31149.621018648148, 'total_duration': 36831.800587415695, 'accumulated_submission_time': 31149.621018648148, 'accumulated_eval_time': 5481.156617641449, 'accumulated_logging_time': 2.6183712482452393}
I0315 07:51:59.463277 140469698807552 logging_writer.py:48] [48281] accumulated_eval_time=5481.16, accumulated_logging_time=2.61837, accumulated_submission_time=31149.6, global_step=48281, preemption_count=0, score=31149.6, test/accuracy=0.4959, test/loss=2.31481, test/num_examples=10000, total_duration=36831.8, train/accuracy=0.701351, train/loss=1.27283, validation/accuracy=0.64494, validation/loss=1.53437, validation/num_examples=50000
I0315 07:54:47.933259 140469707200256 logging_writer.py:48] [48500] global_step=48500, grad_norm=1.05129, loss=2.54214
I0315 07:54:47.937460 140498825811136 submission.py:265] 48500) loss = 2.542, grad_norm = 1.051
I0315 08:00:31.193880 140498825811136 spec.py:321] Evaluating on the training split.
I0315 08:01:11.754077 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 08:01:53.088824 140498825811136 spec.py:349] Evaluating on the test split.
I0315 08:01:54.226398 140498825811136 submission_runner.py:469] Time since start: 37426.59s, 	Step: 48855, 	{'train/accuracy': 0.7067123724489796, 'train/loss': 1.265186543367347, 'validation/accuracy': 0.64464, 'validation/loss': 1.532821875, 'validation/num_examples': 50000, 'test/accuracy': 0.5049, 'test/loss': 2.2889099609375, 'test/num_examples': 10000, 'score': 31658.200715780258, 'total_duration': 37426.592134952545, 'accumulated_submission_time': 31658.200715780258, 'accumulated_eval_time': 5564.189346075058, 'accumulated_logging_time': 2.654761791229248}
I0315 08:01:54.310726 140469698807552 logging_writer.py:48] [48855] accumulated_eval_time=5564.19, accumulated_logging_time=2.65476, accumulated_submission_time=31658.2, global_step=48855, preemption_count=0, score=31658.2, test/accuracy=0.5049, test/loss=2.28891, test/num_examples=10000, total_duration=37426.6, train/accuracy=0.706712, train/loss=1.26519, validation/accuracy=0.64464, validation/loss=1.53282, validation/num_examples=50000
I0315 08:02:58.630913 140469707200256 logging_writer.py:48] [49000] global_step=49000, grad_norm=1.03685, loss=2.50738
I0315 08:02:58.634991 140498825811136 submission.py:265] 49000) loss = 2.507, grad_norm = 1.037
I0315 08:07:19.303563 140469698807552 logging_writer.py:48] [49500] global_step=49500, grad_norm=1.06189, loss=2.62309
I0315 08:07:19.308357 140498825811136 submission.py:265] 49500) loss = 2.623, grad_norm = 1.062
I0315 08:10:26.359137 140498825811136 spec.py:321] Evaluating on the training split.
I0315 08:11:08.918828 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 08:11:50.528542 140498825811136 spec.py:349] Evaluating on the test split.
I0315 08:11:51.653405 140498825811136 submission_runner.py:469] Time since start: 38024.02s, 	Step: 49734, 	{'train/accuracy': 0.701530612244898, 'train/loss': 1.2733942927146444, 'validation/accuracy': 0.6424, 'validation/loss': 1.53053546875, 'validation/num_examples': 50000, 'test/accuracy': 0.4987, 'test/loss': 2.2962619140625, 'test/num_examples': 10000, 'score': 32166.89771413803, 'total_duration': 38024.01919770241, 'accumulated_submission_time': 32166.89771413803, 'accumulated_eval_time': 5649.483825683594, 'accumulated_logging_time': 2.7815165519714355}
I0315 08:11:51.666245 140469707200256 logging_writer.py:48] [49734] accumulated_eval_time=5649.48, accumulated_logging_time=2.78152, accumulated_submission_time=32166.9, global_step=49734, preemption_count=0, score=32166.9, test/accuracy=0.4987, test/loss=2.29626, test/num_examples=10000, total_duration=38024, train/accuracy=0.701531, train/loss=1.27339, validation/accuracy=0.6424, validation/loss=1.53054, validation/num_examples=50000
I0315 08:16:38.135842 140469698807552 logging_writer.py:48] [50000] global_step=50000, grad_norm=1.01754, loss=2.61075
I0315 08:16:38.173358 140498825811136 submission.py:265] 50000) loss = 2.611, grad_norm = 1.018
I0315 08:20:23.933064 140498825811136 spec.py:321] Evaluating on the training split.
I0315 08:21:03.670985 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 08:21:44.006881 140498825811136 spec.py:349] Evaluating on the test split.
I0315 08:21:45.124318 140498825811136 submission_runner.py:469] Time since start: 38617.49s, 	Step: 50433, 	{'train/accuracy': 0.6997369260204082, 'train/loss': 1.2800029832489637, 'validation/accuracy': 0.63878, 'validation/loss': 1.54580671875, 'validation/num_examples': 50000, 'test/accuracy': 0.4905, 'test/loss': 2.3201140625, 'test/num_examples': 10000, 'score': 32675.964158058167, 'total_duration': 38617.49009370804, 'accumulated_submission_time': 32675.964158058167, 'accumulated_eval_time': 5730.675276041031, 'accumulated_logging_time': 2.802506446838379}
I0315 08:21:45.137463 140469707200256 logging_writer.py:48] [50433] accumulated_eval_time=5730.68, accumulated_logging_time=2.80251, accumulated_submission_time=32676, global_step=50433, preemption_count=0, score=32676, test/accuracy=0.4905, test/loss=2.32011, test/num_examples=10000, total_duration=38617.5, train/accuracy=0.699737, train/loss=1.28, validation/accuracy=0.63878, validation/loss=1.54581, validation/num_examples=50000
I0315 08:22:19.560179 140469698807552 logging_writer.py:48] [50500] global_step=50500, grad_norm=1.09083, loss=2.56788
I0315 08:22:19.564148 140498825811136 submission.py:265] 50500) loss = 2.568, grad_norm = 1.091
I0315 08:28:05.635203 140469707200256 logging_writer.py:48] [51000] global_step=51000, grad_norm=1.0427, loss=2.58429
I0315 08:28:05.639481 140498825811136 submission.py:265] 51000) loss = 2.584, grad_norm = 1.043
I0315 08:30:17.170288 140498825811136 spec.py:321] Evaluating on the training split.
I0315 08:30:59.061404 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 08:31:41.408948 140498825811136 spec.py:349] Evaluating on the test split.
I0315 08:31:42.518960 140498825811136 submission_runner.py:469] Time since start: 39214.88s, 	Step: 51122, 	{'train/accuracy': 0.6997568558673469, 'train/loss': 1.2789593910684391, 'validation/accuracy': 0.6435, 'validation/loss': 1.53534515625, 'validation/num_examples': 50000, 'test/accuracy': 0.4936, 'test/loss': 2.330698046875, 'test/num_examples': 10000, 'score': 33184.933522224426, 'total_duration': 39214.88474702835, 'accumulated_submission_time': 33184.933522224426, 'accumulated_eval_time': 5816.024139881134, 'accumulated_logging_time': 2.823922634124756}
I0315 08:31:42.531855 140469698807552 logging_writer.py:48] [51122] accumulated_eval_time=5816.02, accumulated_logging_time=2.82392, accumulated_submission_time=33184.9, global_step=51122, preemption_count=0, score=33184.9, test/accuracy=0.4936, test/loss=2.3307, test/num_examples=10000, total_duration=39214.9, train/accuracy=0.699757, train/loss=1.27896, validation/accuracy=0.6435, validation/loss=1.53535, validation/num_examples=50000
I0315 08:36:30.699895 140469707200256 logging_writer.py:48] [51500] global_step=51500, grad_norm=1.05595, loss=2.52156
I0315 08:36:30.704114 140498825811136 submission.py:265] 51500) loss = 2.522, grad_norm = 1.056
I0315 08:40:14.252619 140498825811136 spec.py:321] Evaluating on the training split.
I0315 08:40:53.398961 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 08:41:33.688958 140498825811136 spec.py:349] Evaluating on the test split.
I0315 08:41:34.817296 140498825811136 submission_runner.py:469] Time since start: 39807.18s, 	Step: 51937, 	{'train/accuracy': 0.7055165816326531, 'train/loss': 1.2928052629743303, 'validation/accuracy': 0.64582, 'validation/loss': 1.5554403125, 'validation/num_examples': 50000, 'test/accuracy': 0.5038, 'test/loss': 2.285869921875, 'test/num_examples': 10000, 'score': 33693.35483407974, 'total_duration': 39807.18305802345, 'accumulated_submission_time': 33693.35483407974, 'accumulated_eval_time': 5896.5889773368835, 'accumulated_logging_time': 2.8711163997650146}
I0315 08:41:34.832023 140469698807552 logging_writer.py:48] [51937] accumulated_eval_time=5896.59, accumulated_logging_time=2.87112, accumulated_submission_time=33693.4, global_step=51937, preemption_count=0, score=33693.4, test/accuracy=0.5038, test/loss=2.28587, test/num_examples=10000, total_duration=39807.2, train/accuracy=0.705517, train/loss=1.29281, validation/accuracy=0.64582, validation/loss=1.55544, validation/num_examples=50000
I0315 08:42:14.325964 140469707200256 logging_writer.py:48] [52000] global_step=52000, grad_norm=1.07577, loss=2.6523
I0315 08:42:14.330230 140498825811136 submission.py:265] 52000) loss = 2.652, grad_norm = 1.076
I0315 08:49:57.258291 140469698807552 logging_writer.py:48] [52500] global_step=52500, grad_norm=1.07634, loss=2.61437
I0315 08:49:57.271072 140498825811136 submission.py:265] 52500) loss = 2.614, grad_norm = 1.076
I0315 08:50:08.324128 140498825811136 spec.py:321] Evaluating on the training split.
I0315 08:50:48.184496 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 08:51:28.698635 140498825811136 spec.py:349] Evaluating on the test split.
I0315 08:51:29.828348 140498825811136 submission_runner.py:469] Time since start: 40402.19s, 	Step: 52508, 	{'train/accuracy': 0.7051578443877551, 'train/loss': 1.2889626172124122, 'validation/accuracy': 0.65116, 'validation/loss': 1.53724640625, 'validation/num_examples': 50000, 'test/accuracy': 0.5003, 'test/loss': 2.2980623046875, 'test/num_examples': 10000, 'score': 34203.778401613235, 'total_duration': 40402.19411468506, 'accumulated_submission_time': 34203.778401613235, 'accumulated_eval_time': 5978.093372344971, 'accumulated_logging_time': 2.8946285247802734}
I0315 08:51:29.842250 140469707200256 logging_writer.py:48] [52508] accumulated_eval_time=5978.09, accumulated_logging_time=2.89463, accumulated_submission_time=34203.8, global_step=52508, preemption_count=0, score=34203.8, test/accuracy=0.5003, test/loss=2.29806, test/num_examples=10000, total_duration=40402.2, train/accuracy=0.705158, train/loss=1.28896, validation/accuracy=0.65116, validation/loss=1.53725, validation/num_examples=50000
I0315 08:55:35.018818 140469698807552 logging_writer.py:48] [53000] global_step=53000, grad_norm=1.1319, loss=2.71895
I0315 08:55:35.022908 140498825811136 submission.py:265] 53000) loss = 2.719, grad_norm = 1.132
I0315 09:00:02.175987 140498825811136 spec.py:321] Evaluating on the training split.
I0315 09:00:45.253371 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 09:01:26.459361 140498825811136 spec.py:349] Evaluating on the test split.
I0315 09:01:27.590771 140498825811136 submission_runner.py:469] Time since start: 40999.96s, 	Step: 53426, 	{'train/accuracy': 0.7006337691326531, 'train/loss': 1.2613734809719785, 'validation/accuracy': 0.64462, 'validation/loss': 1.525243125, 'validation/num_examples': 50000, 'test/accuracy': 0.4908, 'test/loss': 2.3604181640625, 'test/num_examples': 10000, 'score': 34712.752076625824, 'total_duration': 40999.956553697586, 'accumulated_submission_time': 34712.752076625824, 'accumulated_eval_time': 6063.508281946182, 'accumulated_logging_time': 2.916703701019287}
I0315 09:01:27.615327 140469707200256 logging_writer.py:48] [53426] accumulated_eval_time=6063.51, accumulated_logging_time=2.9167, accumulated_submission_time=34712.8, global_step=53426, preemption_count=0, score=34712.8, test/accuracy=0.4908, test/loss=2.36042, test/num_examples=10000, total_duration=41000, train/accuracy=0.700634, train/loss=1.26137, validation/accuracy=0.64462, validation/loss=1.52524, validation/num_examples=50000
I0315 09:02:31.660710 140469698807552 logging_writer.py:48] [53500] global_step=53500, grad_norm=1.05531, loss=2.64868
I0315 09:02:31.664906 140498825811136 submission.py:265] 53500) loss = 2.649, grad_norm = 1.055
I0315 09:09:33.833211 140469707200256 logging_writer.py:48] [54000] global_step=54000, grad_norm=1.10783, loss=2.65538
I0315 09:09:33.837573 140498825811136 submission.py:265] 54000) loss = 2.655, grad_norm = 1.108
I0315 09:09:59.182551 140498825811136 spec.py:321] Evaluating on the training split.
I0315 09:10:40.610692 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 09:11:21.161262 140498825811136 spec.py:349] Evaluating on the test split.
I0315 09:11:22.281675 140498825811136 submission_runner.py:469] Time since start: 41594.65s, 	Step: 54053, 	{'train/accuracy': 0.7034040178571429, 'train/loss': 1.2637934782067124, 'validation/accuracy': 0.6467, 'validation/loss': 1.523490625, 'validation/num_examples': 50000, 'test/accuracy': 0.5066, 'test/loss': 2.2428193359375, 'test/num_examples': 10000, 'score': 35221.14172554016, 'total_duration': 41594.647466897964, 'accumulated_submission_time': 35221.14172554016, 'accumulated_eval_time': 6146.607708930969, 'accumulated_logging_time': 2.949971914291382}
I0315 09:11:22.294502 140469698807552 logging_writer.py:48] [54053] accumulated_eval_time=6146.61, accumulated_logging_time=2.94997, accumulated_submission_time=35221.1, global_step=54053, preemption_count=0, score=35221.1, test/accuracy=0.5066, test/loss=2.24282, test/num_examples=10000, total_duration=41594.6, train/accuracy=0.703404, train/loss=1.26379, validation/accuracy=0.6467, validation/loss=1.52349, validation/num_examples=50000
I0315 09:15:31.659121 140469707200256 logging_writer.py:48] [54500] global_step=54500, grad_norm=1.04838, loss=2.60233
I0315 09:15:31.713344 140498825811136 submission.py:265] 54500) loss = 2.602, grad_norm = 1.048
I0315 09:19:54.094099 140498825811136 spec.py:321] Evaluating on the training split.
I0315 09:20:33.904853 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 09:21:15.198178 140498825811136 spec.py:349] Evaluating on the test split.
I0315 09:21:16.334917 140498825811136 submission_runner.py:469] Time since start: 42188.70s, 	Step: 54808, 	{'train/accuracy': 0.7016900510204082, 'train/loss': 1.267437526157924, 'validation/accuracy': 0.64724, 'validation/loss': 1.52143203125, 'validation/num_examples': 50000, 'test/accuracy': 0.5113, 'test/loss': 2.234728125, 'test/num_examples': 10000, 'score': 35729.69034075737, 'total_duration': 42188.700650930405, 'accumulated_submission_time': 35729.69034075737, 'accumulated_eval_time': 6228.848843574524, 'accumulated_logging_time': 2.9707067012786865}
I0315 09:21:16.349426 140469698807552 logging_writer.py:48] [54808] accumulated_eval_time=6228.85, accumulated_logging_time=2.97071, accumulated_submission_time=35729.7, global_step=54808, preemption_count=0, score=35729.7, test/accuracy=0.5113, test/loss=2.23473, test/num_examples=10000, total_duration=42188.7, train/accuracy=0.70169, train/loss=1.26744, validation/accuracy=0.64724, validation/loss=1.52143, validation/num_examples=50000
I0315 09:25:02.532262 140469707200256 logging_writer.py:48] [55000] global_step=55000, grad_norm=1.10486, loss=2.66608
I0315 09:25:02.536531 140498825811136 submission.py:265] 55000) loss = 2.666, grad_norm = 1.105
I0315 09:29:34.651849 140469698807552 logging_writer.py:48] [55500] global_step=55500, grad_norm=1.05196, loss=2.54429
I0315 09:29:34.657023 140498825811136 submission.py:265] 55500) loss = 2.544, grad_norm = 1.052
I0315 09:29:47.854064 140498825811136 spec.py:321] Evaluating on the training split.
I0315 09:30:30.182239 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 09:31:12.026887 140498825811136 spec.py:349] Evaluating on the test split.
I0315 09:31:13.157566 140498825811136 submission_runner.py:469] Time since start: 42785.52s, 	Step: 55523, 	{'train/accuracy': 0.7069316007653061, 'train/loss': 1.2379281958755182, 'validation/accuracy': 0.6486, 'validation/loss': 1.50573875, 'validation/num_examples': 50000, 'test/accuracy': 0.5109, 'test/loss': 2.23178828125, 'test/num_examples': 10000, 'score': 36237.95554924011, 'total_duration': 42785.523360967636, 'accumulated_submission_time': 36237.95554924011, 'accumulated_eval_time': 6314.152548074722, 'accumulated_logging_time': 2.9940292835235596}
I0315 09:31:13.171564 140469707200256 logging_writer.py:48] [55523] accumulated_eval_time=6314.15, accumulated_logging_time=2.99403, accumulated_submission_time=36238, global_step=55523, preemption_count=0, score=36238, test/accuracy=0.5109, test/loss=2.23179, test/num_examples=10000, total_duration=42785.5, train/accuracy=0.706932, train/loss=1.23793, validation/accuracy=0.6486, validation/loss=1.50574, validation/num_examples=50000
I0315 09:36:38.258908 140469698807552 logging_writer.py:48] [56000] global_step=56000, grad_norm=1.08512, loss=2.49278
I0315 09:36:38.263473 140498825811136 submission.py:265] 56000) loss = 2.493, grad_norm = 1.085
I0315 09:39:46.668410 140498825811136 spec.py:321] Evaluating on the training split.
I0315 09:40:29.093332 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 09:41:11.802366 140498825811136 spec.py:349] Evaluating on the test split.
I0315 09:41:12.941435 140498825811136 submission_runner.py:469] Time since start: 43385.31s, 	Step: 56174, 	{'train/accuracy': 0.7084462691326531, 'train/loss': 1.2465013776506697, 'validation/accuracy': 0.65206, 'validation/loss': 1.500938125, 'validation/num_examples': 50000, 'test/accuracy': 0.5136, 'test/loss': 2.2177478515625, 'test/num_examples': 10000, 'score': 36748.33333277702, 'total_duration': 43385.30722618103, 'accumulated_submission_time': 36748.33333277702, 'accumulated_eval_time': 6400.425736427307, 'accumulated_logging_time': 3.016570568084717}
I0315 09:41:12.973466 140469707200256 logging_writer.py:48] [56174] accumulated_eval_time=6400.43, accumulated_logging_time=3.01657, accumulated_submission_time=36748.3, global_step=56174, preemption_count=0, score=36748.3, test/accuracy=0.5136, test/loss=2.21775, test/num_examples=10000, total_duration=43385.3, train/accuracy=0.708446, train/loss=1.2465, validation/accuracy=0.65206, validation/loss=1.50094, validation/num_examples=50000
I0315 09:45:12.398759 140469698807552 logging_writer.py:48] [56500] global_step=56500, grad_norm=1.08424, loss=2.53741
I0315 09:45:12.423570 140498825811136 submission.py:265] 56500) loss = 2.537, grad_norm = 1.084
I0315 09:49:45.217056 140498825811136 spec.py:321] Evaluating on the training split.
I0315 09:50:24.955846 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 09:51:07.115689 140498825811136 spec.py:349] Evaluating on the test split.
I0315 09:51:08.252548 140498825811136 submission_runner.py:469] Time since start: 43980.62s, 	Step: 56996, 	{'train/accuracy': 0.7062141262755102, 'train/loss': 1.2647301810128349, 'validation/accuracy': 0.65076, 'validation/loss': 1.51984359375, 'validation/num_examples': 50000, 'test/accuracy': 0.5163, 'test/loss': 2.215312890625, 'test/num_examples': 10000, 'score': 37257.34295105934, 'total_duration': 43980.618228673935, 'accumulated_submission_time': 37257.34295105934, 'accumulated_eval_time': 6483.461329936981, 'accumulated_logging_time': 3.057614803314209}
I0315 09:51:08.266650 140469707200256 logging_writer.py:48] [56996] accumulated_eval_time=6483.46, accumulated_logging_time=3.05761, accumulated_submission_time=37257.3, global_step=56996, preemption_count=0, score=37257.3, test/accuracy=0.5163, test/loss=2.21531, test/num_examples=10000, total_duration=43980.6, train/accuracy=0.706214, train/loss=1.26473, validation/accuracy=0.65076, validation/loss=1.51984, validation/num_examples=50000
I0315 09:51:11.841609 140469698807552 logging_writer.py:48] [57000] global_step=57000, grad_norm=1.11755, loss=2.5599
I0315 09:51:11.845516 140498825811136 submission.py:265] 57000) loss = 2.560, grad_norm = 1.118
I0315 09:59:20.131825 140469707200256 logging_writer.py:48] [57500] global_step=57500, grad_norm=1.06011, loss=2.61189
I0315 09:59:20.135707 140498825811136 submission.py:265] 57500) loss = 2.612, grad_norm = 1.060
I0315 09:59:41.771466 140498825811136 spec.py:321] Evaluating on the training split.
I0315 10:00:22.093834 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 10:01:02.770978 140498825811136 spec.py:349] Evaluating on the test split.
I0315 10:01:03.908048 140498825811136 submission_runner.py:469] Time since start: 44576.27s, 	Step: 57516, 	{'train/accuracy': 0.7096420599489796, 'train/loss': 1.220824961759606, 'validation/accuracy': 0.6505, 'validation/loss': 1.4827403125, 'validation/num_examples': 50000, 'test/accuracy': 0.5087, 'test/loss': 2.231934765625, 'test/num_examples': 10000, 'score': 37767.87645936012, 'total_duration': 44576.273723363876, 'accumulated_submission_time': 37767.87645936012, 'accumulated_eval_time': 6565.597932100296, 'accumulated_logging_time': 3.080190658569336}
I0315 10:01:03.924305 140469698807552 logging_writer.py:48] [57516] accumulated_eval_time=6565.6, accumulated_logging_time=3.08019, accumulated_submission_time=37767.9, global_step=57516, preemption_count=0, score=37767.9, test/accuracy=0.5087, test/loss=2.23193, test/num_examples=10000, total_duration=44576.3, train/accuracy=0.709642, train/loss=1.22082, validation/accuracy=0.6505, validation/loss=1.48274, validation/num_examples=50000
I0315 10:05:08.894375 140469707200256 logging_writer.py:48] [58000] global_step=58000, grad_norm=1.13476, loss=2.59708
I0315 10:05:08.938619 140498825811136 submission.py:265] 58000) loss = 2.597, grad_norm = 1.135
I0315 10:09:36.046578 140498825811136 spec.py:321] Evaluating on the training split.
I0315 10:10:18.247089 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 10:10:59.033132 140498825811136 spec.py:349] Evaluating on the test split.
I0315 10:11:00.156788 140498825811136 submission_runner.py:469] Time since start: 45172.52s, 	Step: 58414, 	{'train/accuracy': 0.7120934311224489, 'train/loss': 1.2360346268634408, 'validation/accuracy': 0.65078, 'validation/loss': 1.49999328125, 'validation/num_examples': 50000, 'test/accuracy': 0.5071, 'test/loss': 2.24968046875, 'test/num_examples': 10000, 'score': 38276.70531630516, 'total_duration': 45172.52254104614, 'accumulated_submission_time': 38276.70531630516, 'accumulated_eval_time': 6649.708341121674, 'accumulated_logging_time': 3.1047346591949463}
I0315 10:11:00.190414 140469698807552 logging_writer.py:48] [58414] accumulated_eval_time=6649.71, accumulated_logging_time=3.10473, accumulated_submission_time=38276.7, global_step=58414, preemption_count=0, score=38276.7, test/accuracy=0.5071, test/loss=2.24968, test/num_examples=10000, total_duration=45172.5, train/accuracy=0.712093, train/loss=1.23603, validation/accuracy=0.65078, validation/loss=1.49999, validation/num_examples=50000
I0315 10:12:22.574473 140469707200256 logging_writer.py:48] [58500] global_step=58500, grad_norm=1.10875, loss=2.6681
I0315 10:12:22.578202 140498825811136 submission.py:265] 58500) loss = 2.668, grad_norm = 1.109
I0315 10:19:31.917107 140498825811136 spec.py:321] Evaluating on the training split.
I0315 10:20:12.266126 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 10:20:52.827199 140498825811136 spec.py:349] Evaluating on the test split.
I0315 10:20:53.967568 140498825811136 submission_runner.py:469] Time since start: 45766.33s, 	Step: 58959, 	{'train/accuracy': 0.7127311862244898, 'train/loss': 1.2345099157216597, 'validation/accuracy': 0.65426, 'validation/loss': 1.4932846875, 'validation/num_examples': 50000, 'test/accuracy': 0.5109, 'test/loss': 2.2365220703125, 'test/num_examples': 10000, 'score': 38785.326404333115, 'total_duration': 45766.33331346512, 'accumulated_submission_time': 38785.326404333115, 'accumulated_eval_time': 6731.758955955505, 'accumulated_logging_time': 3.1468679904937744}
I0315 10:20:53.998165 140469698807552 logging_writer.py:48] [58959] accumulated_eval_time=6731.76, accumulated_logging_time=3.14687, accumulated_submission_time=38785.3, global_step=58959, preemption_count=0, score=38785.3, test/accuracy=0.5109, test/loss=2.23652, test/num_examples=10000, total_duration=45766.3, train/accuracy=0.712731, train/loss=1.23451, validation/accuracy=0.65426, validation/loss=1.49328, validation/num_examples=50000
I0315 10:21:13.748654 140469707200256 logging_writer.py:48] [59000] global_step=59000, grad_norm=1.07585, loss=2.56742
I0315 10:21:13.764536 140498825811136 submission.py:265] 59000) loss = 2.567, grad_norm = 1.076
I0315 10:25:44.627371 140469698807552 logging_writer.py:48] [59500] global_step=59500, grad_norm=1.0639, loss=2.49991
I0315 10:25:44.631947 140498825811136 submission.py:265] 59500) loss = 2.500, grad_norm = 1.064
I0315 10:29:25.488031 140498825811136 spec.py:321] Evaluating on the training split.
I0315 10:30:07.269795 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 10:30:48.447326 140498825811136 spec.py:349] Evaluating on the test split.
I0315 10:30:49.581255 140498825811136 submission_runner.py:469] Time since start: 46361.95s, 	Step: 59763, 	{'train/accuracy': 0.7087053571428571, 'train/loss': 1.2237974672901386, 'validation/accuracy': 0.65432, 'validation/loss': 1.48363859375, 'validation/num_examples': 50000, 'test/accuracy': 0.5043, 'test/loss': 2.2560705078125, 'test/num_examples': 10000, 'score': 39293.56871891022, 'total_duration': 46361.94702863693, 'accumulated_submission_time': 39293.56871891022, 'accumulated_eval_time': 6815.85239481926, 'accumulated_logging_time': 3.2348477840423584}
I0315 10:30:49.595452 140469707200256 logging_writer.py:48] [59763] accumulated_eval_time=6815.85, accumulated_logging_time=3.23485, accumulated_submission_time=39293.6, global_step=59763, preemption_count=0, score=39293.6, test/accuracy=0.5043, test/loss=2.25607, test/num_examples=10000, total_duration=46361.9, train/accuracy=0.708705, train/loss=1.2238, validation/accuracy=0.65432, validation/loss=1.48364, validation/num_examples=50000
I0315 10:35:20.948298 140469698807552 logging_writer.py:48] [60000] global_step=60000, grad_norm=1.10994, loss=2.63374
I0315 10:35:20.969031 140498825811136 submission.py:265] 60000) loss = 2.634, grad_norm = 1.110
I0315 10:39:21.170249 140498825811136 spec.py:321] Evaluating on the training split.
I0315 10:40:01.584914 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 10:40:43.175462 140498825811136 spec.py:349] Evaluating on the test split.
I0315 10:40:44.310804 140498825811136 submission_runner.py:469] Time since start: 46956.68s, 	Step: 60438, 	{'train/accuracy': 0.7117346938775511, 'train/loss': 1.2678451538085938, 'validation/accuracy': 0.65184, 'validation/loss': 1.52717, 'validation/num_examples': 50000, 'test/accuracy': 0.5045, 'test/loss': 2.2869333984375, 'test/num_examples': 10000, 'score': 39802.022525548935, 'total_duration': 46956.676550388336, 'accumulated_submission_time': 39802.022525548935, 'accumulated_eval_time': 6898.993069648743, 'accumulated_logging_time': 3.2570090293884277}
I0315 10:40:44.324488 140469707200256 logging_writer.py:48] [60438] accumulated_eval_time=6898.99, accumulated_logging_time=3.25701, accumulated_submission_time=39802, global_step=60438, preemption_count=0, score=39802, test/accuracy=0.5045, test/loss=2.28693, test/num_examples=10000, total_duration=46956.7, train/accuracy=0.711735, train/loss=1.26785, validation/accuracy=0.65184, validation/loss=1.52717, validation/num_examples=50000
I0315 10:41:17.054573 140469698807552 logging_writer.py:48] [60500] global_step=60500, grad_norm=1.07326, loss=2.51571
I0315 10:41:17.058835 140498825811136 submission.py:265] 60500) loss = 2.516, grad_norm = 1.073
I0315 10:47:10.840872 140469707200256 logging_writer.py:48] [61000] global_step=61000, grad_norm=1.1333, loss=2.61049
I0315 10:47:10.845196 140498825811136 submission.py:265] 61000) loss = 2.610, grad_norm = 1.133
I0315 10:49:16.478763 140498825811136 spec.py:321] Evaluating on the training split.
I0315 10:49:57.210417 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 10:50:38.367809 140498825811136 spec.py:349] Evaluating on the test split.
I0315 10:50:39.510891 140498825811136 submission_runner.py:469] Time since start: 47551.88s, 	Step: 61109, 	{'train/accuracy': 0.7092833227040817, 'train/loss': 1.2191109949228716, 'validation/accuracy': 0.6518, 'validation/loss': 1.47699421875, 'validation/num_examples': 50000, 'test/accuracy': 0.5143, 'test/loss': 2.211365234375, 'test/num_examples': 10000, 'score': 40311.039259672165, 'total_duration': 47551.87667512894, 'accumulated_submission_time': 40311.039259672165, 'accumulated_eval_time': 6982.025435209274, 'accumulated_logging_time': 3.278946876525879}
I0315 10:50:39.525012 140469698807552 logging_writer.py:48] [61109] accumulated_eval_time=6982.03, accumulated_logging_time=3.27895, accumulated_submission_time=40311, global_step=61109, preemption_count=0, score=40311, test/accuracy=0.5143, test/loss=2.21137, test/num_examples=10000, total_duration=47551.9, train/accuracy=0.709283, train/loss=1.21911, validation/accuracy=0.6518, validation/loss=1.47699, validation/num_examples=50000
I0315 10:55:53.000048 140469707200256 logging_writer.py:48] [61500] global_step=61500, grad_norm=1.0812, loss=2.55593
I0315 10:55:53.004601 140498825811136 submission.py:265] 61500) loss = 2.556, grad_norm = 1.081
I0315 10:59:11.005484 140498825811136 spec.py:321] Evaluating on the training split.
I0315 10:59:50.951722 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 11:00:31.816921 140498825811136 spec.py:349] Evaluating on the test split.
I0315 11:00:32.955847 140498825811136 submission_runner.py:469] Time since start: 48145.32s, 	Step: 61877, 	{'train/accuracy': 0.7141661352040817, 'train/loss': 1.2124247648278061, 'validation/accuracy': 0.65618, 'validation/loss': 1.47055890625, 'validation/num_examples': 50000, 'test/accuracy': 0.5137, 'test/loss': 2.234994140625, 'test/num_examples': 10000, 'score': 40819.30630207062, 'total_duration': 48145.32156562805, 'accumulated_submission_time': 40819.30630207062, 'accumulated_eval_time': 7063.975959300995, 'accumulated_logging_time': 3.3349969387054443}
I0315 11:00:32.970166 140469698807552 logging_writer.py:48] [61877] accumulated_eval_time=7063.98, accumulated_logging_time=3.335, accumulated_submission_time=40819.3, global_step=61877, preemption_count=0, score=40819.3, test/accuracy=0.5137, test/loss=2.23499, test/num_examples=10000, total_duration=48145.3, train/accuracy=0.714166, train/loss=1.21242, validation/accuracy=0.65618, validation/loss=1.47056, validation/num_examples=50000
I0315 11:01:51.070929 140469707200256 logging_writer.py:48] [62000] global_step=62000, grad_norm=1.08205, loss=2.53952
I0315 11:01:51.075059 140498825811136 submission.py:265] 62000) loss = 2.540, grad_norm = 1.082
I0315 11:09:07.436763 140498825811136 spec.py:321] Evaluating on the training split.
I0315 11:09:49.329915 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 11:10:30.499145 140498825811136 spec.py:349] Evaluating on the test split.
I0315 11:10:31.619894 140498825811136 submission_runner.py:469] Time since start: 48743.99s, 	Step: 62464, 	{'train/accuracy': 0.7159199617346939, 'train/loss': 1.234815636459662, 'validation/accuracy': 0.65628, 'validation/loss': 1.4917134375, 'validation/num_examples': 50000, 'test/accuracy': 0.5191, 'test/loss': 2.20691171875, 'test/num_examples': 10000, 'score': 41330.762298583984, 'total_duration': 48743.985662698746, 'accumulated_submission_time': 41330.762298583984, 'accumulated_eval_time': 7148.159294843674, 'accumulated_logging_time': 3.3580777645111084}
I0315 11:10:31.634896 140469698807552 logging_writer.py:48] [62464] accumulated_eval_time=7148.16, accumulated_logging_time=3.35808, accumulated_submission_time=41330.8, global_step=62464, preemption_count=0, score=41330.8, test/accuracy=0.5191, test/loss=2.20691, test/num_examples=10000, total_duration=48744, train/accuracy=0.71592, train/loss=1.23482, validation/accuracy=0.65628, validation/loss=1.49171, validation/num_examples=50000
I0315 11:11:15.455508 140469707200256 logging_writer.py:48] [62500] global_step=62500, grad_norm=1.11363, loss=2.61562
I0315 11:11:15.459280 140498825811136 submission.py:265] 62500) loss = 2.616, grad_norm = 1.114
I0315 11:15:49.089910 140469698807552 logging_writer.py:48] [63000] global_step=63000, grad_norm=1.10018, loss=2.59306
I0315 11:15:49.093935 140498825811136 submission.py:265] 63000) loss = 2.593, grad_norm = 1.100
I0315 11:19:03.127861 140498825811136 spec.py:321] Evaluating on the training split.
I0315 11:19:44.976778 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 11:20:26.855594 140498825811136 spec.py:349] Evaluating on the test split.
I0315 11:20:27.976872 140498825811136 submission_runner.py:469] Time since start: 49340.34s, 	Step: 63319, 	{'train/accuracy': 0.7158601721938775, 'train/loss': 1.2112908655283403, 'validation/accuracy': 0.65568, 'validation/loss': 1.47890265625, 'validation/num_examples': 50000, 'test/accuracy': 0.5134, 'test/loss': 2.2055341796875, 'test/num_examples': 10000, 'score': 41838.974670410156, 'total_duration': 49340.342596292496, 'accumulated_submission_time': 41838.974670410156, 'accumulated_eval_time': 7233.008470535278, 'accumulated_logging_time': 3.4035189151763916}
I0315 11:20:28.009596 140469707200256 logging_writer.py:48] [63319] accumulated_eval_time=7233.01, accumulated_logging_time=3.40352, accumulated_submission_time=41839, global_step=63319, preemption_count=0, score=41839, test/accuracy=0.5134, test/loss=2.20553, test/num_examples=10000, total_duration=49340.3, train/accuracy=0.71586, train/loss=1.21129, validation/accuracy=0.65568, validation/loss=1.4789, validation/num_examples=50000
I0315 11:22:54.700919 140469698807552 logging_writer.py:48] [63500] global_step=63500, grad_norm=1.02319, loss=2.47521
I0315 11:22:54.705501 140498825811136 submission.py:265] 63500) loss = 2.475, grad_norm = 1.023
I0315 11:28:59.510125 140498825811136 spec.py:321] Evaluating on the training split.
I0315 11:29:41.371847 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 11:30:23.896081 140498825811136 spec.py:349] Evaluating on the test split.
I0315 11:30:25.021358 140498825811136 submission_runner.py:469] Time since start: 49937.39s, 	Step: 63851, 	{'train/accuracy': 0.7207629145408163, 'train/loss': 1.1780605705416933, 'validation/accuracy': 0.66104, 'validation/loss': 1.450574375, 'validation/num_examples': 50000, 'test/accuracy': 0.5163, 'test/loss': 2.178109375, 'test/num_examples': 10000, 'score': 42347.35860490799, 'total_duration': 49937.38713812828, 'accumulated_submission_time': 42347.35860490799, 'accumulated_eval_time': 7318.519927740097, 'accumulated_logging_time': 3.4447102546691895}
I0315 11:30:25.043850 140469707200256 logging_writer.py:48] [63851] accumulated_eval_time=7318.52, accumulated_logging_time=3.44471, accumulated_submission_time=42347.4, global_step=63851, preemption_count=0, score=42347.4, test/accuracy=0.5163, test/loss=2.17811, test/num_examples=10000, total_duration=49937.4, train/accuracy=0.720763, train/loss=1.17806, validation/accuracy=0.66104, validation/loss=1.45057, validation/num_examples=50000
I0315 11:31:31.091812 140469698807552 logging_writer.py:48] [64000] global_step=64000, grad_norm=1.14554, loss=2.52035
I0315 11:31:31.096057 140498825811136 submission.py:265] 64000) loss = 2.520, grad_norm = 1.146
I0315 11:35:44.856108 140469707200256 logging_writer.py:48] [64500] global_step=64500, grad_norm=1.06426, loss=2.55828
I0315 11:35:44.867971 140498825811136 submission.py:265] 64500) loss = 2.558, grad_norm = 1.064
I0315 11:38:58.563827 140498825811136 spec.py:321] Evaluating on the training split.
I0315 11:39:39.041657 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 11:40:19.880705 140498825811136 spec.py:349] Evaluating on the test split.
I0315 11:40:21.023753 140498825811136 submission_runner.py:469] Time since start: 50533.39s, 	Step: 64747, 	{'train/accuracy': 0.7133091517857143, 'train/loss': 1.2202630334970903, 'validation/accuracy': 0.65482, 'validation/loss': 1.47939890625, 'validation/num_examples': 50000, 'test/accuracy': 0.518, 'test/loss': 2.22474609375, 'test/num_examples': 10000, 'score': 42857.53965830803, 'total_duration': 50533.38950061798, 'accumulated_submission_time': 42857.53965830803, 'accumulated_eval_time': 7400.979984760284, 'accumulated_logging_time': 3.475900173187256}
I0315 11:40:21.038252 140469698807552 logging_writer.py:48] [64747] accumulated_eval_time=7400.98, accumulated_logging_time=3.4759, accumulated_submission_time=42857.5, global_step=64747, preemption_count=0, score=42857.5, test/accuracy=0.518, test/loss=2.22475, test/num_examples=10000, total_duration=50533.4, train/accuracy=0.713309, train/loss=1.22026, validation/accuracy=0.65482, validation/loss=1.4794, validation/num_examples=50000
I0315 11:44:50.247096 140469707200256 logging_writer.py:48] [65000] global_step=65000, grad_norm=1.09724, loss=2.56237
I0315 11:44:50.251598 140498825811136 submission.py:265] 65000) loss = 2.562, grad_norm = 1.097
I0315 11:48:52.876142 140498825811136 spec.py:321] Evaluating on the training split.
I0315 11:49:31.810643 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 11:50:13.118069 140498825811136 spec.py:349] Evaluating on the test split.
I0315 11:50:14.256368 140498825811136 submission_runner.py:469] Time since start: 51126.62s, 	Step: 65453, 	{'train/accuracy': 0.7150629783163265, 'train/loss': 1.207449465381856, 'validation/accuracy': 0.65474, 'validation/loss': 1.474636875, 'validation/num_examples': 50000, 'test/accuracy': 0.505, 'test/loss': 2.2606927734375, 'test/num_examples': 10000, 'score': 43366.16034245491, 'total_duration': 51126.622086286545, 'accumulated_submission_time': 43366.16034245491, 'accumulated_eval_time': 7482.360347032547, 'accumulated_logging_time': 3.4989326000213623}
I0315 11:50:14.270953 140469698807552 logging_writer.py:48] [65453] accumulated_eval_time=7482.36, accumulated_logging_time=3.49893, accumulated_submission_time=43366.2, global_step=65453, preemption_count=0, score=43366.2, test/accuracy=0.505, test/loss=2.26069, test/num_examples=10000, total_duration=51126.6, train/accuracy=0.715063, train/loss=1.20745, validation/accuracy=0.65474, validation/loss=1.47464, validation/num_examples=50000
I0315 11:50:39.625092 140469707200256 logging_writer.py:48] [65500] global_step=65500, grad_norm=1.09497, loss=2.55655
I0315 11:50:39.629172 140498825811136 submission.py:265] 65500) loss = 2.557, grad_norm = 1.095
I0315 11:56:09.807917 140469698807552 logging_writer.py:48] [66000] global_step=66000, grad_norm=1.12176, loss=2.62911
I0315 11:56:09.812325 140498825811136 submission.py:265] 66000) loss = 2.629, grad_norm = 1.122
I0315 11:58:46.434188 140498825811136 spec.py:321] Evaluating on the training split.
I0315 11:59:28.580418 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 12:00:10.136929 140498825811136 spec.py:349] Evaluating on the test split.
I0315 12:00:11.268553 140498825811136 submission_runner.py:469] Time since start: 51723.63s, 	Step: 66154, 	{'train/accuracy': 0.7200454400510204, 'train/loss': 1.190682313880142, 'validation/accuracy': 0.66042, 'validation/loss': 1.46196109375, 'validation/num_examples': 50000, 'test/accuracy': 0.5002, 'test/loss': 2.2681267578125, 'test/num_examples': 10000, 'score': 43875.106061697006, 'total_duration': 51723.634266614914, 'accumulated_submission_time': 43875.106061697006, 'accumulated_eval_time': 7567.194854259491, 'accumulated_logging_time': 3.577467441558838}
I0315 12:00:11.303406 140469707200256 logging_writer.py:48] [66154] accumulated_eval_time=7567.19, accumulated_logging_time=3.57747, accumulated_submission_time=43875.1, global_step=66154, preemption_count=0, score=43875.1, test/accuracy=0.5002, test/loss=2.26813, test/num_examples=10000, total_duration=51723.6, train/accuracy=0.720045, train/loss=1.19068, validation/accuracy=0.66042, validation/loss=1.46196, validation/num_examples=50000
I0315 12:04:28.693292 140469698807552 logging_writer.py:48] [66500] global_step=66500, grad_norm=1.11707, loss=2.51492
I0315 12:04:28.697573 140498825811136 submission.py:265] 66500) loss = 2.515, grad_norm = 1.117
I0315 12:08:43.466366 140498825811136 spec.py:321] Evaluating on the training split.
I0315 12:09:23.465094 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 12:10:04.616478 140498825811136 spec.py:349] Evaluating on the test split.
I0315 12:10:05.736448 140498825811136 submission_runner.py:469] Time since start: 52318.10s, 	Step: 66989, 	{'train/accuracy': 0.7206433354591837, 'train/loss': 1.209070244613959, 'validation/accuracy': 0.658, 'validation/loss': 1.47588515625, 'validation/num_examples': 50000, 'test/accuracy': 0.5233, 'test/loss': 2.1896888671875, 'test/num_examples': 10000, 'score': 44383.981123924255, 'total_duration': 52318.10220742226, 'accumulated_submission_time': 44383.981123924255, 'accumulated_eval_time': 7649.465146303177, 'accumulated_logging_time': 3.6563150882720947}
I0315 12:10:05.750732 140469707200256 logging_writer.py:48] [66989] accumulated_eval_time=7649.47, accumulated_logging_time=3.65632, accumulated_submission_time=44384, global_step=66989, preemption_count=0, score=44384, test/accuracy=0.5233, test/loss=2.18969, test/num_examples=10000, total_duration=52318.1, train/accuracy=0.720643, train/loss=1.20907, validation/accuracy=0.658, validation/loss=1.47589, validation/num_examples=50000
I0315 12:10:11.953435 140469698807552 logging_writer.py:48] [67000] global_step=67000, grad_norm=1.09545, loss=2.47666
I0315 12:10:11.957347 140498825811136 submission.py:265] 67000) loss = 2.477, grad_norm = 1.095
I0315 12:17:45.124032 140469707200256 logging_writer.py:48] [67500] global_step=67500, grad_norm=1.11723, loss=2.62114
I0315 12:17:45.161127 140498825811136 submission.py:265] 67500) loss = 2.621, grad_norm = 1.117
I0315 12:18:39.359383 140498825811136 spec.py:321] Evaluating on the training split.
I0315 12:19:19.606479 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 12:20:01.653831 140498825811136 spec.py:349] Evaluating on the test split.
I0315 12:20:02.787397 140498825811136 submission_runner.py:469] Time since start: 52915.15s, 	Step: 67544, 	{'train/accuracy': 0.7171755420918368, 'train/loss': 1.2283884165238361, 'validation/accuracy': 0.6589, 'validation/loss': 1.49220640625, 'validation/num_examples': 50000, 'test/accuracy': 0.5184, 'test/loss': 2.197039453125, 'test/num_examples': 10000, 'score': 44894.59243321419, 'total_duration': 52915.15306520462, 'accumulated_submission_time': 44894.59243321419, 'accumulated_eval_time': 7732.893217086792, 'accumulated_logging_time': 3.67891263961792}
I0315 12:20:02.804955 140469698807552 logging_writer.py:48] [67544] accumulated_eval_time=7732.89, accumulated_logging_time=3.67891, accumulated_submission_time=44894.6, global_step=67544, preemption_count=0, score=44894.6, test/accuracy=0.5184, test/loss=2.19704, test/num_examples=10000, total_duration=52915.2, train/accuracy=0.717176, train/loss=1.22839, validation/accuracy=0.6589, validation/loss=1.49221, validation/num_examples=50000
I0315 12:23:30.305366 140469707200256 logging_writer.py:48] [68000] global_step=68000, grad_norm=1.05723, loss=2.50479
I0315 12:23:30.310032 140498825811136 submission.py:265] 68000) loss = 2.505, grad_norm = 1.057
I0315 12:28:35.854471 140498825811136 spec.py:321] Evaluating on the training split.
I0315 12:29:15.360393 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 12:29:56.454997 140498825811136 spec.py:349] Evaluating on the test split.
I0315 12:29:57.592653 140498825811136 submission_runner.py:469] Time since start: 53509.96s, 	Step: 68472, 	{'train/accuracy': 0.7207828443877551, 'train/loss': 1.1943201337541853, 'validation/accuracy': 0.66336, 'validation/loss': 1.45896, 'validation/num_examples': 50000, 'test/accuracy': 0.5182, 'test/loss': 2.1856201171875, 'test/num_examples': 10000, 'score': 45404.28679513931, 'total_duration': 53509.958396434784, 'accumulated_submission_time': 45404.28679513931, 'accumulated_eval_time': 7814.631432771683, 'accumulated_logging_time': 3.7049484252929688}
I0315 12:29:57.639133 140469698807552 logging_writer.py:48] [68472] accumulated_eval_time=7814.63, accumulated_logging_time=3.70495, accumulated_submission_time=45404.3, global_step=68472, preemption_count=0, score=45404.3, test/accuracy=0.5182, test/loss=2.18562, test/num_examples=10000, total_duration=53510, train/accuracy=0.720783, train/loss=1.19432, validation/accuracy=0.66336, validation/loss=1.45896, validation/num_examples=50000
I0315 12:30:23.747940 140469707200256 logging_writer.py:48] [68500] global_step=68500, grad_norm=1.10317, loss=2.60463
I0315 12:30:23.751687 140498825811136 submission.py:265] 68500) loss = 2.605, grad_norm = 1.103
I0315 12:37:21.678165 140469698807552 logging_writer.py:48] [69000] global_step=69000, grad_norm=1.08759, loss=2.53656
I0315 12:37:21.703294 140498825811136 submission.py:265] 69000) loss = 2.537, grad_norm = 1.088
I0315 12:38:29.237367 140498825811136 spec.py:321] Evaluating on the training split.
I0315 12:39:09.412766 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 12:39:51.058632 140498825811136 spec.py:349] Evaluating on the test split.
I0315 12:39:52.191509 140498825811136 submission_runner.py:469] Time since start: 54104.56s, 	Step: 69142, 	{'train/accuracy': 0.7199258609693877, 'train/loss': 1.2027572320432078, 'validation/accuracy': 0.66066, 'validation/loss': 1.4657025, 'validation/num_examples': 50000, 'test/accuracy': 0.5269, 'test/loss': 2.1647068359375, 'test/num_examples': 10000, 'score': 45912.74379658699, 'total_duration': 54104.5572142601, 'accumulated_submission_time': 45912.74379658699, 'accumulated_eval_time': 7897.585689544678, 'accumulated_logging_time': 3.7597742080688477}
I0315 12:39:52.206469 140469707200256 logging_writer.py:48] [69142] accumulated_eval_time=7897.59, accumulated_logging_time=3.75977, accumulated_submission_time=45912.7, global_step=69142, preemption_count=0, score=45912.7, test/accuracy=0.5269, test/loss=2.16471, test/num_examples=10000, total_duration=54104.6, train/accuracy=0.719926, train/loss=1.20276, validation/accuracy=0.66066, validation/loss=1.4657, validation/num_examples=50000
I0315 12:43:09.358346 140469698807552 logging_writer.py:48] [69500] global_step=69500, grad_norm=1.09122, loss=2.4913
I0315 12:43:09.362185 140498825811136 submission.py:265] 69500) loss = 2.491, grad_norm = 1.091
I0315 12:48:25.697708 140498825811136 spec.py:321] Evaluating on the training split.
I0315 12:49:07.676584 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 12:49:49.455419 140498825811136 spec.py:349] Evaluating on the test split.
I0315 12:49:50.594823 140498825811136 submission_runner.py:469] Time since start: 54702.96s, 	Step: 69870, 	{'train/accuracy': 0.7203244579081632, 'train/loss': 1.2011448607152821, 'validation/accuracy': 0.6613, 'validation/loss': 1.4698909375, 'validation/num_examples': 50000, 'test/accuracy': 0.5269, 'test/loss': 2.1602671875, 'test/num_examples': 10000, 'score': 46423.102276325226, 'total_duration': 54702.96055459976, 'accumulated_submission_time': 46423.102276325226, 'accumulated_eval_time': 7982.482862710953, 'accumulated_logging_time': 3.7842493057250977}
I0315 12:49:50.609003 140469707200256 logging_writer.py:48] [69870] accumulated_eval_time=7982.48, accumulated_logging_time=3.78425, accumulated_submission_time=46423.1, global_step=69870, preemption_count=0, score=46423.1, test/accuracy=0.5269, test/loss=2.16027, test/num_examples=10000, total_duration=54703, train/accuracy=0.720324, train/loss=1.20114, validation/accuracy=0.6613, validation/loss=1.46989, validation/num_examples=50000
I0315 12:52:14.500516 140469698807552 logging_writer.py:48] [70000] global_step=70000, grad_norm=1.10316, loss=2.53439
I0315 12:52:14.504548 140498825811136 submission.py:265] 70000) loss = 2.534, grad_norm = 1.103
I0315 12:56:44.744104 140469707200256 logging_writer.py:48] [70500] global_step=70500, grad_norm=1.08526, loss=2.43784
I0315 12:56:44.748665 140498825811136 submission.py:265] 70500) loss = 2.438, grad_norm = 1.085
I0315 12:58:22.345690 140498825811136 spec.py:321] Evaluating on the training split.
I0315 12:59:02.570482 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 12:59:43.148875 140498825811136 spec.py:349] Evaluating on the test split.
I0315 12:59:44.281307 140498825811136 submission_runner.py:469] Time since start: 55296.65s, 	Step: 70677, 	{'train/accuracy': 0.7213010204081632, 'train/loss': 1.2086920446279097, 'validation/accuracy': 0.65936, 'validation/loss': 1.48050296875, 'validation/num_examples': 50000, 'test/accuracy': 0.5307, 'test/loss': 2.1915640625, 'test/num_examples': 10000, 'score': 46931.74700522423, 'total_duration': 55296.64708280563, 'accumulated_submission_time': 46931.74700522423, 'accumulated_eval_time': 8064.418690919876, 'accumulated_logging_time': 3.8264362812042236}
I0315 12:59:44.296355 140469698807552 logging_writer.py:48] [70677] accumulated_eval_time=8064.42, accumulated_logging_time=3.82644, accumulated_submission_time=46931.7, global_step=70677, preemption_count=0, score=46931.7, test/accuracy=0.5307, test/loss=2.19156, test/num_examples=10000, total_duration=55296.6, train/accuracy=0.721301, train/loss=1.20869, validation/accuracy=0.65936, validation/loss=1.4805, validation/num_examples=50000
I0315 13:03:36.582639 140469707200256 logging_writer.py:48] [71000] global_step=71000, grad_norm=1.14899, loss=2.52413
I0315 13:03:36.623236 140498825811136 submission.py:265] 71000) loss = 2.524, grad_norm = 1.149
I0315 13:08:16.465191 140498825811136 spec.py:321] Evaluating on the training split.
I0315 13:08:58.056526 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 13:09:39.094866 140498825811136 spec.py:349] Evaluating on the test split.
I0315 13:09:40.228774 140498825811136 submission_runner.py:469] Time since start: 55892.59s, 	Step: 71258, 	{'train/accuracy': 0.7253069196428571, 'train/loss': 1.2024669257961973, 'validation/accuracy': 0.66298, 'validation/loss': 1.46953625, 'validation/num_examples': 50000, 'test/accuracy': 0.516, 'test/loss': 2.2214126953125, 'test/num_examples': 10000, 'score': 47440.93011593819, 'total_duration': 55892.59451508522, 'accumulated_submission_time': 47440.93011593819, 'accumulated_eval_time': 8148.182408571243, 'accumulated_logging_time': 3.849593162536621}
I0315 13:09:40.289399 140469698807552 logging_writer.py:48] [71258] accumulated_eval_time=8148.18, accumulated_logging_time=3.84959, accumulated_submission_time=47440.9, global_step=71258, preemption_count=0, score=47440.9, test/accuracy=0.516, test/loss=2.22141, test/num_examples=10000, total_duration=55892.6, train/accuracy=0.725307, train/loss=1.20247, validation/accuracy=0.66298, validation/loss=1.46954, validation/num_examples=50000
I0315 13:12:01.739204 140469707200256 logging_writer.py:48] [71500] global_step=71500, grad_norm=1.11882, loss=2.50791
I0315 13:12:01.743962 140498825811136 submission.py:265] 71500) loss = 2.508, grad_norm = 1.119
I0315 13:16:22.886739 140469698807552 logging_writer.py:48] [72000] global_step=72000, grad_norm=1.11901, loss=2.44866
I0315 13:16:22.902065 140498825811136 submission.py:265] 72000) loss = 2.449, grad_norm = 1.119
I0315 13:18:13.394962 140498825811136 spec.py:321] Evaluating on the training split.
I0315 13:18:54.422456 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 13:19:34.925462 140498825811136 spec.py:349] Evaluating on the test split.
I0315 13:19:36.061012 140498825811136 submission_runner.py:469] Time since start: 56488.43s, 	Step: 72151, 	{'train/accuracy': 0.72265625, 'train/loss': 1.1691789432447783, 'validation/accuracy': 0.66532, 'validation/loss': 1.43427140625, 'validation/num_examples': 50000, 'test/accuracy': 0.5153, 'test/loss': 2.1909419921875, 'test/num_examples': 10000, 'score': 47950.82408952713, 'total_duration': 56488.42675757408, 'accumulated_submission_time': 47950.82408952713, 'accumulated_eval_time': 8230.84866642952, 'accumulated_logging_time': 3.9192569255828857}
I0315 13:19:36.076370 140469707200256 logging_writer.py:48] [72151] accumulated_eval_time=8230.85, accumulated_logging_time=3.91926, accumulated_submission_time=47950.8, global_step=72151, preemption_count=0, score=47950.8, test/accuracy=0.5153, test/loss=2.19094, test/num_examples=10000, total_duration=56488.4, train/accuracy=0.722656, train/loss=1.16918, validation/accuracy=0.66532, validation/loss=1.43427, validation/num_examples=50000
I0315 13:25:41.251980 140469698807552 logging_writer.py:48] [72500] global_step=72500, grad_norm=1.12743, loss=2.52924
I0315 13:25:41.274836 140498825811136 submission.py:265] 72500) loss = 2.529, grad_norm = 1.127
I0315 13:28:07.507943 140498825811136 spec.py:321] Evaluating on the training split.
I0315 13:28:49.157038 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 13:29:29.796645 140498825811136 spec.py:349] Evaluating on the test split.
I0315 13:29:30.916519 140498825811136 submission_runner.py:469] Time since start: 57083.28s, 	Step: 72724, 	{'train/accuracy': 0.7241111288265306, 'train/loss': 1.168430250518176, 'validation/accuracy': 0.6661, 'validation/loss': 1.43794109375, 'validation/num_examples': 50000, 'test/accuracy': 0.5206, 'test/loss': 2.1732333984375, 'test/num_examples': 10000, 'score': 48459.23122668266, 'total_duration': 57083.28226470947, 'accumulated_submission_time': 48459.23122668266, 'accumulated_eval_time': 8314.257390499115, 'accumulated_logging_time': 3.943392753601074}
I0315 13:29:30.933081 140469707200256 logging_writer.py:48] [72724] accumulated_eval_time=8314.26, accumulated_logging_time=3.94339, accumulated_submission_time=48459.2, global_step=72724, preemption_count=0, score=48459.2, test/accuracy=0.5206, test/loss=2.17323, test/num_examples=10000, total_duration=57083.3, train/accuracy=0.724111, train/loss=1.16843, validation/accuracy=0.6661, validation/loss=1.43794, validation/num_examples=50000
I0315 13:31:43.113134 140469698807552 logging_writer.py:48] [73000] global_step=73000, grad_norm=1.14199, loss=2.51205
I0315 13:31:43.117344 140498825811136 submission.py:265] 73000) loss = 2.512, grad_norm = 1.142
I0315 13:37:13.919545 140469707200256 logging_writer.py:48] [73500] global_step=73500, grad_norm=1.10166, loss=2.46059
I0315 13:37:13.923886 140498825811136 submission.py:265] 73500) loss = 2.461, grad_norm = 1.102
I0315 13:38:02.467211 140498825811136 spec.py:321] Evaluating on the training split.
I0315 13:38:45.005620 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 13:39:26.945585 140498825811136 spec.py:349] Evaluating on the test split.
I0315 13:39:28.059359 140498825811136 submission_runner.py:469] Time since start: 57680.43s, 	Step: 73546, 	{'train/accuracy': 0.7293128188775511, 'train/loss': 1.168064039580676, 'validation/accuracy': 0.66598, 'validation/loss': 1.4319275, 'validation/num_examples': 50000, 'test/accuracy': 0.5292, 'test/loss': 2.14775546875, 'test/num_examples': 10000, 'score': 48967.48728680611, 'total_duration': 57680.42510342598, 'accumulated_submission_time': 48967.48728680611, 'accumulated_eval_time': 8399.849638223648, 'accumulated_logging_time': 3.9691107273101807}
I0315 13:39:28.076130 140469698807552 logging_writer.py:48] [73546] accumulated_eval_time=8399.85, accumulated_logging_time=3.96911, accumulated_submission_time=48967.5, global_step=73546, preemption_count=0, score=48967.5, test/accuracy=0.5292, test/loss=2.14776, test/num_examples=10000, total_duration=57680.4, train/accuracy=0.729313, train/loss=1.16806, validation/accuracy=0.66598, validation/loss=1.43193, validation/num_examples=50000
I0315 13:45:55.558535 140469707200256 logging_writer.py:48] [74000] global_step=74000, grad_norm=1.09231, loss=2.43363
I0315 13:45:55.562959 140498825811136 submission.py:265] 74000) loss = 2.434, grad_norm = 1.092
I0315 13:47:59.870395 140498825811136 spec.py:321] Evaluating on the training split.
I0315 13:48:40.705559 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 13:49:20.781760 140498825811136 spec.py:349] Evaluating on the test split.
I0315 13:49:21.900597 140498825811136 submission_runner.py:469] Time since start: 58274.27s, 	Step: 74256, 	{'train/accuracy': 0.7254264987244898, 'train/loss': 1.1579697278081154, 'validation/accuracy': 0.66444, 'validation/loss': 1.4339928125, 'validation/num_examples': 50000, 'test/accuracy': 0.5221, 'test/loss': 2.16555859375, 'test/num_examples': 10000, 'score': 49475.98159766197, 'total_duration': 58274.26638174057, 'accumulated_submission_time': 49475.98159766197, 'accumulated_eval_time': 8481.880017995834, 'accumulated_logging_time': 4.024603366851807}
I0315 13:49:21.915793 140469698807552 logging_writer.py:48] [74256] accumulated_eval_time=8481.88, accumulated_logging_time=4.0246, accumulated_submission_time=49476, global_step=74256, preemption_count=0, score=49476, test/accuracy=0.5221, test/loss=2.16556, test/num_examples=10000, total_duration=58274.3, train/accuracy=0.725426, train/loss=1.15797, validation/accuracy=0.66444, validation/loss=1.43399, validation/num_examples=50000
I0315 13:51:38.727293 140469707200256 logging_writer.py:48] [74500] global_step=74500, grad_norm=1.13004, loss=2.50469
I0315 13:51:38.731976 140498825811136 submission.py:265] 74500) loss = 2.505, grad_norm = 1.130
I0315 13:57:56.628411 140498825811136 spec.py:321] Evaluating on the training split.
I0315 13:58:36.346180 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 13:59:17.994510 140498825811136 spec.py:349] Evaluating on the test split.
I0315 13:59:19.132966 140498825811136 submission_runner.py:469] Time since start: 58871.50s, 	Step: 74934, 	{'train/accuracy': 0.7279376594387755, 'train/loss': 1.165647234235491, 'validation/accuracy': 0.66722, 'validation/loss': 1.43492359375, 'validation/num_examples': 50000, 'test/accuracy': 0.526, 'test/loss': 2.1681359375, 'test/num_examples': 10000, 'score': 49987.51103448868, 'total_duration': 58871.49873876572, 'accumulated_submission_time': 49987.51103448868, 'accumulated_eval_time': 8564.38474726677, 'accumulated_logging_time': 4.048052072525024}
I0315 13:59:19.148222 140469698807552 logging_writer.py:48] [74934] accumulated_eval_time=8564.38, accumulated_logging_time=4.04805, accumulated_submission_time=49987.5, global_step=74934, preemption_count=0, score=49987.5, test/accuracy=0.526, test/loss=2.16814, test/num_examples=10000, total_duration=58871.5, train/accuracy=0.727938, train/loss=1.16565, validation/accuracy=0.66722, validation/loss=1.43492, validation/num_examples=50000
I0315 14:00:29.922842 140469707200256 logging_writer.py:48] [75000] global_step=75000, grad_norm=1.14778, loss=2.50389
I0315 14:00:29.926823 140498825811136 submission.py:265] 75000) loss = 2.504, grad_norm = 1.148
I0315 14:04:55.300415 140469698807552 logging_writer.py:48] [75500] global_step=75500, grad_norm=1.23737, loss=2.56872
I0315 14:04:55.307244 140498825811136 submission.py:265] 75500) loss = 2.569, grad_norm = 1.237
I0315 14:07:51.665579 140498825811136 spec.py:321] Evaluating on the training split.
I0315 14:08:32.665728 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 14:09:14.274167 140498825811136 spec.py:349] Evaluating on the test split.
I0315 14:09:15.412968 140498825811136 submission_runner.py:469] Time since start: 59467.78s, 	Step: 75814, 	{'train/accuracy': 0.7279177295918368, 'train/loss': 1.152340013153699, 'validation/accuracy': 0.665, 'validation/loss': 1.425348125, 'validation/num_examples': 50000, 'test/accuracy': 0.5269, 'test/loss': 2.152031640625, 'test/num_examples': 10000, 'score': 50496.71258020401, 'total_duration': 59467.77874803543, 'accumulated_submission_time': 50496.71258020401, 'accumulated_eval_time': 8648.132372617722, 'accumulated_logging_time': 4.130701303482056}
I0315 14:09:15.428110 140469707200256 logging_writer.py:48] [75814] accumulated_eval_time=8648.13, accumulated_logging_time=4.1307, accumulated_submission_time=50496.7, global_step=75814, preemption_count=0, score=50496.7, test/accuracy=0.5269, test/loss=2.15203, test/num_examples=10000, total_duration=59467.8, train/accuracy=0.727918, train/loss=1.15234, validation/accuracy=0.665, validation/loss=1.42535, validation/num_examples=50000
I0315 14:11:41.613434 140469698807552 logging_writer.py:48] [76000] global_step=76000, grad_norm=1.08329, loss=2.45982
I0315 14:11:41.617793 140498825811136 submission.py:265] 76000) loss = 2.460, grad_norm = 1.083
I0315 14:17:46.919638 140498825811136 spec.py:321] Evaluating on the training split.
I0315 14:18:26.739714 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 14:19:07.077651 140498825811136 spec.py:349] Evaluating on the test split.
I0315 14:19:08.216827 140498825811136 submission_runner.py:469] Time since start: 60060.58s, 	Step: 76403, 	{'train/accuracy': 0.7302096619897959, 'train/loss': 1.1504916755520567, 'validation/accuracy': 0.6665, 'validation/loss': 1.42945203125, 'validation/num_examples': 50000, 'test/accuracy': 0.5286, 'test/loss': 2.1464814453125, 'test/num_examples': 10000, 'score': 51005.145414829254, 'total_duration': 60060.58256268501, 'accumulated_submission_time': 51005.145414829254, 'accumulated_eval_time': 8729.42970919609, 'accumulated_logging_time': 4.154285430908203}
I0315 14:19:08.243314 140469707200256 logging_writer.py:48] [76403] accumulated_eval_time=8729.43, accumulated_logging_time=4.15429, accumulated_submission_time=51005.1, global_step=76403, preemption_count=0, score=51005.1, test/accuracy=0.5286, test/loss=2.14648, test/num_examples=10000, total_duration=60060.6, train/accuracy=0.73021, train/loss=1.15049, validation/accuracy=0.6665, validation/loss=1.42945, validation/num_examples=50000
I0315 14:19:51.660979 140469698807552 logging_writer.py:48] [76500] global_step=76500, grad_norm=1.16593, loss=2.49969
I0315 14:19:51.665503 140498825811136 submission.py:265] 76500) loss = 2.500, grad_norm = 1.166
I0315 14:24:06.453042 140469707200256 logging_writer.py:48] [77000] global_step=77000, grad_norm=1.14372, loss=2.59649
I0315 14:24:06.473596 140498825811136 submission.py:265] 77000) loss = 2.596, grad_norm = 1.144
I0315 14:27:40.641577 140498825811136 spec.py:321] Evaluating on the training split.
I0315 14:28:22.261178 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 14:29:03.651433 140498825811136 spec.py:349] Evaluating on the test split.
I0315 14:29:04.781517 140498825811136 submission_runner.py:469] Time since start: 60657.15s, 	Step: 77275, 	{'train/accuracy': 0.7359295280612245, 'train/loss': 1.144264843999123, 'validation/accuracy': 0.66968, 'validation/loss': 1.42166921875, 'validation/num_examples': 50000, 'test/accuracy': 0.5371, 'test/loss': 2.1184205078125, 'test/num_examples': 10000, 'score': 51514.329228401184, 'total_duration': 60657.14725494385, 'accumulated_submission_time': 51514.329228401184, 'accumulated_eval_time': 8813.569814920425, 'accumulated_logging_time': 4.18924617767334}
I0315 14:29:04.797621 140469698807552 logging_writer.py:48] [77275] accumulated_eval_time=8813.57, accumulated_logging_time=4.18925, accumulated_submission_time=51514.3, global_step=77275, preemption_count=0, score=51514.3, test/accuracy=0.5371, test/loss=2.11842, test/num_examples=10000, total_duration=60657.1, train/accuracy=0.73593, train/loss=1.14426, validation/accuracy=0.66968, validation/loss=1.42167, validation/num_examples=50000
I0315 14:33:05.531668 140469707200256 logging_writer.py:48] [77500] global_step=77500, grad_norm=1.11271, loss=2.45844
I0315 14:33:05.535964 140498825811136 submission.py:265] 77500) loss = 2.458, grad_norm = 1.113
I0315 14:37:37.212310 140498825811136 spec.py:321] Evaluating on the training split.
I0315 14:38:19.923853 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 14:39:02.055886 140498825811136 spec.py:349] Evaluating on the test split.
I0315 14:39:03.171761 140498825811136 submission_runner.py:469] Time since start: 61255.54s, 	Step: 77989, 	{'train/accuracy': 0.7320830676020408, 'train/loss': 1.1567711343570632, 'validation/accuracy': 0.66918, 'validation/loss': 1.4316978125, 'validation/num_examples': 50000, 'test/accuracy': 0.5279, 'test/loss': 2.1532314453125, 'test/num_examples': 10000, 'score': 52023.54143500328, 'total_duration': 61255.53750371933, 'accumulated_submission_time': 52023.54143500328, 'accumulated_eval_time': 8899.52939915657, 'accumulated_logging_time': 4.213721036911011}
I0315 14:39:03.186865 140469698807552 logging_writer.py:48] [77989] accumulated_eval_time=8899.53, accumulated_logging_time=4.21372, accumulated_submission_time=52023.5, global_step=77989, preemption_count=0, score=52023.5, test/accuracy=0.5279, test/loss=2.15323, test/num_examples=10000, total_duration=61255.5, train/accuracy=0.732083, train/loss=1.15677, validation/accuracy=0.66918, validation/loss=1.4317, validation/num_examples=50000
I0315 14:39:09.342568 140469707200256 logging_writer.py:48] [78000] global_step=78000, grad_norm=1.11398, loss=2.45038
I0315 14:39:09.347399 140498825811136 submission.py:265] 78000) loss = 2.450, grad_norm = 1.114
I0315 14:44:27.737566 140469698807552 logging_writer.py:48] [78500] global_step=78500, grad_norm=1.11006, loss=2.45609
I0315 14:44:27.742173 140498825811136 submission.py:265] 78500) loss = 2.456, grad_norm = 1.110
I0315 14:47:37.236493 140498825811136 spec.py:321] Evaluating on the training split.
I0315 14:48:20.873902 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 14:49:03.409907 140498825811136 spec.py:349] Evaluating on the test split.
I0315 14:49:04.530277 140498825811136 submission_runner.py:469] Time since start: 61856.90s, 	Step: 78682, 	{'train/accuracy': 0.7290537308673469, 'train/loss': 1.166353498186384, 'validation/accuracy': 0.6645, 'validation/loss': 1.45264375, 'validation/num_examples': 50000, 'test/accuracy': 0.5272, 'test/loss': 2.164565234375, 'test/num_examples': 10000, 'score': 52534.36103606224, 'total_duration': 61856.89600300789, 'accumulated_submission_time': 52534.36103606224, 'accumulated_eval_time': 8986.823298931122, 'accumulated_logging_time': 4.252779006958008}
I0315 14:49:04.571443 140469707200256 logging_writer.py:48] [78682] accumulated_eval_time=8986.82, accumulated_logging_time=4.25278, accumulated_submission_time=52534.4, global_step=78682, preemption_count=0, score=52534.4, test/accuracy=0.5272, test/loss=2.16457, test/num_examples=10000, total_duration=61856.9, train/accuracy=0.729054, train/loss=1.16635, validation/accuracy=0.6645, validation/loss=1.45264, validation/num_examples=50000
I0315 14:52:54.099182 140469698807552 logging_writer.py:48] [79000] global_step=79000, grad_norm=1.15406, loss=2.44392
I0315 14:52:54.103829 140498825811136 submission.py:265] 79000) loss = 2.444, grad_norm = 1.154
I0315 14:57:11.774111 140469707200256 logging_writer.py:48] [79500] global_step=79500, grad_norm=1.12685, loss=2.4317
I0315 14:57:11.778774 140498825811136 submission.py:265] 79500) loss = 2.432, grad_norm = 1.127
I0315 14:57:37.634475 140498825811136 spec.py:321] Evaluating on the training split.
I0315 14:58:17.138130 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 14:58:57.680880 140498825811136 spec.py:349] Evaluating on the test split.
I0315 14:58:58.821277 140498825811136 submission_runner.py:469] Time since start: 62451.19s, 	Step: 79538, 	{'train/accuracy': 0.7294921875, 'train/loss': 1.1655089709223534, 'validation/accuracy': 0.6679, 'validation/loss': 1.43180796875, 'validation/num_examples': 50000, 'test/accuracy': 0.53, 'test/loss': 2.1438255859375, 'test/num_examples': 10000, 'score': 53044.14259839058, 'total_duration': 62451.18703389168, 'accumulated_submission_time': 53044.14259839058, 'accumulated_eval_time': 9068.010221004486, 'accumulated_logging_time': 4.304200649261475}
I0315 14:58:58.837076 140469698807552 logging_writer.py:48] [79538] accumulated_eval_time=9068.01, accumulated_logging_time=4.3042, accumulated_submission_time=53044.1, global_step=79538, preemption_count=0, score=53044.1, test/accuracy=0.53, test/loss=2.14383, test/num_examples=10000, total_duration=62451.2, train/accuracy=0.729492, train/loss=1.16551, validation/accuracy=0.6679, validation/loss=1.43181, validation/num_examples=50000
I0315 15:05:52.687343 140469707200256 logging_writer.py:48] [80000] global_step=80000, grad_norm=1.15603, loss=2.58844
I0315 15:05:52.721144 140498825811136 submission.py:265] 80000) loss = 2.588, grad_norm = 1.156
I0315 15:07:30.344386 140498825811136 spec.py:321] Evaluating on the training split.
I0315 15:08:09.781269 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 15:08:49.784973 140498825811136 spec.py:349] Evaluating on the test split.
I0315 15:08:50.911725 140498825811136 submission_runner.py:469] Time since start: 63043.28s, 	Step: 80103, 	{'train/accuracy': 0.7372249681122449, 'train/loss': 1.1262428127989477, 'validation/accuracy': 0.67254, 'validation/loss': 1.41023625, 'validation/num_examples': 50000, 'test/accuracy': 0.5257, 'test/loss': 2.186287890625, 'test/num_examples': 10000, 'score': 53552.53848481178, 'total_duration': 63043.277514219284, 'accumulated_submission_time': 53552.53848481178, 'accumulated_eval_time': 9148.577735900879, 'accumulated_logging_time': 4.328479290008545}
I0315 15:08:50.927632 140469698807552 logging_writer.py:48] [80103] accumulated_eval_time=9148.58, accumulated_logging_time=4.32848, accumulated_submission_time=53552.5, global_step=80103, preemption_count=0, score=53552.5, test/accuracy=0.5257, test/loss=2.18629, test/num_examples=10000, total_duration=63043.3, train/accuracy=0.737225, train/loss=1.12624, validation/accuracy=0.67254, validation/loss=1.41024, validation/num_examples=50000
I0315 15:11:52.487715 140469707200256 logging_writer.py:48] [80500] global_step=80500, grad_norm=1.17165, loss=2.46843
I0315 15:11:52.492054 140498825811136 submission.py:265] 80500) loss = 2.468, grad_norm = 1.172
I0315 15:17:18.604598 140469698807552 logging_writer.py:48] [81000] global_step=81000, grad_norm=1.1431, loss=2.53009
I0315 15:17:18.608442 140498825811136 submission.py:265] 81000) loss = 2.530, grad_norm = 1.143
I0315 15:17:23.087077 140498825811136 spec.py:321] Evaluating on the training split.
I0315 15:18:05.503585 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 15:18:47.686590 140498825811136 spec.py:349] Evaluating on the test split.
I0315 15:18:48.828044 140498825811136 submission_runner.py:469] Time since start: 63641.19s, 	Step: 81004, 	{'train/accuracy': 0.7324019451530612, 'train/loss': 1.1490134414361448, 'validation/accuracy': 0.66834, 'validation/loss': 1.4198365625, 'validation/num_examples': 50000, 'test/accuracy': 0.5314, 'test/loss': 2.1351291015625, 'test/num_examples': 10000, 'score': 54061.34584903717, 'total_duration': 63641.193791627884, 'accumulated_submission_time': 54061.34584903717, 'accumulated_eval_time': 9234.318907260895, 'accumulated_logging_time': 4.352547645568848}
I0315 15:18:48.843113 140469707200256 logging_writer.py:48] [81004] accumulated_eval_time=9234.32, accumulated_logging_time=4.35255, accumulated_submission_time=54061.3, global_step=81004, preemption_count=0, score=54061.3, test/accuracy=0.5314, test/loss=2.13513, test/num_examples=10000, total_duration=63641.2, train/accuracy=0.732402, train/loss=1.14901, validation/accuracy=0.66834, validation/loss=1.41984, validation/num_examples=50000
I0315 15:25:46.261451 140469698807552 logging_writer.py:48] [81500] global_step=81500, grad_norm=1.14934, loss=2.42694
I0315 15:25:46.319503 140498825811136 submission.py:265] 81500) loss = 2.427, grad_norm = 1.149
I0315 15:27:20.700230 140498825811136 spec.py:321] Evaluating on the training split.
I0315 15:28:00.964816 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 15:28:42.820712 140498825811136 spec.py:349] Evaluating on the test split.
I0315 15:28:43.952674 140498825811136 submission_runner.py:469] Time since start: 64236.32s, 	Step: 81699, 	{'train/accuracy': 0.7374441964285714, 'train/loss': 1.146372347461934, 'validation/accuracy': 0.6734, 'validation/loss': 1.42878046875, 'validation/num_examples': 50000, 'test/accuracy': 0.525, 'test/loss': 2.1849322265625, 'test/num_examples': 10000, 'score': 54569.937517404556, 'total_duration': 64236.31839132309, 'accumulated_submission_time': 54569.937517404556, 'accumulated_eval_time': 9317.571401834488, 'accumulated_logging_time': 4.37550950050354}
I0315 15:28:43.969514 140469707200256 logging_writer.py:48] [81699] accumulated_eval_time=9317.57, accumulated_logging_time=4.37551, accumulated_submission_time=54569.9, global_step=81699, preemption_count=0, score=54569.9, test/accuracy=0.525, test/loss=2.18493, test/num_examples=10000, total_duration=64236.3, train/accuracy=0.737444, train/loss=1.14637, validation/accuracy=0.6734, validation/loss=1.42878, validation/num_examples=50000
I0315 15:31:31.689539 140469698807552 logging_writer.py:48] [82000] global_step=82000, grad_norm=1.16997, loss=2.50787
I0315 15:31:31.693727 140498825811136 submission.py:265] 82000) loss = 2.508, grad_norm = 1.170
I0315 15:37:16.016597 140498825811136 spec.py:321] Evaluating on the training split.
I0315 15:37:56.183909 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 15:38:36.359273 140498825811136 spec.py:349] Evaluating on the test split.
I0315 15:38:37.496814 140498825811136 submission_runner.py:469] Time since start: 64829.86s, 	Step: 82400, 	{'train/accuracy': 0.7351522640306123, 'train/loss': 1.1377310460927534, 'validation/accuracy': 0.67246, 'validation/loss': 1.4116525, 'validation/num_examples': 50000, 'test/accuracy': 0.5287, 'test/loss': 2.136186328125, 'test/num_examples': 10000, 'score': 55078.86093878746, 'total_duration': 64829.86259293556, 'accumulated_submission_time': 55078.86093878746, 'accumulated_eval_time': 9399.05182647705, 'accumulated_logging_time': 4.40130090713501}
I0315 15:38:37.539150 140469707200256 logging_writer.py:48] [82400] accumulated_eval_time=9399.05, accumulated_logging_time=4.4013, accumulated_submission_time=55078.9, global_step=82400, preemption_count=0, score=55078.9, test/accuracy=0.5287, test/loss=2.13619, test/num_examples=10000, total_duration=64829.9, train/accuracy=0.735152, train/loss=1.13773, validation/accuracy=0.67246, validation/loss=1.41165, validation/num_examples=50000
I0315 15:40:28.455998 140469698807552 logging_writer.py:48] [82500] global_step=82500, grad_norm=1.14023, loss=2.44166
I0315 15:40:28.459648 140498825811136 submission.py:265] 82500) loss = 2.442, grad_norm = 1.140
I0315 15:45:06.433779 140469707200256 logging_writer.py:48] [83000] global_step=83000, grad_norm=1.19848, loss=2.45673
I0315 15:45:06.438928 140498825811136 submission.py:265] 83000) loss = 2.457, grad_norm = 1.198
I0315 15:47:09.008689 140498825811136 spec.py:321] Evaluating on the training split.
I0315 15:47:50.223664 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 15:48:31.036941 140498825811136 spec.py:349] Evaluating on the test split.
I0315 15:48:32.159068 140498825811136 submission_runner.py:469] Time since start: 65424.52s, 	Step: 83223, 	{'train/accuracy': 0.7354312818877551, 'train/loss': 1.1312315804617745, 'validation/accuracy': 0.6718, 'validation/loss': 1.4063953125, 'validation/num_examples': 50000, 'test/accuracy': 0.5235, 'test/loss': 2.161065234375, 'test/num_examples': 10000, 'score': 55587.125921964645, 'total_duration': 65424.52487397194, 'accumulated_submission_time': 55587.125921964645, 'accumulated_eval_time': 9482.202495098114, 'accumulated_logging_time': 4.469343900680542}
I0315 15:48:32.174564 140469698807552 logging_writer.py:48] [83223] accumulated_eval_time=9482.2, accumulated_logging_time=4.46934, accumulated_submission_time=55587.1, global_step=83223, preemption_count=0, score=55587.1, test/accuracy=0.5235, test/loss=2.16107, test/num_examples=10000, total_duration=65424.5, train/accuracy=0.735431, train/loss=1.13123, validation/accuracy=0.6718, validation/loss=1.4064, validation/num_examples=50000
I0315 15:51:56.590837 140469707200256 logging_writer.py:48] [83500] global_step=83500, grad_norm=1.18058, loss=2.49201
I0315 15:51:56.626888 140498825811136 submission.py:265] 83500) loss = 2.492, grad_norm = 1.181
I0315 15:57:04.619306 140498825811136 spec.py:321] Evaluating on the training split.
I0315 15:57:46.620437 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 15:58:27.829437 140498825811136 spec.py:349] Evaluating on the test split.
I0315 15:58:28.955155 140498825811136 submission_runner.py:469] Time since start: 66021.32s, 	Step: 83783, 	{'train/accuracy': 0.7375637755102041, 'train/loss': 1.1349696723782285, 'validation/accuracy': 0.67372, 'validation/loss': 1.408754375, 'validation/num_examples': 50000, 'test/accuracy': 0.5332, 'test/loss': 2.1365162109375, 'test/num_examples': 10000, 'score': 56096.533638715744, 'total_duration': 66021.32094955444, 'accumulated_submission_time': 56096.533638715744, 'accumulated_eval_time': 9566.538491487503, 'accumulated_logging_time': 4.49404501914978}
I0315 15:58:28.987920 140469698807552 logging_writer.py:48] [83783] accumulated_eval_time=9566.54, accumulated_logging_time=4.49405, accumulated_submission_time=56096.5, global_step=83783, preemption_count=0, score=56096.5, test/accuracy=0.5332, test/loss=2.13652, test/num_examples=10000, total_duration=66021.3, train/accuracy=0.737564, train/loss=1.13497, validation/accuracy=0.67372, validation/loss=1.40875, validation/num_examples=50000
I0315 16:00:29.890752 140469707200256 logging_writer.py:48] [84000] global_step=84000, grad_norm=1.13988, loss=2.42218
I0315 16:00:29.895041 140498825811136 submission.py:265] 84000) loss = 2.422, grad_norm = 1.140
I0315 16:04:48.757948 140469698807552 logging_writer.py:48] [84500] global_step=84500, grad_norm=1.17433, loss=2.52998
I0315 16:04:48.762011 140498825811136 submission.py:265] 84500) loss = 2.530, grad_norm = 1.174
I0315 16:07:01.059659 140498825811136 spec.py:321] Evaluating on the training split.
I0315 16:07:42.360014 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 16:08:24.207665 140498825811136 spec.py:349] Evaluating on the test split.
I0315 16:08:25.342952 140498825811136 submission_runner.py:469] Time since start: 66617.71s, 	Step: 84679, 	{'train/accuracy': 0.7368662308673469, 'train/loss': 1.1448959039182078, 'validation/accuracy': 0.67358, 'validation/loss': 1.4160428125, 'validation/num_examples': 50000, 'test/accuracy': 0.5348, 'test/loss': 2.130053125, 'test/num_examples': 10000, 'score': 56605.275490522385, 'total_duration': 66617.70872426033, 'accumulated_submission_time': 56605.275490522385, 'accumulated_eval_time': 9650.821912765503, 'accumulated_logging_time': 4.535937309265137}
I0315 16:08:25.358622 140469707200256 logging_writer.py:48] [84679] accumulated_eval_time=9650.82, accumulated_logging_time=4.53594, accumulated_submission_time=56605.3, global_step=84679, preemption_count=0, score=56605.3, test/accuracy=0.5348, test/loss=2.13005, test/num_examples=10000, total_duration=66617.7, train/accuracy=0.736866, train/loss=1.1449, validation/accuracy=0.67358, validation/loss=1.41604, validation/num_examples=50000
I0315 16:13:56.119770 140469698807552 logging_writer.py:48] [85000] global_step=85000, grad_norm=1.16226, loss=2.47877
I0315 16:13:56.123936 140498825811136 submission.py:265] 85000) loss = 2.479, grad_norm = 1.162
I0315 16:16:56.870592 140498825811136 spec.py:321] Evaluating on the training split.
I0315 16:17:38.822176 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 16:18:19.604468 140498825811136 spec.py:349] Evaluating on the test split.
I0315 16:18:20.735943 140498825811136 submission_runner.py:469] Time since start: 67213.10s, 	Step: 85292, 	{'train/accuracy': 0.7377032844387755, 'train/loss': 1.1125252392827247, 'validation/accuracy': 0.673, 'validation/loss': 1.3987025, 'validation/num_examples': 50000, 'test/accuracy': 0.5373, 'test/loss': 2.13135546875, 'test/num_examples': 10000, 'score': 57113.57889294624, 'total_duration': 67213.10175418854, 'accumulated_submission_time': 57113.57889294624, 'accumulated_eval_time': 9734.687460899353, 'accumulated_logging_time': 4.560203313827515}
I0315 16:18:20.773881 140469707200256 logging_writer.py:48] [85292] accumulated_eval_time=9734.69, accumulated_logging_time=4.5602, accumulated_submission_time=57113.6, global_step=85292, preemption_count=0, score=57113.6, test/accuracy=0.5373, test/loss=2.13136, test/num_examples=10000, total_duration=67213.1, train/accuracy=0.737703, train/loss=1.11253, validation/accuracy=0.673, validation/loss=1.3987, validation/num_examples=50000
I0315 16:20:01.163428 140469698807552 logging_writer.py:48] [85500] global_step=85500, grad_norm=1.19072, loss=2.41431
I0315 16:20:01.167814 140498825811136 submission.py:265] 85500) loss = 2.414, grad_norm = 1.191
I0315 16:25:26.286383 140469707200256 logging_writer.py:48] [86000] global_step=86000, grad_norm=1.12699, loss=2.42498
I0315 16:25:26.290830 140498825811136 submission.py:265] 86000) loss = 2.425, grad_norm = 1.127
I0315 16:26:52.223355 140498825811136 spec.py:321] Evaluating on the training split.
I0315 16:27:33.354437 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 16:28:14.265763 140498825811136 spec.py:349] Evaluating on the test split.
I0315 16:28:15.385292 140498825811136 submission_runner.py:469] Time since start: 67807.75s, 	Step: 86085, 	{'train/accuracy': 0.7426857461734694, 'train/loss': 1.0879968137157208, 'validation/accuracy': 0.67492, 'validation/loss': 1.381520625, 'validation/num_examples': 50000, 'test/accuracy': 0.5334, 'test/loss': 2.1185513671875, 'test/num_examples': 10000, 'score': 57621.69284462929, 'total_duration': 67807.7510817051, 'accumulated_submission_time': 57621.69284462929, 'accumulated_eval_time': 9817.849631786346, 'accumulated_logging_time': 4.709585428237915}
I0315 16:28:15.400435 140469698807552 logging_writer.py:48] [86085] accumulated_eval_time=9817.85, accumulated_logging_time=4.70959, accumulated_submission_time=57621.7, global_step=86085, preemption_count=0, score=57621.7, test/accuracy=0.5334, test/loss=2.11855, test/num_examples=10000, total_duration=67807.8, train/accuracy=0.742686, train/loss=1.088, validation/accuracy=0.67492, validation/loss=1.38152, validation/num_examples=50000
I0315 16:33:53.014573 140469707200256 logging_writer.py:48] [86500] global_step=86500, grad_norm=1.21074, loss=2.40309
I0315 16:33:53.019093 140498825811136 submission.py:265] 86500) loss = 2.403, grad_norm = 1.211
I0315 16:36:47.969350 140498825811136 spec.py:321] Evaluating on the training split.
I0315 16:37:28.507650 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 16:38:09.949092 140498825811136 spec.py:349] Evaluating on the test split.
I0315 16:38:11.069454 140498825811136 submission_runner.py:469] Time since start: 68403.44s, 	Step: 86852, 	{'train/accuracy': 0.7383808992346939, 'train/loss': 1.1203781439333547, 'validation/accuracy': 0.67462, 'validation/loss': 1.40338828125, 'validation/num_examples': 50000, 'test/accuracy': 0.5402, 'test/loss': 2.1200390625, 'test/num_examples': 10000, 'score': 58131.24727368355, 'total_duration': 68403.43524837494, 'accumulated_submission_time': 58131.24727368355, 'accumulated_eval_time': 9900.949953079224, 'accumulated_logging_time': 4.732925176620483}
I0315 16:38:11.100243 140469698807552 logging_writer.py:48] [86852] accumulated_eval_time=9900.95, accumulated_logging_time=4.73293, accumulated_submission_time=58131.2, global_step=86852, preemption_count=0, score=58131.2, test/accuracy=0.5402, test/loss=2.12004, test/num_examples=10000, total_duration=68403.4, train/accuracy=0.738381, train/loss=1.12038, validation/accuracy=0.67462, validation/loss=1.40339, validation/num_examples=50000
I0315 16:39:38.371290 140469707200256 logging_writer.py:48] [87000] global_step=87000, grad_norm=1.2013, loss=2.45423
I0315 16:39:38.375323 140498825811136 submission.py:265] 87000) loss = 2.454, grad_norm = 1.201
I0315 16:46:42.894992 140498825811136 spec.py:321] Evaluating on the training split.
I0315 16:47:24.308872 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 16:48:07.571434 140498825811136 spec.py:349] Evaluating on the test split.
I0315 16:48:08.706600 140498825811136 submission_runner.py:469] Time since start: 69001.07s, 	Step: 87476, 	{'train/accuracy': 0.7399354272959183, 'train/loss': 1.105907985142299, 'validation/accuracy': 0.67508, 'validation/loss': 1.39549578125, 'validation/num_examples': 50000, 'test/accuracy': 0.5426, 'test/loss': 2.088252734375, 'test/num_examples': 10000, 'score': 58639.83200573921, 'total_duration': 69001.07234811783, 'accumulated_submission_time': 58639.83200573921, 'accumulated_eval_time': 9986.761648893356, 'accumulated_logging_time': 4.772420167922974}
I0315 16:48:08.725278 140469698807552 logging_writer.py:48] [87476] accumulated_eval_time=9986.76, accumulated_logging_time=4.77242, accumulated_submission_time=58639.8, global_step=87476, preemption_count=0, score=58639.8, test/accuracy=0.5426, test/loss=2.08825, test/num_examples=10000, total_duration=69001.1, train/accuracy=0.739935, train/loss=1.10591, validation/accuracy=0.67508, validation/loss=1.3955, validation/num_examples=50000
I0315 16:48:34.270207 140469707200256 logging_writer.py:48] [87500] global_step=87500, grad_norm=1.16394, loss=2.43486
I0315 16:48:34.274353 140498825811136 submission.py:265] 87500) loss = 2.435, grad_norm = 1.164
I0315 16:53:11.556335 140469698807552 logging_writer.py:48] [88000] global_step=88000, grad_norm=1.23651, loss=2.46929
I0315 16:53:11.560978 140498825811136 submission.py:265] 88000) loss = 2.469, grad_norm = 1.237
I0315 16:56:41.233085 140498825811136 spec.py:321] Evaluating on the training split.
I0315 16:57:23.414417 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 16:58:05.207366 140498825811136 spec.py:349] Evaluating on the test split.
I0315 16:58:06.338716 140498825811136 submission_runner.py:469] Time since start: 69598.70s, 	Step: 88355, 	{'train/accuracy': 0.7403539540816326, 'train/loss': 1.107699102284957, 'validation/accuracy': 0.67128, 'validation/loss': 1.40183953125, 'validation/num_examples': 50000, 'test/accuracy': 0.5295, 'test/loss': 2.1400732421875, 'test/num_examples': 10000, 'score': 59148.98277449608, 'total_duration': 69598.70450377464, 'accumulated_submission_time': 59148.98277449608, 'accumulated_eval_time': 10071.867470741272, 'accumulated_logging_time': 4.82051682472229}
I0315 16:58:06.354131 140469707200256 logging_writer.py:48] [88355] accumulated_eval_time=10071.9, accumulated_logging_time=4.82052, accumulated_submission_time=59149, global_step=88355, preemption_count=0, score=59149, test/accuracy=0.5295, test/loss=2.14007, test/num_examples=10000, total_duration=69598.7, train/accuracy=0.740354, train/loss=1.1077, validation/accuracy=0.67128, validation/loss=1.40184, validation/num_examples=50000
I0315 17:00:02.631736 140469698807552 logging_writer.py:48] [88500] global_step=88500, grad_norm=1.20915, loss=2.53003
I0315 17:00:02.636408 140498825811136 submission.py:265] 88500) loss = 2.530, grad_norm = 1.209
I0315 17:06:38.092176 140498825811136 spec.py:321] Evaluating on the training split.
I0315 17:07:19.449626 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 17:08:01.374851 140498825811136 spec.py:349] Evaluating on the test split.
I0315 17:08:02.495400 140498825811136 submission_runner.py:469] Time since start: 70194.86s, 	Step: 88913, 	{'train/accuracy': 0.7424864477040817, 'train/loss': 1.1005235788773517, 'validation/accuracy': 0.67894, 'validation/loss': 1.386843125, 'validation/num_examples': 50000, 'test/accuracy': 0.532, 'test/loss': 2.13635234375, 'test/num_examples': 10000, 'score': 59657.546358823776, 'total_duration': 70194.86119008064, 'accumulated_submission_time': 59657.546358823776, 'accumulated_eval_time': 10156.270891904831, 'accumulated_logging_time': 4.844162940979004}
I0315 17:08:02.511582 140469707200256 logging_writer.py:48] [88913] accumulated_eval_time=10156.3, accumulated_logging_time=4.84416, accumulated_submission_time=59657.5, global_step=88913, preemption_count=0, score=59657.5, test/accuracy=0.532, test/loss=2.13635, test/num_examples=10000, total_duration=70194.9, train/accuracy=0.742486, train/loss=1.10052, validation/accuracy=0.67894, validation/loss=1.38684, validation/num_examples=50000
I0315 17:08:43.470000 140469698807552 logging_writer.py:48] [89000] global_step=89000, grad_norm=1.15584, loss=2.44775
I0315 17:08:43.474237 140498825811136 submission.py:265] 89000) loss = 2.448, grad_norm = 1.156
I0315 17:13:04.171313 140469707200256 logging_writer.py:48] [89500] global_step=89500, grad_norm=1.14917, loss=2.3718
I0315 17:13:04.212011 140498825811136 submission.py:265] 89500) loss = 2.372, grad_norm = 1.149
I0315 17:16:34.377647 140498825811136 spec.py:321] Evaluating on the training split.
I0315 17:17:17.565831 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 17:17:59.123553 140498825811136 spec.py:349] Evaluating on the test split.
I0315 17:18:00.234285 140498825811136 submission_runner.py:469] Time since start: 70792.60s, 	Step: 89771, 	{'train/accuracy': 0.7431042729591837, 'train/loss': 1.10569716473015, 'validation/accuracy': 0.67926, 'validation/loss': 1.3861578125, 'validation/num_examples': 50000, 'test/accuracy': 0.5284, 'test/loss': 2.1365501953125, 'test/num_examples': 10000, 'score': 60166.10707426071, 'total_duration': 70792.60007667542, 'accumulated_submission_time': 60166.10707426071, 'accumulated_eval_time': 10242.127782583237, 'accumulated_logging_time': 4.8688905239105225}
I0315 17:18:00.280095 140469698807552 logging_writer.py:48] [89771] accumulated_eval_time=10242.1, accumulated_logging_time=4.86889, accumulated_submission_time=60166.1, global_step=89771, preemption_count=0, score=60166.1, test/accuracy=0.5284, test/loss=2.13655, test/num_examples=10000, total_duration=70792.6, train/accuracy=0.743104, train/loss=1.1057, validation/accuracy=0.67926, validation/loss=1.38616, validation/num_examples=50000
I0315 17:22:04.290327 140469707200256 logging_writer.py:48] [90000] global_step=90000, grad_norm=1.17031, loss=2.39732
I0315 17:22:04.294509 140498825811136 submission.py:265] 90000) loss = 2.397, grad_norm = 1.170
I0315 17:26:31.909790 140498825811136 spec.py:321] Evaluating on the training split.
I0315 17:27:14.745210 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 17:27:57.066074 140498825811136 spec.py:349] Evaluating on the test split.
I0315 17:27:58.178844 140498825811136 submission_runner.py:469] Time since start: 71390.54s, 	Step: 90469, 	{'train/accuracy': 0.7473094706632653, 'train/loss': 1.0688446200623805, 'validation/accuracy': 0.6831, 'validation/loss': 1.35883796875, 'validation/num_examples': 50000, 'test/accuracy': 0.5424, 'test/loss': 2.073463671875, 'test/num_examples': 10000, 'score': 60674.54400587082, 'total_duration': 71390.5445921421, 'accumulated_submission_time': 60674.54400587082, 'accumulated_eval_time': 10328.397015571594, 'accumulated_logging_time': 4.923119783401489}
I0315 17:27:58.196675 140469698807552 logging_writer.py:48] [90469] accumulated_eval_time=10328.4, accumulated_logging_time=4.92312, accumulated_submission_time=60674.5, global_step=90469, preemption_count=0, score=60674.5, test/accuracy=0.5424, test/loss=2.07346, test/num_examples=10000, total_duration=71390.5, train/accuracy=0.747309, train/loss=1.06884, validation/accuracy=0.6831, validation/loss=1.35884, validation/num_examples=50000
I0315 17:28:14.919875 140469707200256 logging_writer.py:48] [90500] global_step=90500, grad_norm=1.20544, loss=2.44605
I0315 17:28:14.924138 140498825811136 submission.py:265] 90500) loss = 2.446, grad_norm = 1.205
I0315 17:33:38.507038 140469698807552 logging_writer.py:48] [91000] global_step=91000, grad_norm=1.22523, loss=2.47865
I0315 17:33:38.511200 140498825811136 submission.py:265] 91000) loss = 2.479, grad_norm = 1.225
I0315 17:36:31.369222 140498825811136 spec.py:321] Evaluating on the training split.
I0315 17:37:13.242757 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 17:37:53.984690 140498825811136 spec.py:349] Evaluating on the test split.
I0315 17:37:55.101947 140498825811136 submission_runner.py:469] Time since start: 71987.47s, 	Step: 91161, 	{'train/accuracy': 0.7457948022959183, 'train/loss': 1.0893924479581871, 'validation/accuracy': 0.68064, 'validation/loss': 1.375835, 'validation/num_examples': 50000, 'test/accuracy': 0.5331, 'test/loss': 2.1308126953125, 'test/num_examples': 10000, 'score': 61184.44985413551, 'total_duration': 71987.46764397621, 'accumulated_submission_time': 61184.44985413551, 'accumulated_eval_time': 10412.129774093628, 'accumulated_logging_time': 4.979798316955566}
I0315 17:37:55.119284 140469707200256 logging_writer.py:48] [91161] accumulated_eval_time=10412.1, accumulated_logging_time=4.9798, accumulated_submission_time=61184.4, global_step=91161, preemption_count=0, score=61184.4, test/accuracy=0.5331, test/loss=2.13081, test/num_examples=10000, total_duration=71987.5, train/accuracy=0.745795, train/loss=1.08939, validation/accuracy=0.68064, validation/loss=1.37583, validation/num_examples=50000
I0315 17:42:18.058970 140469698807552 logging_writer.py:48] [91500] global_step=91500, grad_norm=1.26911, loss=2.46418
I0315 17:42:18.070947 140498825811136 submission.py:265] 91500) loss = 2.464, grad_norm = 1.269
I0315 17:46:26.651981 140498825811136 spec.py:321] Evaluating on the training split.
I0315 17:47:08.885808 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 17:47:50.932898 140498825811136 spec.py:349] Evaluating on the test split.
I0315 17:47:52.049399 140498825811136 submission_runner.py:469] Time since start: 72584.42s, 	Step: 91990, 	{'train/accuracy': 0.7428252551020408, 'train/loss': 1.1219055798588966, 'validation/accuracy': 0.67614, 'validation/loss': 1.4035309375, 'validation/num_examples': 50000, 'test/accuracy': 0.5379, 'test/loss': 2.12730625, 'test/num_examples': 10000, 'score': 61692.72982621193, 'total_duration': 72584.4151673317, 'accumulated_submission_time': 61692.72982621193, 'accumulated_eval_time': 10497.527377605438, 'accumulated_logging_time': 5.0058434009552}
I0315 17:47:52.104571 140469707200256 logging_writer.py:48] [91990] accumulated_eval_time=10497.5, accumulated_logging_time=5.00584, accumulated_submission_time=61692.7, global_step=91990, preemption_count=0, score=61692.7, test/accuracy=0.5379, test/loss=2.12731, test/num_examples=10000, total_duration=72584.4, train/accuracy=0.742825, train/loss=1.12191, validation/accuracy=0.67614, validation/loss=1.40353, validation/num_examples=50000
I0315 17:47:58.227084 140469698807552 logging_writer.py:48] [92000] global_step=92000, grad_norm=1.20253, loss=2.42414
I0315 17:47:58.231454 140498825811136 submission.py:265] 92000) loss = 2.424, grad_norm = 1.203
I0315 17:55:36.043702 140469707200256 logging_writer.py:48] [92500] global_step=92500, grad_norm=1.24734, loss=2.4482
I0315 17:55:36.048039 140498825811136 submission.py:265] 92500) loss = 2.448, grad_norm = 1.247
I0315 17:56:25.100791 140498825811136 spec.py:321] Evaluating on the training split.
I0315 17:57:05.812829 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 17:57:46.752456 140498825811136 spec.py:349] Evaluating on the test split.
I0315 17:57:47.880913 140498825811136 submission_runner.py:469] Time since start: 73180.25s, 	Step: 92540, 	{'train/accuracy': 0.7511160714285714, 'train/loss': 1.06484097850566, 'validation/accuracy': 0.68572, 'validation/loss': 1.3553953125, 'validation/num_examples': 50000, 'test/accuracy': 0.5437, 'test/loss': 2.0608046875, 'test/num_examples': 10000, 'score': 62202.637932777405, 'total_duration': 73180.24644589424, 'accumulated_submission_time': 62202.637932777405, 'accumulated_eval_time': 10580.307527303696, 'accumulated_logging_time': 5.0704851150512695}
I0315 17:57:47.897788 140469698807552 logging_writer.py:48] [92540] accumulated_eval_time=10580.3, accumulated_logging_time=5.07049, accumulated_submission_time=62202.6, global_step=92540, preemption_count=0, score=62202.6, test/accuracy=0.5437, test/loss=2.0608, test/num_examples=10000, total_duration=73180.2, train/accuracy=0.751116, train/loss=1.06484, validation/accuracy=0.68572, validation/loss=1.3554, validation/num_examples=50000
I0315 18:01:45.985618 140469707200256 logging_writer.py:48] [93000] global_step=93000, grad_norm=1.16838, loss=2.42738
I0315 18:01:45.990182 140498825811136 submission.py:265] 93000) loss = 2.427, grad_norm = 1.168
I0315 18:06:20.422478 140498825811136 spec.py:321] Evaluating on the training split.
I0315 18:07:01.521061 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 18:07:42.891083 140498825811136 spec.py:349] Evaluating on the test split.
I0315 18:07:44.031570 140498825811136 submission_runner.py:469] Time since start: 73776.40s, 	Step: 93441, 	{'train/accuracy': 0.7488839285714286, 'train/loss': 1.0686646286322146, 'validation/accuracy': 0.68662, 'validation/loss': 1.355295, 'validation/num_examples': 50000, 'test/accuracy': 0.5489, 'test/loss': 2.059588671875, 'test/num_examples': 10000, 'score': 62711.84440636635, 'total_duration': 73776.39730525017, 'accumulated_submission_time': 62711.84440636635, 'accumulated_eval_time': 10663.91672039032, 'accumulated_logging_time': 5.095800161361694}
I0315 18:07:44.069618 140469698807552 logging_writer.py:48] [93441] accumulated_eval_time=10663.9, accumulated_logging_time=5.0958, accumulated_submission_time=62711.8, global_step=93441, preemption_count=0, score=62711.8, test/accuracy=0.5489, test/loss=2.05959, test/num_examples=10000, total_duration=73776.4, train/accuracy=0.748884, train/loss=1.06866, validation/accuracy=0.68662, validation/loss=1.35529, validation/num_examples=50000
I0315 18:08:35.439614 140469707200256 logging_writer.py:48] [93500] global_step=93500, grad_norm=1.2215, loss=2.42959
I0315 18:08:35.444405 140498825811136 submission.py:265] 93500) loss = 2.430, grad_norm = 1.222
I0315 18:15:52.201943 140469698807552 logging_writer.py:48] [94000] global_step=94000, grad_norm=1.16751, loss=2.36982
I0315 18:15:52.266941 140498825811136 submission.py:265] 94000) loss = 2.370, grad_norm = 1.168
I0315 18:16:15.519917 140498825811136 spec.py:321] Evaluating on the training split.
I0315 18:16:56.040712 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 18:17:36.743572 140498825811136 spec.py:349] Evaluating on the test split.
I0315 18:17:37.879872 140498825811136 submission_runner.py:469] Time since start: 74370.25s, 	Step: 94047, 	{'train/accuracy': 0.751335299744898, 'train/loss': 1.059067239566725, 'validation/accuracy': 0.6851, 'validation/loss': 1.353528125, 'validation/num_examples': 50000, 'test/accuracy': 0.5453, 'test/loss': 2.0648248046875, 'test/num_examples': 10000, 'score': 63220.12459754944, 'total_duration': 74370.24567198753, 'accumulated_submission_time': 63220.12459754944, 'accumulated_eval_time': 10746.276811122894, 'accumulated_logging_time': 5.142218589782715}
I0315 18:17:37.896546 140469707200256 logging_writer.py:48] [94047] accumulated_eval_time=10746.3, accumulated_logging_time=5.14222, accumulated_submission_time=63220.1, global_step=94047, preemption_count=0, score=63220.1, test/accuracy=0.5453, test/loss=2.06482, test/num_examples=10000, total_duration=74370.2, train/accuracy=0.751335, train/loss=1.05907, validation/accuracy=0.6851, validation/loss=1.35353, validation/num_examples=50000
I0315 18:21:41.341353 140469698807552 logging_writer.py:48] [94500] global_step=94500, grad_norm=1.2092, loss=2.42245
I0315 18:21:41.345677 140498825811136 submission.py:265] 94500) loss = 2.422, grad_norm = 1.209
I0315 18:26:09.458014 140498825811136 spec.py:321] Evaluating on the training split.
I0315 18:26:50.960337 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 18:27:33.621716 140498825811136 spec.py:349] Evaluating on the test split.
I0315 18:27:34.757462 140498825811136 submission_runner.py:469] Time since start: 74967.12s, 	Step: 94824, 	{'train/accuracy': 0.7490632971938775, 'train/loss': 1.0800945515535316, 'validation/accuracy': 0.68394, 'validation/loss': 1.3590675, 'validation/num_examples': 50000, 'test/accuracy': 0.5415, 'test/loss': 2.08815703125, 'test/num_examples': 10000, 'score': 63728.687324762344, 'total_duration': 74967.12325668335, 'accumulated_submission_time': 63728.687324762344, 'accumulated_eval_time': 10831.576718330383, 'accumulated_logging_time': 5.167607307434082}
I0315 18:27:34.774355 140469707200256 logging_writer.py:48] [94824] accumulated_eval_time=10831.6, accumulated_logging_time=5.16761, accumulated_submission_time=63728.7, global_step=94824, preemption_count=0, score=63728.7, test/accuracy=0.5415, test/loss=2.08816, test/num_examples=10000, total_duration=74967.1, train/accuracy=0.749063, train/loss=1.08009, validation/accuracy=0.68394, validation/loss=1.35907, validation/num_examples=50000
I0315 18:30:47.136023 140469698807552 logging_writer.py:48] [95000] global_step=95000, grad_norm=1.2313, loss=2.44807
I0315 18:30:47.140043 140498825811136 submission.py:265] 95000) loss = 2.448, grad_norm = 1.231
I0315 18:35:41.524873 140469707200256 logging_writer.py:48] [95500] global_step=95500, grad_norm=1.17369, loss=2.38794
I0315 18:35:41.529141 140498825811136 submission.py:265] 95500) loss = 2.388, grad_norm = 1.174
I0315 18:36:06.403336 140498825811136 spec.py:321] Evaluating on the training split.
I0315 18:36:46.814083 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 18:37:27.652500 140498825811136 spec.py:349] Evaluating on the test split.
I0315 18:37:28.768620 140498825811136 submission_runner.py:469] Time since start: 75561.13s, 	Step: 95545, 	{'train/accuracy': 0.7544842155612245, 'train/loss': 1.0518299024932238, 'validation/accuracy': 0.68718, 'validation/loss': 1.3448165625, 'validation/num_examples': 50000, 'test/accuracy': 0.5464, 'test/loss': 2.0757708984375, 'test/num_examples': 10000, 'score': 64237.145743370056, 'total_duration': 75561.1342754364, 'accumulated_submission_time': 64237.145743370056, 'accumulated_eval_time': 10913.942085266113, 'accumulated_logging_time': 5.193201541900635}
I0315 18:37:28.826480 140469698807552 logging_writer.py:48] [95545] accumulated_eval_time=10913.9, accumulated_logging_time=5.1932, accumulated_submission_time=64237.1, global_step=95545, preemption_count=0, score=64237.1, test/accuracy=0.5464, test/loss=2.07577, test/num_examples=10000, total_duration=75561.1, train/accuracy=0.754484, train/loss=1.05183, validation/accuracy=0.68718, validation/loss=1.34482, validation/num_examples=50000
I0315 18:42:37.179597 140469707200256 logging_writer.py:48] [96000] global_step=96000, grad_norm=1.17284, loss=2.28241
I0315 18:42:37.200758 140498825811136 submission.py:265] 96000) loss = 2.282, grad_norm = 1.173
I0315 18:46:00.304339 140498825811136 spec.py:321] Evaluating on the training split.
I0315 18:46:41.041432 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 18:47:22.083814 140498825811136 spec.py:349] Evaluating on the test split.
I0315 18:47:23.224928 140498825811136 submission_runner.py:469] Time since start: 76155.59s, 	Step: 96190, 	{'train/accuracy': 0.7528898278061225, 'train/loss': 1.0538078619509328, 'validation/accuracy': 0.68706, 'validation/loss': 1.344794375, 'validation/num_examples': 50000, 'test/accuracy': 0.5444, 'test/loss': 2.0666994140625, 'test/num_examples': 10000, 'score': 64745.536230802536, 'total_duration': 76155.59070944786, 'accumulated_submission_time': 64745.536230802536, 'accumulated_eval_time': 10996.86277127266, 'accumulated_logging_time': 5.259819507598877}
I0315 18:47:23.241402 140469698807552 logging_writer.py:48] [96190] accumulated_eval_time=10996.9, accumulated_logging_time=5.25982, accumulated_submission_time=64745.5, global_step=96190, preemption_count=0, score=64745.5, test/accuracy=0.5444, test/loss=2.0667, test/num_examples=10000, total_duration=76155.6, train/accuracy=0.75289, train/loss=1.05381, validation/accuracy=0.68706, validation/loss=1.34479, validation/num_examples=50000
I0315 18:51:13.130858 140469707200256 logging_writer.py:48] [96500] global_step=96500, grad_norm=1.21072, loss=2.37926
I0315 18:51:13.135030 140498825811136 submission.py:265] 96500) loss = 2.379, grad_norm = 1.211
I0315 18:55:27.359999 140469698807552 logging_writer.py:48] [97000] global_step=97000, grad_norm=1.21292, loss=2.36658
I0315 18:55:27.364820 140498825811136 submission.py:265] 97000) loss = 2.367, grad_norm = 1.213
I0315 18:55:54.844823 140498825811136 spec.py:321] Evaluating on the training split.
I0315 18:56:34.615237 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 18:57:14.816926 140498825811136 spec.py:349] Evaluating on the test split.
I0315 18:57:15.947916 140498825811136 submission_runner.py:469] Time since start: 76748.31s, 	Step: 97043, 	{'train/accuracy': 0.7540856186224489, 'train/loss': 1.0565681457519531, 'validation/accuracy': 0.687, 'validation/loss': 1.349326875, 'validation/num_examples': 50000, 'test/accuracy': 0.5447, 'test/loss': 2.06528828125, 'test/num_examples': 10000, 'score': 65254.06753754616, 'total_duration': 76748.31371331215, 'accumulated_submission_time': 65254.06753754616, 'accumulated_eval_time': 11077.966226100922, 'accumulated_logging_time': 5.284224987030029}
I0315 18:57:16.008481 140469707200256 logging_writer.py:48] [97043] accumulated_eval_time=11078, accumulated_logging_time=5.28422, accumulated_submission_time=65254.1, global_step=97043, preemption_count=0, score=65254.1, test/accuracy=0.5447, test/loss=2.06529, test/num_examples=10000, total_duration=76748.3, train/accuracy=0.754086, train/loss=1.05657, validation/accuracy=0.687, validation/loss=1.34933, validation/num_examples=50000
I0315 19:04:16.036503 140469698807552 logging_writer.py:48] [97500] global_step=97500, grad_norm=1.26526, loss=2.4895
I0315 19:04:16.040531 140498825811136 submission.py:265] 97500) loss = 2.489, grad_norm = 1.265
I0315 19:05:47.448164 140498825811136 spec.py:321] Evaluating on the training split.
I0315 19:06:29.999801 140498825811136 spec.py:333] Evaluating on the validation split.
I0315 19:07:12.449985 140498825811136 spec.py:349] Evaluating on the test split.
I0315 19:07:13.569287 140498825811136 submission_runner.py:469] Time since start: 77345.94s, 	Step: 97577, 	{'train/accuracy': 0.7568160076530612, 'train/loss': 1.056412054567921, 'validation/accuracy': 0.69102, 'validation/loss': 1.34594578125, 'validation/num_examples': 50000, 'test/accuracy': 0.5563, 'test/loss': 2.042258203125, 'test/num_examples': 10000, 'score': 65762.61107516289, 'total_duration': 77345.9350373745, 'accumulated_submission_time': 65762.61107516289, 'accumulated_eval_time': 11164.087461233139, 'accumulated_logging_time': 5.352982759475708}
I0315 19:07:13.618783 140469707200256 logging_writer.py:48] [97577] accumulated_eval_time=11164.1, accumulated_logging_time=5.35298, accumulated_submission_time=65762.6, global_step=97577, preemption_count=0, score=65762.6, test/accuracy=0.5563, test/loss=2.04226, test/num_examples=10000, total_duration=77345.9, train/accuracy=0.756816, train/loss=1.05641, validation/accuracy=0.69102, validation/loss=1.34595, validation/num_examples=50000
I0315 19:10:35.593839 140469698807552 logging_writer.py:48] [98000] global_step=98000, grad_norm=1.214, loss=2.36134
I0315 19:10:35.640398 140498825811136 submission.py:265] 98000) loss = 2.361, grad_norm = 1.214
I0315 19:15:44.514009 140469707200256 logging_writer.py:48] [98479] global_step=98479, preemption_count=0, score=66271.6
I0315 19:15:48.348778 140498825811136 submission_runner.py:646] Tuning trial 3/5
I0315 19:15:48.349053 140498825811136 submission_runner.py:647] Hyperparameters: Hyperparameters(learning_rate=4.199449275251465, one_minus_beta1=1.0, one_minus_beta2=0.0023701743773090066, epsilon=1e-08, one_minus_momentum=0.03150207249544311, use_momentum=True, weight_decay=6.404237434173623e-05, max_preconditioner_dim=1024, precondition_frequency=100, start_preconditioning_step=-1, inv_root_override=0, exponent_multiplier=1.0, grafting_type='SGD', grafting_epsilon=1e-08, use_normalized_grafting=False, communication_dtype='FP32', communicate_params=True, use_cosine_decay=True, warmup_factor=0.02, label_smoothing=0.1, dropout_rate=0.0, use_nadam=False, step_hint_factor=1.0)
I0315 19:15:48.351259 140498825811136 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/accuracy': 0.001016422193877551, 'train/loss': 6.91202467315051, 'validation/accuracy': 0.0009, 'validation/loss': 6.9119425, 'validation/num_examples': 50000, 'test/accuracy': 0.0012, 'test/loss': 6.9129984375, 'test/num_examples': 10000, 'score': 107.10950207710266, 'total_duration': 516.6698548793793, 'accumulated_submission_time': 107.10950207710266, 'accumulated_eval_time': 408.65377712249756, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (433, {'train/accuracy': 0.03077168367346939, 'train/loss': 6.195235894650829, 'validation/accuracy': 0.03022, 'validation/loss': 6.232455, 'validation/num_examples': 50000, 'test/accuracy': 0.0175, 'test/loss': 6.366544140625, 'test/num_examples': 10000, 'score': 618.1501262187958, 'total_duration': 1113.5057480335236, 'accumulated_submission_time': 618.1501262187958, 'accumulated_eval_time': 491.2667407989502, 'accumulated_logging_time': 0.0179290771484375, 'global_step': 433, 'preemption_count': 0}), (871, {'train/accuracy': 0.08302774234693877, 'train/loss': 5.374753368144133, 'validation/accuracy': 0.07748, 'validation/loss': 5.459123125, 'validation/num_examples': 50000, 'test/accuracy': 0.05, 'test/loss': 5.750669140625, 'test/num_examples': 10000, 'score': 1128.4965028762817, 'total_duration': 1707.294766664505, 'accumulated_submission_time': 1128.4965028762817, 'accumulated_eval_time': 571.728408575058, 'accumulated_logging_time': 0.03631782531738281, 'global_step': 871, 'preemption_count': 0}), (1379, {'train/accuracy': 0.1466438137755102, 'train/loss': 4.571158895687181, 'validation/accuracy': 0.13178, 'validation/loss': 4.69486625, 'validation/num_examples': 50000, 'test/accuracy': 0.0911, 'test/loss': 5.147365625, 'test/num_examples': 10000, 'score': 1637.8483209609985, 'total_duration': 2300.9973809719086, 'accumulated_submission_time': 1637.8483209609985, 'accumulated_eval_time': 652.9425506591797, 'accumulated_logging_time': 0.05721259117126465, 'global_step': 1379, 'preemption_count': 0}), (2236, {'train/accuracy': 0.298030931122449, 'train/loss': 3.4236001773756377, 'validation/accuracy': 0.27212, 'validation/loss': 3.5646621875, 'validation/num_examples': 50000, 'test/accuracy': 0.1853, 'test/loss': 4.224787109375, 'test/num_examples': 10000, 'score': 2145.9948003292084, 'total_duration': 2896.821388244629, 'accumulated_submission_time': 2145.9948003292084, 'accumulated_eval_time': 737.2947862148285, 'accumulated_logging_time': 0.11806011199951172, 'global_step': 2236, 'preemption_count': 0}), (3000, {'train/accuracy': 0.40708705357142855, 'train/loss': 2.8126083685427297, 'validation/accuracy': 0.37536, 'validation/loss': 2.9731296875, 'validation/num_examples': 50000, 'test/accuracy': 0.2587, 'test/loss': 3.73683125, 'test/num_examples': 10000, 'score': 2654.7711610794067, 'total_duration': 3490.305849790573, 'accumulated_submission_time': 2654.7711610794067, 'accumulated_eval_time': 818.8198070526123, 'accumulated_logging_time': 0.13681578636169434, 'global_step': 3000, 'preemption_count': 0}), (3740, {'train/accuracy': 0.4516103316326531, 'train/loss': 2.5264626327826054, 'validation/accuracy': 0.41548, 'validation/loss': 2.7033590625, 'validation/num_examples': 50000, 'test/accuracy': 0.2952, 'test/loss': 3.481933984375, 'test/num_examples': 10000, 'score': 3163.9997503757477, 'total_duration': 4085.5834527015686, 'accumulated_submission_time': 3163.9997503757477, 'accumulated_eval_time': 901.7183556556702, 'accumulated_logging_time': 0.15584373474121094, 'global_step': 3740, 'preemption_count': 0}), (4678, {'train/accuracy': 0.5200693558673469, 'train/loss': 2.1601232411910076, 'validation/accuracy': 0.48154, 'validation/loss': 2.34627859375, 'validation/num_examples': 50000, 'test/accuracy': 0.3521, 'test/loss': 3.1220181640625, 'test/num_examples': 10000, 'score': 3674.542419195175, 'total_duration': 4681.621529579163, 'accumulated_submission_time': 3674.542419195175, 'accumulated_eval_time': 983.8328664302826, 'accumulated_logging_time': 0.23341703414916992, 'global_step': 4678, 'preemption_count': 0}), (5405, {'train/accuracy': 0.5469347895408163, 'train/loss': 2.0122524962133292, 'validation/accuracy': 0.50722, 'validation/loss': 2.221385, 'validation/num_examples': 50000, 'test/accuracy': 0.3721, 'test/loss': 3.0044435546875, 'test/num_examples': 10000, 'score': 4182.806913137436, 'total_duration': 5277.5464787483215, 'accumulated_submission_time': 4182.806913137436, 'accumulated_eval_time': 1068.2456591129303, 'accumulated_logging_time': 0.2519814968109131, 'global_step': 5405, 'preemption_count': 0}), (6142, {'train/accuracy': 0.5642737563775511, 'train/loss': 1.9611919169523278, 'validation/accuracy': 0.52344, 'validation/loss': 2.1668059375, 'validation/num_examples': 50000, 'test/accuracy': 0.378, 'test/loss': 2.947890625, 'test/num_examples': 10000, 'score': 4694.277507781982, 'total_duration': 5874.550024986267, 'accumulated_submission_time': 4694.277507781982, 'accumulated_eval_time': 1150.5484170913696, 'accumulated_logging_time': 0.26991796493530273, 'global_step': 6142, 'preemption_count': 0}), (7065, {'train/accuracy': 0.589225924744898, 'train/loss': 1.8145524628308354, 'validation/accuracy': 0.54478, 'validation/loss': 2.03369953125, 'validation/num_examples': 50000, 'test/accuracy': 0.4079, 'test/loss': 2.771328515625, 'test/num_examples': 10000, 'score': 5202.502809047699, 'total_duration': 6468.202593564987, 'accumulated_submission_time': 5202.502809047699, 'accumulated_eval_time': 1232.6363155841827, 'accumulated_logging_time': 0.30586719512939453, 'global_step': 7065, 'preemption_count': 0}), (7751, {'train/accuracy': 0.5987125318877551, 'train/loss': 1.7709064094387754, 'validation/accuracy': 0.55386, 'validation/loss': 1.9840478125, 'validation/num_examples': 50000, 'test/accuracy': 0.4094, 'test/loss': 2.776784765625, 'test/num_examples': 10000, 'score': 5711.111362695694, 'total_duration': 7062.912135601044, 'accumulated_submission_time': 5711.111362695694, 'accumulated_eval_time': 1315.596096754074, 'accumulated_logging_time': 0.3243408203125, 'global_step': 7751, 'preemption_count': 0}), (8571, {'train/accuracy': 0.6064453125, 'train/loss': 1.745419249242666, 'validation/accuracy': 0.55786, 'validation/loss': 1.96768546875, 'validation/num_examples': 50000, 'test/accuracy': 0.4171, 'test/loss': 2.7391240234375, 'test/num_examples': 10000, 'score': 6220.486655473709, 'total_duration': 7658.279411315918, 'accumulated_submission_time': 6220.486655473709, 'accumulated_eval_time': 1398.289455652237, 'accumulated_logging_time': 0.36058902740478516, 'global_step': 8571, 'preemption_count': 0}), (9473, {'train/accuracy': 0.6228475765306123, 'train/loss': 1.666953417719627, 'validation/accuracy': 0.5759, 'validation/loss': 1.894779375, 'validation/num_examples': 50000, 'test/accuracy': 0.4365, 'test/loss': 2.6209654296875, 'test/num_examples': 10000, 'score': 6728.717941045761, 'total_duration': 8251.646416664124, 'accumulated_submission_time': 6728.717941045761, 'accumulated_eval_time': 1480.0222208499908, 'accumulated_logging_time': 0.40282273292541504, 'global_step': 9473, 'preemption_count': 0}), (10206, {'train/accuracy': 0.6249003507653061, 'train/loss': 1.6324669974190849, 'validation/accuracy': 0.5776, 'validation/loss': 1.86240484375, 'validation/num_examples': 50000, 'test/accuracy': 0.44, 'test/loss': 2.623902734375, 'test/num_examples': 10000, 'score': 7237.305422306061, 'total_duration': 8846.469753980637, 'accumulated_submission_time': 7237.305422306061, 'accumulated_eval_time': 1563.0469081401825, 'accumulated_logging_time': 0.42098569869995117, 'global_step': 10206, 'preemption_count': 0}), (11105, {'train/accuracy': 0.6355827487244898, 'train/loss': 1.5829047378228636, 'validation/accuracy': 0.58272, 'validation/loss': 1.8143053125, 'validation/num_examples': 50000, 'test/accuracy': 0.4452, 'test/loss': 2.5451052734375, 'test/num_examples': 10000, 'score': 7745.894095182419, 'total_duration': 9443.223860263824, 'accumulated_submission_time': 7745.894095182419, 'accumulated_eval_time': 1647.7964024543762, 'accumulated_logging_time': 0.4670698642730713, 'global_step': 11105, 'preemption_count': 0}), (12069, {'train/accuracy': 0.6371771364795918, 'train/loss': 1.5758514404296875, 'validation/accuracy': 0.58716, 'validation/loss': 1.80757296875, 'validation/num_examples': 50000, 'test/accuracy': 0.4485, 'test/loss': 2.568693359375, 'test/num_examples': 10000, 'score': 8253.957944393158, 'total_duration': 10037.552994728088, 'accumulated_submission_time': 8253.957944393158, 'accumulated_eval_time': 1730.5997998714447, 'accumulated_logging_time': 0.5368022918701172, 'global_step': 12069, 'preemption_count': 0}), (12862, {'train/accuracy': 0.6376355229591837, 'train/loss': 1.565310575524155, 'validation/accuracy': 0.59232, 'validation/loss': 1.7948803125, 'validation/num_examples': 50000, 'test/accuracy': 0.4439, 'test/loss': 2.59265859375, 'test/num_examples': 10000, 'score': 8762.27849650383, 'total_duration': 10631.607153177261, 'accumulated_submission_time': 8762.27849650383, 'accumulated_eval_time': 1813.0880572795868, 'accumulated_logging_time': 0.5809571743011475, 'global_step': 12862, 'preemption_count': 0}), (13670, {'train/accuracy': 0.6405253507653061, 'train/loss': 1.5644222960180165, 'validation/accuracy': 0.594, 'validation/loss': 1.792005, 'validation/num_examples': 50000, 'test/accuracy': 0.4623, 'test/loss': 2.5011990234375, 'test/num_examples': 10000, 'score': 9271.093402862549, 'total_duration': 11226.886065006256, 'accumulated_submission_time': 9271.093402862549, 'accumulated_eval_time': 1896.3792967796326, 'accumulated_logging_time': 0.5998821258544922, 'global_step': 13670, 'preemption_count': 0}), (14642, {'train/accuracy': 0.6482780612244898, 'train/loss': 1.5432155375577965, 'validation/accuracy': 0.59948, 'validation/loss': 1.76803859375, 'validation/num_examples': 50000, 'test/accuracy': 0.45, 'test/loss': 2.5557091796875, 'test/num_examples': 10000, 'score': 9779.372640132904, 'total_duration': 11821.986961841583, 'accumulated_submission_time': 9779.372640132904, 'accumulated_eval_time': 1979.8489379882812, 'accumulated_logging_time': 0.665999174118042, 'global_step': 14642, 'preemption_count': 0}), (15434, {'train/accuracy': 0.6485172193877551, 'train/loss': 1.5096701797173948, 'validation/accuracy': 0.59996, 'validation/loss': 1.7494190625, 'validation/num_examples': 50000, 'test/accuracy': 0.4629, 'test/loss': 2.474128515625, 'test/num_examples': 10000, 'score': 10288.00061416626, 'total_duration': 12416.597063779831, 'accumulated_submission_time': 10288.00061416626, 'accumulated_eval_time': 2062.576160430908, 'accumulated_logging_time': 0.6855707168579102, 'global_step': 15434, 'preemption_count': 0}), (16190, {'train/accuracy': 0.6552335778061225, 'train/loss': 1.4798185387436225, 'validation/accuracy': 0.60214, 'validation/loss': 1.7157496875, 'validation/num_examples': 50000, 'test/accuracy': 0.4691, 'test/loss': 2.4246767578125, 'test/num_examples': 10000, 'score': 10796.242122650146, 'total_duration': 13010.649475812912, 'accumulated_submission_time': 10796.242122650146, 'accumulated_eval_time': 2145.1582510471344, 'accumulated_logging_time': 0.7050795555114746, 'global_step': 16190, 'preemption_count': 0}), (17169, {'train/accuracy': 0.6622887436224489, 'train/loss': 1.4655115555743783, 'validation/accuracy': 0.6116, 'validation/loss': 1.69697125, 'validation/num_examples': 50000, 'test/accuracy': 0.4684, 'test/loss': 2.482653125, 'test/num_examples': 10000, 'score': 11304.382072210312, 'total_duration': 13603.126015901566, 'accumulated_submission_time': 11304.382072210312, 'accumulated_eval_time': 2226.0283443927765, 'accumulated_logging_time': 0.8276746273040771, 'global_step': 17169, 'preemption_count': 0}), (17958, {'train/accuracy': 0.6540377869897959, 'train/loss': 1.519357019541215, 'validation/accuracy': 0.60116, 'validation/loss': 1.76038296875, 'validation/num_examples': 50000, 'test/accuracy': 0.4509, 'test/loss': 2.5470642578125, 'test/num_examples': 10000, 'score': 11812.686482429504, 'total_duration': 14196.939190387726, 'accumulated_submission_time': 11812.686482429504, 'accumulated_eval_time': 2308.2878658771515, 'accumulated_logging_time': 0.8636391162872314, 'global_step': 17958, 'preemption_count': 0}), (18690, {'train/accuracy': 0.6618104272959183, 'train/loss': 1.4921854758749202, 'validation/accuracy': 0.60656, 'validation/loss': 1.737459375, 'validation/num_examples': 50000, 'test/accuracy': 0.4587, 'test/loss': 2.51851328125, 'test/num_examples': 10000, 'score': 12321.603185415268, 'total_duration': 14792.121434926987, 'accumulated_submission_time': 12321.603185415268, 'accumulated_eval_time': 2391.3504645824432, 'accumulated_logging_time': 0.8848352432250977, 'global_step': 18690, 'preemption_count': 0}), (19648, {'train/accuracy': 0.6584821428571429, 'train/loss': 1.4843502433932558, 'validation/accuracy': 0.60516, 'validation/loss': 1.7232921875, 'validation/num_examples': 50000, 'test/accuracy': 0.464, 'test/loss': 2.4990232421875, 'test/num_examples': 10000, 'score': 12831.057042837143, 'total_duration': 15386.98199224472, 'accumulated_submission_time': 12831.057042837143, 'accumulated_eval_time': 2473.3185799121857, 'accumulated_logging_time': 0.9682323932647705, 'global_step': 19648, 'preemption_count': 0}), (20422, {'train/accuracy': 0.6583824936224489, 'train/loss': 1.4949622640804368, 'validation/accuracy': 0.60388, 'validation/loss': 1.73942078125, 'validation/num_examples': 50000, 'test/accuracy': 0.4627, 'test/loss': 2.5099642578125, 'test/num_examples': 10000, 'score': 13339.496413469315, 'total_duration': 15980.42686533928, 'accumulated_submission_time': 13339.496413469315, 'accumulated_eval_time': 2555.0610501766205, 'accumulated_logging_time': 0.9875450134277344, 'global_step': 20422, 'preemption_count': 0}), (21180, {'train/accuracy': 0.6651985012755102, 'train/loss': 1.4406674443459024, 'validation/accuracy': 0.61306, 'validation/loss': 1.69074859375, 'validation/num_examples': 50000, 'test/accuracy': 0.4702, 'test/loss': 2.4636744140625, 'test/num_examples': 10000, 'score': 13847.956590414047, 'total_duration': 16574.753980398178, 'accumulated_submission_time': 13847.956590414047, 'accumulated_eval_time': 2637.7575104236603, 'accumulated_logging_time': 1.006631851196289, 'global_step': 21180, 'preemption_count': 0}), (22118, {'train/accuracy': 0.6575055803571429, 'train/loss': 1.491804940359933, 'validation/accuracy': 0.60544, 'validation/loss': 1.73799515625, 'validation/num_examples': 50000, 'test/accuracy': 0.4586, 'test/loss': 2.5184923828125, 'test/num_examples': 10000, 'score': 14356.709750652313, 'total_duration': 17168.658967494965, 'accumulated_submission_time': 14356.709750652313, 'accumulated_eval_time': 2719.505704164505, 'accumulated_logging_time': 1.0749948024749756, 'global_step': 22118, 'preemption_count': 0}), (22877, {'train/accuracy': 0.6690051020408163, 'train/loss': 1.4153140321069835, 'validation/accuracy': 0.61778, 'validation/loss': 1.65129203125, 'validation/num_examples': 50000, 'test/accuracy': 0.4819, 'test/loss': 2.4001310546875, 'test/num_examples': 10000, 'score': 14865.333568572998, 'total_duration': 17765.699872016907, 'accumulated_submission_time': 14865.333568572998, 'accumulated_eval_time': 2804.6072981357574, 'accumulated_logging_time': 1.1302120685577393, 'global_step': 22877, 'preemption_count': 0}), (23648, {'train/accuracy': 0.6658561862244898, 'train/loss': 1.4655758604711415, 'validation/accuracy': 0.61444, 'validation/loss': 1.69396390625, 'validation/num_examples': 50000, 'test/accuracy': 0.47, 'test/loss': 2.4852849609375, 'test/num_examples': 10000, 'score': 15375.455873250961, 'total_duration': 18362.134083271027, 'accumulated_submission_time': 15375.455873250961, 'accumulated_eval_time': 2887.6139566898346, 'accumulated_logging_time': 1.17726731300354, 'global_step': 23648, 'preemption_count': 0}), (24570, {'train/accuracy': 0.671516262755102, 'train/loss': 1.3860895585040658, 'validation/accuracy': 0.61844, 'validation/loss': 1.62911296875, 'validation/num_examples': 50000, 'test/accuracy': 0.4714, 'test/loss': 2.41489765625, 'test/num_examples': 10000, 'score': 15884.773327350616, 'total_duration': 18957.359013795853, 'accumulated_submission_time': 15884.773327350616, 'accumulated_eval_time': 2970.1142847537994, 'accumulated_logging_time': 1.2386932373046875, 'global_step': 24570, 'preemption_count': 0}), (25262, {'train/accuracy': 0.6739078443877551, 'train/loss': 1.4024239364935427, 'validation/accuracy': 0.62012, 'validation/loss': 1.649681875, 'validation/num_examples': 50000, 'test/accuracy': 0.4814, 'test/loss': 2.384304296875, 'test/num_examples': 10000, 'score': 16393.414318561554, 'total_duration': 19551.45368695259, 'accumulated_submission_time': 16393.414318561554, 'accumulated_eval_time': 3052.3468840122223, 'accumulated_logging_time': 1.279970407485962, 'global_step': 25262, 'preemption_count': 0}), (26085, {'train/accuracy': 0.6746452487244898, 'train/loss': 1.3851776123046875, 'validation/accuracy': 0.61556, 'validation/loss': 1.6445059375, 'validation/num_examples': 50000, 'test/accuracy': 0.4892, 'test/loss': 2.33088359375, 'test/num_examples': 10000, 'score': 16901.973237752914, 'total_duration': 20149.239444971085, 'accumulated_submission_time': 16901.973237752914, 'accumulated_eval_time': 3138.316793203354, 'accumulated_logging_time': 1.3203949928283691, 'global_step': 26085, 'preemption_count': 0}), (26978, {'train/accuracy': 0.6806640625, 'train/loss': 1.3638934699856504, 'validation/accuracy': 0.6257, 'validation/loss': 1.6159971875, 'validation/num_examples': 50000, 'test/accuracy': 0.489, 'test/loss': 2.339446484375, 'test/num_examples': 10000, 'score': 17411.281683683395, 'total_duration': 20743.750941991806, 'accumulated_submission_time': 17411.281683683395, 'accumulated_eval_time': 3220.1760029792786, 'accumulated_logging_time': 1.3773982524871826, 'global_step': 26978, 'preemption_count': 0}), (27638, {'train/accuracy': 0.6592992665816326, 'train/loss': 1.4719546571069835, 'validation/accuracy': 0.60788, 'validation/loss': 1.7058434375, 'validation/num_examples': 50000, 'test/accuracy': 0.4549, 'test/loss': 2.553552734375, 'test/num_examples': 10000, 'score': 17919.73151087761, 'total_duration': 21339.31384921074, 'accumulated_submission_time': 17919.73151087761, 'accumulated_eval_time': 3304.074120759964, 'accumulated_logging_time': 1.3972454071044922, 'global_step': 27638, 'preemption_count': 0}), (28535, {'train/accuracy': 0.6733697385204082, 'train/loss': 1.4034285253408003, 'validation/accuracy': 0.61962, 'validation/loss': 1.6477103125, 'validation/num_examples': 50000, 'test/accuracy': 0.4775, 'test/loss': 2.4441453125, 'test/num_examples': 10000, 'score': 18427.966715097427, 'total_duration': 21934.905863523483, 'accumulated_submission_time': 18427.966715097427, 'accumulated_eval_time': 3388.0296330451965, 'accumulated_logging_time': 1.4611072540283203, 'global_step': 28535, 'preemption_count': 0}), (29420, {'train/accuracy': 0.6741669323979592, 'train/loss': 1.4036005759725765, 'validation/accuracy': 0.61848, 'validation/loss': 1.64650765625, 'validation/num_examples': 50000, 'test/accuracy': 0.4705, 'test/loss': 2.435341015625, 'test/num_examples': 10000, 'score': 18936.553476333618, 'total_duration': 22528.17417573929, 'accumulated_submission_time': 18936.553476333618, 'accumulated_eval_time': 3469.2712552547455, 'accumulated_logging_time': 1.5221326351165771, 'global_step': 29420, 'preemption_count': 0}), (30112, {'train/accuracy': 0.6864835778061225, 'train/loss': 1.3688983527981504, 'validation/accuracy': 0.63362, 'validation/loss': 1.6107109375, 'validation/num_examples': 50000, 'test/accuracy': 0.4937, 'test/loss': 2.3251962890625, 'test/num_examples': 10000, 'score': 19444.809466838837, 'total_duration': 23122.474955797195, 'accumulated_submission_time': 19444.809466838837, 'accumulated_eval_time': 3552.093462228775, 'accumulated_logging_time': 1.5438423156738281, 'global_step': 30112, 'preemption_count': 0}), (31049, {'train/accuracy': 0.678352200255102, 'train/loss': 1.3651959166234853, 'validation/accuracy': 0.62532, 'validation/loss': 1.61416890625, 'validation/num_examples': 50000, 'test/accuracy': 0.4928, 'test/loss': 2.3249451171875, 'test/num_examples': 10000, 'score': 19955.038588047028, 'total_duration': 23721.04411172867, 'accumulated_submission_time': 19955.038588047028, 'accumulated_eval_time': 3637.0048472881317, 'accumulated_logging_time': 1.6243822574615479, 'global_step': 31049, 'preemption_count': 0}), (31941, {'train/accuracy': 0.6797672193877551, 'train/loss': 1.3584562029157365, 'validation/accuracy': 0.6256, 'validation/loss': 1.60840359375, 'validation/num_examples': 50000, 'test/accuracy': 0.4923, 'test/loss': 2.286796875, 'test/num_examples': 10000, 'score': 20463.305315732956, 'total_duration': 24315.14782857895, 'accumulated_submission_time': 20463.305315732956, 'accumulated_eval_time': 3719.4422886371613, 'accumulated_logging_time': 1.729114055633545, 'global_step': 31941, 'preemption_count': 0}), (32651, {'train/accuracy': 0.6852877869897959, 'train/loss': 1.3629454009386959, 'validation/accuracy': 0.62848, 'validation/loss': 1.61762765625, 'validation/num_examples': 50000, 'test/accuracy': 0.4883, 'test/loss': 2.3384326171875, 'test/num_examples': 10000, 'score': 20971.90588283539, 'total_duration': 24912.91662287712, 'accumulated_submission_time': 20971.90588283539, 'accumulated_eval_time': 3805.427412033081, 'accumulated_logging_time': 1.7495570182800293, 'global_step': 32651, 'preemption_count': 0}), (33564, {'train/accuracy': 0.6807437818877551, 'train/loss': 1.3970400751853476, 'validation/accuracy': 0.62672, 'validation/loss': 1.64211703125, 'validation/num_examples': 50000, 'test/accuracy': 0.4946, 'test/loss': 2.355875390625, 'test/num_examples': 10000, 'score': 21481.290788173676, 'total_duration': 25510.803968906403, 'accumulated_submission_time': 21481.290788173676, 'accumulated_eval_time': 3890.509779691696, 'accumulated_logging_time': 1.8141224384307861, 'global_step': 33564, 'preemption_count': 0}), (34444, {'train/accuracy': 0.6874003507653061, 'train/loss': 1.355239401058275, 'validation/accuracy': 0.62932, 'validation/loss': 1.613869375, 'validation/num_examples': 50000, 'test/accuracy': 0.4886, 'test/loss': 2.36275390625, 'test/num_examples': 10000, 'score': 21990.251036643982, 'total_duration': 26104.246784687042, 'accumulated_submission_time': 21990.251036643982, 'accumulated_eval_time': 3971.574115037918, 'accumulated_logging_time': 1.923140287399292, 'global_step': 34444, 'preemption_count': 0}), (35113, {'train/accuracy': 0.6856465242346939, 'train/loss': 1.3333506681481186, 'validation/accuracy': 0.63072, 'validation/loss': 1.59338953125, 'validation/num_examples': 50000, 'test/accuracy': 0.4856, 'test/loss': 2.378709765625, 'test/num_examples': 10000, 'score': 22498.79735827446, 'total_duration': 26697.330793380737, 'accumulated_submission_time': 22498.79735827446, 'accumulated_eval_time': 4052.8564648628235, 'accumulated_logging_time': 1.9428296089172363, 'global_step': 35113, 'preemption_count': 0}), (36045, {'train/accuracy': 0.688835299744898, 'train/loss': 1.3443827726403061, 'validation/accuracy': 0.63008, 'validation/loss': 1.5989709375, 'validation/num_examples': 50000, 'test/accuracy': 0.4947, 'test/loss': 2.34717421875, 'test/num_examples': 10000, 'score': 23008.64829659462, 'total_duration': 27296.66603755951, 'accumulated_submission_time': 23008.64829659462, 'accumulated_eval_time': 4138.999138593674, 'accumulated_logging_time': 1.99222731590271, 'global_step': 36045, 'preemption_count': 0}), (36952, {'train/accuracy': 0.6915457589285714, 'train/loss': 1.3276015301139987, 'validation/accuracy': 0.63266, 'validation/loss': 1.58546359375, 'validation/num_examples': 50000, 'test/accuracy': 0.504, 'test/loss': 2.30903125, 'test/num_examples': 10000, 'score': 23516.921560287476, 'total_duration': 27889.767565011978, 'accumulated_submission_time': 23516.921560287476, 'accumulated_eval_time': 4220.4147255420685, 'accumulated_logging_time': 2.0806312561035156, 'global_step': 36952, 'preemption_count': 0}), (37721, {'train/accuracy': 0.6964485012755102, 'train/loss': 1.308468565648916, 'validation/accuracy': 0.64022, 'validation/loss': 1.56357234375, 'validation/num_examples': 50000, 'test/accuracy': 0.4962, 'test/loss': 2.322283203125, 'test/num_examples': 10000, 'score': 24025.191588640213, 'total_duration': 28482.878329515457, 'accumulated_submission_time': 24025.191588640213, 'accumulated_eval_time': 4301.986670970917, 'accumulated_logging_time': 2.1012399196624756, 'global_step': 37721, 'preemption_count': 0}), (38634, {'train/accuracy': 0.6850884885204082, 'train/loss': 1.3487955210160236, 'validation/accuracy': 0.63268, 'validation/loss': 1.6061584375, 'validation/num_examples': 50000, 'test/accuracy': 0.4964, 'test/loss': 2.3268537109375, 'test/num_examples': 10000, 'score': 24535.890243530273, 'total_duration': 29079.47523522377, 'accumulated_submission_time': 24535.890243530273, 'accumulated_eval_time': 4384.604499578476, 'accumulated_logging_time': 2.1294875144958496, 'global_step': 38634, 'preemption_count': 0}), (39489, {'train/accuracy': 0.6890345982142857, 'train/loss': 1.3699955842932876, 'validation/accuracy': 0.63466, 'validation/loss': 1.61291859375, 'validation/num_examples': 50000, 'test/accuracy': 0.4879, 'test/loss': 2.393735546875, 'test/num_examples': 10000, 'score': 25044.58056783676, 'total_duration': 29678.187004327774, 'accumulated_submission_time': 25044.58056783676, 'accumulated_eval_time': 4471.1994071006775, 'accumulated_logging_time': 2.2348995208740234, 'global_step': 39489, 'preemption_count': 0}), (40022, {'train/accuracy': 0.6891541772959183, 'train/loss': 1.3396358879245058, 'validation/accuracy': 0.63478, 'validation/loss': 1.59013515625, 'validation/num_examples': 50000, 'test/accuracy': 0.4922, 'test/loss': 2.33349609375, 'test/num_examples': 10000, 'score': 25555.04408097267, 'total_duration': 30275.350208997726, 'accumulated_submission_time': 25555.04408097267, 'accumulated_eval_time': 4554.715639829636, 'accumulated_logging_time': 2.264030694961548, 'global_step': 40022, 'preemption_count': 0}), (40944, {'train/accuracy': 0.6881576849489796, 'train/loss': 1.3547979860889667, 'validation/accuracy': 0.63384, 'validation/loss': 1.60105140625, 'validation/num_examples': 50000, 'test/accuracy': 0.4961, 'test/loss': 2.31831171875, 'test/num_examples': 10000, 'score': 26063.302978277206, 'total_duration': 30870.62711238861, 'accumulated_submission_time': 26063.302978277206, 'accumulated_eval_time': 4638.359055519104, 'accumulated_logging_time': 2.2994790077209473, 'global_step': 40944, 'preemption_count': 0}), (41576, {'train/accuracy': 0.6920041454081632, 'train/loss': 1.3322453401526626, 'validation/accuracy': 0.63372, 'validation/loss': 1.593311875, 'validation/num_examples': 50000, 'test/accuracy': 0.4912, 'test/loss': 2.35595546875, 'test/num_examples': 10000, 'score': 26571.651468515396, 'total_duration': 31465.93518781662, 'accumulated_submission_time': 26571.651468515396, 'accumulated_eval_time': 4722.150715351105, 'accumulated_logging_time': 2.3195791244506836, 'global_step': 41576, 'preemption_count': 0}), (42329, {'train/accuracy': 0.6904296875, 'train/loss': 1.3020098939233897, 'validation/accuracy': 0.63494, 'validation/loss': 1.56340140625, 'validation/num_examples': 50000, 'test/accuracy': 0.5011, 'test/loss': 2.2755966796875, 'test/num_examples': 10000, 'score': 27080.823556423187, 'total_duration': 32060.590950012207, 'accumulated_submission_time': 27080.823556423187, 'accumulated_eval_time': 4804.631064891815, 'accumulated_logging_time': 2.341977834701538, 'global_step': 42329, 'preemption_count': 0}), (43099, {'train/accuracy': 0.6950534119897959, 'train/loss': 1.3223820900430485, 'validation/accuracy': 0.63608, 'validation/loss': 1.57451484375, 'validation/num_examples': 50000, 'test/accuracy': 0.4932, 'test/loss': 2.3397646484375, 'test/num_examples': 10000, 'score': 27589.283241033554, 'total_duration': 32654.829916715622, 'accumulated_submission_time': 27589.283241033554, 'accumulated_eval_time': 4887.133038520813, 'accumulated_logging_time': 2.39498233795166, 'global_step': 43099, 'preemption_count': 0}), (43702, {'train/accuracy': 0.6926817602040817, 'train/loss': 1.3233134989835778, 'validation/accuracy': 0.63928, 'validation/loss': 1.57109484375, 'validation/num_examples': 50000, 'test/accuracy': 0.4906, 'test/loss': 2.359754296875, 'test/num_examples': 10000, 'score': 28097.602426290512, 'total_duration': 33251.98486113548, 'accumulated_submission_time': 28097.602426290512, 'accumulated_eval_time': 4972.789545536041, 'accumulated_logging_time': 2.442422866821289, 'global_step': 43702, 'preemption_count': 0}), (44585, {'train/accuracy': 0.6947544642857143, 'train/loss': 1.3269165973274075, 'validation/accuracy': 0.64032, 'validation/loss': 1.57675234375, 'validation/num_examples': 50000, 'test/accuracy': 0.4986, 'test/loss': 2.318326953125, 'test/num_examples': 10000, 'score': 28605.82988333702, 'total_duration': 33847.23049449921, 'accumulated_submission_time': 28605.82988333702, 'accumulated_eval_time': 5056.455642461777, 'accumulated_logging_time': 2.473900318145752, 'global_step': 44585, 'preemption_count': 0}), (45152, {'train/accuracy': 0.6934789540816326, 'train/loss': 1.3474890261280292, 'validation/accuracy': 0.63834, 'validation/loss': 1.59560265625, 'validation/num_examples': 50000, 'test/accuracy': 0.5126, 'test/loss': 2.2796935546875, 'test/num_examples': 10000, 'score': 29114.331090450287, 'total_duration': 34446.1423971653, 'accumulated_submission_time': 29114.331090450287, 'accumulated_eval_time': 5143.6395173072815, 'accumulated_logging_time': 2.52937650680542, 'global_step': 45152, 'preemption_count': 0}), (46009, {'train/accuracy': 0.6949936224489796, 'train/loss': 1.3204870418626435, 'validation/accuracy': 0.6385, 'validation/loss': 1.570214375, 'validation/num_examples': 50000, 'test/accuracy': 0.494, 'test/loss': 2.3302587890625, 'test/num_examples': 10000, 'score': 29623.896772384644, 'total_duration': 35041.99530720711, 'accumulated_submission_time': 29623.896772384644, 'accumulated_eval_time': 5226.617787837982, 'accumulated_logging_time': 2.552734613418579, 'global_step': 46009, 'preemption_count': 0}), (46727, {'train/accuracy': 0.7013512436224489, 'train/loss': 1.2718483282595265, 'validation/accuracy': 0.64738, 'validation/loss': 1.52066984375, 'validation/num_examples': 50000, 'test/accuracy': 0.4989, 'test/loss': 2.28841015625, 'test/num_examples': 10000, 'score': 30132.337628364563, 'total_duration': 35637.88538265228, 'accumulated_submission_time': 30132.337628364563, 'accumulated_eval_time': 5310.9028215408325, 'accumulated_logging_time': 2.573523759841919, 'global_step': 46727, 'preemption_count': 0}), (47408, {'train/accuracy': 0.7011320153061225, 'train/loss': 1.2789909985600685, 'validation/accuracy': 0.64502, 'validation/loss': 1.53536671875, 'validation/num_examples': 50000, 'test/accuracy': 0.5112, 'test/loss': 2.242773828125, 'test/num_examples': 10000, 'score': 30640.819804906845, 'total_duration': 36234.985122442245, 'accumulated_submission_time': 30640.819804906845, 'accumulated_eval_time': 5396.364427804947, 'accumulated_logging_time': 2.596203565597534, 'global_step': 47408, 'preemption_count': 0}), (48281, {'train/accuracy': 0.7013512436224489, 'train/loss': 1.2728276155432876, 'validation/accuracy': 0.64494, 'validation/loss': 1.53436859375, 'validation/num_examples': 50000, 'test/accuracy': 0.4959, 'test/loss': 2.314810546875, 'test/num_examples': 10000, 'score': 31149.621018648148, 'total_duration': 36831.800587415695, 'accumulated_submission_time': 31149.621018648148, 'accumulated_eval_time': 5481.156617641449, 'accumulated_logging_time': 2.6183712482452393, 'global_step': 48281, 'preemption_count': 0}), (48855, {'train/accuracy': 0.7067123724489796, 'train/loss': 1.265186543367347, 'validation/accuracy': 0.64464, 'validation/loss': 1.532821875, 'validation/num_examples': 50000, 'test/accuracy': 0.5049, 'test/loss': 2.2889099609375, 'test/num_examples': 10000, 'score': 31658.200715780258, 'total_duration': 37426.592134952545, 'accumulated_submission_time': 31658.200715780258, 'accumulated_eval_time': 5564.189346075058, 'accumulated_logging_time': 2.654761791229248, 'global_step': 48855, 'preemption_count': 0}), (49734, {'train/accuracy': 0.701530612244898, 'train/loss': 1.2733942927146444, 'validation/accuracy': 0.6424, 'validation/loss': 1.53053546875, 'validation/num_examples': 50000, 'test/accuracy': 0.4987, 'test/loss': 2.2962619140625, 'test/num_examples': 10000, 'score': 32166.89771413803, 'total_duration': 38024.01919770241, 'accumulated_submission_time': 32166.89771413803, 'accumulated_eval_time': 5649.483825683594, 'accumulated_logging_time': 2.7815165519714355, 'global_step': 49734, 'preemption_count': 0}), (50433, {'train/accuracy': 0.6997369260204082, 'train/loss': 1.2800029832489637, 'validation/accuracy': 0.63878, 'validation/loss': 1.54580671875, 'validation/num_examples': 50000, 'test/accuracy': 0.4905, 'test/loss': 2.3201140625, 'test/num_examples': 10000, 'score': 32675.964158058167, 'total_duration': 38617.49009370804, 'accumulated_submission_time': 32675.964158058167, 'accumulated_eval_time': 5730.675276041031, 'accumulated_logging_time': 2.802506446838379, 'global_step': 50433, 'preemption_count': 0}), (51122, {'train/accuracy': 0.6997568558673469, 'train/loss': 1.2789593910684391, 'validation/accuracy': 0.6435, 'validation/loss': 1.53534515625, 'validation/num_examples': 50000, 'test/accuracy': 0.4936, 'test/loss': 2.330698046875, 'test/num_examples': 10000, 'score': 33184.933522224426, 'total_duration': 39214.88474702835, 'accumulated_submission_time': 33184.933522224426, 'accumulated_eval_time': 5816.024139881134, 'accumulated_logging_time': 2.823922634124756, 'global_step': 51122, 'preemption_count': 0}), (51937, {'train/accuracy': 0.7055165816326531, 'train/loss': 1.2928052629743303, 'validation/accuracy': 0.64582, 'validation/loss': 1.5554403125, 'validation/num_examples': 50000, 'test/accuracy': 0.5038, 'test/loss': 2.285869921875, 'test/num_examples': 10000, 'score': 33693.35483407974, 'total_duration': 39807.18305802345, 'accumulated_submission_time': 33693.35483407974, 'accumulated_eval_time': 5896.5889773368835, 'accumulated_logging_time': 2.8711163997650146, 'global_step': 51937, 'preemption_count': 0}), (52508, {'train/accuracy': 0.7051578443877551, 'train/loss': 1.2889626172124122, 'validation/accuracy': 0.65116, 'validation/loss': 1.53724640625, 'validation/num_examples': 50000, 'test/accuracy': 0.5003, 'test/loss': 2.2980623046875, 'test/num_examples': 10000, 'score': 34203.778401613235, 'total_duration': 40402.19411468506, 'accumulated_submission_time': 34203.778401613235, 'accumulated_eval_time': 5978.093372344971, 'accumulated_logging_time': 2.8946285247802734, 'global_step': 52508, 'preemption_count': 0}), (53426, {'train/accuracy': 0.7006337691326531, 'train/loss': 1.2613734809719785, 'validation/accuracy': 0.64462, 'validation/loss': 1.525243125, 'validation/num_examples': 50000, 'test/accuracy': 0.4908, 'test/loss': 2.3604181640625, 'test/num_examples': 10000, 'score': 34712.752076625824, 'total_duration': 40999.956553697586, 'accumulated_submission_time': 34712.752076625824, 'accumulated_eval_time': 6063.508281946182, 'accumulated_logging_time': 2.916703701019287, 'global_step': 53426, 'preemption_count': 0}), (54053, {'train/accuracy': 0.7034040178571429, 'train/loss': 1.2637934782067124, 'validation/accuracy': 0.6467, 'validation/loss': 1.523490625, 'validation/num_examples': 50000, 'test/accuracy': 0.5066, 'test/loss': 2.2428193359375, 'test/num_examples': 10000, 'score': 35221.14172554016, 'total_duration': 41594.647466897964, 'accumulated_submission_time': 35221.14172554016, 'accumulated_eval_time': 6146.607708930969, 'accumulated_logging_time': 2.949971914291382, 'global_step': 54053, 'preemption_count': 0}), (54808, {'train/accuracy': 0.7016900510204082, 'train/loss': 1.267437526157924, 'validation/accuracy': 0.64724, 'validation/loss': 1.52143203125, 'validation/num_examples': 50000, 'test/accuracy': 0.5113, 'test/loss': 2.234728125, 'test/num_examples': 10000, 'score': 35729.69034075737, 'total_duration': 42188.700650930405, 'accumulated_submission_time': 35729.69034075737, 'accumulated_eval_time': 6228.848843574524, 'accumulated_logging_time': 2.9707067012786865, 'global_step': 54808, 'preemption_count': 0}), (55523, {'train/accuracy': 0.7069316007653061, 'train/loss': 1.2379281958755182, 'validation/accuracy': 0.6486, 'validation/loss': 1.50573875, 'validation/num_examples': 50000, 'test/accuracy': 0.5109, 'test/loss': 2.23178828125, 'test/num_examples': 10000, 'score': 36237.95554924011, 'total_duration': 42785.523360967636, 'accumulated_submission_time': 36237.95554924011, 'accumulated_eval_time': 6314.152548074722, 'accumulated_logging_time': 2.9940292835235596, 'global_step': 55523, 'preemption_count': 0}), (56174, {'train/accuracy': 0.7084462691326531, 'train/loss': 1.2465013776506697, 'validation/accuracy': 0.65206, 'validation/loss': 1.500938125, 'validation/num_examples': 50000, 'test/accuracy': 0.5136, 'test/loss': 2.2177478515625, 'test/num_examples': 10000, 'score': 36748.33333277702, 'total_duration': 43385.30722618103, 'accumulated_submission_time': 36748.33333277702, 'accumulated_eval_time': 6400.425736427307, 'accumulated_logging_time': 3.016570568084717, 'global_step': 56174, 'preemption_count': 0}), (56996, {'train/accuracy': 0.7062141262755102, 'train/loss': 1.2647301810128349, 'validation/accuracy': 0.65076, 'validation/loss': 1.51984359375, 'validation/num_examples': 50000, 'test/accuracy': 0.5163, 'test/loss': 2.215312890625, 'test/num_examples': 10000, 'score': 37257.34295105934, 'total_duration': 43980.618228673935, 'accumulated_submission_time': 37257.34295105934, 'accumulated_eval_time': 6483.461329936981, 'accumulated_logging_time': 3.057614803314209, 'global_step': 56996, 'preemption_count': 0}), (57516, {'train/accuracy': 0.7096420599489796, 'train/loss': 1.220824961759606, 'validation/accuracy': 0.6505, 'validation/loss': 1.4827403125, 'validation/num_examples': 50000, 'test/accuracy': 0.5087, 'test/loss': 2.231934765625, 'test/num_examples': 10000, 'score': 37767.87645936012, 'total_duration': 44576.273723363876, 'accumulated_submission_time': 37767.87645936012, 'accumulated_eval_time': 6565.597932100296, 'accumulated_logging_time': 3.080190658569336, 'global_step': 57516, 'preemption_count': 0}), (58414, {'train/accuracy': 0.7120934311224489, 'train/loss': 1.2360346268634408, 'validation/accuracy': 0.65078, 'validation/loss': 1.49999328125, 'validation/num_examples': 50000, 'test/accuracy': 0.5071, 'test/loss': 2.24968046875, 'test/num_examples': 10000, 'score': 38276.70531630516, 'total_duration': 45172.52254104614, 'accumulated_submission_time': 38276.70531630516, 'accumulated_eval_time': 6649.708341121674, 'accumulated_logging_time': 3.1047346591949463, 'global_step': 58414, 'preemption_count': 0}), (58959, {'train/accuracy': 0.7127311862244898, 'train/loss': 1.2345099157216597, 'validation/accuracy': 0.65426, 'validation/loss': 1.4932846875, 'validation/num_examples': 50000, 'test/accuracy': 0.5109, 'test/loss': 2.2365220703125, 'test/num_examples': 10000, 'score': 38785.326404333115, 'total_duration': 45766.33331346512, 'accumulated_submission_time': 38785.326404333115, 'accumulated_eval_time': 6731.758955955505, 'accumulated_logging_time': 3.1468679904937744, 'global_step': 58959, 'preemption_count': 0}), (59763, {'train/accuracy': 0.7087053571428571, 'train/loss': 1.2237974672901386, 'validation/accuracy': 0.65432, 'validation/loss': 1.48363859375, 'validation/num_examples': 50000, 'test/accuracy': 0.5043, 'test/loss': 2.2560705078125, 'test/num_examples': 10000, 'score': 39293.56871891022, 'total_duration': 46361.94702863693, 'accumulated_submission_time': 39293.56871891022, 'accumulated_eval_time': 6815.85239481926, 'accumulated_logging_time': 3.2348477840423584, 'global_step': 59763, 'preemption_count': 0}), (60438, {'train/accuracy': 0.7117346938775511, 'train/loss': 1.2678451538085938, 'validation/accuracy': 0.65184, 'validation/loss': 1.52717, 'validation/num_examples': 50000, 'test/accuracy': 0.5045, 'test/loss': 2.2869333984375, 'test/num_examples': 10000, 'score': 39802.022525548935, 'total_duration': 46956.676550388336, 'accumulated_submission_time': 39802.022525548935, 'accumulated_eval_time': 6898.993069648743, 'accumulated_logging_time': 3.2570090293884277, 'global_step': 60438, 'preemption_count': 0}), (61109, {'train/accuracy': 0.7092833227040817, 'train/loss': 1.2191109949228716, 'validation/accuracy': 0.6518, 'validation/loss': 1.47699421875, 'validation/num_examples': 50000, 'test/accuracy': 0.5143, 'test/loss': 2.211365234375, 'test/num_examples': 10000, 'score': 40311.039259672165, 'total_duration': 47551.87667512894, 'accumulated_submission_time': 40311.039259672165, 'accumulated_eval_time': 6982.025435209274, 'accumulated_logging_time': 3.278946876525879, 'global_step': 61109, 'preemption_count': 0}), (61877, {'train/accuracy': 0.7141661352040817, 'train/loss': 1.2124247648278061, 'validation/accuracy': 0.65618, 'validation/loss': 1.47055890625, 'validation/num_examples': 50000, 'test/accuracy': 0.5137, 'test/loss': 2.234994140625, 'test/num_examples': 10000, 'score': 40819.30630207062, 'total_duration': 48145.32156562805, 'accumulated_submission_time': 40819.30630207062, 'accumulated_eval_time': 7063.975959300995, 'accumulated_logging_time': 3.3349969387054443, 'global_step': 61877, 'preemption_count': 0}), (62464, {'train/accuracy': 0.7159199617346939, 'train/loss': 1.234815636459662, 'validation/accuracy': 0.65628, 'validation/loss': 1.4917134375, 'validation/num_examples': 50000, 'test/accuracy': 0.5191, 'test/loss': 2.20691171875, 'test/num_examples': 10000, 'score': 41330.762298583984, 'total_duration': 48743.985662698746, 'accumulated_submission_time': 41330.762298583984, 'accumulated_eval_time': 7148.159294843674, 'accumulated_logging_time': 3.3580777645111084, 'global_step': 62464, 'preemption_count': 0}), (63319, {'train/accuracy': 0.7158601721938775, 'train/loss': 1.2112908655283403, 'validation/accuracy': 0.65568, 'validation/loss': 1.47890265625, 'validation/num_examples': 50000, 'test/accuracy': 0.5134, 'test/loss': 2.2055341796875, 'test/num_examples': 10000, 'score': 41838.974670410156, 'total_duration': 49340.342596292496, 'accumulated_submission_time': 41838.974670410156, 'accumulated_eval_time': 7233.008470535278, 'accumulated_logging_time': 3.4035189151763916, 'global_step': 63319, 'preemption_count': 0}), (63851, {'train/accuracy': 0.7207629145408163, 'train/loss': 1.1780605705416933, 'validation/accuracy': 0.66104, 'validation/loss': 1.450574375, 'validation/num_examples': 50000, 'test/accuracy': 0.5163, 'test/loss': 2.178109375, 'test/num_examples': 10000, 'score': 42347.35860490799, 'total_duration': 49937.38713812828, 'accumulated_submission_time': 42347.35860490799, 'accumulated_eval_time': 7318.519927740097, 'accumulated_logging_time': 3.4447102546691895, 'global_step': 63851, 'preemption_count': 0}), (64747, {'train/accuracy': 0.7133091517857143, 'train/loss': 1.2202630334970903, 'validation/accuracy': 0.65482, 'validation/loss': 1.47939890625, 'validation/num_examples': 50000, 'test/accuracy': 0.518, 'test/loss': 2.22474609375, 'test/num_examples': 10000, 'score': 42857.53965830803, 'total_duration': 50533.38950061798, 'accumulated_submission_time': 42857.53965830803, 'accumulated_eval_time': 7400.979984760284, 'accumulated_logging_time': 3.475900173187256, 'global_step': 64747, 'preemption_count': 0}), (65453, {'train/accuracy': 0.7150629783163265, 'train/loss': 1.207449465381856, 'validation/accuracy': 0.65474, 'validation/loss': 1.474636875, 'validation/num_examples': 50000, 'test/accuracy': 0.505, 'test/loss': 2.2606927734375, 'test/num_examples': 10000, 'score': 43366.16034245491, 'total_duration': 51126.622086286545, 'accumulated_submission_time': 43366.16034245491, 'accumulated_eval_time': 7482.360347032547, 'accumulated_logging_time': 3.4989326000213623, 'global_step': 65453, 'preemption_count': 0}), (66154, {'train/accuracy': 0.7200454400510204, 'train/loss': 1.190682313880142, 'validation/accuracy': 0.66042, 'validation/loss': 1.46196109375, 'validation/num_examples': 50000, 'test/accuracy': 0.5002, 'test/loss': 2.2681267578125, 'test/num_examples': 10000, 'score': 43875.106061697006, 'total_duration': 51723.634266614914, 'accumulated_submission_time': 43875.106061697006, 'accumulated_eval_time': 7567.194854259491, 'accumulated_logging_time': 3.577467441558838, 'global_step': 66154, 'preemption_count': 0}), (66989, {'train/accuracy': 0.7206433354591837, 'train/loss': 1.209070244613959, 'validation/accuracy': 0.658, 'validation/loss': 1.47588515625, 'validation/num_examples': 50000, 'test/accuracy': 0.5233, 'test/loss': 2.1896888671875, 'test/num_examples': 10000, 'score': 44383.981123924255, 'total_duration': 52318.10220742226, 'accumulated_submission_time': 44383.981123924255, 'accumulated_eval_time': 7649.465146303177, 'accumulated_logging_time': 3.6563150882720947, 'global_step': 66989, 'preemption_count': 0}), (67544, {'train/accuracy': 0.7171755420918368, 'train/loss': 1.2283884165238361, 'validation/accuracy': 0.6589, 'validation/loss': 1.49220640625, 'validation/num_examples': 50000, 'test/accuracy': 0.5184, 'test/loss': 2.197039453125, 'test/num_examples': 10000, 'score': 44894.59243321419, 'total_duration': 52915.15306520462, 'accumulated_submission_time': 44894.59243321419, 'accumulated_eval_time': 7732.893217086792, 'accumulated_logging_time': 3.67891263961792, 'global_step': 67544, 'preemption_count': 0}), (68472, {'train/accuracy': 0.7207828443877551, 'train/loss': 1.1943201337541853, 'validation/accuracy': 0.66336, 'validation/loss': 1.45896, 'validation/num_examples': 50000, 'test/accuracy': 0.5182, 'test/loss': 2.1856201171875, 'test/num_examples': 10000, 'score': 45404.28679513931, 'total_duration': 53509.958396434784, 'accumulated_submission_time': 45404.28679513931, 'accumulated_eval_time': 7814.631432771683, 'accumulated_logging_time': 3.7049484252929688, 'global_step': 68472, 'preemption_count': 0}), (69142, {'train/accuracy': 0.7199258609693877, 'train/loss': 1.2027572320432078, 'validation/accuracy': 0.66066, 'validation/loss': 1.4657025, 'validation/num_examples': 50000, 'test/accuracy': 0.5269, 'test/loss': 2.1647068359375, 'test/num_examples': 10000, 'score': 45912.74379658699, 'total_duration': 54104.5572142601, 'accumulated_submission_time': 45912.74379658699, 'accumulated_eval_time': 7897.585689544678, 'accumulated_logging_time': 3.7597742080688477, 'global_step': 69142, 'preemption_count': 0}), (69870, {'train/accuracy': 0.7203244579081632, 'train/loss': 1.2011448607152821, 'validation/accuracy': 0.6613, 'validation/loss': 1.4698909375, 'validation/num_examples': 50000, 'test/accuracy': 0.5269, 'test/loss': 2.1602671875, 'test/num_examples': 10000, 'score': 46423.102276325226, 'total_duration': 54702.96055459976, 'accumulated_submission_time': 46423.102276325226, 'accumulated_eval_time': 7982.482862710953, 'accumulated_logging_time': 3.7842493057250977, 'global_step': 69870, 'preemption_count': 0}), (70677, {'train/accuracy': 0.7213010204081632, 'train/loss': 1.2086920446279097, 'validation/accuracy': 0.65936, 'validation/loss': 1.48050296875, 'validation/num_examples': 50000, 'test/accuracy': 0.5307, 'test/loss': 2.1915640625, 'test/num_examples': 10000, 'score': 46931.74700522423, 'total_duration': 55296.64708280563, 'accumulated_submission_time': 46931.74700522423, 'accumulated_eval_time': 8064.418690919876, 'accumulated_logging_time': 3.8264362812042236, 'global_step': 70677, 'preemption_count': 0}), (71258, {'train/accuracy': 0.7253069196428571, 'train/loss': 1.2024669257961973, 'validation/accuracy': 0.66298, 'validation/loss': 1.46953625, 'validation/num_examples': 50000, 'test/accuracy': 0.516, 'test/loss': 2.2214126953125, 'test/num_examples': 10000, 'score': 47440.93011593819, 'total_duration': 55892.59451508522, 'accumulated_submission_time': 47440.93011593819, 'accumulated_eval_time': 8148.182408571243, 'accumulated_logging_time': 3.849593162536621, 'global_step': 71258, 'preemption_count': 0}), (72151, {'train/accuracy': 0.72265625, 'train/loss': 1.1691789432447783, 'validation/accuracy': 0.66532, 'validation/loss': 1.43427140625, 'validation/num_examples': 50000, 'test/accuracy': 0.5153, 'test/loss': 2.1909419921875, 'test/num_examples': 10000, 'score': 47950.82408952713, 'total_duration': 56488.42675757408, 'accumulated_submission_time': 47950.82408952713, 'accumulated_eval_time': 8230.84866642952, 'accumulated_logging_time': 3.9192569255828857, 'global_step': 72151, 'preemption_count': 0}), (72724, {'train/accuracy': 0.7241111288265306, 'train/loss': 1.168430250518176, 'validation/accuracy': 0.6661, 'validation/loss': 1.43794109375, 'validation/num_examples': 50000, 'test/accuracy': 0.5206, 'test/loss': 2.1732333984375, 'test/num_examples': 10000, 'score': 48459.23122668266, 'total_duration': 57083.28226470947, 'accumulated_submission_time': 48459.23122668266, 'accumulated_eval_time': 8314.257390499115, 'accumulated_logging_time': 3.943392753601074, 'global_step': 72724, 'preemption_count': 0}), (73546, {'train/accuracy': 0.7293128188775511, 'train/loss': 1.168064039580676, 'validation/accuracy': 0.66598, 'validation/loss': 1.4319275, 'validation/num_examples': 50000, 'test/accuracy': 0.5292, 'test/loss': 2.14775546875, 'test/num_examples': 10000, 'score': 48967.48728680611, 'total_duration': 57680.42510342598, 'accumulated_submission_time': 48967.48728680611, 'accumulated_eval_time': 8399.849638223648, 'accumulated_logging_time': 3.9691107273101807, 'global_step': 73546, 'preemption_count': 0}), (74256, {'train/accuracy': 0.7254264987244898, 'train/loss': 1.1579697278081154, 'validation/accuracy': 0.66444, 'validation/loss': 1.4339928125, 'validation/num_examples': 50000, 'test/accuracy': 0.5221, 'test/loss': 2.16555859375, 'test/num_examples': 10000, 'score': 49475.98159766197, 'total_duration': 58274.26638174057, 'accumulated_submission_time': 49475.98159766197, 'accumulated_eval_time': 8481.880017995834, 'accumulated_logging_time': 4.024603366851807, 'global_step': 74256, 'preemption_count': 0}), (74934, {'train/accuracy': 0.7279376594387755, 'train/loss': 1.165647234235491, 'validation/accuracy': 0.66722, 'validation/loss': 1.43492359375, 'validation/num_examples': 50000, 'test/accuracy': 0.526, 'test/loss': 2.1681359375, 'test/num_examples': 10000, 'score': 49987.51103448868, 'total_duration': 58871.49873876572, 'accumulated_submission_time': 49987.51103448868, 'accumulated_eval_time': 8564.38474726677, 'accumulated_logging_time': 4.048052072525024, 'global_step': 74934, 'preemption_count': 0}), (75814, {'train/accuracy': 0.7279177295918368, 'train/loss': 1.152340013153699, 'validation/accuracy': 0.665, 'validation/loss': 1.425348125, 'validation/num_examples': 50000, 'test/accuracy': 0.5269, 'test/loss': 2.152031640625, 'test/num_examples': 10000, 'score': 50496.71258020401, 'total_duration': 59467.77874803543, 'accumulated_submission_time': 50496.71258020401, 'accumulated_eval_time': 8648.132372617722, 'accumulated_logging_time': 4.130701303482056, 'global_step': 75814, 'preemption_count': 0}), (76403, {'train/accuracy': 0.7302096619897959, 'train/loss': 1.1504916755520567, 'validation/accuracy': 0.6665, 'validation/loss': 1.42945203125, 'validation/num_examples': 50000, 'test/accuracy': 0.5286, 'test/loss': 2.1464814453125, 'test/num_examples': 10000, 'score': 51005.145414829254, 'total_duration': 60060.58256268501, 'accumulated_submission_time': 51005.145414829254, 'accumulated_eval_time': 8729.42970919609, 'accumulated_logging_time': 4.154285430908203, 'global_step': 76403, 'preemption_count': 0}), (77275, {'train/accuracy': 0.7359295280612245, 'train/loss': 1.144264843999123, 'validation/accuracy': 0.66968, 'validation/loss': 1.42166921875, 'validation/num_examples': 50000, 'test/accuracy': 0.5371, 'test/loss': 2.1184205078125, 'test/num_examples': 10000, 'score': 51514.329228401184, 'total_duration': 60657.14725494385, 'accumulated_submission_time': 51514.329228401184, 'accumulated_eval_time': 8813.569814920425, 'accumulated_logging_time': 4.18924617767334, 'global_step': 77275, 'preemption_count': 0}), (77989, {'train/accuracy': 0.7320830676020408, 'train/loss': 1.1567711343570632, 'validation/accuracy': 0.66918, 'validation/loss': 1.4316978125, 'validation/num_examples': 50000, 'test/accuracy': 0.5279, 'test/loss': 2.1532314453125, 'test/num_examples': 10000, 'score': 52023.54143500328, 'total_duration': 61255.53750371933, 'accumulated_submission_time': 52023.54143500328, 'accumulated_eval_time': 8899.52939915657, 'accumulated_logging_time': 4.213721036911011, 'global_step': 77989, 'preemption_count': 0}), (78682, {'train/accuracy': 0.7290537308673469, 'train/loss': 1.166353498186384, 'validation/accuracy': 0.6645, 'validation/loss': 1.45264375, 'validation/num_examples': 50000, 'test/accuracy': 0.5272, 'test/loss': 2.164565234375, 'test/num_examples': 10000, 'score': 52534.36103606224, 'total_duration': 61856.89600300789, 'accumulated_submission_time': 52534.36103606224, 'accumulated_eval_time': 8986.823298931122, 'accumulated_logging_time': 4.252779006958008, 'global_step': 78682, 'preemption_count': 0}), (79538, {'train/accuracy': 0.7294921875, 'train/loss': 1.1655089709223534, 'validation/accuracy': 0.6679, 'validation/loss': 1.43180796875, 'validation/num_examples': 50000, 'test/accuracy': 0.53, 'test/loss': 2.1438255859375, 'test/num_examples': 10000, 'score': 53044.14259839058, 'total_duration': 62451.18703389168, 'accumulated_submission_time': 53044.14259839058, 'accumulated_eval_time': 9068.010221004486, 'accumulated_logging_time': 4.304200649261475, 'global_step': 79538, 'preemption_count': 0}), (80103, {'train/accuracy': 0.7372249681122449, 'train/loss': 1.1262428127989477, 'validation/accuracy': 0.67254, 'validation/loss': 1.41023625, 'validation/num_examples': 50000, 'test/accuracy': 0.5257, 'test/loss': 2.186287890625, 'test/num_examples': 10000, 'score': 53552.53848481178, 'total_duration': 63043.277514219284, 'accumulated_submission_time': 53552.53848481178, 'accumulated_eval_time': 9148.577735900879, 'accumulated_logging_time': 4.328479290008545, 'global_step': 80103, 'preemption_count': 0}), (81004, {'train/accuracy': 0.7324019451530612, 'train/loss': 1.1490134414361448, 'validation/accuracy': 0.66834, 'validation/loss': 1.4198365625, 'validation/num_examples': 50000, 'test/accuracy': 0.5314, 'test/loss': 2.1351291015625, 'test/num_examples': 10000, 'score': 54061.34584903717, 'total_duration': 63641.193791627884, 'accumulated_submission_time': 54061.34584903717, 'accumulated_eval_time': 9234.318907260895, 'accumulated_logging_time': 4.352547645568848, 'global_step': 81004, 'preemption_count': 0}), (81699, {'train/accuracy': 0.7374441964285714, 'train/loss': 1.146372347461934, 'validation/accuracy': 0.6734, 'validation/loss': 1.42878046875, 'validation/num_examples': 50000, 'test/accuracy': 0.525, 'test/loss': 2.1849322265625, 'test/num_examples': 10000, 'score': 54569.937517404556, 'total_duration': 64236.31839132309, 'accumulated_submission_time': 54569.937517404556, 'accumulated_eval_time': 9317.571401834488, 'accumulated_logging_time': 4.37550950050354, 'global_step': 81699, 'preemption_count': 0}), (82400, {'train/accuracy': 0.7351522640306123, 'train/loss': 1.1377310460927534, 'validation/accuracy': 0.67246, 'validation/loss': 1.4116525, 'validation/num_examples': 50000, 'test/accuracy': 0.5287, 'test/loss': 2.136186328125, 'test/num_examples': 10000, 'score': 55078.86093878746, 'total_duration': 64829.86259293556, 'accumulated_submission_time': 55078.86093878746, 'accumulated_eval_time': 9399.05182647705, 'accumulated_logging_time': 4.40130090713501, 'global_step': 82400, 'preemption_count': 0}), (83223, {'train/accuracy': 0.7354312818877551, 'train/loss': 1.1312315804617745, 'validation/accuracy': 0.6718, 'validation/loss': 1.4063953125, 'validation/num_examples': 50000, 'test/accuracy': 0.5235, 'test/loss': 2.161065234375, 'test/num_examples': 10000, 'score': 55587.125921964645, 'total_duration': 65424.52487397194, 'accumulated_submission_time': 55587.125921964645, 'accumulated_eval_time': 9482.202495098114, 'accumulated_logging_time': 4.469343900680542, 'global_step': 83223, 'preemption_count': 0}), (83783, {'train/accuracy': 0.7375637755102041, 'train/loss': 1.1349696723782285, 'validation/accuracy': 0.67372, 'validation/loss': 1.408754375, 'validation/num_examples': 50000, 'test/accuracy': 0.5332, 'test/loss': 2.1365162109375, 'test/num_examples': 10000, 'score': 56096.533638715744, 'total_duration': 66021.32094955444, 'accumulated_submission_time': 56096.533638715744, 'accumulated_eval_time': 9566.538491487503, 'accumulated_logging_time': 4.49404501914978, 'global_step': 83783, 'preemption_count': 0}), (84679, {'train/accuracy': 0.7368662308673469, 'train/loss': 1.1448959039182078, 'validation/accuracy': 0.67358, 'validation/loss': 1.4160428125, 'validation/num_examples': 50000, 'test/accuracy': 0.5348, 'test/loss': 2.130053125, 'test/num_examples': 10000, 'score': 56605.275490522385, 'total_duration': 66617.70872426033, 'accumulated_submission_time': 56605.275490522385, 'accumulated_eval_time': 9650.821912765503, 'accumulated_logging_time': 4.535937309265137, 'global_step': 84679, 'preemption_count': 0}), (85292, {'train/accuracy': 0.7377032844387755, 'train/loss': 1.1125252392827247, 'validation/accuracy': 0.673, 'validation/loss': 1.3987025, 'validation/num_examples': 50000, 'test/accuracy': 0.5373, 'test/loss': 2.13135546875, 'test/num_examples': 10000, 'score': 57113.57889294624, 'total_duration': 67213.10175418854, 'accumulated_submission_time': 57113.57889294624, 'accumulated_eval_time': 9734.687460899353, 'accumulated_logging_time': 4.560203313827515, 'global_step': 85292, 'preemption_count': 0}), (86085, {'train/accuracy': 0.7426857461734694, 'train/loss': 1.0879968137157208, 'validation/accuracy': 0.67492, 'validation/loss': 1.381520625, 'validation/num_examples': 50000, 'test/accuracy': 0.5334, 'test/loss': 2.1185513671875, 'test/num_examples': 10000, 'score': 57621.69284462929, 'total_duration': 67807.7510817051, 'accumulated_submission_time': 57621.69284462929, 'accumulated_eval_time': 9817.849631786346, 'accumulated_logging_time': 4.709585428237915, 'global_step': 86085, 'preemption_count': 0}), (86852, {'train/accuracy': 0.7383808992346939, 'train/loss': 1.1203781439333547, 'validation/accuracy': 0.67462, 'validation/loss': 1.40338828125, 'validation/num_examples': 50000, 'test/accuracy': 0.5402, 'test/loss': 2.1200390625, 'test/num_examples': 10000, 'score': 58131.24727368355, 'total_duration': 68403.43524837494, 'accumulated_submission_time': 58131.24727368355, 'accumulated_eval_time': 9900.949953079224, 'accumulated_logging_time': 4.732925176620483, 'global_step': 86852, 'preemption_count': 0}), (87476, {'train/accuracy': 0.7399354272959183, 'train/loss': 1.105907985142299, 'validation/accuracy': 0.67508, 'validation/loss': 1.39549578125, 'validation/num_examples': 50000, 'test/accuracy': 0.5426, 'test/loss': 2.088252734375, 'test/num_examples': 10000, 'score': 58639.83200573921, 'total_duration': 69001.07234811783, 'accumulated_submission_time': 58639.83200573921, 'accumulated_eval_time': 9986.761648893356, 'accumulated_logging_time': 4.772420167922974, 'global_step': 87476, 'preemption_count': 0}), (88355, {'train/accuracy': 0.7403539540816326, 'train/loss': 1.107699102284957, 'validation/accuracy': 0.67128, 'validation/loss': 1.40183953125, 'validation/num_examples': 50000, 'test/accuracy': 0.5295, 'test/loss': 2.1400732421875, 'test/num_examples': 10000, 'score': 59148.98277449608, 'total_duration': 69598.70450377464, 'accumulated_submission_time': 59148.98277449608, 'accumulated_eval_time': 10071.867470741272, 'accumulated_logging_time': 4.82051682472229, 'global_step': 88355, 'preemption_count': 0}), (88913, {'train/accuracy': 0.7424864477040817, 'train/loss': 1.1005235788773517, 'validation/accuracy': 0.67894, 'validation/loss': 1.386843125, 'validation/num_examples': 50000, 'test/accuracy': 0.532, 'test/loss': 2.13635234375, 'test/num_examples': 10000, 'score': 59657.546358823776, 'total_duration': 70194.86119008064, 'accumulated_submission_time': 59657.546358823776, 'accumulated_eval_time': 10156.270891904831, 'accumulated_logging_time': 4.844162940979004, 'global_step': 88913, 'preemption_count': 0}), (89771, {'train/accuracy': 0.7431042729591837, 'train/loss': 1.10569716473015, 'validation/accuracy': 0.67926, 'validation/loss': 1.3861578125, 'validation/num_examples': 50000, 'test/accuracy': 0.5284, 'test/loss': 2.1365501953125, 'test/num_examples': 10000, 'score': 60166.10707426071, 'total_duration': 70792.60007667542, 'accumulated_submission_time': 60166.10707426071, 'accumulated_eval_time': 10242.127782583237, 'accumulated_logging_time': 4.8688905239105225, 'global_step': 89771, 'preemption_count': 0}), (90469, {'train/accuracy': 0.7473094706632653, 'train/loss': 1.0688446200623805, 'validation/accuracy': 0.6831, 'validation/loss': 1.35883796875, 'validation/num_examples': 50000, 'test/accuracy': 0.5424, 'test/loss': 2.073463671875, 'test/num_examples': 10000, 'score': 60674.54400587082, 'total_duration': 71390.5445921421, 'accumulated_submission_time': 60674.54400587082, 'accumulated_eval_time': 10328.397015571594, 'accumulated_logging_time': 4.923119783401489, 'global_step': 90469, 'preemption_count': 0}), (91161, {'train/accuracy': 0.7457948022959183, 'train/loss': 1.0893924479581871, 'validation/accuracy': 0.68064, 'validation/loss': 1.375835, 'validation/num_examples': 50000, 'test/accuracy': 0.5331, 'test/loss': 2.1308126953125, 'test/num_examples': 10000, 'score': 61184.44985413551, 'total_duration': 71987.46764397621, 'accumulated_submission_time': 61184.44985413551, 'accumulated_eval_time': 10412.129774093628, 'accumulated_logging_time': 4.979798316955566, 'global_step': 91161, 'preemption_count': 0}), (91990, {'train/accuracy': 0.7428252551020408, 'train/loss': 1.1219055798588966, 'validation/accuracy': 0.67614, 'validation/loss': 1.4035309375, 'validation/num_examples': 50000, 'test/accuracy': 0.5379, 'test/loss': 2.12730625, 'test/num_examples': 10000, 'score': 61692.72982621193, 'total_duration': 72584.4151673317, 'accumulated_submission_time': 61692.72982621193, 'accumulated_eval_time': 10497.527377605438, 'accumulated_logging_time': 5.0058434009552, 'global_step': 91990, 'preemption_count': 0}), (92540, {'train/accuracy': 0.7511160714285714, 'train/loss': 1.06484097850566, 'validation/accuracy': 0.68572, 'validation/loss': 1.3553953125, 'validation/num_examples': 50000, 'test/accuracy': 0.5437, 'test/loss': 2.0608046875, 'test/num_examples': 10000, 'score': 62202.637932777405, 'total_duration': 73180.24644589424, 'accumulated_submission_time': 62202.637932777405, 'accumulated_eval_time': 10580.307527303696, 'accumulated_logging_time': 5.0704851150512695, 'global_step': 92540, 'preemption_count': 0}), (93441, {'train/accuracy': 0.7488839285714286, 'train/loss': 1.0686646286322146, 'validation/accuracy': 0.68662, 'validation/loss': 1.355295, 'validation/num_examples': 50000, 'test/accuracy': 0.5489, 'test/loss': 2.059588671875, 'test/num_examples': 10000, 'score': 62711.84440636635, 'total_duration': 73776.39730525017, 'accumulated_submission_time': 62711.84440636635, 'accumulated_eval_time': 10663.91672039032, 'accumulated_logging_time': 5.095800161361694, 'global_step': 93441, 'preemption_count': 0}), (94047, {'train/accuracy': 0.751335299744898, 'train/loss': 1.059067239566725, 'validation/accuracy': 0.6851, 'validation/loss': 1.353528125, 'validation/num_examples': 50000, 'test/accuracy': 0.5453, 'test/loss': 2.0648248046875, 'test/num_examples': 10000, 'score': 63220.12459754944, 'total_duration': 74370.24567198753, 'accumulated_submission_time': 63220.12459754944, 'accumulated_eval_time': 10746.276811122894, 'accumulated_logging_time': 5.142218589782715, 'global_step': 94047, 'preemption_count': 0}), (94824, {'train/accuracy': 0.7490632971938775, 'train/loss': 1.0800945515535316, 'validation/accuracy': 0.68394, 'validation/loss': 1.3590675, 'validation/num_examples': 50000, 'test/accuracy': 0.5415, 'test/loss': 2.08815703125, 'test/num_examples': 10000, 'score': 63728.687324762344, 'total_duration': 74967.12325668335, 'accumulated_submission_time': 63728.687324762344, 'accumulated_eval_time': 10831.576718330383, 'accumulated_logging_time': 5.167607307434082, 'global_step': 94824, 'preemption_count': 0}), (95545, {'train/accuracy': 0.7544842155612245, 'train/loss': 1.0518299024932238, 'validation/accuracy': 0.68718, 'validation/loss': 1.3448165625, 'validation/num_examples': 50000, 'test/accuracy': 0.5464, 'test/loss': 2.0757708984375, 'test/num_examples': 10000, 'score': 64237.145743370056, 'total_duration': 75561.1342754364, 'accumulated_submission_time': 64237.145743370056, 'accumulated_eval_time': 10913.942085266113, 'accumulated_logging_time': 5.193201541900635, 'global_step': 95545, 'preemption_count': 0}), (96190, {'train/accuracy': 0.7528898278061225, 'train/loss': 1.0538078619509328, 'validation/accuracy': 0.68706, 'validation/loss': 1.344794375, 'validation/num_examples': 50000, 'test/accuracy': 0.5444, 'test/loss': 2.0666994140625, 'test/num_examples': 10000, 'score': 64745.536230802536, 'total_duration': 76155.59070944786, 'accumulated_submission_time': 64745.536230802536, 'accumulated_eval_time': 10996.86277127266, 'accumulated_logging_time': 5.259819507598877, 'global_step': 96190, 'preemption_count': 0}), (97043, {'train/accuracy': 0.7540856186224489, 'train/loss': 1.0565681457519531, 'validation/accuracy': 0.687, 'validation/loss': 1.349326875, 'validation/num_examples': 50000, 'test/accuracy': 0.5447, 'test/loss': 2.06528828125, 'test/num_examples': 10000, 'score': 65254.06753754616, 'total_duration': 76748.31371331215, 'accumulated_submission_time': 65254.06753754616, 'accumulated_eval_time': 11077.966226100922, 'accumulated_logging_time': 5.284224987030029, 'global_step': 97043, 'preemption_count': 0}), (97577, {'train/accuracy': 0.7568160076530612, 'train/loss': 1.056412054567921, 'validation/accuracy': 0.69102, 'validation/loss': 1.34594578125, 'validation/num_examples': 50000, 'test/accuracy': 0.5563, 'test/loss': 2.042258203125, 'test/num_examples': 10000, 'score': 65762.61107516289, 'total_duration': 77345.9350373745, 'accumulated_submission_time': 65762.61107516289, 'accumulated_eval_time': 11164.087461233139, 'accumulated_logging_time': 5.352982759475708, 'global_step': 97577, 'preemption_count': 0})], 'global_step': 98479}
I0315 19:15:48.351555 140498825811136 submission_runner.py:649] Timing: 66271.57811379433
I0315 19:15:48.351604 140498825811136 submission_runner.py:651] Total number of evals: 130
I0315 19:15:48.351639 140498825811136 submission_runner.py:652] ====================
I0315 19:15:48.351927 140498825811136 submission_runner.py:750] Final imagenet_resnet score: 2
