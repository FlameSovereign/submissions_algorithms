torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=imagenet_resnet --submission_path=submissions_algorithms/leaderboard/external_tuning/shampoo_submission/submission.py --data_dir=/data/imagenet/pytorch --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/external_tuning/shampoo/study_2 --overwrite=True --save_checkpoints=False --rng_seed=-1065354048 --imagenet_v2_data_dir=/data/imagenet/pytorch --torch_compile=true --tuning_ruleset=external --tuning_search_space=submissions_algorithms/leaderboard/external_tuning/shampoo_submission/tuning_search_space.json --num_tuning_trials=5 --hparam_start_index=2 --hparam_end_index=3 2>&1 | tee -a /logs/imagenet_resnet_pytorch_03-14-2025-21-37-37.log
W0314 21:37:38.863000 9 site-packages/torch/distributed/run.py:793] 
W0314 21:37:38.863000 9 site-packages/torch/distributed/run.py:793] *****************************************
W0314 21:37:38.863000 9 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0314 21:37:38.863000 9 site-packages/torch/distributed/run.py:793] *****************************************
2025-03-14 21:37:39.866230: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-14 21:37:39.866227: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-14 21:37:39.866260: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-14 21:37:39.866237: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-14 21:37:39.866227: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-14 21:37:39.866248: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-14 21:37:39.866227: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-14 21:37:39.866414: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741988259.887217      51 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741988259.887214      46 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741988259.887216      50 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741988259.887214      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741988259.887217      45 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741988259.887218      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741988259.887240      49 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741988259.887811      44 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741988259.893526      45 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1741988259.893531      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1741988259.893531      49 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1741988259.893541      50 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1741988259.893556      51 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1741988259.893562      46 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1741988259.893561      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1741988259.894276      44 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
[rank0]:[W314 21:37:48.151518092 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank1]:[W314 21:37:48.481683769 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank5]:[W314 21:37:48.483768344 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank3]:[W314 21:37:48.502333844 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank7]:[W314 21:37:48.531298004 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank4]:[W314 21:37:48.540473549 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank6]:[W314 21:37:48.549536872 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank2]:[W314 21:37:48.556954022 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
I0314 21:37:50.309031 139732128158912 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch.
I0314 21:37:50.309034 139878978585792 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch.
I0314 21:37:50.309035 139756371608768 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch.
I0314 21:37:50.309034 139925059253440 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch.
I0314 21:37:50.309032 140664408499392 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch.
I0314 21:37:50.309052 140053993235648 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch.
I0314 21:37:50.309048 139887263319232 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch.
I0314 21:37:50.309140 140585381643456 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch.
I0314 21:37:50.393889 139925059253440 submission_runner.py:606] Using RNG seed -1065354048
I0314 21:37:50.394767 139732128158912 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:50.395357 139925059253440 submission_runner.py:615] --- Tuning run 3/5 ---
I0314 21:37:50.395486 139925059253440 submission_runner.py:620] Creating tuning directory at /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch/trial_3.
I0314 21:37:50.395468 140585381643456 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:50.395740 139925059253440 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:50.395978 139878978585792 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:50.396060 140053993235648 logger_utils.py:97] Saving hparams to /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:50.396285 139756371608768 logger_utils.py:91] Loading hparams from /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:50.396697 139887263319232 logger_utils.py:91] Loading hparams from /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:50.397424 140664408499392 logger_utils.py:91] Loading hparams from /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch/trial_3/hparams.json.
I0314 21:37:50.730502 139925059253440 submission_runner.py:218] Initializing dataset.
I0314 21:38:04.148265 139925059253440 submission_runner.py:229] Initializing model.
I0314 21:38:04.650034 139925059253440 submission_runner.py:268] Performing `torch.compile`.
I0314 21:38:05.627648 139925059253440 submission_runner.py:272] Initializing optimizer.
W0314 21:38:05.631809 139925059253440 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
W0314 21:38:05.631814 140664408499392 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
I0314 21:38:05.638381 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
W0314 21:38:05.638356 139878978585792 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
I0314 21:38:05.638593 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([0])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.638741 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([0])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.638897 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:05.639026 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([0])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.639128 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([0])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.639066 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
I0314 21:38:05.639257 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.639287 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([0])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.639363 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([0])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.639441 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([0])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.639470 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([0])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.639586 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.639682 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([0])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.639733 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([64, 64]), torch.Size([64, 64])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:05.639895 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([0])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.639898 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([256, 256])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.640022 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([0])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.640047 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.640163 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([0])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.640174 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.640260 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([0])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.640292 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([0])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.640382 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.640393 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([0])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.640509 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.640540 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([64, 64])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.640615 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([0])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.640651 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([0])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.640715 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([0])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.640836 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.640848 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([64, 64]), torch.Size([576, 576])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.640979 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([0])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.641010 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([256, 256])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.641077 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([0])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.641126 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([0])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.641206 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.641251 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.641358 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([0])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.641302 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([0])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.641454 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([0])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.641516 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([0])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.641576 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.641651 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.641746 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([0])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.641839 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([0])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.641968 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.642442 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([64, 64])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.642591 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([0])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.642741 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.642799 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([64, 64])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.642944 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([0])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.643074 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.643179 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([0])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.643337 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([256, 256])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.643476 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:05.643572 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([0])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.643666 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([0])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.643812 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.643924 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([0])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.644021 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([0])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
W0314 21:38:05.644057 139887263319232 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
I0314 21:38:05.644169 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.644262 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([0])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.644356 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([0])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.644489 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:05.644582 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([0])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.644673 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([0])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.644791 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.642838 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([0])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.644893 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([0])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.644985 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([0])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.645043 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([0])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.645129 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.645190 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.645222 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([0])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.645291 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([0])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.645313 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([0])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.645388 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([0])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.645432 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.645521 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.645524 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([0])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.645608 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([0])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.645625 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([0])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.645713 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([0])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.645736 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.645836 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.645912 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([128, 128])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.645946 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([0])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.646024 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([0])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.646044 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([0])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.646169 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.646262 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([0])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.646278 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([128, 128]), torch.Size([256, 256])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:05.646353 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([0])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.646306 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([192, 192]), torch.Size([49, 49])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
I0314 21:38:05.646443 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([128, 128])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.646471 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.646554 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([0])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.646560 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([0])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.646545 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([0])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.646684 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([0])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.646704 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.646792 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([0])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.646851 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:05.646963 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([128, 128])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
W0314 21:38:05.646918 139732128158912 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
I0314 21:38:05.647057 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([64, 64])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.647106 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.647135 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([512, 512])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.647201 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([0])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.647293 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.647337 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.647449 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([0])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.647562 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([0])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.647690 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.647679 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([512, 512])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.647787 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([0])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.647808 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([0])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.647881 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([0])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.648012 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.648109 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([0])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.648239 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([0])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.648461 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([512, 512]), torch.Size([256, 256])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:05.648594 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([0])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.648885 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([64, 64]), torch.Size([256, 256])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.649044 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([0])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.649152 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([512, 512])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.649209 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([64, 64])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.649315 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.649352 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.649371 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([0])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.649417 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([0])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.649450 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([0])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.649504 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([0])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.649554 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([0])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.649560 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([0])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.649662 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.649683 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.649714 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.649761 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([0])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.649854 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([0])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.649883 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([128, 128])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.649986 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.650010 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([0])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.650083 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([0])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.650141 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.650182 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([0])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.650238 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([0])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.650329 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([0])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.650448 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:05.650539 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([0])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.650630 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([0])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.650784 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.650878 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([0])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.650895 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([128, 128]), torch.Size([512, 512])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.650982 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([0])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.651028 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([0])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.651100 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.651192 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([0])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.651192 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([128, 128])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.651284 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([0])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.651247 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
I0314 21:38:05.651352 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.651396 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([0])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.651404 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.651450 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([0])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.651489 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([0])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.651529 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([0])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.651546 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([0])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.651580 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([0])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.651664 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.651685 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:05.651705 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.649779 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([0])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.651759 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([0])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.651803 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([0])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.651804 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([0])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.651852 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([0])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.651904 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([0])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.651961 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([256, 256])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.651973 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([256, 256])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.651990 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.652023 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.652149 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([0])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.652144 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.652155 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.652182 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([0])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.652242 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([0])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.652247 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([0])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.652251 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([0])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.652298 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([0])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.652336 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([0])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.652344 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([0])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.652353 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.652433 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([0])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.652444 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.652461 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.652462 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.652524 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([0])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.652537 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([0])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.652559 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([0])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.652608 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([1024, 1024])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.652690 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([128, 128])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.652716 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([0])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.652721 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([64, 64])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.652752 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([256, 256]), torch.Size([64, 64])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.652827 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.652839 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.652852 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.652864 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([0])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.652935 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([0])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.652944 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([0])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.652963 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([0])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.653026 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([0])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.653051 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.653060 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([0])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.653127 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([0])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.653167 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.653180 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:05.653210 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([0])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.653260 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([0])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.653265 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([0])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.653315 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.653353 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([0])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.653398 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([0])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.653384 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([512, 512])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.653424 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([256, 256])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.653480 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([0])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.653502 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([0])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.653517 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.653549 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.653534 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
I0314 21:38:05.653591 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.653609 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([0])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.653617 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:05.653647 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([0])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.653695 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([0])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.653686 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([0])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.653738 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([0])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.653814 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.653819 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([0])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.653848 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.653908 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([0])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.653942 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([0])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.653952 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:05.654026 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([0])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.654023 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([0])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.654046 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([0])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.654140 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([0])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.654147 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:05.654149 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([256, 256])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.654173 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.654259 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.654263 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([0])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.654337 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([0])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.654358 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([0])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.654410 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.654435 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([0])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.654513 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([0])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.654528 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([64, 64])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.654552 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.654606 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([0])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.654649 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.654731 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.654757 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([512, 512])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.654798 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([256, 256])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.654829 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([0])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.654888 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([0])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.654892 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([0])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.654928 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([0])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.653665 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([0])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.654998 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.655023 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.655048 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.655082 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([0])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.655075 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([0])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.655113 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([0])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.655133 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([0])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.655155 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([0])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.655152 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([1024, 1024])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.655201 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.655217 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([0])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.655223 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([0])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.655258 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.655265 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([0])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.655289 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([0])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.655325 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.655338 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([0])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.655366 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([0])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.655375 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.655379 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.655411 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([0])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.655426 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([0])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.655464 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.655463 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([0])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.655504 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.655513 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([0])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.655532 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([128, 128])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.655555 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([0])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.655580 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([0])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.655631 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([0])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.655644 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([0])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.655652 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([0])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.655656 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.655759 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.655759 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.655810 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([256, 256])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.655846 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([0])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.655944 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([0])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.656038 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([256, 256])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.656069 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.656175 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([0])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.656269 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.656278 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([0])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.656373 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([0])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.656403 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.656439 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([256, 256]), torch.Size([64, 64])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.656466 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([0])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.656489 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([0])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.656489 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([512, 512])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.656572 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([0])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.656559 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([0])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.656581 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.656661 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([0])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.656667 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([0])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.656673 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.656715 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.656751 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([0])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.656765 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([0])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.656799 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:05.656800 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([0])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.656865 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([0])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.656894 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([0])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.656901 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([0])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.656974 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([0])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.656981 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([256, 256]), torch.Size([1024, 1024])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.657020 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.657028 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.657087 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([0])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.657117 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([0])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.657174 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([1024, 1024])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.657183 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([0])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.657202 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([0])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.657209 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([128, 128]), torch.Size([384, 384]), torch.Size([3, 3])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.655847 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([0])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.657285 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([0])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.657310 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([0])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.657319 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.657328 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.657399 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.657402 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([0])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.657402 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([0])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.657417 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([0])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.657449 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([0])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.657502 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([0])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.657539 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([256, 256])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.657556 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([256, 256])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.657588 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.657655 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([0])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.657675 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([0])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.657680 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.657802 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.657851 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([64, 64])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.657989 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([0])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.658107 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([0])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.658123 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([512, 512]), torch.Size([128, 128])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.658236 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.658282 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([0])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.658332 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([0])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.658382 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([0])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.658425 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([0])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.658419 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([128, 128]), torch.Size([512, 512])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.658511 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:05.658527 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([1024, 1024])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.658601 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([0])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.658657 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([0])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.658668 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([128, 128])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.658687 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([0])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.658683 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([64, 64]), torch.Size([576, 576])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.658807 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.658818 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.658824 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([0])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.658827 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([0])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.658898 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([0])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.658914 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([0])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.658921 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([0])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.658984 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([0])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.659010 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([0])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.659015 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
W0314 21:38:05.658932 140585381643456 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
I0314 21:38:05.659040 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([256, 256]), torch.Size([1024, 1024])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.659119 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.659156 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([0])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.659152 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([256, 256])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
W0314 21:38:05.659083 139756371608768 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
I0314 21:38:05.659208 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([0])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.659243 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([0])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.659246 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([0])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.659297 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([0])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.659342 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:05.659392 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.659406 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.659427 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([0])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.659489 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([0])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.659500 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([0])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.659516 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([128, 128]), torch.Size([384, 384]), torch.Size([3, 3])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.659571 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([0])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.659617 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.659656 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([0])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.659673 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.659698 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([0])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.659759 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([0])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.659755 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([0])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.659815 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([0])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.659859 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([0])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.659883 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.659933 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.659993 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.660003 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([0])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.659984 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([256, 256])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.660019 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([0])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.660090 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([0])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.660094 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([0])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.660107 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([0])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.660106 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([0])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.660137 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([512, 512]), torch.Size([512, 512]), torch.Size([9, 9])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.660188 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([0])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.660225 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:05.660239 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:05.660269 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.660326 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([0])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.660333 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([0])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.660406 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([0])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.660419 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([0])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.660436 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([1024, 1024])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.660509 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.660551 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([0])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.660567 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.660588 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([0])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
W0314 21:38:05.660524 140053993235648 distributed_shampoo.py:341] start_preconditioning_step set to -1. Setting start_preconditioning_step equal to precondition frequency 100 by default.
I0314 21:38:05.660655 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([0])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.660675 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.660696 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([0])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.660771 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([0])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.660804 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([256, 256])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.660800 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([512, 512])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.660842 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.660868 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([0])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.660930 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([0])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.660931 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([0])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.660927 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([512, 512]), torch.Size([128, 128])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.660971 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.661037 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([0])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.661062 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.661074 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([0])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.661079 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([128, 128])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.661141 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([0])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.661142 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([256, 256]), torch.Size([768, 768]), torch.Size([3, 3])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.661160 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([0])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.661190 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.661198 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.661247 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([0])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.661267 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.661273 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.661279 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([0])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.661288 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.661347 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([0])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.661357 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([0])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.661356 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([0])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.661379 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.661426 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([0])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.661439 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([0])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.661471 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.661478 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.661525 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([0])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.661549 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.661543 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([1024, 1024])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.661566 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([0])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.661567 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([0])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.661644 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.661653 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([0])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.661656 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([0])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.661656 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([0])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.661667 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.661765 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([0])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.661769 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:05.661774 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([0])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.661805 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.661813 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.661848 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([0])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.661890 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([0])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.661896 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:05.661924 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.661931 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([0])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.661977 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.661993 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([0])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.661995 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.662022 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([0])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.662032 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([0])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.662064 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([0])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.662079 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.662095 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.662119 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([0])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.662148 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([0])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.662170 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.662220 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([1024, 1024])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.662240 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.662256 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:05.662266 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([0])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.662327 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([0])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.662330 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.662335 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([0])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.662413 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([0])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.662420 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([0])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.662443 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.662546 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.662557 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.662638 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([0])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.662640 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([0])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.662624 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([512, 512])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.662656 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.662728 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([0])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.662734 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([0])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.662760 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([0])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.662790 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([256, 256])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.662848 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.662855 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([0])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.662867 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.662934 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([0])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.662961 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.662945 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([512, 512])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.663008 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.663018 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([0])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.663028 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([0])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.663059 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([0])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.663093 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.663106 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([0])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.663122 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.663158 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([0])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.663200 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([0])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.663209 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([128, 128])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.663239 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.663284 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([0])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.663303 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.663376 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.663400 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([0])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.663461 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([0])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.663492 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([0])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.663556 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([0])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.663612 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.663669 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.663705 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([0])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.663722 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([512, 512])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.663749 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([0])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.663796 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([0])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.663832 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([0])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.663879 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.663935 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:05.663946 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.664014 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([0])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.664018 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.664092 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([0])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.664104 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.664111 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([0])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.664104 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([256, 256]), torch.Size([1024, 1024])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.664101 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([1024, 1024])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.664214 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.664243 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.664252 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([0])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.664252 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.664328 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([0])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.664339 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([0])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.664343 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.664416 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([0])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.664428 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.664459 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.664540 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:05.664552 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([0])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.664601 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([1024, 1024]), torch.Size([256, 256])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.664629 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([0])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.664700 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([0])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.664727 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.664749 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([1024, 1024]), torch.Size([1024, 1024])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:05.664799 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([0])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.664815 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([0])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.664872 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([256, 256])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.664897 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([0])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.664905 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.664978 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([0])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.665026 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([1024, 1024])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.665057 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([0])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.665126 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([1024, 1024]), torch.Size([256, 256])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.665138 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.665152 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.665246 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([0])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.665253 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.665291 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([256, 256])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.665345 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([0])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.665364 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.665404 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([0])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.665399 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([1024, 1024])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.665448 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([0])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.665474 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.665514 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([256, 256]), torch.Size([1024, 1024])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.665531 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.665537 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.665548 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([0])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.665563 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([0])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.665617 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([0])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.665628 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([0])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.665630 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.665646 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([0])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.665698 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([0])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.665695 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.665705 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([0])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.665728 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.665783 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([0])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.665844 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.665893 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([0])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.665904 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([256, 256]), torch.Size([768, 768]), torch.Size([3, 3])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.665929 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([0])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.666003 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([0])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.666024 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.666029 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([0])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.666118 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([0])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.666142 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.666223 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([0])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.666241 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.666317 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([0])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.666327 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([0])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.666412 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([0])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.666428 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.666441 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([512, 512]), torch.Size([1024, 1024])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.666515 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([0])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.666535 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.666594 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([0])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.666623 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([0])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.666673 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.666719 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.666770 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([256, 256])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.666792 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([0])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.666815 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([1024, 1024]), torch.Size([512, 512])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.666775 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
I0314 21:38:05.666880 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([0])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.666863 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([1024, 1024]), torch.Size([256, 256])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.666909 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([0])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.666845 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
I0314 21:38:05.666941 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.666960 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.666986 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([0])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.666988 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([0])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.666994 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([0])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.667042 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.667065 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.667066 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([0])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.667096 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.667103 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([0])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.667126 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.667132 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([1024, 1024])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.667153 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([0])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.667153 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([0])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.667176 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([0])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.667239 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([0])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.667252 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([0])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.667222 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([64, 64])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.667264 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.667266 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.667258 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([0])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.667348 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([0])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.667350 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([0])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.667354 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.667362 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.667435 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([0])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.667409 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:05.667439 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([0])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.667420 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:05.667431 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([0])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.667474 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.667552 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([0])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.667537 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([0])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.667541 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([0])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.667564 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.667578 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.667650 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([0])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.667636 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([1024, 1024])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.667652 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([0])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.667691 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.667705 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([256, 256])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.667776 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([0])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.667773 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.667790 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:05.667787 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.667815 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([0])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.667857 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([0])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.667912 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([0])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.667916 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:05.667928 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.667960 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.667958 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([64, 64])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.668004 139925059253440 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([0])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:05.668020 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([0])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.668017 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([0])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.668053 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([0])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.668098 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([0])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.668101 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([0])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.668153 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([0])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.668152 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([1024, 1024])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.668183 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.668247 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.668247 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([512, 512])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.668270 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.668281 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([0])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.668272 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.668305 139925059253440 shampoo_preconditioner_list.py:612] Rank 0: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:05.668221 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 0.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 0 (torch.Size([64, 3, 7, 7])), Block block_0 (torch.Size([192, 49])).
I0314 21:38:05.668330 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([0])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.668344 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([0])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.668358 139925059253440 shampoo_preconditioner_list.py:615] Rank 0: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288)
I0314 21:38:05.668371 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([0])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.668380 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.668380 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([0])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.668396 139925059253440 shampoo_preconditioner_list.py:618] Rank 0: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:05.668405 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([0])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.668429 139925059253440 shampoo_preconditioner_list.py:621] Rank 0: ShampooPreconditionerList Total Bytes: 11455240
I0314 21:38:05.668430 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([0])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.668466 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.668502 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.668520 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.668522 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.668551 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.668533 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 1.block_0 ([torch.Size([64, 64])]) for Parameter 1 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.668594 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([0])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.668603 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.668609 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([0])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.668625 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([0])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.668681 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([0])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.668677 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([0])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.668694 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([0])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.668698 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([0])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.668688 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 2.block_0 ([torch.Size([0])]) for Parameter 2 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.668779 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([0])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.668761 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([256, 256]), torch.Size([64, 64])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.668805 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.668812 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.668820 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.668839 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 3.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 3 (torch.Size([64, 64, 1, 1])), Block block_0 (torch.Size([64, 64])).
I0314 21:38:05.668891 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([0])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.668894 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.668903 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([0])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.668921 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([0])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.668990 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([0])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.668989 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([0])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.668983 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 4.block_0 ([torch.Size([0])]) for Parameter 4 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.668999 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([0])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.669009 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([0])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.669116 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.669117 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.669139 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.669162 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 5.block_0 ([torch.Size([64, 64])]) for Parameter 5 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.669205 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([0])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.669204 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([0])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.669226 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([0])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.669209 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([512, 512]), torch.Size([1024, 1024])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.669291 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([0])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.669291 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([0])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.669311 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([0])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.669364 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 6.block_0 ([torch.Size([64, 64]), torch.Size([576, 576])]) for Parameter 6 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.669423 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.669424 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.669443 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.669502 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([0])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.669498 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 7.block_0 ([torch.Size([0])]) for Parameter 7 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.669514 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([0])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.669585 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([0])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.669600 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([0])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.669610 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 8.block_0 ([torch.Size([0])]) for Parameter 8 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.669615 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([1024, 1024])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.669694 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.669711 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.669745 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 9.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 9 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.669762 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.669795 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([0])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.669824 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.669840 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 10.block_0 ([torch.Size([0])]) for Parameter 10 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.669900 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([0])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.669905 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.669903 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([256, 256])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.669938 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 11.block_0 ([torch.Size([0])]) for Parameter 11 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.669960 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([512, 512])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.669990 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.669999 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([0])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.670053 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 12.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 12 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.670073 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.670106 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([0])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.670104 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([1024, 1024]), torch.Size([512, 512])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.670135 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.670146 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.670146 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([256, 256]), torch.Size([64, 64])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.670161 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 13.block_0 ([torch.Size([0])]) for Parameter 13 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.670222 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([0])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.670235 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.670244 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:05.670254 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.670304 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([0])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.670326 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.670340 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([0])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.670359 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:05.670408 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.670430 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.670436 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.670438 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([0])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.670504 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.670507 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([0])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.670523 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.670559 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.670595 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([0])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.670603 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.670666 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.670679 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.670705 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.670791 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([0])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.670762 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 14.block_0 ([torch.Size([256, 256])]) for Parameter 14 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.670800 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.670821 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([1024, 1024])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.670888 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([0])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.670938 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 15.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 15 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.670946 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.670989 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.671024 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.671033 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.671040 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 16.block_0 ([torch.Size([0])]) for Parameter 16 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.671086 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([0])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.671121 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.671128 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 17.block_0 ([torch.Size([0])]) for Parameter 17 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.671139 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([1024, 1024]), torch.Size([1024, 1024])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:05.671162 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([256, 256])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.671173 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([0])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.671230 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:05.671239 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 18.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 18 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.671254 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([0])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.671296 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:05.669533 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([0])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.671314 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.671333 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 19.block_0 ([torch.Size([0])]) for Parameter 19 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.671350 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:05.671385 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.671409 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([0])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.671432 140664408499392 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([0])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:05.671455 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([0])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.671477 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.671490 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([0])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.671501 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 20.block_0 ([torch.Size([64, 64])]) for Parameter 20 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.671597 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.671600 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.671613 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.671680 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 21.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 21 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.671675 139925059253440 submission.py:142] No large parameters detected! Continuing with only Shampoo....
I0314 21:38:05.671704 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.671708 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([0])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.671717 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.671772 140664408499392 shampoo_preconditioner_list.py:612] Rank 4: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:05.671799 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([0])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.671803 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.671798 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([1024, 1024]), torch.Size([256, 256])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.671817 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.671835 140664408499392 shampoo_preconditioner_list.py:615] Rank 4: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768)
I0314 21:38:05.671880 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.671874 140664408499392 shampoo_preconditioner_list.py:618] Rank 4: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:05.671878 139925059253440 submission_runner.py:279] Initializing metrics bundle.
I0314 21:38:05.671917 140664408499392 shampoo_preconditioner_list.py:621] Rank 4: ShampooPreconditionerList Total Bytes: 14830344
I0314 21:38:05.671907 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([0])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.671927 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.671965 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.672023 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.672031 139925059253440 submission_runner.py:301] Initializing checkpoint and logger.
I0314 21:38:05.672034 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([0])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.672047 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.672045 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([1024, 1024])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.672143 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([0])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.672152 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([0])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.672162 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.672186 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.672262 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.670312 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([256, 256])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.672285 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([0])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.672288 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.672344 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([0])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.672380 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([0])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.672407 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([0])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.672424 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([0])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.672478 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([0])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.672475 139925059253440 submission_runner.py:321] Saving meta data to /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch/trial_3/meta_data_0.json.
I0314 21:38:05.672561 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.672616 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:05.672714 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([0])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.672736 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([64, 64])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.672723 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([512, 512])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.672812 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([0])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.672842 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([0])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.672917 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.672970 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.672973 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.673008 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([512, 512])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.673032 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([0])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.673061 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([0])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.673062 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([0])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.673120 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([0])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.673149 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([0])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.673150 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([0])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.673168 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.673244 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([0])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.673242 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.673276 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.673279 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.673324 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([0])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.673354 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.673368 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([0])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.673368 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([0])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.673417 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([512, 512]), torch.Size([512, 512]), torch.Size([9, 9])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.673438 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.673448 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.673465 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([0])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.673468 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([0])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.673532 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.673538 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.673537 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([0])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.673589 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:05.673610 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.673605 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:05.673624 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.673650 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([0])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.671787 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 22.block_0 ([torch.Size([0])]) for Parameter 22 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.673676 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([0])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.673680 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.673695 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([0])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.673709 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.673757 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.673759 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.673769 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([0])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.673783 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([0])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.673809 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 23.block_0 ([torch.Size([0])]) for Parameter 23 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.673860 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.673914 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.673935 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.674008 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.674061 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 24.block_0 ([torch.Size([64, 64]), torch.Size([256, 256])]) for Parameter 24 (torch.Size([64, 256, 1, 1])), Block block_0 (torch.Size([64, 256])).
I0314 21:38:05.674090 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.674080 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([128, 128])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.674173 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.674179 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([0])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.674185 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 25.block_0 ([torch.Size([0])]) for Parameter 25 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.674279 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 26.block_0 ([torch.Size([0])]) for Parameter 26 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.674288 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:05.674290 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.674376 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([0])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.674391 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:05.674404 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 27.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 27 (torch.Size([64, 64, 3, 3])), Block block_0 (torch.Size([64, 576])).
I0314 21:38:05.674466 139887263319232 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([0])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:05.674503 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 28.block_0 ([torch.Size([0])]) for Parameter 28 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.674596 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 29.block_0 ([torch.Size([0])]) for Parameter 29 (torch.Size([64])), Block block_0 (torch.Size([64])).
I0314 21:38:05.674673 139887263319232 shampoo_preconditioner_list.py:612] Rank 2: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:05.674664 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([512, 512]), torch.Size([1024, 1024])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.674721 139887263319232 shampoo_preconditioner_list.py:615] Rank 2: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768)
I0314 21:38:05.674730 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 30.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 30 (torch.Size([256, 64, 1, 1])), Block block_0 (torch.Size([256, 64])).
I0314 21:38:05.674758 139887263319232 shampoo_preconditioner_list.py:618] Rank 2: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:05.674785 139887263319232 shampoo_preconditioner_list.py:621] Rank 2: ShampooPreconditionerList Total Bytes: 3230472
I0314 21:38:05.674778 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([1024, 1024])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.674801 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.674822 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 31.block_0 ([torch.Size([0])]) for Parameter 31 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.674907 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:05.674906 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([0])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.674951 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 32.block_0 ([torch.Size([0])]) for Parameter 32 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.675019 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:05.675021 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([0])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.675087 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 33.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 33 (torch.Size([128, 256, 1, 1])), Block block_0 (torch.Size([128, 256])).
I0314 21:38:05.675101 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.675117 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([128, 128]), torch.Size([512, 512])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.675163 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.675187 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.675198 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 34.block_0 ([torch.Size([0])]) for Parameter 34 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.675197 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([512, 512])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.675250 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([0])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.675255 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([0])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.675272 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.675349 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([0])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.675351 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:05.675351 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 35.block_0 ([torch.Size([128, 128])]) for Parameter 35 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.675401 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([1024, 1024])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.675457 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([0])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.675505 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 36.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 36 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.675513 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.675557 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([0])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.675594 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 37.block_0 ([torch.Size([0])]) for Parameter 37 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.675679 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 38.block_0 ([torch.Size([0])]) for Parameter 38 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.675681 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.675685 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.675777 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([0])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.675777 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([0])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.675805 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 39.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 39 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.675869 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([0])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.675867 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([512, 512])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.675915 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 40.block_0 ([torch.Size([0])]) for Parameter 40 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.675964 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([128, 128])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.676017 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 41.block_0 ([torch.Size([0])]) for Parameter 41 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.676025 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.676155 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 42.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 42 (torch.Size([512, 256, 1, 1])), Block block_0 (torch.Size([512, 256])).
I0314 21:38:05.676141 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([128, 128]), torch.Size([384, 384]), torch.Size([3, 3])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.676165 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.676173 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.676259 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([0])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.676265 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.676266 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([0])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.676268 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 43.block_0 ([torch.Size([0])]) for Parameter 43 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.676349 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.676357 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 44.block_0 ([torch.Size([0])]) for Parameter 44 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.676360 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([0])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.676365 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([0])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.676470 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 45.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 45 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.676477 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.676478 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.676509 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([1024, 1024])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.676589 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([0])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.676630 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.676627 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 46.block_0 ([torch.Size([128, 128])]) for Parameter 46 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.676694 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([0])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.676743 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 47.block_0 ([torch.Size([0])]) for Parameter 47 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.676748 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:05.676834 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.676877 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:05.676906 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 48.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 48 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.676918 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([512, 512]), torch.Size([512, 512]), torch.Size([9, 9])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.676953 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([0])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.676975 139878978585792 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([0])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:05.677007 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 49.block_0 ([torch.Size([0])]) for Parameter 49 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.677046 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([0])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.677093 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 50.block_0 ([torch.Size([0])]) for Parameter 50 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.677198 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.677238 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([512, 512])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.677268 139878978585792 shampoo_preconditioner_list.py:612] Rank 3: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:05.677296 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([0])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.677318 139878978585792 shampoo_preconditioner_list.py:615] Rank 3: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056)
I0314 21:38:05.677365 139878978585792 shampoo_preconditioner_list.py:618] Rank 3: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:05.677369 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([0])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.677384 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([0])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.677408 139878978585792 shampoo_preconditioner_list.py:621] Rank 3: ShampooPreconditionerList Total Bytes: 12012296
I0314 21:38:05.677481 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([512, 512])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.677501 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.677506 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.677591 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([0])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.677595 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([0])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.677604 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([0])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.677688 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([0])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.677692 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([0])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.677707 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.677782 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 51.block_0 ([torch.Size([512, 512]), torch.Size([128, 128])]) for Parameter 51 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.677818 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.677833 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.677837 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.677896 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.677929 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([0])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.677928 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 52.block_0 ([torch.Size([0])]) for Parameter 52 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.677977 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.678021 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 53.block_0 ([torch.Size([0])]) for Parameter 53 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.678017 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([0])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.678056 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.678091 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([128, 128])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.678121 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([0])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.678164 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 54.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 54 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.678251 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.678263 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 55.block_0 ([torch.Size([0])]) for Parameter 55 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.678265 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.678353 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([0])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.678363 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 56.block_0 ([torch.Size([0])]) for Parameter 56 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.678370 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([0])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.678452 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([0])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.678460 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([0])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.678551 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([1024, 1024])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.678586 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.678695 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.678767 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([0])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.678827 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.678892 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([0])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.678911 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([0])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.679010 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([0])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.679069 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.679141 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.679167 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([0])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.679190 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 57.block_0 ([torch.Size([128, 128]), torch.Size([384, 384]), torch.Size([3, 3])]) for Parameter 57 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.679241 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([0])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.679252 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([0])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.679323 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([0])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.679303 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([512, 512]), torch.Size([128, 128])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.679362 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.679371 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 58.block_0 ([torch.Size([128, 128])]) for Parameter 58 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.679423 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([0])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.679444 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.679458 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([0])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.679495 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 59.block_0 ([torch.Size([0])]) for Parameter 59 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.679529 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([0])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.679547 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.679623 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.679628 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 60.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 60 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.679649 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:05.679708 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.679732 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 61.block_0 ([torch.Size([0])]) for Parameter 61 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.679738 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([0])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.679810 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.679823 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 62.block_0 ([torch.Size([0])]) for Parameter 62 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.679824 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([0])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.679906 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.679961 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 63.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 63 (torch.Size([128, 512, 1, 1])), Block block_0 (torch.Size([128, 512])).
I0314 21:38:05.679991 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.679977 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([512, 512])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.680018 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:05.680083 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([0])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.680148 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:05.680181 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 64.block_0 ([torch.Size([0])]) for Parameter 64 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.680241 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([0])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.680300 139732128158912 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([1000, 1000])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:05.680298 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 65.block_0 ([torch.Size([0])]) for Parameter 65 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.680382 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.680453 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 66.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 66 (torch.Size([128, 128, 3, 3])), Block block_0 (torch.Size([128, 384, 3])).
I0314 21:38:05.680493 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([0])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.680550 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 67.block_0 ([torch.Size([0])]) for Parameter 67 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.680574 139732128158912 shampoo_preconditioner_list.py:612] Rank 1: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:05.680592 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([0])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.680624 139732128158912 shampoo_preconditioner_list.py:615] Rank 1: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056)
I0314 21:38:05.680643 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 68.block_0 ([torch.Size([0])]) for Parameter 68 (torch.Size([128])), Block block_0 (torch.Size([128])).
I0314 21:38:05.680626 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([256, 256]), torch.Size([512, 512])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:05.680666 139732128158912 shampoo_preconditioner_list.py:618] Rank 1: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:05.680697 139732128158912 shampoo_preconditioner_list.py:621] Rank 1: ShampooPreconditionerList Total Bytes: 12012296
I0314 21:38:05.680710 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.680757 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 69.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 69 (torch.Size([512, 128, 1, 1])), Block block_0 (torch.Size([512, 128])).
I0314 21:38:05.680762 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([0])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.680797 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([0])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.680870 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 70.block_0 ([torch.Size([0])]) for Parameter 70 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.680865 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([0])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.680895 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([0])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.680971 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 71.block_0 ([torch.Size([0])]) for Parameter 71 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.681033 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.681104 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 72.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 72 (torch.Size([256, 512, 1, 1])), Block block_0 (torch.Size([256, 512])).
I0314 21:38:05.681149 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([0])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.681200 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 73.block_0 ([torch.Size([0])]) for Parameter 73 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.681257 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([0])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.681362 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 74.block_0 ([torch.Size([256, 256])]) for Parameter 74 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.681416 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.681466 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([256, 256]), torch.Size([768, 768]), torch.Size([3, 3])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.681505 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([0])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.681526 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 75.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 75 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.681593 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([0])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.681632 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([0])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.681665 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 76.block_0 ([torch.Size([256, 256])]) for Parameter 76 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.681718 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([0])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.681719 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.681781 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 77.block_0 ([torch.Size([0])]) for Parameter 77 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.681806 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([0])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.681843 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.681928 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([0])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.681931 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 78.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 78 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.681949 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([0])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.682047 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([0])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.682061 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.682087 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 79.block_0 ([torch.Size([1024, 1024])]) for Parameter 79 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.682149 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([0])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.682171 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.682245 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([0])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.682258 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([0])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.682343 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([0])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.682463 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.682538 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([256, 256]), torch.Size([768, 768]), torch.Size([3, 3])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.682581 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([0])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.682660 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([0])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.682682 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([0])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.682679 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 80.block_0 ([torch.Size([1024, 1024])]) for Parameter 80 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.682760 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([0])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.682832 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.682938 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([0])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.683096 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([256, 256])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.683235 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.683303 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 81.block_0 ([torch.Size([1024, 1024]), torch.Size([512, 512])]) for Parameter 81 (torch.Size([1024, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.683332 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([0])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.683419 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([0])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.683480 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([1024, 1024]), torch.Size([256, 256])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.683559 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.683614 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([0])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.683657 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([0])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.683718 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([0])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.683743 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([0])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.683848 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.683886 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.683912 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 82.block_0 ([torch.Size([1024, 1024])]) for Parameter 82 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.683955 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([0])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.683974 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([0])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.684046 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([0])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.684071 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([0])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.684100 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 83.block_0 ([torch.Size([1024, 1024])]) for Parameter 83 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.684223 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.684232 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.684256 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 84.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 84 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.684324 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([0])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.684361 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 85.block_0 ([torch.Size([0])]) for Parameter 85 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.684418 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([0])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.684424 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([0])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.684484 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 86.block_0 ([torch.Size([0])]) for Parameter 86 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.684523 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([0])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.684644 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.684746 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([0])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.684765 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 87.block_0 ([torch.Size([256, 256]), torch.Size([768, 768]), torch.Size([3, 3])]) for Parameter 87 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.684850 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([0])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.684871 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 88.block_0 ([torch.Size([0])]) for Parameter 88 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.684971 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 89.block_0 ([torch.Size([0])]) for Parameter 89 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.684982 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.685070 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([0])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.685098 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 90.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 90 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.685104 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([256, 256]), torch.Size([1024, 1024])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.685181 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([0])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.685184 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 91.block_0 ([torch.Size([0])]) for Parameter 91 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.685222 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([0])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.685269 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 92.block_0 ([torch.Size([0])]) for Parameter 92 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.685343 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.685357 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([256, 256])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.685410 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 93.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 93 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.685443 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([0])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.685530 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([0])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.685568 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 94.block_0 ([torch.Size([256, 256])]) for Parameter 94 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.685586 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([256, 256]), torch.Size([768, 768]), torch.Size([3, 3])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.685653 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.685667 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 95.block_0 ([torch.Size([0])]) for Parameter 95 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.685760 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([0])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.685774 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([0])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.685805 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 96.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 96 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.685858 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([0])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.685879 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([0])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.685900 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 97.block_0 ([torch.Size([0])]) for Parameter 97 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.685990 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.686003 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 98.block_0 ([torch.Size([0])]) for Parameter 98 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.686020 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.686088 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([0])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.686111 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([0])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.686138 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 99.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 99 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.686197 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([0])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.686211 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([0])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.686227 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 100.block_0 ([torch.Size([0])]) for Parameter 100 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.686328 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.686351 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.686366 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 101.block_0 ([torch.Size([1024, 1024])]) for Parameter 101 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.686429 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([0])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.686440 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([0])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.686491 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 102.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 102 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.686524 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([0])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.686526 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([0])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.686601 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 103.block_0 ([torch.Size([0])]) for Parameter 103 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.686649 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.686689 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.686692 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 104.block_0 ([torch.Size([0])]) for Parameter 104 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.686743 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([0])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.686787 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([0])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.686825 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 105.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 105 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.686841 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([0])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.686949 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([256, 256])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.687108 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.687207 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([0])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.687302 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([0])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.687425 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.687520 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([0])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.687615 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([0])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.687789 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.687899 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([0])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.687996 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([0])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.688139 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.688243 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([0])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.688342 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([0])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.688478 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.688577 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([0])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.688683 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([0])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.688777 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 106.block_0 ([torch.Size([256, 256])]) for Parameter 106 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.688830 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.688929 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([0])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.688942 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 107.block_0 ([torch.Size([0])]) for Parameter 107 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.689023 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([0])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.689104 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 108.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 108 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.689224 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 109.block_0 ([torch.Size([0])]) for Parameter 109 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.689327 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 110.block_0 ([torch.Size([0])]) for Parameter 110 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.689469 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 111.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 111 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.689570 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 112.block_0 ([torch.Size([0])]) for Parameter 112 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.689578 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([512, 512]), torch.Size([1024, 1024])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.689664 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 113.block_0 ([torch.Size([0])]) for Parameter 113 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.689746 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([0])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.689822 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 114.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 114 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.689863 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([0])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.689935 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 115.block_0 ([torch.Size([0])]) for Parameter 115 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.690033 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 116.block_0 ([torch.Size([0])]) for Parameter 116 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.690036 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.690142 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([0])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.690239 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([0])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.690374 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.690502 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.690595 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.690686 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.690778 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.690869 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.690995 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:05.691116 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:05.691206 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.691320 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.691416 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.691508 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.691642 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.691852 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.691971 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([0])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.692069 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([0])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.692153 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 117.block_0 ([torch.Size([1024, 1024]), torch.Size([256, 256])]) for Parameter 117 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.692252 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([1024, 1024]), torch.Size([512, 512])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.692274 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.692329 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 118.block_0 ([torch.Size([0])]) for Parameter 118 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.692370 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([0])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.692435 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.692466 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([0])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.692496 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 119.block_0 ([torch.Size([1024, 1024])]) for Parameter 119 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.692558 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.692644 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 120.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 120 (torch.Size([256, 1024, 1, 1])), Block block_0 (torch.Size([256, 1024])).
I0314 21:38:05.692659 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.692747 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.692796 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 121.block_0 ([torch.Size([256, 256])]) for Parameter 121 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.692841 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.692916 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 122.block_0 ([torch.Size([0])]) for Parameter 122 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.692977 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:05.693063 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([1024, 1024]), torch.Size([512, 512])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.693094 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 123.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 123 (torch.Size([256, 256, 3, 3])), Block block_0 (torch.Size([256, 768, 3])).
I0314 21:38:05.693099 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:05.693185 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.693209 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 124.block_0 ([torch.Size([0])]) for Parameter 124 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.693229 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.693277 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.693310 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 125.block_0 ([torch.Size([0])]) for Parameter 125 (torch.Size([256])), Block block_0 (torch.Size([256])).
I0314 21:38:05.693325 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.693384 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.693444 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.693446 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 126.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 126 (torch.Size([1024, 256, 1, 1])), Block block_0 (torch.Size([1024, 256])).
I0314 21:38:05.693508 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.693554 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 127.block_0 ([torch.Size([0])]) for Parameter 127 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.693562 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.693629 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.693654 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 128.block_0 ([torch.Size([0])]) for Parameter 128 (torch.Size([1024])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.693664 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.693785 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.693787 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 129.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 129 (torch.Size([512, 1024, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.693837 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.693874 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 130.block_0 ([torch.Size([0])]) for Parameter 130 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.693923 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.693968 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 131.block_0 ([torch.Size([0])]) for Parameter 131 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.693956 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([0])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.694025 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([0])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.694064 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([0])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.694116 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 132.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 132 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.694122 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([0])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.694219 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 133.block_0 ([torch.Size([0])]) for Parameter 133 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.694231 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.694267 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.694314 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 134.block_0 ([torch.Size([0])]) for Parameter 134 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.694322 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([0])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.694374 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([0])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.694407 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([0])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.694440 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.694482 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([0])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.694519 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.694568 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 135.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 135 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.694607 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.694671 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_0 ([torch.Size([0])]) for Parameter 136 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.694732 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.694829 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.694943 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.695045 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.695148 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.695720 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 136.block_1 ([torch.Size([1024, 1024])]) for Parameter 136 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.695858 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_0 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.695922 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([1000, 1000]), torch.Size([1024, 1024])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:05.695966 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 137.block_1 ([torch.Size([0])]) for Parameter 137 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.696086 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:05.696090 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_0 (torch.Size([1024, 1024])).
I0314 21:38:05.696205 139756371608768 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([0])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:05.696233 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 138.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 138 (torch.Size([2048, 1024, 1, 1])), Block block_1 (torch.Size([1024, 1024])).
I0314 21:38:05.696323 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_0 ([torch.Size([0])]) for Parameter 139 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.696486 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 139.block_1 ([torch.Size([1024, 1024])]) for Parameter 139 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.696499 139756371608768 shampoo_preconditioner_list.py:612] Rank 5: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:05.696550 139756371608768 shampoo_preconditioner_list.py:615] Rank 5: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768)
I0314 21:38:05.696595 139756371608768 shampoo_preconditioner_list.py:618] Rank 5: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:05.696614 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_0 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.696649 139756371608768 shampoo_preconditioner_list.py:621] Rank 5: ShampooPreconditionerList Total Bytes: 3230472
I0314 21:38:05.696702 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 140.block_1 ([torch.Size([0])]) for Parameter 140 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.696826 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.696997 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([1024, 1024]), torch.Size([512, 512])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.697143 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.697251 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.697351 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.697447 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.697589 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.697715 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.697813 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([0])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.698571 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 141.block_1 ([torch.Size([512, 512]), torch.Size([1024, 1024])]) for Parameter 141 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.699163 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([512, 512])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.699349 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.699453 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([0])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.699550 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([0])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.699545 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 142.block_0 ([torch.Size([512, 512])]) for Parameter 142 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.699678 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 143.block_0 ([torch.Size([0])]) for Parameter 143 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.699686 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.699806 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.699852 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 144.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 144 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.699915 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.699960 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 145.block_0 ([torch.Size([0])]) for Parameter 145 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.700011 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.700059 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 146.block_0 ([torch.Size([0])]) for Parameter 146 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.700103 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.700211 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.700222 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.700337 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 147.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 147 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.700340 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:05.700436 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_0 ([torch.Size([0])]) for Parameter 148 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.702252 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([1000, 1000]), torch.Size([1024, 1024])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:05.702386 140053993235648 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([0])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:05.702698 140053993235648 shampoo_preconditioner_list.py:612] Rank 6: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:05.702761 140053993235648 shampoo_preconditioner_list.py:615] Rank 6: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768)
I0314 21:38:05.702808 140053993235648 shampoo_preconditioner_list.py:618] Rank 6: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:05.702849 140053993235648 shampoo_preconditioner_list.py:621] Rank 6: ShampooPreconditionerList Total Bytes: 9849608
I0314 21:38:05.703549 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 148.block_1 ([torch.Size([1024, 1024])]) for Parameter 148 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.703700 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_0 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.703809 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 149.block_1 ([torch.Size([0])]) for Parameter 149 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.703951 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_0 (torch.Size([512, 1024])).
I0314 21:38:05.704080 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 150.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 150 (torch.Size([512, 2048, 1, 1])), Block block_1 (torch.Size([512, 1024])).
I0314 21:38:05.704206 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 151.block_0 ([torch.Size([0])]) for Parameter 151 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.704314 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 152.block_0 ([torch.Size([0])]) for Parameter 152 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.704465 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 153.block_0 ([torch.Size([0]), torch.Size([0]), torch.Size([0])]) for Parameter 153 (torch.Size([512, 512, 3, 3])), Block block_0 (torch.Size([512, 512, 9])).
I0314 21:38:05.706203 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 154.block_0 ([torch.Size([512, 512])]) for Parameter 154 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.706339 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 155.block_0 ([torch.Size([0])]) for Parameter 155 (torch.Size([512])), Block block_0 (torch.Size([512])).
I0314 21:38:05.707661 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_0 ([torch.Size([1024, 1024]), torch.Size([512, 512])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_0 (torch.Size([1024, 512])).
I0314 21:38:05.707836 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 156.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 156 (torch.Size([2048, 512, 1, 1])), Block block_1 (torch.Size([1024, 512])).
I0314 21:38:05.707948 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_0 ([torch.Size([0])]) for Parameter 157 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.709813 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 157.block_1 ([torch.Size([1024, 1024])]) for Parameter 157 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.709955 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_0 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_0 (torch.Size([1024])).
I0314 21:38:05.710070 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 158.block_1 ([torch.Size([0])]) for Parameter 158 (torch.Size([2048])), Block block_1 (torch.Size([1024])).
I0314 21:38:05.710219 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_0 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_0 (torch.Size([1000, 1024])).
I0314 21:38:05.710358 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 159.block_1 ([torch.Size([0]), torch.Size([0])]) for Parameter 159 (torch.Size([1000, 2048])), Block block_1 (torch.Size([1000, 1024])).
I0314 21:38:05.710459 140585381643456 shampoo_preconditioner_list.py:574] Instantiated Shampoo Preconditioner 160.block_0 ([torch.Size([0])]) for Parameter 160 (torch.Size([1000])), Block block_0 (torch.Size([1000])).
I0314 21:38:05.710773 140585381643456 shampoo_preconditioner_list.py:612] Rank 7: ShampooPreconditionerList Numel Breakdown: (78530, 8192, 8192, 16384, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 139264, 8192, 8192, 671744, 8192, 8192, 139264, 131072, 131072, 163840, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 327698, 32768, 32768, 557056, 524288, 524288, 655360, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2228224, 131072, 131072, 1310738, 131072, 131072, 2228224, 2097152, 2097152, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4194304, 4194304, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 2621440, 2621440, 524288, 524288, 1048738, 524288, 524288, 2621440, 2621440, 2097152, 2097152, 2097152, 2097152, 4097152, 4097152, 2000000)
I0314 21:38:05.710835 140585381643456 shampoo_preconditioner_list.py:615] Rank 7: ShampooPreconditionerList Bytes Breakdown: (314120, 32768, 32768, 65536, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 557056, 32768, 32768, 2686976, 32768, 32768, 557056, 524288, 524288, 655360, 131072)
I0314 21:38:05.710882 140585381643456 shampoo_preconditioner_list.py:618] Rank 7: ShampooPreconditionerList Total Elements: 174473948
I0314 21:38:05.710922 140585381643456 shampoo_preconditioner_list.py:621] Rank 7: ShampooPreconditionerList Total Bytes: 17222408
I0314 21:38:05.968414 139925059253440 submission_runner.py:325] Saving flags to /experiment_runs/submissions/rolling_leaderboard/external_tuning/shampoo/study_2/imagenet_resnet_pytorch/trial_3/flags_0.json.
I0314 21:38:06.025879 139925059253440 submission_runner.py:337] Starting training loop.
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
/usr/local/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = os.fork()
[rank2]:W0314 21:38:12.575000 46 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank3]:W0314 21:38:12.644000 47 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank5]:W0314 21:38:12.752000 49 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank7]:W0314 21:38:12.752000 51 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank4]:W0314 21:38:12.826000 48 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank0]:W0314 21:38:12.853000 44 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank6]:W0314 21:38:12.877000 50 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
[rank1]:W0314 21:38:12.881000 45 site-packages/torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512]
bucket_view.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
I0314 21:39:53.473956 139903167395584 logging_writer.py:48] [0] global_step=0, grad_norm=0.590454, loss=6.92783
I0314 21:39:53.495765 139925059253440 submission.py:265] 0) loss = 6.928, grad_norm = 0.590
I0314 21:39:54.427804 139925059253440 spec.py:321] Evaluating on the training split.
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
/usr/local/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:725: UserWarning: Graph break due to unsupported builtin torch._C._distributed_c10d.PyCapsule._broadcast_coalesced. This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind). If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround. If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use torch.compiler.allow_in_graph.
  torch._dynamo.utils.warn_once(msg)
I0314 21:44:38.332037 139925059253440 spec.py:333] Evaluating on the validation split.
I0314 21:46:09.192511 139925059253440 spec.py:349] Evaluating on the test split.
I0314 21:46:09.379933 139925059253440 dataset_info.py:690] Load dataset info from /data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0
I0314 21:46:09.389194 139925059253440 reader.py:261] Creating a tf.data.Dataset reading 16 files located in folders: /data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0.
I0314 21:46:09.445712 139925059253440 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/pytorch/imagenet_v2/matched-frequency/3.0.0
I0314 21:46:43.649887 139925059253440 submission_runner.py:469] Time since start: 517.62s, 	Step: 1, 	{'train/accuracy': 0.0009167729591836735, 'train/loss': 6.911649742904975, 'validation/accuracy': 0.00112, 'validation/loss': 6.911316875, 'validation/num_examples': 50000, 'test/accuracy': 0.0011, 'test/loss': 6.912528125, 'test/num_examples': 10000, 'score': 107.47067213058472, 'total_duration': 517.6241047382355, 'accumulated_submission_time': 107.47067213058472, 'accumulated_eval_time': 409.22225880622864, 'accumulated_logging_time': 0}
I0314 21:46:43.659406 139896102577920 logging_writer.py:48] [1] accumulated_eval_time=409.222, accumulated_logging_time=0, accumulated_submission_time=107.471, global_step=1, preemption_count=0, score=107.471, test/accuracy=0.0011, test/loss=6.91253, test/num_examples=10000, total_duration=517.624, train/accuracy=0.000916773, train/loss=6.91165, validation/accuracy=0.00112, validation/loss=6.91132, validation/num_examples=50000
I0314 21:46:45.415553 139896094185216 logging_writer.py:48] [1] global_step=1, grad_norm=0.61713, loss=6.93942
I0314 21:46:45.419157 139925059253440 submission.py:265] 1) loss = 6.939, grad_norm = 0.617
I0314 21:46:45.776157 139896102577920 logging_writer.py:48] [2] global_step=2, grad_norm=0.60725, loss=6.92836
I0314 21:46:45.779733 139925059253440 submission.py:265] 2) loss = 6.928, grad_norm = 0.607
I0314 21:46:46.138120 139896094185216 logging_writer.py:48] [3] global_step=3, grad_norm=0.605483, loss=6.92772
I0314 21:46:46.142150 139925059253440 submission.py:265] 3) loss = 6.928, grad_norm = 0.605
I0314 21:46:46.499322 139896102577920 logging_writer.py:48] [4] global_step=4, grad_norm=0.599934, loss=6.92664
I0314 21:46:46.502984 139925059253440 submission.py:265] 4) loss = 6.927, grad_norm = 0.600
I0314 21:46:46.859348 139896094185216 logging_writer.py:48] [5] global_step=5, grad_norm=0.587136, loss=6.91558
I0314 21:46:46.862699 139925059253440 submission.py:265] 5) loss = 6.916, grad_norm = 0.587
I0314 21:46:47.217715 139896102577920 logging_writer.py:48] [6] global_step=6, grad_norm=0.608149, loss=6.92042
I0314 21:46:47.221184 139925059253440 submission.py:265] 6) loss = 6.920, grad_norm = 0.608
I0314 21:46:47.577110 139896094185216 logging_writer.py:48] [7] global_step=7, grad_norm=0.610313, loss=6.92291
I0314 21:46:47.580590 139925059253440 submission.py:265] 7) loss = 6.923, grad_norm = 0.610
I0314 21:46:47.937535 139896102577920 logging_writer.py:48] [8] global_step=8, grad_norm=0.604774, loss=6.92032
I0314 21:46:47.941132 139925059253440 submission.py:265] 8) loss = 6.920, grad_norm = 0.605
I0314 21:46:49.347254 139896094185216 logging_writer.py:48] [9] global_step=9, grad_norm=0.626306, loss=6.93491
I0314 21:46:49.350827 139925059253440 submission.py:265] 9) loss = 6.935, grad_norm = 0.626
I0314 21:46:49.990067 139896102577920 logging_writer.py:48] [10] global_step=10, grad_norm=0.599992, loss=6.92452
I0314 21:46:49.993998 139925059253440 submission.py:265] 10) loss = 6.925, grad_norm = 0.600
I0314 21:46:50.705816 139896094185216 logging_writer.py:48] [11] global_step=11, grad_norm=0.603879, loss=6.93511
I0314 21:46:50.709321 139925059253440 submission.py:265] 11) loss = 6.935, grad_norm = 0.604
I0314 21:46:51.274004 139896102577920 logging_writer.py:48] [12] global_step=12, grad_norm=0.591304, loss=6.92602
I0314 21:46:51.278061 139925059253440 submission.py:265] 12) loss = 6.926, grad_norm = 0.591
I0314 21:46:54.190044 139896094185216 logging_writer.py:48] [13] global_step=13, grad_norm=0.611037, loss=6.93572
I0314 21:46:54.193979 139925059253440 submission.py:265] 13) loss = 6.936, grad_norm = 0.611
I0314 21:46:54.923471 139896102577920 logging_writer.py:48] [14] global_step=14, grad_norm=0.618192, loss=6.92679
I0314 21:46:54.927457 139925059253440 submission.py:265] 14) loss = 6.927, grad_norm = 0.618
I0314 21:46:55.554031 139896094185216 logging_writer.py:48] [15] global_step=15, grad_norm=0.587251, loss=6.9265
I0314 21:46:55.558115 139925059253440 submission.py:265] 15) loss = 6.927, grad_norm = 0.587
I0314 21:46:56.437600 139896102577920 logging_writer.py:48] [16] global_step=16, grad_norm=0.589725, loss=6.9291
I0314 21:46:56.441216 139925059253440 submission.py:265] 16) loss = 6.929, grad_norm = 0.590
I0314 21:46:59.149219 139896094185216 logging_writer.py:48] [17] global_step=17, grad_norm=0.594654, loss=6.92569
I0314 21:46:59.152714 139925059253440 submission.py:265] 17) loss = 6.926, grad_norm = 0.595
I0314 21:46:59.698592 139896102577920 logging_writer.py:48] [18] global_step=18, grad_norm=0.604144, loss=6.92611
I0314 21:46:59.702460 139925059253440 submission.py:265] 18) loss = 6.926, grad_norm = 0.604
I0314 21:47:00.223439 139896094185216 logging_writer.py:48] [19] global_step=19, grad_norm=0.595223, loss=6.91301
I0314 21:47:00.227013 139925059253440 submission.py:265] 19) loss = 6.913, grad_norm = 0.595
I0314 21:47:00.950477 139896102577920 logging_writer.py:48] [20] global_step=20, grad_norm=0.605894, loss=6.92945
I0314 21:47:00.953943 139925059253440 submission.py:265] 20) loss = 6.929, grad_norm = 0.606
I0314 21:47:04.304404 139896094185216 logging_writer.py:48] [21] global_step=21, grad_norm=0.595936, loss=6.92838
I0314 21:47:04.307794 139925059253440 submission.py:265] 21) loss = 6.928, grad_norm = 0.596
I0314 21:47:04.662911 139896102577920 logging_writer.py:48] [22] global_step=22, grad_norm=0.602001, loss=6.92659
I0314 21:47:04.666490 139925059253440 submission.py:265] 22) loss = 6.927, grad_norm = 0.602
I0314 21:47:05.473111 139896094185216 logging_writer.py:48] [23] global_step=23, grad_norm=0.593678, loss=6.9315
I0314 21:47:05.477012 139925059253440 submission.py:265] 23) loss = 6.931, grad_norm = 0.594
I0314 21:47:05.843598 139896102577920 logging_writer.py:48] [24] global_step=24, grad_norm=0.599845, loss=6.91625
I0314 21:47:05.847085 139925059253440 submission.py:265] 24) loss = 6.916, grad_norm = 0.600
I0314 21:47:08.931833 139896094185216 logging_writer.py:48] [25] global_step=25, grad_norm=0.591658, loss=6.92508
I0314 21:47:08.935805 139925059253440 submission.py:265] 25) loss = 6.925, grad_norm = 0.592
I0314 21:47:09.548717 139896102577920 logging_writer.py:48] [26] global_step=26, grad_norm=0.60969, loss=6.91801
I0314 21:47:09.552325 139925059253440 submission.py:265] 26) loss = 6.918, grad_norm = 0.610
I0314 21:47:10.342817 139896094185216 logging_writer.py:48] [27] global_step=27, grad_norm=0.581212, loss=6.92178
I0314 21:47:10.346545 139925059253440 submission.py:265] 27) loss = 6.922, grad_norm = 0.581
I0314 21:47:11.153125 139896102577920 logging_writer.py:48] [28] global_step=28, grad_norm=0.600906, loss=6.91663
I0314 21:47:11.156749 139925059253440 submission.py:265] 28) loss = 6.917, grad_norm = 0.601
I0314 21:47:13.988279 139896094185216 logging_writer.py:48] [29] global_step=29, grad_norm=0.61021, loss=6.92152
I0314 21:47:13.991778 139925059253440 submission.py:265] 29) loss = 6.922, grad_norm = 0.610
I0314 21:47:14.936845 139896102577920 logging_writer.py:48] [30] global_step=30, grad_norm=0.607391, loss=6.92816
I0314 21:47:14.940478 139925059253440 submission.py:265] 30) loss = 6.928, grad_norm = 0.607
I0314 21:47:15.438490 139896094185216 logging_writer.py:48] [31] global_step=31, grad_norm=0.588273, loss=6.92627
I0314 21:47:15.442110 139925059253440 submission.py:265] 31) loss = 6.926, grad_norm = 0.588
I0314 21:47:15.798440 139896102577920 logging_writer.py:48] [32] global_step=32, grad_norm=0.579406, loss=6.9226
I0314 21:47:15.802353 139925059253440 submission.py:265] 32) loss = 6.923, grad_norm = 0.579
I0314 21:47:18.631055 139896094185216 logging_writer.py:48] [33] global_step=33, grad_norm=0.615379, loss=6.92377
I0314 21:47:18.635231 139925059253440 submission.py:265] 33) loss = 6.924, grad_norm = 0.615
I0314 21:47:19.651544 139896102577920 logging_writer.py:48] [34] global_step=34, grad_norm=0.595291, loss=6.9163
I0314 21:47:19.655458 139925059253440 submission.py:265] 34) loss = 6.916, grad_norm = 0.595
I0314 21:47:20.195081 139896094185216 logging_writer.py:48] [35] global_step=35, grad_norm=0.59113, loss=6.91697
I0314 21:47:20.198959 139925059253440 submission.py:265] 35) loss = 6.917, grad_norm = 0.591
I0314 21:47:21.231374 139896102577920 logging_writer.py:48] [36] global_step=36, grad_norm=0.60776, loss=6.91622
I0314 21:47:21.235251 139925059253440 submission.py:265] 36) loss = 6.916, grad_norm = 0.608
I0314 21:47:23.754501 139896094185216 logging_writer.py:48] [37] global_step=37, grad_norm=0.601222, loss=6.9162
I0314 21:47:23.758405 139925059253440 submission.py:265] 37) loss = 6.916, grad_norm = 0.601
I0314 21:47:24.138194 139896102577920 logging_writer.py:48] [38] global_step=38, grad_norm=0.595241, loss=6.92558
I0314 21:47:24.141920 139925059253440 submission.py:265] 38) loss = 6.926, grad_norm = 0.595
I0314 21:47:25.445353 139896094185216 logging_writer.py:48] [39] global_step=39, grad_norm=0.592855, loss=6.9159
I0314 21:47:25.448968 139925059253440 submission.py:265] 39) loss = 6.916, grad_norm = 0.593
I0314 21:47:25.864006 139896102577920 logging_writer.py:48] [40] global_step=40, grad_norm=0.6052, loss=6.92295
I0314 21:47:25.867882 139925059253440 submission.py:265] 40) loss = 6.923, grad_norm = 0.605
I0314 21:47:28.687680 139896094185216 logging_writer.py:48] [41] global_step=41, grad_norm=0.579778, loss=6.91472
I0314 21:47:28.691251 139925059253440 submission.py:265] 41) loss = 6.915, grad_norm = 0.580
I0314 21:47:29.046313 139896102577920 logging_writer.py:48] [42] global_step=42, grad_norm=0.591178, loss=6.91176
I0314 21:47:29.050013 139925059253440 submission.py:265] 42) loss = 6.912, grad_norm = 0.591
I0314 21:47:30.758041 139896094185216 logging_writer.py:48] [43] global_step=43, grad_norm=0.602179, loss=6.91736
I0314 21:47:30.761417 139925059253440 submission.py:265] 43) loss = 6.917, grad_norm = 0.602
I0314 21:47:31.116143 139896102577920 logging_writer.py:48] [44] global_step=44, grad_norm=0.590691, loss=6.90479
I0314 21:47:31.119749 139925059253440 submission.py:265] 44) loss = 6.905, grad_norm = 0.591
I0314 21:47:33.806262 139896094185216 logging_writer.py:48] [45] global_step=45, grad_norm=0.575753, loss=6.91244
I0314 21:47:33.809941 139925059253440 submission.py:265] 45) loss = 6.912, grad_norm = 0.576
I0314 21:47:34.168041 139896102577920 logging_writer.py:48] [46] global_step=46, grad_norm=0.610588, loss=6.91755
I0314 21:47:34.171546 139925059253440 submission.py:265] 46) loss = 6.918, grad_norm = 0.611
I0314 21:47:35.856082 139896094185216 logging_writer.py:48] [47] global_step=47, grad_norm=0.594908, loss=6.9136
I0314 21:47:35.859481 139925059253440 submission.py:265] 47) loss = 6.914, grad_norm = 0.595
I0314 21:47:36.215508 139896102577920 logging_writer.py:48] [48] global_step=48, grad_norm=0.583503, loss=6.91103
I0314 21:47:36.219400 139925059253440 submission.py:265] 48) loss = 6.911, grad_norm = 0.584
I0314 21:47:38.756714 139896094185216 logging_writer.py:48] [49] global_step=49, grad_norm=0.599607, loss=6.90745
I0314 21:47:38.760710 139925059253440 submission.py:265] 49) loss = 6.907, grad_norm = 0.600
I0314 21:47:39.133689 139896102577920 logging_writer.py:48] [50] global_step=50, grad_norm=0.589452, loss=6.91182
I0314 21:47:39.137183 139925059253440 submission.py:265] 50) loss = 6.912, grad_norm = 0.589
I0314 21:47:40.912306 139896094185216 logging_writer.py:48] [51] global_step=51, grad_norm=0.590209, loss=6.91202
I0314 21:47:40.915763 139925059253440 submission.py:265] 51) loss = 6.912, grad_norm = 0.590
I0314 21:47:41.271648 139896102577920 logging_writer.py:48] [52] global_step=52, grad_norm=0.585119, loss=6.91064
I0314 21:47:41.275659 139925059253440 submission.py:265] 52) loss = 6.911, grad_norm = 0.585
I0314 21:47:43.512259 139896094185216 logging_writer.py:48] [53] global_step=53, grad_norm=0.578519, loss=6.90646
I0314 21:47:43.516308 139925059253440 submission.py:265] 53) loss = 6.906, grad_norm = 0.579
I0314 21:47:44.297373 139896102577920 logging_writer.py:48] [54] global_step=54, grad_norm=0.5997, loss=6.91085
I0314 21:47:44.301411 139925059253440 submission.py:265] 54) loss = 6.911, grad_norm = 0.600
I0314 21:47:46.601535 139896094185216 logging_writer.py:48] [55] global_step=55, grad_norm=0.582338, loss=6.90841
I0314 21:47:46.605749 139925059253440 submission.py:265] 55) loss = 6.908, grad_norm = 0.582
I0314 21:47:46.963252 139896102577920 logging_writer.py:48] [56] global_step=56, grad_norm=0.593781, loss=6.90404
I0314 21:47:46.967113 139925059253440 submission.py:265] 56) loss = 6.904, grad_norm = 0.594
I0314 21:47:49.577294 139896094185216 logging_writer.py:48] [57] global_step=57, grad_norm=0.59989, loss=6.90756
I0314 21:47:49.580894 139925059253440 submission.py:265] 57) loss = 6.908, grad_norm = 0.600
I0314 21:47:49.935276 139896102577920 logging_writer.py:48] [58] global_step=58, grad_norm=0.615269, loss=6.89853
I0314 21:47:49.938713 139925059253440 submission.py:265] 58) loss = 6.899, grad_norm = 0.615
I0314 21:47:51.441412 139896094185216 logging_writer.py:48] [59] global_step=59, grad_norm=0.604739, loss=6.91146
I0314 21:47:51.445080 139925059253440 submission.py:265] 59) loss = 6.911, grad_norm = 0.605
I0314 21:47:52.002439 139896102577920 logging_writer.py:48] [60] global_step=60, grad_norm=0.598554, loss=6.91042
I0314 21:47:52.005911 139925059253440 submission.py:265] 60) loss = 6.910, grad_norm = 0.599
I0314 21:47:54.607191 139896094185216 logging_writer.py:48] [61] global_step=61, grad_norm=0.56989, loss=6.89707
I0314 21:47:54.610789 139925059253440 submission.py:265] 61) loss = 6.897, grad_norm = 0.570
I0314 21:47:54.967788 139896102577920 logging_writer.py:48] [62] global_step=62, grad_norm=0.5761, loss=6.89972
I0314 21:47:54.971361 139925059253440 submission.py:265] 62) loss = 6.900, grad_norm = 0.576
I0314 21:47:56.293256 139896094185216 logging_writer.py:48] [63] global_step=63, grad_norm=0.598428, loss=6.89197
I0314 21:47:56.296506 139925059253440 submission.py:265] 63) loss = 6.892, grad_norm = 0.598
I0314 21:47:57.064616 139896102577920 logging_writer.py:48] [64] global_step=64, grad_norm=0.61736, loss=6.90162
I0314 21:47:57.068087 139925059253440 submission.py:265] 64) loss = 6.902, grad_norm = 0.617
I0314 21:47:59.618739 139896094185216 logging_writer.py:48] [65] global_step=65, grad_norm=0.591701, loss=6.89794
I0314 21:47:59.622488 139925059253440 submission.py:265] 65) loss = 6.898, grad_norm = 0.592
I0314 21:47:59.978871 139896102577920 logging_writer.py:48] [66] global_step=66, grad_norm=0.588576, loss=6.89453
I0314 21:47:59.982840 139925059253440 submission.py:265] 66) loss = 6.895, grad_norm = 0.589
I0314 21:48:01.180900 139896094185216 logging_writer.py:48] [67] global_step=67, grad_norm=0.60221, loss=6.89983
I0314 21:48:01.184354 139925059253440 submission.py:265] 67) loss = 6.900, grad_norm = 0.602
I0314 21:48:01.975638 139896102577920 logging_writer.py:48] [68] global_step=68, grad_norm=0.600427, loss=6.89293
I0314 21:48:01.979499 139925059253440 submission.py:265] 68) loss = 6.893, grad_norm = 0.600
I0314 21:48:05.038434 139896094185216 logging_writer.py:48] [69] global_step=69, grad_norm=0.570148, loss=6.89635
I0314 21:48:05.042151 139925059253440 submission.py:265] 69) loss = 6.896, grad_norm = 0.570
I0314 21:48:05.396670 139896102577920 logging_writer.py:48] [70] global_step=70, grad_norm=0.595987, loss=6.89015
I0314 21:48:05.400084 139925059253440 submission.py:265] 70) loss = 6.890, grad_norm = 0.596
I0314 21:48:06.542467 139896094185216 logging_writer.py:48] [71] global_step=71, grad_norm=0.597048, loss=6.90101
I0314 21:48:06.546171 139925059253440 submission.py:265] 71) loss = 6.901, grad_norm = 0.597
I0314 21:48:07.666846 139896102577920 logging_writer.py:48] [72] global_step=72, grad_norm=0.594087, loss=6.88584
I0314 21:48:07.671083 139925059253440 submission.py:265] 72) loss = 6.886, grad_norm = 0.594
I0314 21:48:10.493268 139896094185216 logging_writer.py:48] [73] global_step=73, grad_norm=0.602528, loss=6.89275
I0314 21:48:10.496810 139925059253440 submission.py:265] 73) loss = 6.893, grad_norm = 0.603
I0314 21:48:10.855150 139896102577920 logging_writer.py:48] [74] global_step=74, grad_norm=0.576662, loss=6.88751
I0314 21:48:10.858959 139925059253440 submission.py:265] 74) loss = 6.888, grad_norm = 0.577
I0314 21:48:12.564106 139896094185216 logging_writer.py:48] [75] global_step=75, grad_norm=0.590095, loss=6.88941
I0314 21:48:12.568198 139925059253440 submission.py:265] 75) loss = 6.889, grad_norm = 0.590
I0314 21:48:13.452706 139896102577920 logging_writer.py:48] [76] global_step=76, grad_norm=0.582305, loss=6.88826
I0314 21:48:13.456255 139925059253440 submission.py:265] 76) loss = 6.888, grad_norm = 0.582
I0314 21:48:15.263930 139896094185216 logging_writer.py:48] [77] global_step=77, grad_norm=0.586395, loss=6.88683
I0314 21:48:15.267484 139925059253440 submission.py:265] 77) loss = 6.887, grad_norm = 0.586
I0314 21:48:15.623351 139896102577920 logging_writer.py:48] [78] global_step=78, grad_norm=0.594355, loss=6.88646
I0314 21:48:15.626863 139925059253440 submission.py:265] 78) loss = 6.886, grad_norm = 0.594
I0314 21:48:17.331234 139896094185216 logging_writer.py:48] [79] global_step=79, grad_norm=0.608911, loss=6.89449
I0314 21:48:17.335336 139925059253440 submission.py:265] 79) loss = 6.894, grad_norm = 0.609
I0314 21:48:18.223148 139896102577920 logging_writer.py:48] [80] global_step=80, grad_norm=0.575561, loss=6.88844
I0314 21:48:18.226860 139925059253440 submission.py:265] 80) loss = 6.888, grad_norm = 0.576
I0314 21:48:20.036377 139896094185216 logging_writer.py:48] [81] global_step=81, grad_norm=0.578026, loss=6.88825
I0314 21:48:20.039887 139925059253440 submission.py:265] 81) loss = 6.888, grad_norm = 0.578
I0314 21:48:20.396262 139896102577920 logging_writer.py:48] [82] global_step=82, grad_norm=0.579352, loss=6.88442
I0314 21:48:20.399808 139925059253440 submission.py:265] 82) loss = 6.884, grad_norm = 0.579
I0314 21:48:21.802165 139896094185216 logging_writer.py:48] [83] global_step=83, grad_norm=0.596209, loss=6.88027
I0314 21:48:21.805981 139925059253440 submission.py:265] 83) loss = 6.880, grad_norm = 0.596
I0314 21:48:23.139852 139896102577920 logging_writer.py:48] [84] global_step=84, grad_norm=0.588016, loss=6.89145
I0314 21:48:23.143798 139925059253440 submission.py:265] 84) loss = 6.891, grad_norm = 0.588
I0314 21:48:24.688056 139896094185216 logging_writer.py:48] [85] global_step=85, grad_norm=0.578803, loss=6.87943
I0314 21:48:24.691989 139925059253440 submission.py:265] 85) loss = 6.879, grad_norm = 0.579
I0314 21:48:25.328281 139896102577920 logging_writer.py:48] [86] global_step=86, grad_norm=0.602931, loss=6.87635
I0314 21:48:25.332251 139925059253440 submission.py:265] 86) loss = 6.876, grad_norm = 0.603
I0314 21:48:26.820357 139896094185216 logging_writer.py:48] [87] global_step=87, grad_norm=0.591855, loss=6.87921
I0314 21:48:26.823847 139925059253440 submission.py:265] 87) loss = 6.879, grad_norm = 0.592
I0314 21:48:28.469331 139896102577920 logging_writer.py:48] [88] global_step=88, grad_norm=0.601242, loss=6.87414
I0314 21:48:28.473241 139925059253440 submission.py:265] 88) loss = 6.874, grad_norm = 0.601
I0314 21:48:30.024869 139896094185216 logging_writer.py:48] [89] global_step=89, grad_norm=0.583822, loss=6.8631
I0314 21:48:30.029075 139925059253440 submission.py:265] 89) loss = 6.863, grad_norm = 0.584
I0314 21:48:30.385273 139896102577920 logging_writer.py:48] [90] global_step=90, grad_norm=0.606955, loss=6.88107
I0314 21:48:30.389136 139925059253440 submission.py:265] 90) loss = 6.881, grad_norm = 0.607
I0314 21:48:31.766697 139896094185216 logging_writer.py:48] [91] global_step=91, grad_norm=0.5864, loss=6.87765
I0314 21:48:31.770179 139925059253440 submission.py:265] 91) loss = 6.878, grad_norm = 0.586
I0314 21:48:33.114747 139896102577920 logging_writer.py:48] [92] global_step=92, grad_norm=0.597868, loss=6.8695
I0314 21:48:33.118469 139925059253440 submission.py:265] 92) loss = 6.869, grad_norm = 0.598
I0314 21:48:34.812772 139896094185216 logging_writer.py:48] [93] global_step=93, grad_norm=0.59113, loss=6.86603
I0314 21:48:34.816498 139925059253440 submission.py:265] 93) loss = 6.866, grad_norm = 0.591
I0314 21:48:35.174207 139896102577920 logging_writer.py:48] [94] global_step=94, grad_norm=0.580109, loss=6.87325
I0314 21:48:35.177829 139925059253440 submission.py:265] 94) loss = 6.873, grad_norm = 0.580
I0314 21:48:36.867179 139896094185216 logging_writer.py:48] [95] global_step=95, grad_norm=0.590312, loss=6.8763
I0314 21:48:36.870902 139925059253440 submission.py:265] 95) loss = 6.876, grad_norm = 0.590
I0314 21:48:38.113316 139896102577920 logging_writer.py:48] [96] global_step=96, grad_norm=0.585494, loss=6.86854
I0314 21:48:38.117321 139925059253440 submission.py:265] 96) loss = 6.869, grad_norm = 0.585
I0314 21:48:39.938323 139896094185216 logging_writer.py:48] [97] global_step=97, grad_norm=0.595743, loss=6.85144
I0314 21:48:39.942104 139925059253440 submission.py:265] 97) loss = 6.851, grad_norm = 0.596
I0314 21:48:40.298856 139896102577920 logging_writer.py:48] [98] global_step=98, grad_norm=0.596844, loss=6.86422
I0314 21:48:40.302340 139925059253440 submission.py:265] 98) loss = 6.864, grad_norm = 0.597
I0314 21:48:42.435222 139896094185216 logging_writer.py:48] [99] global_step=99, grad_norm=0.60328, loss=6.87138
I0314 21:48:42.439067 139925059253440 submission.py:265] 99) loss = 6.871, grad_norm = 0.603
I0314 21:48:42.796787 139896102577920 logging_writer.py:48] [100] global_step=100, grad_norm=0.592497, loss=6.86273
I0314 21:48:42.800376 139925059253440 submission.py:265] 100) loss = 6.863, grad_norm = 0.592
I0314 21:55:15.732840 139925059253440 spec.py:321] Evaluating on the training split.
I0314 21:55:55.780264 139925059253440 spec.py:333] Evaluating on the validation split.
I0314 21:56:35.812431 139925059253440 spec.py:349] Evaluating on the test split.
I0314 21:56:36.942551 139925059253440 submission_runner.py:469] Time since start: 1110.92s, 	Step: 424, 	{'train/accuracy': 0.02961575255102041, 'train/loss': 6.223091592594069, 'validation/accuracy': 0.03048, 'validation/loss': 6.250234375, 'validation/num_examples': 50000, 'test/accuracy': 0.0197, 'test/loss': 6.37908125, 'test/num_examples': 10000, 'score': 616.5652029514313, 'total_duration': 1110.9168598651886, 'accumulated_submission_time': 616.5652029514313, 'accumulated_eval_time': 490.43212938308716, 'accumulated_logging_time': 0.01801776885986328}
I0314 21:56:36.952099 139896110970624 logging_writer.py:48] [424] accumulated_eval_time=490.432, accumulated_logging_time=0.0180178, accumulated_submission_time=616.565, global_step=424, preemption_count=0, score=616.565, test/accuracy=0.0197, test/loss=6.37908, test/num_examples=10000, total_duration=1110.92, train/accuracy=0.0296158, train/loss=6.22309, validation/accuracy=0.03048, validation/loss=6.25023, validation/num_examples=50000
I0314 21:58:00.938288 139896463251200 logging_writer.py:48] [500] global_step=500, grad_norm=0.919728, loss=6.28845
I0314 21:58:00.942022 139925059253440 submission.py:265] 500) loss = 6.288, grad_norm = 0.920
I0314 22:05:08.541601 139925059253440 spec.py:321] Evaluating on the training split.
I0314 22:05:47.516393 139925059253440 spec.py:333] Evaluating on the validation split.
I0314 22:06:27.732717 139925059253440 spec.py:349] Evaluating on the test split.
I0314 22:06:28.851326 139925059253440 submission_runner.py:469] Time since start: 1702.83s, 	Step: 859, 	{'train/accuracy': 0.08175223214285714, 'train/loss': 5.420374033402424, 'validation/accuracy': 0.0739, 'validation/loss': 5.49067, 'validation/num_examples': 50000, 'test/accuracy': 0.0465, 'test/loss': 5.767450390625, 'test/num_examples': 10000, 'score': 1125.0643401145935, 'total_duration': 1702.825607061386, 'accumulated_submission_time': 1125.0643401145935, 'accumulated_eval_time': 570.7421221733093, 'accumulated_logging_time': 0.03578305244445801}
I0314 22:06:28.882875 139896110970624 logging_writer.py:48] [859] accumulated_eval_time=570.742, accumulated_logging_time=0.0357831, accumulated_submission_time=1125.06, global_step=859, preemption_count=0, score=1125.06, test/accuracy=0.0465, test/loss=5.76745, test/num_examples=10000, total_duration=1702.83, train/accuracy=0.0817522, train/loss=5.42037, validation/accuracy=0.0739, validation/loss=5.49067, validation/num_examples=50000
I0314 22:09:19.637444 139896463251200 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.905636, loss=5.66269
I0314 22:09:19.661208 139925059253440 submission.py:265] 1000) loss = 5.663, grad_norm = 0.906
I0314 22:15:00.537374 139925059253440 spec.py:321] Evaluating on the training split.
I0314 22:15:39.077018 139925059253440 spec.py:333] Evaluating on the validation split.
I0314 22:16:19.706193 139925059253440 spec.py:349] Evaluating on the test split.
I0314 22:16:20.816449 139925059253440 submission_runner.py:469] Time since start: 2294.79s, 	Step: 1317, 	{'train/accuracy': 0.14174107142857142, 'train/loss': 4.709414735132334, 'validation/accuracy': 0.12564, 'validation/loss': 4.79989125, 'validation/num_examples': 50000, 'test/accuracy': 0.0827, 'test/loss': 5.2381140625, 'test/num_examples': 10000, 'score': 1633.6429414749146, 'total_duration': 2294.7907276153564, 'accumulated_submission_time': 1633.6429414749146, 'accumulated_eval_time': 651.02143907547, 'accumulated_logging_time': 0.11875700950622559}
I0314 22:16:20.848044 139896110970624 logging_writer.py:48] [1317] accumulated_eval_time=651.021, accumulated_logging_time=0.118757, accumulated_submission_time=1633.64, global_step=1317, preemption_count=0, score=1633.64, test/accuracy=0.0827, test/loss=5.23811, test/num_examples=10000, total_duration=2294.79, train/accuracy=0.141741, train/loss=4.70941, validation/accuracy=0.12564, validation/loss=4.79989, validation/num_examples=50000
I0314 22:17:52.604543 139896463251200 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.52824, loss=5.08992
I0314 22:17:52.608969 139925059253440 submission.py:265] 1500) loss = 5.090, grad_norm = 1.528
I0314 22:22:19.026203 139896110970624 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.14938, loss=4.64127
I0314 22:22:19.030280 139925059253440 submission.py:265] 2000) loss = 4.641, grad_norm = 1.149
I0314 22:24:53.734301 139925059253440 spec.py:321] Evaluating on the training split.
I0314 22:25:34.121901 139925059253440 spec.py:333] Evaluating on the validation split.
I0314 22:26:14.942066 139925059253440 spec.py:349] Evaluating on the test split.
I0314 22:26:16.052986 139925059253440 submission_runner.py:469] Time since start: 2890.03s, 	Step: 2208, 	{'train/accuracy': 0.28029336734693877, 'train/loss': 3.538737394371811, 'validation/accuracy': 0.25768, 'validation/loss': 3.6894621875, 'validation/num_examples': 50000, 'test/accuracy': 0.1716, 'test/loss': 4.391719921875, 'test/num_examples': 10000, 'score': 2143.319287776947, 'total_duration': 2890.0272657871246, 'accumulated_submission_time': 2143.319287776947, 'accumulated_eval_time': 733.3403203487396, 'accumulated_logging_time': 0.1589193344116211}
I0314 22:26:16.072379 139896463251200 logging_writer.py:48] [2208] accumulated_eval_time=733.34, accumulated_logging_time=0.158919, accumulated_submission_time=2143.32, global_step=2208, preemption_count=0, score=2143.32, test/accuracy=0.1716, test/loss=4.39172, test/num_examples=10000, total_duration=2890.03, train/accuracy=0.280293, train/loss=3.53874, validation/accuracy=0.25768, validation/loss=3.68946, validation/num_examples=50000
I0314 22:31:19.085628 139896110970624 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.35127, loss=4.24027
I0314 22:31:19.162891 139925059253440 submission.py:265] 2500) loss = 4.240, grad_norm = 1.351
I0314 22:34:47.504039 139925059253440 spec.py:321] Evaluating on the training split.
I0314 22:35:25.883785 139925059253440 spec.py:333] Evaluating on the validation split.
I0314 22:36:06.658521 139925059253440 spec.py:349] Evaluating on the test split.
I0314 22:36:07.771019 139925059253440 submission_runner.py:469] Time since start: 3481.75s, 	Step: 2974, 	{'train/accuracy': 0.39026626275510207, 'train/loss': 2.9098031180245534, 'validation/accuracy': 0.36212, 'validation/loss': 3.0464159375, 'validation/num_examples': 50000, 'test/accuracy': 0.2563, 'test/loss': 3.72038671875, 'test/num_examples': 10000, 'score': 2651.5329144001007, 'total_duration': 3481.7453124523163, 'accumulated_submission_time': 2651.5329144001007, 'accumulated_eval_time': 813.6074542999268, 'accumulated_logging_time': 0.18682265281677246}
I0314 22:36:07.781388 139896463251200 logging_writer.py:48] [2974] accumulated_eval_time=813.607, accumulated_logging_time=0.186823, accumulated_submission_time=2651.53, global_step=2974, preemption_count=0, score=2651.53, test/accuracy=0.2563, test/loss=3.72039, test/num_examples=10000, total_duration=3481.75, train/accuracy=0.390266, train/loss=2.9098, validation/accuracy=0.36212, validation/loss=3.04642, validation/num_examples=50000
I0314 22:36:21.588952 139896110970624 logging_writer.py:48] [3000] global_step=3000, grad_norm=1.13301, loss=3.86733
I0314 22:36:21.592971 139925059253440 submission.py:265] 3000) loss = 3.867, grad_norm = 1.133
I0314 22:40:34.266690 139896463251200 logging_writer.py:48] [3500] global_step=3500, grad_norm=1.00556, loss=3.63708
I0314 22:40:34.270779 139925059253440 submission.py:265] 3500) loss = 3.637, grad_norm = 1.006
I0314 22:44:39.892198 139925059253440 spec.py:321] Evaluating on the training split.
I0314 22:45:20.524356 139925059253440 spec.py:333] Evaluating on the validation split.
I0314 22:46:02.148415 139925059253440 spec.py:349] Evaluating on the test split.
I0314 22:46:03.257272 139925059253440 submission_runner.py:469] Time since start: 4077.23s, 	Step: 3754, 	{'train/accuracy': 0.4621532206632653, 'train/loss': 2.4937231881277904, 'validation/accuracy': 0.43042, 'validation/loss': 2.6436709375, 'validation/num_examples': 50000, 'test/accuracy': 0.3105, 'test/loss': 3.393751171875, 'test/num_examples': 10000, 'score': 3160.442153453827, 'total_duration': 4077.231496810913, 'accumulated_submission_time': 3160.442153453827, 'accumulated_eval_time': 896.9726026058197, 'accumulated_logging_time': 0.2058122158050537}
I0314 22:46:03.289845 139896110970624 logging_writer.py:48] [3754] accumulated_eval_time=896.973, accumulated_logging_time=0.205812, accumulated_submission_time=3160.44, global_step=3754, preemption_count=0, score=3160.44, test/accuracy=0.3105, test/loss=3.39375, test/num_examples=10000, total_duration=4077.23, train/accuracy=0.462153, train/loss=2.49372, validation/accuracy=0.43042, validation/loss=2.64367, validation/num_examples=50000
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
/usr/local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
I0314 22:47:46.177167 139896463251200 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.984721, loss=3.55085
I0314 22:47:46.181567 139925059253440 submission.py:265] 4000) loss = 3.551, grad_norm = 0.985
I0314 22:52:01.467033 139896110970624 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.943453, loss=3.33537
I0314 22:52:01.471605 139925059253440 submission.py:265] 4500) loss = 3.335, grad_norm = 0.943
I0314 22:54:35.406899 139925059253440 spec.py:321] Evaluating on the training split.
I0314 22:55:14.763722 139925059253440 spec.py:333] Evaluating on the validation split.
I0314 22:55:56.448515 139925059253440 spec.py:349] Evaluating on the test split.
I0314 22:55:57.555747 139925059253440 submission_runner.py:469] Time since start: 4671.53s, 	Step: 4718, 	{'train/accuracy': 0.5231784119897959, 'train/loss': 2.199096056879783, 'validation/accuracy': 0.48894, 'validation/loss': 2.3569846875, 'validation/num_examples': 50000, 'test/accuracy': 0.3532, 'test/loss': 3.1282423828125, 'test/num_examples': 10000, 'score': 3669.2544972896576, 'total_duration': 4671.530030012131, 'accumulated_submission_time': 3669.2544972896576, 'accumulated_eval_time': 979.1215584278107, 'accumulated_logging_time': 0.2772786617279053}
I0314 22:55:57.621113 139896463251200 logging_writer.py:48] [4718] accumulated_eval_time=979.122, accumulated_logging_time=0.277279, accumulated_submission_time=3669.25, global_step=4718, preemption_count=0, score=3669.25, test/accuracy=0.3532, test/loss=3.12824, test/num_examples=10000, total_duration=4671.53, train/accuracy=0.523178, train/loss=2.1991, validation/accuracy=0.48894, validation/loss=2.35698, validation/num_examples=50000
I0314 23:00:27.544295 139896110970624 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.958658, loss=3.3595
I0314 23:00:27.548325 139925059253440 submission.py:265] 5000) loss = 3.360, grad_norm = 0.959
I0314 23:03:55.898021 139896463251200 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.955996, loss=3.28052
I0314 23:03:55.902238 139925059253440 submission.py:265] 5500) loss = 3.281, grad_norm = 0.956
I0314 23:04:29.755216 139925059253440 spec.py:321] Evaluating on the training split.
I0314 23:05:08.975535 139925059253440 spec.py:333] Evaluating on the validation split.
I0314 23:05:50.329890 139925059253440 spec.py:349] Evaluating on the test split.
I0314 23:05:51.439180 139925059253440 submission_runner.py:469] Time since start: 5265.41s, 	Step: 5569, 	{'train/accuracy': 0.5506218112244898, 'train/loss': 1.98255967120735, 'validation/accuracy': 0.5127, 'validation/loss': 2.16876578125, 'validation/num_examples': 50000, 'test/accuracy': 0.3872, 'test/loss': 2.8830830078125, 'test/num_examples': 10000, 'score': 4178.118154764175, 'total_duration': 5265.413460493088, 'accumulated_submission_time': 4178.118154764175, 'accumulated_eval_time': 1060.8057141304016, 'accumulated_logging_time': 0.3684208393096924}
I0314 23:05:51.449748 139896110970624 logging_writer.py:48] [5569] accumulated_eval_time=1060.81, accumulated_logging_time=0.368421, accumulated_submission_time=4178.12, global_step=5569, preemption_count=0, score=4178.12, test/accuracy=0.3872, test/loss=2.88308, test/num_examples=10000, total_duration=5265.41, train/accuracy=0.550622, train/loss=1.98256, validation/accuracy=0.5127, validation/loss=2.16877, validation/num_examples=50000
I0314 23:10:25.541687 139896463251200 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.966792, loss=3.20991
I0314 23:10:25.562098 139925059253440 submission.py:265] 6000) loss = 3.210, grad_norm = 0.967
I0314 23:14:23.949211 139925059253440 spec.py:321] Evaluating on the training split.
I0314 23:15:04.894948 139925059253440 spec.py:333] Evaluating on the validation split.
I0314 23:15:45.281573 139925059253440 spec.py:349] Evaluating on the test split.
I0314 23:15:46.384541 139925059253440 submission_runner.py:469] Time since start: 5860.36s, 	Step: 6256, 	{'train/accuracy': 0.5708705357142857, 'train/loss': 1.9034056371572066, 'validation/accuracy': 0.53218, 'validation/loss': 2.07280328125, 'validation/num_examples': 50000, 'test/accuracy': 0.3986, 'test/loss': 2.849094140625, 'test/num_examples': 10000, 'score': 4687.382040262222, 'total_duration': 5860.358816385269, 'accumulated_submission_time': 4687.382040262222, 'accumulated_eval_time': 1143.2412989139557, 'accumulated_logging_time': 0.3878462314605713}
I0314 23:15:46.400274 139896110970624 logging_writer.py:48] [6256] accumulated_eval_time=1143.24, accumulated_logging_time=0.387846, accumulated_submission_time=4687.38, global_step=6256, preemption_count=0, score=4687.38, test/accuracy=0.3986, test/loss=2.84909, test/num_examples=10000, total_duration=5860.36, train/accuracy=0.570871, train/loss=1.90341, validation/accuracy=0.53218, validation/loss=2.0728, validation/num_examples=50000
I0314 23:17:26.355325 139896463251200 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.976434, loss=3.1488
I0314 23:17:26.359477 139925059253440 submission.py:265] 6500) loss = 3.149, grad_norm = 0.976
I0314 23:21:13.617000 139896110970624 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.98527, loss=3.09608
I0314 23:21:13.630134 139925059253440 submission.py:265] 7000) loss = 3.096, grad_norm = 0.985
I0314 23:24:18.254455 139925059253440 spec.py:321] Evaluating on the training split.
I0314 23:24:57.277169 139925059253440 spec.py:333] Evaluating on the validation split.
I0314 23:25:37.848718 139925059253440 spec.py:349] Evaluating on the test split.
I0314 23:25:38.954380 139925059253440 submission_runner.py:469] Time since start: 6452.93s, 	Step: 7265, 	{'train/accuracy': 0.5860770089285714, 'train/loss': 1.865480695452009, 'validation/accuracy': 0.54092, 'validation/loss': 2.0557559375, 'validation/num_examples': 50000, 'test/accuracy': 0.4006, 'test/loss': 2.8008642578125, 'test/num_examples': 10000, 'score': 5195.943376302719, 'total_duration': 6452.928684949875, 'accumulated_submission_time': 5195.943376302719, 'accumulated_eval_time': 1223.9414556026459, 'accumulated_logging_time': 0.4116635322570801}
I0314 23:25:38.987741 139896463251200 logging_writer.py:48] [7265] accumulated_eval_time=1223.94, accumulated_logging_time=0.411664, accumulated_submission_time=5195.94, global_step=7265, preemption_count=0, score=5195.94, test/accuracy=0.4006, test/loss=2.80086, test/num_examples=10000, total_duration=6452.93, train/accuracy=0.586077, train/loss=1.86548, validation/accuracy=0.54092, validation/loss=2.05576, validation/num_examples=50000
I0314 23:29:24.938938 139896110970624 logging_writer.py:48] [7500] global_step=7500, grad_norm=1.00133, loss=3.10542
I0314 23:29:24.943060 139925059253440 submission.py:265] 7500) loss = 3.105, grad_norm = 1.001
I0314 23:32:51.595269 139896463251200 logging_writer.py:48] [8000] global_step=8000, grad_norm=1.0048, loss=3.02725
I0314 23:32:51.599634 139925059253440 submission.py:265] 8000) loss = 3.027, grad_norm = 1.005
I0314 23:34:10.551150 139925059253440 spec.py:321] Evaluating on the training split.
I0314 23:34:50.203649 139925059253440 spec.py:333] Evaluating on the validation split.
I0314 23:35:31.248189 139925059253440 spec.py:349] Evaluating on the test split.
I0314 23:35:32.355293 139925059253440 submission_runner.py:469] Time since start: 7046.33s, 	Step: 8168, 	{'train/accuracy': 0.6065250318877551, 'train/loss': 1.7365006427375638, 'validation/accuracy': 0.56104, 'validation/loss': 1.9276584375, 'validation/num_examples': 50000, 'test/accuracy': 0.4234, 'test/loss': 2.697825390625, 'test/num_examples': 10000, 'score': 5704.216891288757, 'total_duration': 7046.32958483696, 'accumulated_submission_time': 5704.216891288757, 'accumulated_eval_time': 1305.745949268341, 'accumulated_logging_time': 0.4677109718322754}
I0314 23:35:32.366765 139896110970624 logging_writer.py:48] [8168] accumulated_eval_time=1305.75, accumulated_logging_time=0.467711, accumulated_submission_time=5704.22, global_step=8168, preemption_count=0, score=5704.22, test/accuracy=0.4234, test/loss=2.69783, test/num_examples=10000, total_duration=7046.33, train/accuracy=0.606525, train/loss=1.7365, validation/accuracy=0.56104, validation/loss=1.92766, validation/num_examples=50000
I0314 23:39:07.652504 139896463251200 logging_writer.py:48] [8500] global_step=8500, grad_norm=1.01115, loss=3.00962
I0314 23:39:07.676533 139925059253440 submission.py:265] 8500) loss = 3.010, grad_norm = 1.011
I0314 23:44:04.087557 139925059253440 spec.py:321] Evaluating on the training split.
I0314 23:44:43.091384 139925059253440 spec.py:333] Evaluating on the validation split.
I0314 23:45:23.474012 139925059253440 spec.py:349] Evaluating on the test split.
I0314 23:45:24.577116 139925059253440 submission_runner.py:469] Time since start: 7638.55s, 	Step: 8880, 	{'train/accuracy': 0.6073620854591837, 'train/loss': 1.7228887129803092, 'validation/accuracy': 0.56194, 'validation/loss': 1.9178409375, 'validation/num_examples': 50000, 'test/accuracy': 0.4119, 'test/loss': 2.74017890625, 'test/num_examples': 10000, 'score': 6212.764410734177, 'total_duration': 7638.551360845566, 'accumulated_submission_time': 6212.764410734177, 'accumulated_eval_time': 1386.2355909347534, 'accumulated_logging_time': 0.48870372772216797}
I0314 23:45:24.631867 139896110970624 logging_writer.py:48] [8880] accumulated_eval_time=1386.24, accumulated_logging_time=0.488704, accumulated_submission_time=6212.76, global_step=8880, preemption_count=0, score=6212.76, test/accuracy=0.4119, test/loss=2.74018, test/num_examples=10000, total_duration=7638.55, train/accuracy=0.607362, train/loss=1.72289, validation/accuracy=0.56194, validation/loss=1.91784, validation/num_examples=50000
I0314 23:46:15.926796 139896463251200 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.985596, loss=2.98226
I0314 23:46:15.941056 139925059253440 submission.py:265] 9000) loss = 2.982, grad_norm = 0.986
I0314 23:49:42.627550 139896110970624 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.993966, loss=2.97733
I0314 23:49:42.631944 139925059253440 submission.py:265] 9500) loss = 2.977, grad_norm = 0.994
I0314 23:53:56.984266 139925059253440 spec.py:321] Evaluating on the training split.
I0314 23:54:38.318595 139925059253440 spec.py:333] Evaluating on the validation split.
I0314 23:55:19.507304 139925059253440 spec.py:349] Evaluating on the test split.
I0314 23:55:20.613922 139925059253440 submission_runner.py:469] Time since start: 8234.59s, 	Step: 9865, 	{'train/accuracy': 0.6216916454081632, 'train/loss': 1.666939404545998, 'validation/accuracy': 0.57604, 'validation/loss': 1.87018359375, 'validation/num_examples': 50000, 'test/accuracy': 0.438, 'test/loss': 2.6048619140625, 'test/num_examples': 10000, 'score': 6721.821131229401, 'total_duration': 8234.588216304779, 'accumulated_submission_time': 6721.821131229401, 'accumulated_eval_time': 1469.8654177188873, 'accumulated_logging_time': 0.5521407127380371}
I0314 23:55:20.661417 139896463251200 logging_writer.py:48] [9865] accumulated_eval_time=1469.87, accumulated_logging_time=0.552141, accumulated_submission_time=6721.82, global_step=9865, preemption_count=0, score=6721.82, test/accuracy=0.438, test/loss=2.60486, test/num_examples=10000, total_duration=8234.59, train/accuracy=0.621692, train/loss=1.66694, validation/accuracy=0.57604, validation/loss=1.87018, validation/num_examples=50000
I0314 23:57:45.075716 139896110970624 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.955025, loss=2.9227
I0314 23:57:45.079440 139925059253440 submission.py:265] 10000) loss = 2.923, grad_norm = 0.955
I0315 00:01:30.565286 139896463251200 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.988273, loss=2.92677
I0315 00:01:30.569606 139925059253440 submission.py:265] 10500) loss = 2.927, grad_norm = 0.988
I0315 00:03:52.249233 139925059253440 spec.py:321] Evaluating on the training split.
I0315 00:04:32.411710 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 00:05:12.596580 139925059253440 spec.py:349] Evaluating on the test split.
I0315 00:05:13.707591 139925059253440 submission_runner.py:469] Time since start: 8827.68s, 	Step: 10765, 	{'train/accuracy': 0.6248405612244898, 'train/loss': 1.6267888594646842, 'validation/accuracy': 0.58006, 'validation/loss': 1.84031734375, 'validation/num_examples': 50000, 'test/accuracy': 0.4454, 'test/loss': 2.559526171875, 'test/num_examples': 10000, 'score': 7230.052751541138, 'total_duration': 8827.681890964508, 'accumulated_submission_time': 7230.052751541138, 'accumulated_eval_time': 1551.3239657878876, 'accumulated_logging_time': 0.6205580234527588}
I0315 00:05:13.717714 139896110970624 logging_writer.py:48] [10765] accumulated_eval_time=1551.32, accumulated_logging_time=0.620558, accumulated_submission_time=7230.05, global_step=10765, preemption_count=0, score=7230.05, test/accuracy=0.4454, test/loss=2.55953, test/num_examples=10000, total_duration=8827.68, train/accuracy=0.624841, train/loss=1.62679, validation/accuracy=0.58006, validation/loss=1.84032, validation/num_examples=50000
I0315 00:08:11.192204 139896463251200 logging_writer.py:48] [11000] global_step=11000, grad_norm=1.05435, loss=2.85518
I0315 00:08:11.196666 139925059253440 submission.py:265] 11000) loss = 2.855, grad_norm = 1.054
I0315 00:13:45.321914 139925059253440 spec.py:321] Evaluating on the training split.
I0315 00:14:24.455247 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 00:15:05.290742 139925059253440 spec.py:349] Evaluating on the test split.
I0315 00:15:06.397475 139925059253440 submission_runner.py:469] Time since start: 9420.37s, 	Step: 11459, 	{'train/accuracy': 0.6271125637755102, 'train/loss': 1.6297088934450734, 'validation/accuracy': 0.57922, 'validation/loss': 1.838754375, 'validation/num_examples': 50000, 'test/accuracy': 0.454, 'test/loss': 2.5172078125, 'test/num_examples': 10000, 'score': 7738.480170965195, 'total_duration': 9420.371783971786, 'accumulated_submission_time': 7738.480170965195, 'accumulated_eval_time': 1632.3996999263763, 'accumulated_logging_time': 0.6392207145690918}
I0315 00:15:06.408292 139896110970624 logging_writer.py:48] [11459] accumulated_eval_time=1632.4, accumulated_logging_time=0.639221, accumulated_submission_time=7738.48, global_step=11459, preemption_count=0, score=7738.48, test/accuracy=0.454, test/loss=2.51721, test/num_examples=10000, total_duration=9420.37, train/accuracy=0.627113, train/loss=1.62971, validation/accuracy=0.57922, validation/loss=1.83875, validation/num_examples=50000
I0315 00:15:25.481775 139896463251200 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.983586, loss=2.80674
I0315 00:15:25.485704 139925059253440 submission.py:265] 11500) loss = 2.807, grad_norm = 0.984
I0315 00:19:31.341627 139896110970624 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.99052, loss=2.87173
I0315 00:19:31.355465 139925059253440 submission.py:265] 12000) loss = 2.872, grad_norm = 0.991
I0315 00:23:39.592212 139925059253440 spec.py:321] Evaluating on the training split.
I0315 00:24:19.445121 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 00:25:01.280636 139925059253440 spec.py:349] Evaluating on the test split.
I0315 00:25:02.399865 139925059253440 submission_runner.py:469] Time since start: 10016.37s, 	Step: 12323, 	{'train/accuracy': 0.6315768494897959, 'train/loss': 1.602774950922752, 'validation/accuracy': 0.58344, 'validation/loss': 1.82060375, 'validation/num_examples': 50000, 'test/accuracy': 0.4515, 'test/loss': 2.567936328125, 'test/num_examples': 10000, 'score': 8248.43051981926, 'total_duration': 10016.374151229858, 'accumulated_submission_time': 8248.43051981926, 'accumulated_eval_time': 1715.2075335979462, 'accumulated_logging_time': 0.6583881378173828}
I0315 00:25:02.429227 139896463251200 logging_writer.py:48] [12323] accumulated_eval_time=1715.21, accumulated_logging_time=0.658388, accumulated_submission_time=8248.43, global_step=12323, preemption_count=0, score=8248.43, test/accuracy=0.4515, test/loss=2.56794, test/num_examples=10000, total_duration=10016.4, train/accuracy=0.631577, train/loss=1.60277, validation/accuracy=0.58344, validation/loss=1.8206, validation/num_examples=50000
I0315 00:28:00.610078 139896110970624 logging_writer.py:48] [12500] global_step=12500, grad_norm=1.05934, loss=2.95697
I0315 00:28:00.614278 139925059253440 submission.py:265] 12500) loss = 2.957, grad_norm = 1.059
I0315 00:31:36.139106 139896463251200 logging_writer.py:48] [13000] global_step=13000, grad_norm=1.059, loss=2.82279
I0315 00:31:36.150524 139925059253440 submission.py:265] 13000) loss = 2.823, grad_norm = 1.059
I0315 00:33:34.241706 139925059253440 spec.py:321] Evaluating on the training split.
I0315 00:34:13.939920 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 00:34:54.657337 139925059253440 spec.py:349] Evaluating on the test split.
I0315 00:34:55.763010 139925059253440 submission_runner.py:469] Time since start: 10609.74s, 	Step: 13228, 	{'train/accuracy': 0.6381935586734694, 'train/loss': 1.603255914182079, 'validation/accuracy': 0.58996, 'validation/loss': 1.819635625, 'validation/num_examples': 50000, 'test/accuracy': 0.4529, 'test/loss': 2.5703978515625, 'test/num_examples': 10000, 'score': 8756.915067911148, 'total_duration': 10609.737285852432, 'accumulated_submission_time': 8756.915067911148, 'accumulated_eval_time': 1796.7290258407593, 'accumulated_logging_time': 0.697404146194458}
I0315 00:34:55.773565 139896110970624 logging_writer.py:48] [13228] accumulated_eval_time=1796.73, accumulated_logging_time=0.697404, accumulated_submission_time=8756.92, global_step=13228, preemption_count=0, score=8756.92, test/accuracy=0.4529, test/loss=2.5704, test/num_examples=10000, total_duration=10609.7, train/accuracy=0.638194, train/loss=1.60326, validation/accuracy=0.58996, validation/loss=1.81964, validation/num_examples=50000
I0315 00:38:15.891205 139896463251200 logging_writer.py:48] [13500] global_step=13500, grad_norm=1.02739, loss=2.83777
I0315 00:38:15.895500 139925059253440 submission.py:265] 13500) loss = 2.838, grad_norm = 1.027
I0315 00:43:27.479638 139925059253440 spec.py:321] Evaluating on the training split.
I0315 00:44:05.983725 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 00:44:46.727499 139925059253440 spec.py:349] Evaluating on the test split.
I0315 00:44:47.834027 139925059253440 submission_runner.py:469] Time since start: 11201.81s, 	Step: 13885, 	{'train/accuracy': 0.6509885204081632, 'train/loss': 1.5312781820491868, 'validation/accuracy': 0.60114, 'validation/loss': 1.749699375, 'validation/num_examples': 50000, 'test/accuracy': 0.4654, 'test/loss': 2.4881814453125, 'test/num_examples': 10000, 'score': 9265.61754322052, 'total_duration': 11201.808292865753, 'accumulated_submission_time': 9265.61754322052, 'accumulated_eval_time': 1877.0836174488068, 'accumulated_logging_time': 0.7166333198547363}
I0315 00:44:47.866413 139896110970624 logging_writer.py:48] [13885] accumulated_eval_time=1877.08, accumulated_logging_time=0.716633, accumulated_submission_time=9265.62, global_step=13885, preemption_count=0, score=9265.62, test/accuracy=0.4654, test/loss=2.48818, test/num_examples=10000, total_duration=11201.8, train/accuracy=0.650989, train/loss=1.53128, validation/accuracy=0.60114, validation/loss=1.7497, validation/num_examples=50000
I0315 00:45:38.824109 139896463251200 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.992046, loss=2.76224
I0315 00:45:38.828029 139925059253440 submission.py:265] 14000) loss = 2.762, grad_norm = 0.992
I0315 00:49:45.744981 139896110970624 logging_writer.py:48] [14500] global_step=14500, grad_norm=1.06423, loss=2.80243
I0315 00:49:45.748917 139925059253440 submission.py:265] 14500) loss = 2.802, grad_norm = 1.064
I0315 00:53:20.476433 139925059253440 spec.py:321] Evaluating on the training split.
I0315 00:53:59.343486 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 00:54:40.553735 139925059253440 spec.py:349] Evaluating on the test split.
I0315 00:54:41.655195 139925059253440 submission_runner.py:469] Time since start: 11795.63s, 	Step: 14779, 	{'train/accuracy': 0.6494339923469388, 'train/loss': 1.501454411720743, 'validation/accuracy': 0.60028, 'validation/loss': 1.72192078125, 'validation/num_examples': 50000, 'test/accuracy': 0.4696, 'test/loss': 2.4237791015625, 'test/num_examples': 10000, 'score': 9775.070176839828, 'total_duration': 11795.629420518875, 'accumulated_submission_time': 9775.070176839828, 'accumulated_eval_time': 1958.262563943863, 'accumulated_logging_time': 0.7706775665283203}
I0315 00:54:41.667056 139896463251200 logging_writer.py:48] [14779] accumulated_eval_time=1958.26, accumulated_logging_time=0.770678, accumulated_submission_time=9775.07, global_step=14779, preemption_count=0, score=9775.07, test/accuracy=0.4696, test/loss=2.42378, test/num_examples=10000, total_duration=11795.6, train/accuracy=0.649434, train/loss=1.50145, validation/accuracy=0.60028, validation/loss=1.72192, validation/num_examples=50000
I0315 00:58:31.027924 139896110970624 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.986071, loss=2.77332
I0315 00:58:31.065503 139925059253440 submission.py:265] 15000) loss = 2.773, grad_norm = 0.986
I0315 01:02:11.748258 139896463251200 logging_writer.py:48] [15500] global_step=15500, grad_norm=1.02205, loss=2.74859
I0315 01:02:11.752304 139925059253440 submission.py:265] 15500) loss = 2.749, grad_norm = 1.022
I0315 01:03:13.157890 139925059253440 spec.py:321] Evaluating on the training split.
I0315 01:03:52.124062 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 01:04:33.531060 139925059253440 spec.py:349] Evaluating on the test split.
I0315 01:04:34.637154 139925059253440 submission_runner.py:469] Time since start: 12388.61s, 	Step: 15621, 	{'train/accuracy': 0.6496731505102041, 'train/loss': 1.5467003024354273, 'validation/accuracy': 0.60586, 'validation/loss': 1.75280125, 'validation/num_examples': 50000, 'test/accuracy': 0.4696, 'test/loss': 2.4984009765625, 'test/num_examples': 10000, 'score': 10283.316243886948, 'total_duration': 12388.611430644989, 'accumulated_submission_time': 10283.316243886948, 'accumulated_eval_time': 2039.7419390678406, 'accumulated_logging_time': 0.7911643981933594}
I0315 01:04:34.648693 139896110970624 logging_writer.py:48] [15621] accumulated_eval_time=2039.74, accumulated_logging_time=0.791164, accumulated_submission_time=10283.3, global_step=15621, preemption_count=0, score=10283.3, test/accuracy=0.4696, test/loss=2.4984, test/num_examples=10000, total_duration=12388.6, train/accuracy=0.649673, train/loss=1.5467, validation/accuracy=0.60586, validation/loss=1.7528, validation/num_examples=50000
I0315 01:08:52.441810 139896463251200 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.971937, loss=2.77232
I0315 01:08:52.446035 139925059253440 submission.py:265] 16000) loss = 2.772, grad_norm = 0.972
I0315 01:13:06.491414 139925059253440 spec.py:321] Evaluating on the training split.
I0315 01:13:46.199521 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 01:14:26.672033 139925059253440 spec.py:349] Evaluating on the test split.
I0315 01:14:27.778767 139925059253440 submission_runner.py:469] Time since start: 12981.75s, 	Step: 16248, 	{'train/accuracy': 0.6462651466836735, 'train/loss': 1.5586968246771364, 'validation/accuracy': 0.59826, 'validation/loss': 1.7781103125, 'validation/num_examples': 50000, 'test/accuracy': 0.4582, 'test/loss': 2.515841796875, 'test/num_examples': 10000, 'score': 10792.28248333931, 'total_duration': 12981.753015756607, 'accumulated_submission_time': 10792.28248333931, 'accumulated_eval_time': 2121.02946972847, 'accumulated_logging_time': 0.8111519813537598}
I0315 01:14:27.806592 139896110970624 logging_writer.py:48] [16248] accumulated_eval_time=2121.03, accumulated_logging_time=0.811152, accumulated_submission_time=10792.3, global_step=16248, preemption_count=0, score=10792.3, test/accuracy=0.4582, test/loss=2.51584, test/num_examples=10000, total_duration=12981.8, train/accuracy=0.646265, train/loss=1.5587, validation/accuracy=0.59826, validation/loss=1.77811, validation/num_examples=50000
I0315 01:16:23.452136 139896463251200 logging_writer.py:48] [16500] global_step=16500, grad_norm=1.00159, loss=2.77953
I0315 01:16:23.456317 139925059253440 submission.py:265] 16500) loss = 2.780, grad_norm = 1.002
I0315 01:20:23.794368 139896110970624 logging_writer.py:48] [17000] global_step=17000, grad_norm=1.07278, loss=2.84941
I0315 01:20:23.798987 139925059253440 submission.py:265] 17000) loss = 2.849, grad_norm = 1.073
I0315 01:22:59.337971 139925059253440 spec.py:321] Evaluating on the training split.
I0315 01:23:38.283021 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 01:24:18.208111 139925059253440 spec.py:349] Evaluating on the test split.
I0315 01:24:19.315387 139925059253440 submission_runner.py:469] Time since start: 13573.29s, 	Step: 17214, 	{'train/accuracy': 0.6556521045918368, 'train/loss': 1.514524187360491, 'validation/accuracy': 0.6083, 'validation/loss': 1.72887, 'validation/num_examples': 50000, 'test/accuracy': 0.4717, 'test/loss': 2.4427814453125, 'test/num_examples': 10000, 'score': 11300.4684882164, 'total_duration': 13573.289619922638, 'accumulated_submission_time': 11300.4684882164, 'accumulated_eval_time': 2201.007009744644, 'accumulated_logging_time': 0.9038207530975342}
I0315 01:24:19.326890 139896463251200 logging_writer.py:48] [17214] accumulated_eval_time=2201.01, accumulated_logging_time=0.903821, accumulated_submission_time=11300.5, global_step=17214, preemption_count=0, score=11300.5, test/accuracy=0.4717, test/loss=2.44278, test/num_examples=10000, total_duration=13573.3, train/accuracy=0.655652, train/loss=1.51452, validation/accuracy=0.6083, validation/loss=1.72887, validation/num_examples=50000
I0315 01:29:04.522200 139896110970624 logging_writer.py:48] [17500] global_step=17500, grad_norm=1.04072, loss=2.84825
I0315 01:29:04.553704 139925059253440 submission.py:265] 17500) loss = 2.848, grad_norm = 1.041
I0315 01:32:46.636234 139896463251200 logging_writer.py:48] [18000] global_step=18000, grad_norm=1.03844, loss=2.78736
I0315 01:32:46.640851 139925059253440 submission.py:265] 18000) loss = 2.787, grad_norm = 1.038
I0315 01:32:50.804471 139925059253440 spec.py:321] Evaluating on the training split.
I0315 01:33:30.167607 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 01:34:10.817626 139925059253440 spec.py:349] Evaluating on the test split.
I0315 01:34:11.917522 139925059253440 submission_runner.py:469] Time since start: 14165.89s, 	Step: 18008, 	{'train/accuracy': 0.6623684630102041, 'train/loss': 1.468217032296317, 'validation/accuracy': 0.6116, 'validation/loss': 1.6902753125, 'validation/num_examples': 50000, 'test/accuracy': 0.4662, 'test/loss': 2.4455240234375, 'test/num_examples': 10000, 'score': 11808.709686994553, 'total_duration': 14165.89183139801, 'accumulated_submission_time': 11808.709686994553, 'accumulated_eval_time': 2282.120290994644, 'accumulated_logging_time': 0.9232122898101807}
I0315 01:34:11.927729 139896110970624 logging_writer.py:48] [18008] accumulated_eval_time=2282.12, accumulated_logging_time=0.923212, accumulated_submission_time=11808.7, global_step=18008, preemption_count=0, score=11808.7, test/accuracy=0.4662, test/loss=2.44552, test/num_examples=10000, total_duration=14165.9, train/accuracy=0.662368, train/loss=1.46822, validation/accuracy=0.6116, validation/loss=1.69028, validation/num_examples=50000
I0315 01:39:30.831770 139896463251200 logging_writer.py:48] [18500] global_step=18500, grad_norm=1.00336, loss=2.82001
I0315 01:39:30.835704 139925059253440 submission.py:265] 18500) loss = 2.820, grad_norm = 1.003
I0315 01:42:44.084552 139925059253440 spec.py:321] Evaluating on the training split.
I0315 01:43:22.764008 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 01:44:03.376638 139925059253440 spec.py:349] Evaluating on the test split.
I0315 01:44:04.483381 139925059253440 submission_runner.py:469] Time since start: 14758.46s, 	Step: 18697, 	{'train/accuracy': 0.6581632653061225, 'train/loss': 1.4852329176299426, 'validation/accuracy': 0.60772, 'validation/loss': 1.71311515625, 'validation/num_examples': 50000, 'test/accuracy': 0.4711, 'test/loss': 2.46288984375, 'test/num_examples': 10000, 'score': 12317.72209906578, 'total_duration': 14758.457606554031, 'accumulated_submission_time': 12317.72209906578, 'accumulated_eval_time': 2362.5193288326263, 'accumulated_logging_time': 0.9413371086120605}
I0315 01:44:04.559032 139896110970624 logging_writer.py:48] [18697] accumulated_eval_time=2362.52, accumulated_logging_time=0.941337, accumulated_submission_time=12317.7, global_step=18697, preemption_count=0, score=12317.7, test/accuracy=0.4711, test/loss=2.46289, test/num_examples=10000, total_duration=14758.5, train/accuracy=0.658163, train/loss=1.48523, validation/accuracy=0.60772, validation/loss=1.71312, validation/num_examples=50000
I0315 01:46:52.781398 139896463251200 logging_writer.py:48] [19000] global_step=19000, grad_norm=1.01989, loss=2.74253
I0315 01:46:52.804109 139925059253440 submission.py:265] 19000) loss = 2.743, grad_norm = 1.020
I0315 01:51:00.822056 139896110970624 logging_writer.py:48] [19500] global_step=19500, grad_norm=1.07958, loss=2.69731
I0315 01:51:00.826395 139925059253440 submission.py:265] 19500) loss = 2.697, grad_norm = 1.080
I0315 01:52:36.185261 139925059253440 spec.py:321] Evaluating on the training split.
I0315 01:53:15.212884 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 01:53:55.466584 139925059253440 spec.py:349] Evaluating on the test split.
I0315 01:53:56.567718 139925059253440 submission_runner.py:469] Time since start: 15350.54s, 	Step: 19646, 	{'train/accuracy': 0.6605548469387755, 'train/loss': 1.499438071737484, 'validation/accuracy': 0.61188, 'validation/loss': 1.7142309375, 'validation/num_examples': 50000, 'test/accuracy': 0.4725, 'test/loss': 2.4208578125, 'test/num_examples': 10000, 'score': 12826.070837259293, 'total_duration': 15350.541978597641, 'accumulated_submission_time': 12826.070837259293, 'accumulated_eval_time': 2442.901951789856, 'accumulated_logging_time': 1.0455667972564697}
I0315 01:53:56.578730 139896463251200 logging_writer.py:48] [19646] accumulated_eval_time=2442.9, accumulated_logging_time=1.04557, accumulated_submission_time=12826.1, global_step=19646, preemption_count=0, score=12826.1, test/accuracy=0.4725, test/loss=2.42086, test/num_examples=10000, total_duration=15350.5, train/accuracy=0.660555, train/loss=1.49944, validation/accuracy=0.61188, validation/loss=1.71423, validation/num_examples=50000
I0315 01:59:33.935276 139896110970624 logging_writer.py:48] [20000] global_step=20000, grad_norm=1.03585, loss=2.76865
I0315 01:59:33.950769 139925059253440 submission.py:265] 20000) loss = 2.769, grad_norm = 1.036
I0315 02:02:28.248798 139925059253440 spec.py:321] Evaluating on the training split.
I0315 02:03:07.036547 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 02:03:47.350831 139925059253440 spec.py:349] Evaluating on the test split.
I0315 02:03:48.453860 139925059253440 submission_runner.py:469] Time since start: 15942.43s, 	Step: 20398, 	{'train/accuracy': 0.6627471301020408, 'train/loss': 1.4753821236746651, 'validation/accuracy': 0.61246, 'validation/loss': 1.69695796875, 'validation/num_examples': 50000, 'test/accuracy': 0.4694, 'test/loss': 2.44257890625, 'test/num_examples': 10000, 'score': 13334.506560325623, 'total_duration': 15942.428157567978, 'accumulated_submission_time': 13334.506560325623, 'accumulated_eval_time': 2523.1072075366974, 'accumulated_logging_time': 1.0647289752960205}
I0315 02:03:48.464933 139896463251200 logging_writer.py:48] [20398] accumulated_eval_time=2523.11, accumulated_logging_time=1.06473, accumulated_submission_time=13334.5, global_step=20398, preemption_count=0, score=13334.5, test/accuracy=0.4694, test/loss=2.44258, test/num_examples=10000, total_duration=15942.4, train/accuracy=0.662747, train/loss=1.47538, validation/accuracy=0.61246, validation/loss=1.69696, validation/num_examples=50000
I0315 02:04:40.451154 139896110970624 logging_writer.py:48] [20500] global_step=20500, grad_norm=1.03609, loss=2.74894
I0315 02:04:40.455354 139925059253440 submission.py:265] 20500) loss = 2.749, grad_norm = 1.036
I0315 02:09:48.512740 139896463251200 logging_writer.py:48] [21000] global_step=21000, grad_norm=1.00954, loss=2.68915
I0315 02:09:48.523613 139925059253440 submission.py:265] 21000) loss = 2.689, grad_norm = 1.010
I0315 02:12:20.132589 139925059253440 spec.py:321] Evaluating on the training split.
I0315 02:12:58.435800 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 02:13:38.975989 139925059253440 spec.py:349] Evaluating on the test split.
I0315 02:13:40.078359 139925059253440 submission_runner.py:469] Time since start: 16534.05s, 	Step: 21158, 	{'train/accuracy': 0.6602359693877551, 'train/loss': 1.4762596597476882, 'validation/accuracy': 0.61548, 'validation/loss': 1.68282984375, 'validation/num_examples': 50000, 'test/accuracy': 0.479, 'test/loss': 2.400184375, 'test/num_examples': 10000, 'score': 13843.056567668915, 'total_duration': 16534.05265522003, 'accumulated_submission_time': 13843.056567668915, 'accumulated_eval_time': 2603.0532104969025, 'accumulated_logging_time': 1.0839827060699463}
I0315 02:13:40.127583 139896110970624 logging_writer.py:48] [21158] accumulated_eval_time=2603.05, accumulated_logging_time=1.08398, accumulated_submission_time=13843.1, global_step=21158, preemption_count=0, score=13843.1, test/accuracy=0.479, test/loss=2.40018, test/num_examples=10000, total_duration=16534.1, train/accuracy=0.660236, train/loss=1.47626, validation/accuracy=0.61548, validation/loss=1.68283, validation/num_examples=50000
I0315 02:17:13.908766 139896463251200 logging_writer.py:48] [21500] global_step=21500, grad_norm=1.05301, loss=2.74383
I0315 02:17:13.928210 139925059253440 submission.py:265] 21500) loss = 2.744, grad_norm = 1.053
I0315 02:21:15.980963 139896110970624 logging_writer.py:48] [22000] global_step=22000, grad_norm=1.06063, loss=2.85567
I0315 02:21:15.984936 139925059253440 submission.py:265] 22000) loss = 2.856, grad_norm = 1.061
I0315 02:22:11.706563 139925059253440 spec.py:321] Evaluating on the training split.
I0315 02:22:51.520353 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 02:23:32.303755 139925059253440 spec.py:349] Evaluating on the test split.
I0315 02:23:33.404796 139925059253440 submission_runner.py:469] Time since start: 17127.38s, 	Step: 22082, 	{'train/accuracy': 0.6717753507653061, 'train/loss': 1.436492141412229, 'validation/accuracy': 0.61956, 'validation/loss': 1.651159375, 'validation/num_examples': 50000, 'test/accuracy': 0.4895, 'test/loss': 2.3626853515625, 'test/num_examples': 10000, 'score': 14351.371251821518, 'total_duration': 17127.379098653793, 'accumulated_submission_time': 14351.371251821518, 'accumulated_eval_time': 2684.751639842987, 'accumulated_logging_time': 1.1409130096435547}
I0315 02:23:33.415401 139896463251200 logging_writer.py:48] [22082] accumulated_eval_time=2684.75, accumulated_logging_time=1.14091, accumulated_submission_time=14351.4, global_step=22082, preemption_count=0, score=14351.4, test/accuracy=0.4895, test/loss=2.36269, test/num_examples=10000, total_duration=17127.4, train/accuracy=0.671775, train/loss=1.43649, validation/accuracy=0.61956, validation/loss=1.65116, validation/num_examples=50000
I0315 02:29:37.126900 139896110970624 logging_writer.py:48] [22500] global_step=22500, grad_norm=1.01399, loss=2.75826
I0315 02:29:37.131377 139925059253440 submission.py:265] 22500) loss = 2.758, grad_norm = 1.014
I0315 02:32:05.108774 139925059253440 spec.py:321] Evaluating on the training split.
I0315 02:32:43.652302 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 02:33:24.782404 139925059253440 spec.py:349] Evaluating on the test split.
I0315 02:33:25.891384 139925059253440 submission_runner.py:469] Time since start: 17719.87s, 	Step: 22838, 	{'train/accuracy': 0.6655173788265306, 'train/loss': 1.4351305280412947, 'validation/accuracy': 0.6116, 'validation/loss': 1.66900625, 'validation/num_examples': 50000, 'test/accuracy': 0.4733, 'test/loss': 2.4145650390625, 'test/num_examples': 10000, 'score': 14859.782289743423, 'total_duration': 17719.865710496902, 'accumulated_submission_time': 14859.782289743423, 'accumulated_eval_time': 2765.5345017910004, 'accumulated_logging_time': 1.1996984481811523}
I0315 02:33:25.902234 139896463251200 logging_writer.py:48] [22838] accumulated_eval_time=2765.53, accumulated_logging_time=1.1997, accumulated_submission_time=14859.8, global_step=22838, preemption_count=0, score=14859.8, test/accuracy=0.4733, test/loss=2.41457, test/num_examples=10000, total_duration=17719.9, train/accuracy=0.665517, train/loss=1.43513, validation/accuracy=0.6116, validation/loss=1.66901, validation/num_examples=50000
I0315 02:34:42.386282 139896110970624 logging_writer.py:48] [23000] global_step=23000, grad_norm=1.0123, loss=2.7309
I0315 02:34:42.390332 139925059253440 submission.py:265] 23000) loss = 2.731, grad_norm = 1.012
I0315 02:39:54.635656 139896463251200 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.973714, loss=2.70704
I0315 02:39:54.645970 139925059253440 submission.py:265] 23500) loss = 2.707, grad_norm = 0.974
I0315 02:41:58.166598 139925059253440 spec.py:321] Evaluating on the training split.
I0315 02:42:38.924224 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 02:43:21.142018 139925059253440 spec.py:349] Evaluating on the test split.
I0315 02:43:22.244740 139925059253440 submission_runner.py:469] Time since start: 18316.22s, 	Step: 23636, 	{'train/accuracy': 0.6668526785714286, 'train/loss': 1.4203187592175541, 'validation/accuracy': 0.6147, 'validation/loss': 1.64922765625, 'validation/num_examples': 50000, 'test/accuracy': 0.4865, 'test/loss': 2.3957216796875, 'test/num_examples': 10000, 'score': 15368.868700265884, 'total_duration': 18316.21905040741, 'accumulated_submission_time': 15368.868700265884, 'accumulated_eval_time': 2849.6128475666046, 'accumulated_logging_time': 1.2188961505889893}
I0315 02:43:22.276705 139896110970624 logging_writer.py:48] [23636] accumulated_eval_time=2849.61, accumulated_logging_time=1.2189, accumulated_submission_time=15368.9, global_step=23636, preemption_count=0, score=15368.9, test/accuracy=0.4865, test/loss=2.39572, test/num_examples=10000, total_duration=18316.2, train/accuracy=0.666853, train/loss=1.42032, validation/accuracy=0.6147, validation/loss=1.64923, validation/num_examples=50000
I0315 02:47:11.607452 139896463251200 logging_writer.py:48] [24000] global_step=24000, grad_norm=1.0318, loss=2.6666
I0315 02:47:11.612018 139925059253440 submission.py:265] 24000) loss = 2.667, grad_norm = 1.032
I0315 02:51:13.209139 139896110970624 logging_writer.py:48] [24500] global_step=24500, grad_norm=1.05361, loss=2.70916
I0315 02:51:13.213428 139925059253440 submission.py:265] 24500) loss = 2.709, grad_norm = 1.054
I0315 02:51:53.718732 139925059253440 spec.py:321] Evaluating on the training split.
I0315 02:52:33.183920 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 02:53:14.845966 139925059253440 spec.py:349] Evaluating on the test split.
I0315 02:53:15.950596 139925059253440 submission_runner.py:469] Time since start: 18909.92s, 	Step: 24564, 	{'train/accuracy': 0.6751434948979592, 'train/loss': 1.4067941782425861, 'validation/accuracy': 0.62564, 'validation/loss': 1.63091375, 'validation/num_examples': 50000, 'test/accuracy': 0.4958, 'test/loss': 2.331418359375, 'test/num_examples': 10000, 'score': 15877.069551229477, 'total_duration': 18909.924867630005, 'accumulated_submission_time': 15877.069551229477, 'accumulated_eval_time': 2931.844833612442, 'accumulated_logging_time': 1.2590551376342773}
I0315 02:53:15.961983 139896463251200 logging_writer.py:48] [24564] accumulated_eval_time=2931.84, accumulated_logging_time=1.25906, accumulated_submission_time=15877.1, global_step=24564, preemption_count=0, score=15877.1, test/accuracy=0.4958, test/loss=2.33142, test/num_examples=10000, total_duration=18909.9, train/accuracy=0.675143, train/loss=1.40679, validation/accuracy=0.62564, validation/loss=1.63091, validation/num_examples=50000
I0315 02:59:38.022344 139896110970624 logging_writer.py:48] [25000] global_step=25000, grad_norm=1.01117, loss=2.72742
I0315 02:59:38.026336 139925059253440 submission.py:265] 25000) loss = 2.727, grad_norm = 1.011
I0315 03:01:47.661515 139925059253440 spec.py:321] Evaluating on the training split.
I0315 03:02:26.627702 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 03:03:06.406882 139925059253440 spec.py:349] Evaluating on the test split.
I0315 03:03:07.507733 139925059253440 submission_runner.py:469] Time since start: 19501.48s, 	Step: 25297, 	{'train/accuracy': 0.6753627232142857, 'train/loss': 1.4069919196926817, 'validation/accuracy': 0.6234, 'validation/loss': 1.63268734375, 'validation/num_examples': 50000, 'test/accuracy': 0.4854, 'test/loss': 2.36761640625, 'test/num_examples': 10000, 'score': 16385.77275443077, 'total_duration': 19501.482042074203, 'accumulated_submission_time': 16385.77275443077, 'accumulated_eval_time': 3011.691407442093, 'accumulated_logging_time': 1.2786266803741455}
I0315 03:03:07.518857 139896463251200 logging_writer.py:48] [25297] accumulated_eval_time=3011.69, accumulated_logging_time=1.27863, accumulated_submission_time=16385.8, global_step=25297, preemption_count=0, score=16385.8, test/accuracy=0.4854, test/loss=2.36762, test/num_examples=10000, total_duration=19501.5, train/accuracy=0.675363, train/loss=1.40699, validation/accuracy=0.6234, validation/loss=1.63269, validation/num_examples=50000
I0315 03:04:44.675683 139896110970624 logging_writer.py:48] [25500] global_step=25500, grad_norm=1.0448, loss=2.71593
I0315 03:04:44.707232 139925059253440 submission.py:265] 25500) loss = 2.716, grad_norm = 1.045
I0315 03:09:45.231528 139896463251200 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.997597, loss=2.67866
I0315 03:09:45.235513 139925059253440 submission.py:265] 26000) loss = 2.679, grad_norm = 0.998
I0315 03:11:39.245081 139925059253440 spec.py:321] Evaluating on the training split.
I0315 03:12:20.329589 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 03:13:02.499674 139925059253440 spec.py:349] Evaluating on the test split.
I0315 03:13:03.602056 139925059253440 submission_runner.py:469] Time since start: 20097.58s, 	Step: 26127, 	{'train/accuracy': 0.6723533163265306, 'train/loss': 1.4310687318140147, 'validation/accuracy': 0.61986, 'validation/loss': 1.66946625, 'validation/num_examples': 50000, 'test/accuracy': 0.4776, 'test/loss': 2.4187427734375, 'test/num_examples': 10000, 'score': 16894.242168426514, 'total_duration': 20097.576339244843, 'accumulated_submission_time': 16894.242168426514, 'accumulated_eval_time': 3096.0484907627106, 'accumulated_logging_time': 1.2984225749969482}
I0315 03:13:03.662708 139896110970624 logging_writer.py:48] [26127] accumulated_eval_time=3096.05, accumulated_logging_time=1.29842, accumulated_submission_time=16894.2, global_step=26127, preemption_count=0, score=16894.2, test/accuracy=0.4776, test/loss=2.41874, test/num_examples=10000, total_duration=20097.6, train/accuracy=0.672353, train/loss=1.43107, validation/accuracy=0.61986, validation/loss=1.66947, validation/num_examples=50000
I0315 03:17:03.414368 139896463251200 logging_writer.py:48] [26500] global_step=26500, grad_norm=1.02018, loss=2.78808
I0315 03:17:03.458514 139925059253440 submission.py:265] 26500) loss = 2.788, grad_norm = 1.020
I0315 03:20:54.354285 139896110970624 logging_writer.py:48] [27000] global_step=27000, grad_norm=1.06024, loss=2.75984
I0315 03:20:54.358453 139925059253440 submission.py:265] 27000) loss = 2.760, grad_norm = 1.060
I0315 03:21:35.280282 139925059253440 spec.py:321] Evaluating on the training split.
I0315 03:22:16.044135 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 03:22:57.178219 139925059253440 spec.py:349] Evaluating on the test split.
I0315 03:22:58.289887 139925059253440 submission_runner.py:469] Time since start: 20692.26s, 	Step: 27068, 	{'train/accuracy': 0.6677295918367347, 'train/loss': 1.458228130729831, 'validation/accuracy': 0.61486, 'validation/loss': 1.68823765625, 'validation/num_examples': 50000, 'test/accuracy': 0.4896, 'test/loss': 2.373322265625, 'test/num_examples': 10000, 'score': 17402.449024677277, 'total_duration': 20692.264118433, 'accumulated_submission_time': 17402.449024677277, 'accumulated_eval_time': 3179.0582723617554, 'accumulated_logging_time': 1.3680493831634521}
I0315 03:22:58.301295 139896463251200 logging_writer.py:48] [27068] accumulated_eval_time=3179.06, accumulated_logging_time=1.36805, accumulated_submission_time=17402.4, global_step=27068, preemption_count=0, score=17402.4, test/accuracy=0.4896, test/loss=2.37332, test/num_examples=10000, total_duration=20692.3, train/accuracy=0.66773, train/loss=1.45823, validation/accuracy=0.61486, validation/loss=1.68824, validation/num_examples=50000
I0315 03:29:19.411732 139896110970624 logging_writer.py:48] [27500] global_step=27500, grad_norm=1.03503, loss=2.70435
I0315 03:29:19.415667 139925059253440 submission.py:265] 27500) loss = 2.704, grad_norm = 1.035
I0315 03:31:29.837537 139925059253440 spec.py:321] Evaluating on the training split.
I0315 03:32:10.161257 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 03:32:50.705680 139925059253440 spec.py:349] Evaluating on the test split.
I0315 03:32:51.808379 139925059253440 submission_runner.py:469] Time since start: 21285.78s, 	Step: 27785, 	{'train/accuracy': 0.6789500956632653, 'train/loss': 1.3849358072086257, 'validation/accuracy': 0.62534, 'validation/loss': 1.61053296875, 'validation/num_examples': 50000, 'test/accuracy': 0.4859, 'test/loss': 2.3653490234375, 'test/num_examples': 10000, 'score': 17910.791379213333, 'total_duration': 21285.782597780228, 'accumulated_submission_time': 17910.791379213333, 'accumulated_eval_time': 3261.029375553131, 'accumulated_logging_time': 1.3880445957183838}
I0315 03:32:51.838621 139896463251200 logging_writer.py:48] [27785] accumulated_eval_time=3261.03, accumulated_logging_time=1.38804, accumulated_submission_time=17910.8, global_step=27785, preemption_count=0, score=17910.8, test/accuracy=0.4859, test/loss=2.36535, test/num_examples=10000, total_duration=21285.8, train/accuracy=0.67895, train/loss=1.38494, validation/accuracy=0.62534, validation/loss=1.61053, validation/num_examples=50000
I0315 03:34:32.497742 139896110970624 logging_writer.py:48] [28000] global_step=28000, grad_norm=1.02043, loss=2.6644
I0315 03:34:32.502216 139925059253440 submission.py:265] 28000) loss = 2.664, grad_norm = 1.020
I0315 03:39:48.617204 139896463251200 logging_writer.py:48] [28500] global_step=28500, grad_norm=1.00963, loss=2.70552
I0315 03:39:48.670208 139925059253440 submission.py:265] 28500) loss = 2.706, grad_norm = 1.010
I0315 03:41:24.354914 139925059253440 spec.py:321] Evaluating on the training split.
I0315 03:42:05.493754 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 03:42:47.767964 139925059253440 spec.py:349] Evaluating on the test split.
I0315 03:42:48.869145 139925059253440 submission_runner.py:469] Time since start: 21882.84s, 	Step: 28604, 	{'train/accuracy': 0.6775550063775511, 'train/loss': 1.3980150806660554, 'validation/accuracy': 0.62682, 'validation/loss': 1.62477421875, 'validation/num_examples': 50000, 'test/accuracy': 0.4857, 'test/loss': 2.3713482421875, 'test/num_examples': 10000, 'score': 18420.026364326477, 'total_duration': 21882.843428373337, 'accumulated_submission_time': 18420.026364326477, 'accumulated_eval_time': 3345.543921470642, 'accumulated_logging_time': 1.4271376132965088}
I0315 03:42:48.894819 139896110970624 logging_writer.py:48] [28604] accumulated_eval_time=3345.54, accumulated_logging_time=1.42714, accumulated_submission_time=18420, global_step=28604, preemption_count=0, score=18420, test/accuracy=0.4857, test/loss=2.37135, test/num_examples=10000, total_duration=21882.8, train/accuracy=0.677555, train/loss=1.39802, validation/accuracy=0.62682, validation/loss=1.62477, validation/num_examples=50000
I0315 03:47:11.263926 139896463251200 logging_writer.py:48] [29000] global_step=29000, grad_norm=1.00917, loss=2.63881
I0315 03:47:11.268563 139925059253440 submission.py:265] 29000) loss = 2.639, grad_norm = 1.009
I0315 03:51:11.475129 139896110970624 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.999804, loss=2.62993
I0315 03:51:11.479720 139925059253440 submission.py:265] 29500) loss = 2.630, grad_norm = 1.000
I0315 03:51:20.997229 139925059253440 spec.py:321] Evaluating on the training split.
I0315 03:52:01.035754 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 03:52:41.359451 139925059253440 spec.py:349] Evaluating on the test split.
I0315 03:52:42.462938 139925059253440 submission_runner.py:469] Time since start: 22476.44s, 	Step: 29516, 	{'train/accuracy': 0.6743463010204082, 'train/loss': 1.4149400360730229, 'validation/accuracy': 0.61866, 'validation/loss': 1.64442296875, 'validation/num_examples': 50000, 'test/accuracy': 0.4805, 'test/loss': 2.3698986328125, 'test/num_examples': 10000, 'score': 18928.80771422386, 'total_duration': 22476.437198400497, 'accumulated_submission_time': 18928.80771422386, 'accumulated_eval_time': 3427.00976896286, 'accumulated_logging_time': 1.4611997604370117}
I0315 03:52:42.474193 139896463251200 logging_writer.py:48] [29516] accumulated_eval_time=3427.01, accumulated_logging_time=1.4612, accumulated_submission_time=18928.8, global_step=29516, preemption_count=0, score=18928.8, test/accuracy=0.4805, test/loss=2.3699, test/num_examples=10000, total_duration=22476.4, train/accuracy=0.674346, train/loss=1.41494, validation/accuracy=0.61866, validation/loss=1.64442, validation/num_examples=50000
I0315 03:59:36.954084 139896110970624 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.976718, loss=2.57479
I0315 03:59:36.958523 139925059253440 submission.py:265] 30000) loss = 2.575, grad_norm = 0.977
I0315 04:01:14.222926 139925059253440 spec.py:321] Evaluating on the training split.
I0315 04:01:54.087984 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 04:02:35.106219 139925059253440 spec.py:349] Evaluating on the test split.
I0315 04:02:36.206490 139925059253440 submission_runner.py:469] Time since start: 23070.18s, 	Step: 30201, 	{'train/accuracy': 0.6847496811224489, 'train/loss': 1.3504470513791453, 'validation/accuracy': 0.62966, 'validation/loss': 1.58175015625, 'validation/num_examples': 50000, 'test/accuracy': 0.4967, 'test/loss': 2.3175212890625, 'test/num_examples': 10000, 'score': 19437.373670101166, 'total_duration': 23070.180783510208, 'accumulated_submission_time': 19437.373670101166, 'accumulated_eval_time': 3508.993463754654, 'accumulated_logging_time': 1.4806747436523438}
I0315 04:02:36.249676 139896463251200 logging_writer.py:48] [30201] accumulated_eval_time=3508.99, accumulated_logging_time=1.48067, accumulated_submission_time=19437.4, global_step=30201, preemption_count=0, score=19437.4, test/accuracy=0.4967, test/loss=2.31752, test/num_examples=10000, total_duration=23070.2, train/accuracy=0.68475, train/loss=1.35045, validation/accuracy=0.62966, validation/loss=1.58175, validation/num_examples=50000
I0315 04:04:52.499990 139896110970624 logging_writer.py:48] [30500] global_step=30500, grad_norm=1.04541, loss=2.73586
I0315 04:04:52.559293 139925059253440 submission.py:265] 30500) loss = 2.736, grad_norm = 1.045
I0315 04:09:59.383620 139896463251200 logging_writer.py:48] [31000] global_step=31000, grad_norm=1.09725, loss=2.68693
I0315 04:09:59.388084 139925059253440 submission.py:265] 31000) loss = 2.687, grad_norm = 1.097
I0315 04:11:08.832887 139925059253440 spec.py:321] Evaluating on the training split.
I0315 04:11:50.148977 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 04:12:32.230875 139925059253440 spec.py:349] Evaluating on the test split.
I0315 04:12:33.333766 139925059253440 submission_runner.py:469] Time since start: 23667.31s, 	Step: 31076, 	{'train/accuracy': 0.6782724808673469, 'train/loss': 1.416348204320791, 'validation/accuracy': 0.62634, 'validation/loss': 1.6418334375, 'validation/num_examples': 50000, 'test/accuracy': 0.4715, 'test/loss': 2.4357486328125, 'test/num_examples': 10000, 'score': 19946.700329065323, 'total_duration': 23667.30804347992, 'accumulated_submission_time': 19946.700329065323, 'accumulated_eval_time': 3593.494477033615, 'accumulated_logging_time': 1.5322413444519043}
I0315 04:12:33.400542 139896110970624 logging_writer.py:48] [31076] accumulated_eval_time=3593.49, accumulated_logging_time=1.53224, accumulated_submission_time=19946.7, global_step=31076, preemption_count=0, score=19946.7, test/accuracy=0.4715, test/loss=2.43575, test/num_examples=10000, total_duration=23667.3, train/accuracy=0.678272, train/loss=1.41635, validation/accuracy=0.62634, validation/loss=1.64183, validation/num_examples=50000
I0315 04:17:20.919296 139896463251200 logging_writer.py:48] [31500] global_step=31500, grad_norm=1.02388, loss=2.64823
I0315 04:17:20.969824 139925059253440 submission.py:265] 31500) loss = 2.648, grad_norm = 1.024
I0315 04:21:04.882403 139925059253440 spec.py:321] Evaluating on the training split.
I0315 04:21:44.029897 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 04:22:25.097267 139925059253440 spec.py:349] Evaluating on the test split.
I0315 04:22:26.198289 139925059253440 submission_runner.py:469] Time since start: 24260.17s, 	Step: 31967, 	{'train/accuracy': 0.6802654655612245, 'train/loss': 1.3967951560507015, 'validation/accuracy': 0.62748, 'validation/loss': 1.62790921875, 'validation/num_examples': 50000, 'test/accuracy': 0.4812, 'test/loss': 2.380094140625, 'test/num_examples': 10000, 'score': 20454.862374782562, 'total_duration': 24260.17257642746, 'accumulated_submission_time': 20454.862374782562, 'accumulated_eval_time': 3674.8105189800262, 'accumulated_logging_time': 1.6078832149505615}
I0315 04:22:26.209777 139896110970624 logging_writer.py:48] [31967] accumulated_eval_time=3674.81, accumulated_logging_time=1.60788, accumulated_submission_time=20454.9, global_step=31967, preemption_count=0, score=20454.9, test/accuracy=0.4812, test/loss=2.38009, test/num_examples=10000, total_duration=24260.2, train/accuracy=0.680265, train/loss=1.3968, validation/accuracy=0.62748, validation/loss=1.62791, validation/num_examples=50000
I0315 04:22:47.839475 139896463251200 logging_writer.py:48] [32000] global_step=32000, grad_norm=1.03028, loss=2.67697
I0315 04:22:47.843432 139925059253440 submission.py:265] 32000) loss = 2.677, grad_norm = 1.030
I0315 04:29:42.662596 139896110970624 logging_writer.py:48] [32500] global_step=32500, grad_norm=1.04219, loss=2.81573
I0315 04:29:42.681720 139925059253440 submission.py:265] 32500) loss = 2.816, grad_norm = 1.042
I0315 04:30:57.837421 139925059253440 spec.py:321] Evaluating on the training split.
I0315 04:31:37.360963 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 04:32:18.089378 139925059253440 spec.py:349] Evaluating on the test split.
I0315 04:32:19.195372 139925059253440 submission_runner.py:469] Time since start: 24853.17s, 	Step: 32644, 	{'train/accuracy': 0.6804049744897959, 'train/loss': 1.3772296516262754, 'validation/accuracy': 0.6288, 'validation/loss': 1.60769375, 'validation/num_examples': 50000, 'test/accuracy': 0.4993, 'test/loss': 2.300462890625, 'test/num_examples': 10000, 'score': 20963.299649715424, 'total_duration': 24853.169666290283, 'accumulated_submission_time': 20963.299649715424, 'accumulated_eval_time': 3756.1686868667603, 'accumulated_logging_time': 1.6278128623962402}
I0315 04:32:19.211968 139896463251200 logging_writer.py:48] [32644] accumulated_eval_time=3756.17, accumulated_logging_time=1.62781, accumulated_submission_time=20963.3, global_step=32644, preemption_count=0, score=20963.3, test/accuracy=0.4993, test/loss=2.30046, test/num_examples=10000, total_duration=24853.2, train/accuracy=0.680405, train/loss=1.37723, validation/accuracy=0.6288, validation/loss=1.60769, validation/num_examples=50000
I0315 04:34:58.766630 139896110970624 logging_writer.py:48] [33000] global_step=33000, grad_norm=1.04643, loss=2.71331
I0315 04:34:58.770889 139925059253440 submission.py:265] 33000) loss = 2.713, grad_norm = 1.046
I0315 04:40:12.994233 139896463251200 logging_writer.py:48] [33500] global_step=33500, grad_norm=1.05779, loss=2.73129
I0315 04:40:13.011710 139925059253440 submission.py:265] 33500) loss = 2.731, grad_norm = 1.058
I0315 04:40:50.732159 139925059253440 spec.py:321] Evaluating on the training split.
I0315 04:41:31.669940 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 04:42:14.493574 139925059253440 spec.py:349] Evaluating on the test split.
I0315 04:42:15.594202 139925059253440 submission_runner.py:469] Time since start: 25449.57s, 	Step: 33542, 	{'train/accuracy': 0.6846500318877551, 'train/loss': 1.3918044421137596, 'validation/accuracy': 0.6324, 'validation/loss': 1.62516140625, 'validation/num_examples': 50000, 'test/accuracy': 0.4931, 'test/loss': 2.3363654296875, 'test/num_examples': 10000, 'score': 21471.59898543358, 'total_duration': 25449.56843471527, 'accumulated_submission_time': 21471.59898543358, 'accumulated_eval_time': 3841.030893087387, 'accumulated_logging_time': 1.6526682376861572}
I0315 04:42:15.606685 139896110970624 logging_writer.py:48] [33542] accumulated_eval_time=3841.03, accumulated_logging_time=1.65267, accumulated_submission_time=21471.6, global_step=33542, preemption_count=0, score=21471.6, test/accuracy=0.4931, test/loss=2.33637, test/num_examples=10000, total_duration=25449.6, train/accuracy=0.68465, train/loss=1.3918, validation/accuracy=0.6324, validation/loss=1.62516, validation/num_examples=50000
I0315 04:47:39.538323 139896463251200 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.997486, loss=2.52374
I0315 04:47:39.557294 139925059253440 submission.py:265] 34000) loss = 2.524, grad_norm = 0.997
I0315 04:50:47.224288 139925059253440 spec.py:321] Evaluating on the training split.
I0315 04:51:26.254028 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 04:52:06.779815 139925059253440 spec.py:349] Evaluating on the test split.
I0315 04:52:07.877070 139925059253440 submission_runner.py:469] Time since start: 26041.85s, 	Step: 34405, 	{'train/accuracy': 0.6848294005102041, 'train/loss': 1.3728070940290178, 'validation/accuracy': 0.63152, 'validation/loss': 1.60454546875, 'validation/num_examples': 50000, 'test/accuracy': 0.4886, 'test/loss': 2.3548595703125, 'test/num_examples': 10000, 'score': 21980.084597349167, 'total_duration': 26041.85134792328, 'accumulated_submission_time': 21980.084597349167, 'accumulated_eval_time': 3921.6838812828064, 'accumulated_logging_time': 1.6752574443817139}
I0315 04:52:07.923813 139896110970624 logging_writer.py:48] [34405] accumulated_eval_time=3921.68, accumulated_logging_time=1.67526, accumulated_submission_time=21980.1, global_step=34405, preemption_count=0, score=21980.1, test/accuracy=0.4886, test/loss=2.35486, test/num_examples=10000, total_duration=26041.9, train/accuracy=0.684829, train/loss=1.37281, validation/accuracy=0.63152, validation/loss=1.60455, validation/num_examples=50000
I0315 04:53:04.713142 139896463251200 logging_writer.py:48] [34500] global_step=34500, grad_norm=1.06796, loss=2.72877
I0315 04:53:04.717322 139925059253440 submission.py:265] 34500) loss = 2.729, grad_norm = 1.068
I0315 05:00:07.370770 139896110970624 logging_writer.py:48] [35000] global_step=35000, grad_norm=1.05065, loss=2.56587
I0315 05:00:07.411783 139925059253440 submission.py:265] 35000) loss = 2.566, grad_norm = 1.051
I0315 05:00:41.027524 139925059253440 spec.py:321] Evaluating on the training split.
I0315 05:01:20.054791 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 05:02:00.904924 139925059253440 spec.py:349] Evaluating on the test split.
I0315 05:02:02.009374 139925059253440 submission_runner.py:469] Time since start: 26635.98s, 	Step: 35029, 	{'train/accuracy': 0.6837531887755102, 'train/loss': 1.392933903908243, 'validation/accuracy': 0.63382, 'validation/loss': 1.62121578125, 'validation/num_examples': 50000, 'test/accuracy': 0.4916, 'test/loss': 2.3459619140625, 'test/num_examples': 10000, 'score': 22490.10764169693, 'total_duration': 26635.983645677567, 'accumulated_submission_time': 22490.10764169693, 'accumulated_eval_time': 4002.665917158127, 'accumulated_logging_time': 1.7308950424194336}
I0315 05:02:02.040301 139896463251200 logging_writer.py:48] [35029] accumulated_eval_time=4002.67, accumulated_logging_time=1.7309, accumulated_submission_time=22490.1, global_step=35029, preemption_count=0, score=22490.1, test/accuracy=0.4916, test/loss=2.34596, test/num_examples=10000, total_duration=26636, train/accuracy=0.683753, train/loss=1.39293, validation/accuracy=0.63382, validation/loss=1.62122, validation/num_examples=50000
I0315 05:05:28.135390 139896110970624 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.998839, loss=2.54867
I0315 05:05:28.139712 139925059253440 submission.py:265] 35500) loss = 2.549, grad_norm = 0.999
I0315 05:10:33.758749 139925059253440 spec.py:321] Evaluating on the training split.
I0315 05:11:13.937068 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 05:11:54.791125 139925059253440 spec.py:349] Evaluating on the test split.
I0315 05:11:55.896855 139925059253440 submission_runner.py:469] Time since start: 27229.87s, 	Step: 35999, 	{'train/accuracy': 0.6826769770408163, 'train/loss': 1.3742189991230866, 'validation/accuracy': 0.62928, 'validation/loss': 1.600976875, 'validation/num_examples': 50000, 'test/accuracy': 0.4773, 'test/loss': 2.406099609375, 'test/num_examples': 10000, 'score': 22998.50823521614, 'total_duration': 27229.87111544609, 'accumulated_submission_time': 22998.50823521614, 'accumulated_eval_time': 4084.8041694164276, 'accumulated_logging_time': 1.7712891101837158}
I0315 05:11:55.908999 139896463251200 logging_writer.py:48] [35999] accumulated_eval_time=4084.8, accumulated_logging_time=1.77129, accumulated_submission_time=22998.5, global_step=35999, preemption_count=0, score=22998.5, test/accuracy=0.4773, test/loss=2.4061, test/num_examples=10000, total_duration=27229.9, train/accuracy=0.682677, train/loss=1.37422, validation/accuracy=0.62928, validation/loss=1.60098, validation/num_examples=50000
I0315 05:11:58.408195 139896110970624 logging_writer.py:48] [36000] global_step=36000, grad_norm=1.03332, loss=2.58294
I0315 05:11:58.412147 139925059253440 submission.py:265] 36000) loss = 2.583, grad_norm = 1.033
I0315 05:18:04.052698 139896463251200 logging_writer.py:48] [36500] global_step=36500, grad_norm=1.0325, loss=2.67781
I0315 05:18:04.057102 139925059253440 submission.py:265] 36500) loss = 2.678, grad_norm = 1.032
I0315 05:20:27.843998 139925059253440 spec.py:321] Evaluating on the training split.
I0315 05:21:06.964848 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 05:21:48.302363 139925059253440 spec.py:349] Evaluating on the test split.
I0315 05:21:49.409267 139925059253440 submission_runner.py:469] Time since start: 27823.38s, 	Step: 36824, 	{'train/accuracy': 0.6836535395408163, 'train/loss': 1.373213631766183, 'validation/accuracy': 0.62994, 'validation/loss': 1.61262171875, 'validation/num_examples': 50000, 'test/accuracy': 0.492, 'test/loss': 2.357156640625, 'test/num_examples': 10000, 'score': 23507.14585995674, 'total_duration': 27823.3835375309, 'accumulated_submission_time': 23507.14585995674, 'accumulated_eval_time': 4166.369605541229, 'accumulated_logging_time': 1.8180444240570068}
I0315 05:21:49.442191 139896110970624 logging_writer.py:48] [36824] accumulated_eval_time=4166.37, accumulated_logging_time=1.81804, accumulated_submission_time=23507.1, global_step=36824, preemption_count=0, score=23507.1, test/accuracy=0.492, test/loss=2.35716, test/num_examples=10000, total_duration=27823.4, train/accuracy=0.683654, train/loss=1.37321, validation/accuracy=0.62994, validation/loss=1.61262, validation/num_examples=50000
I0315 05:23:21.333110 139896463251200 logging_writer.py:48] [37000] global_step=37000, grad_norm=1.05365, loss=2.71834
I0315 05:23:21.337206 139925059253440 submission.py:265] 37000) loss = 2.718, grad_norm = 1.054
I0315 05:29:37.967283 139896110970624 logging_writer.py:48] [37500] global_step=37500, grad_norm=1.07003, loss=2.66969
I0315 05:29:38.026657 139925059253440 submission.py:265] 37500) loss = 2.670, grad_norm = 1.070
I0315 05:30:21.101368 139925059253440 spec.py:321] Evaluating on the training split.
I0315 05:31:00.795982 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 05:31:41.643033 139925059253440 spec.py:349] Evaluating on the test split.
I0315 05:31:42.746313 139925059253440 submission_runner.py:469] Time since start: 28416.72s, 	Step: 37559, 	{'train/accuracy': 0.6880381058673469, 'train/loss': 1.3389895692163585, 'validation/accuracy': 0.63672, 'validation/loss': 1.5647571875, 'validation/num_examples': 50000, 'test/accuracy': 0.5016, 'test/loss': 2.264956640625, 'test/num_examples': 10000, 'score': 24015.681949853897, 'total_duration': 28416.720584630966, 'accumulated_submission_time': 24015.681949853897, 'accumulated_eval_time': 4248.014618873596, 'accumulated_logging_time': 1.8590383529663086}
I0315 05:31:42.803312 139896463251200 logging_writer.py:48] [37559] accumulated_eval_time=4248.01, accumulated_logging_time=1.85904, accumulated_submission_time=24015.7, global_step=37559, preemption_count=0, score=24015.7, test/accuracy=0.5016, test/loss=2.26496, test/num_examples=10000, total_duration=28416.7, train/accuracy=0.688038, train/loss=1.33899, validation/accuracy=0.63672, validation/loss=1.56476, validation/num_examples=50000
I0315 05:34:43.202597 139896110970624 logging_writer.py:48] [38000] global_step=38000, grad_norm=1.01606, loss=2.60811
I0315 05:34:43.206708 139925059253440 submission.py:265] 38000) loss = 2.608, grad_norm = 1.016
I0315 05:39:22.460311 139896463251200 logging_writer.py:48] [38500] global_step=38500, grad_norm=1.09933, loss=2.66688
I0315 05:39:22.464681 139925059253440 submission.py:265] 38500) loss = 2.667, grad_norm = 1.099
I0315 05:40:14.210502 139925059253440 spec.py:321] Evaluating on the training split.
I0315 05:40:55.482724 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 05:41:38.371941 139925059253440 spec.py:349] Evaluating on the test split.
I0315 05:41:39.480503 139925059253440 submission_runner.py:469] Time since start: 29013.45s, 	Step: 38565, 	{'train/accuracy': 0.6847696109693877, 'train/loss': 1.3639415818817762, 'validation/accuracy': 0.63338, 'validation/loss': 1.5867365625, 'validation/num_examples': 50000, 'test/accuracy': 0.4894, 'test/loss': 2.3261671875, 'test/num_examples': 10000, 'score': 24523.739703178406, 'total_duration': 29013.454742193222, 'accumulated_submission_time': 24523.739703178406, 'accumulated_eval_time': 4333.284723520279, 'accumulated_logging_time': 1.924267292022705}
I0315 05:41:39.525327 139896110970624 logging_writer.py:48] [38565] accumulated_eval_time=4333.28, accumulated_logging_time=1.92427, accumulated_submission_time=24523.7, global_step=38565, preemption_count=0, score=24523.7, test/accuracy=0.4894, test/loss=2.32617, test/num_examples=10000, total_duration=29013.5, train/accuracy=0.68477, train/loss=1.36394, validation/accuracy=0.63338, validation/loss=1.58674, validation/num_examples=50000
I0315 05:46:27.716046 139896463251200 logging_writer.py:48] [39000] global_step=39000, grad_norm=1.06682, loss=2.66466
I0315 05:46:27.720776 139925059253440 submission.py:265] 39000) loss = 2.665, grad_norm = 1.067
I0315 05:50:11.026940 139925059253440 spec.py:321] Evaluating on the training split.
I0315 05:50:49.902570 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 05:51:29.855882 139925059253440 spec.py:349] Evaluating on the test split.
I0315 05:51:30.962868 139925059253440 submission_runner.py:469] Time since start: 29604.94s, 	Step: 39488, 	{'train/accuracy': 0.6840521364795918, 'train/loss': 1.3641735777562978, 'validation/accuracy': 0.63022, 'validation/loss': 1.603979375, 'validation/num_examples': 50000, 'test/accuracy': 0.4801, 'test/loss': 2.38642421875, 'test/num_examples': 10000, 'score': 25031.940733909607, 'total_duration': 29604.93714618683, 'accumulated_submission_time': 25031.940733909607, 'accumulated_eval_time': 4413.220862150192, 'accumulated_logging_time': 1.978187084197998}
I0315 05:51:30.975659 139896110970624 logging_writer.py:48] [39488] accumulated_eval_time=4413.22, accumulated_logging_time=1.97819, accumulated_submission_time=25031.9, global_step=39488, preemption_count=0, score=25031.9, test/accuracy=0.4801, test/loss=2.38642, test/num_examples=10000, total_duration=29604.9, train/accuracy=0.684052, train/loss=1.36417, validation/accuracy=0.63022, validation/loss=1.60398, validation/num_examples=50000
I0315 05:51:38.940721 139896463251200 logging_writer.py:48] [39500] global_step=39500, grad_norm=1.04771, loss=2.6853
I0315 05:51:38.953072 139925059253440 submission.py:265] 39500) loss = 2.685, grad_norm = 1.048
I0315 05:58:09.170452 139896110970624 logging_writer.py:48] [40000] global_step=40000, grad_norm=1.03681, loss=2.71708
I0315 05:58:09.195426 139925059253440 submission.py:265] 40000) loss = 2.717, grad_norm = 1.037
I0315 06:00:02.444727 139925059253440 spec.py:321] Evaluating on the training split.
I0315 06:00:41.436402 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 06:01:21.238659 139925059253440 spec.py:349] Evaluating on the test split.
I0315 06:01:22.344108 139925059253440 submission_runner.py:469] Time since start: 30196.32s, 	Step: 40231, 	{'train/accuracy': 0.6887356505102041, 'train/loss': 1.3279769274653221, 'validation/accuracy': 0.63304, 'validation/loss': 1.573351875, 'validation/num_examples': 50000, 'test/accuracy': 0.4873, 'test/loss': 2.347129296875, 'test/num_examples': 10000, 'score': 25540.251209020615, 'total_duration': 30196.318422317505, 'accumulated_submission_time': 25540.251209020615, 'accumulated_eval_time': 4493.12048125267, 'accumulated_logging_time': 1.999892234802246}
I0315 06:01:22.356398 139896463251200 logging_writer.py:48] [40231] accumulated_eval_time=4493.12, accumulated_logging_time=1.99989, accumulated_submission_time=25540.3, global_step=40231, preemption_count=0, score=25540.3, test/accuracy=0.4873, test/loss=2.34713, test/num_examples=10000, total_duration=30196.3, train/accuracy=0.688736, train/loss=1.32798, validation/accuracy=0.63304, validation/loss=1.57335, validation/num_examples=50000
I0315 06:03:18.950587 139896110970624 logging_writer.py:48] [40500] global_step=40500, grad_norm=1.06993, loss=2.65598
I0315 06:03:18.954377 139925059253440 submission.py:265] 40500) loss = 2.656, grad_norm = 1.070
I0315 06:08:00.186318 139896463251200 logging_writer.py:48] [41000] global_step=41000, grad_norm=1.04468, loss=2.66131
I0315 06:08:00.197015 139925059253440 submission.py:265] 41000) loss = 2.661, grad_norm = 1.045
I0315 06:09:54.159925 139925059253440 spec.py:321] Evaluating on the training split.
I0315 06:10:36.111379 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 06:11:18.735080 139925059253440 spec.py:349] Evaluating on the test split.
I0315 06:11:19.840681 139925059253440 submission_runner.py:469] Time since start: 30793.81s, 	Step: 41131, 	{'train/accuracy': 0.6945551658163265, 'train/loss': 1.321434955207669, 'validation/accuracy': 0.64092, 'validation/loss': 1.55130453125, 'validation/num_examples': 50000, 'test/accuracy': 0.5009, 'test/loss': 2.2950310546875, 'test/num_examples': 10000, 'score': 26048.75089406967, 'total_duration': 30793.814932584763, 'accumulated_submission_time': 26048.75089406967, 'accumulated_eval_time': 4578.801331996918, 'accumulated_logging_time': 2.0206968784332275}
I0315 06:11:19.872796 139896110970624 logging_writer.py:48] [41131] accumulated_eval_time=4578.8, accumulated_logging_time=2.0207, accumulated_submission_time=26048.8, global_step=41131, preemption_count=0, score=26048.8, test/accuracy=0.5009, test/loss=2.29503, test/num_examples=10000, total_duration=30793.8, train/accuracy=0.694555, train/loss=1.32143, validation/accuracy=0.64092, validation/loss=1.5513, validation/num_examples=50000
I0315 06:15:14.358627 139896463251200 logging_writer.py:48] [41500] global_step=41500, grad_norm=1.0448, loss=2.59982
I0315 06:15:14.363186 139925059253440 submission.py:265] 41500) loss = 2.600, grad_norm = 1.045
I0315 06:19:04.215560 139896110970624 logging_writer.py:48] [42000] global_step=42000, grad_norm=1.04003, loss=2.61252
I0315 06:19:04.219633 139925059253440 submission.py:265] 42000) loss = 2.613, grad_norm = 1.040
I0315 06:19:52.299193 139925059253440 spec.py:321] Evaluating on the training split.
I0315 06:20:34.014162 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 06:21:16.138474 139925059253440 spec.py:349] Evaluating on the test split.
I0315 06:21:17.238683 139925059253440 submission_runner.py:469] Time since start: 31391.21s, 	Step: 42080, 	{'train/accuracy': 0.6914461096938775, 'train/loss': 1.332809759646046, 'validation/accuracy': 0.63874, 'validation/loss': 1.56871875, 'validation/num_examples': 50000, 'test/accuracy': 0.4968, 'test/loss': 2.338083984375, 'test/num_examples': 10000, 'score': 26557.777857542038, 'total_duration': 31391.21298933029, 'accumulated_submission_time': 26557.777857542038, 'accumulated_eval_time': 4663.740928888321, 'accumulated_logging_time': 2.0621771812438965}
I0315 06:21:17.251929 139896463251200 logging_writer.py:48] [42080] accumulated_eval_time=4663.74, accumulated_logging_time=2.06218, accumulated_submission_time=26557.8, global_step=42080, preemption_count=0, score=26557.8, test/accuracy=0.4968, test/loss=2.33808, test/num_examples=10000, total_duration=31391.2, train/accuracy=0.691446, train/loss=1.33281, validation/accuracy=0.63874, validation/loss=1.56872, validation/num_examples=50000
I0315 06:27:13.222400 139896110970624 logging_writer.py:48] [42500] global_step=42500, grad_norm=0.990746, loss=2.51769
I0315 06:27:13.235962 139925059253440 submission.py:265] 42500) loss = 2.518, grad_norm = 0.991
I0315 06:29:48.762637 139925059253440 spec.py:321] Evaluating on the training split.
I0315 06:30:28.466717 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 06:31:09.015469 139925059253440 spec.py:349] Evaluating on the test split.
I0315 06:31:10.122374 139925059253440 submission_runner.py:469] Time since start: 31984.10s, 	Step: 42834, 	{'train/accuracy': 0.6934789540816326, 'train/loss': 1.3194035121372767, 'validation/accuracy': 0.63886, 'validation/loss': 1.5643221875, 'validation/num_examples': 50000, 'test/accuracy': 0.4885, 'test/loss': 2.354053515625, 'test/num_examples': 10000, 'score': 27065.98811841011, 'total_duration': 31984.09667778015, 'accumulated_submission_time': 27065.98811841011, 'accumulated_eval_time': 4745.1008477211, 'accumulated_logging_time': 2.1435322761535645}
I0315 06:31:10.134973 139896463251200 logging_writer.py:48] [42834] accumulated_eval_time=4745.1, accumulated_logging_time=2.14353, accumulated_submission_time=27066, global_step=42834, preemption_count=0, score=27066, test/accuracy=0.4885, test/loss=2.35405, test/num_examples=10000, total_duration=31984.1, train/accuracy=0.693479, train/loss=1.3194, validation/accuracy=0.63886, validation/loss=1.56432, validation/num_examples=50000
I0315 06:32:25.718153 139896110970624 logging_writer.py:48] [43000] global_step=43000, grad_norm=1.03273, loss=2.64437
I0315 06:32:25.722050 139925059253440 submission.py:265] 43000) loss = 2.644, grad_norm = 1.033
I0315 06:37:20.918734 139896463251200 logging_writer.py:48] [43500] global_step=43500, grad_norm=1.01832, loss=2.62131
I0315 06:37:20.923003 139925059253440 submission.py:265] 43500) loss = 2.621, grad_norm = 1.018
I0315 06:39:44.165821 139925059253440 spec.py:321] Evaluating on the training split.
I0315 06:40:24.834373 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 06:41:06.548983 139925059253440 spec.py:349] Evaluating on the test split.
I0315 06:41:07.650144 139925059253440 submission_runner.py:469] Time since start: 32581.62s, 	Step: 43660, 	{'train/accuracy': 0.6948142538265306, 'train/loss': 1.3406298890405772, 'validation/accuracy': 0.64046, 'validation/loss': 1.57015203125, 'validation/num_examples': 50000, 'test/accuracy': 0.4956, 'test/loss': 2.33862578125, 'test/num_examples': 10000, 'score': 27576.926027536392, 'total_duration': 32581.624357938766, 'accumulated_submission_time': 27576.926027536392, 'accumulated_eval_time': 4828.5853061676025, 'accumulated_logging_time': 2.1645400524139404}
I0315 06:41:07.674898 139896110970624 logging_writer.py:48] [43660] accumulated_eval_time=4828.59, accumulated_logging_time=2.16454, accumulated_submission_time=27576.9, global_step=43660, preemption_count=0, score=27576.9, test/accuracy=0.4956, test/loss=2.33863, test/num_examples=10000, total_duration=32581.6, train/accuracy=0.694814, train/loss=1.34063, validation/accuracy=0.64046, validation/loss=1.57015, validation/num_examples=50000
I0315 06:44:37.071442 139896463251200 logging_writer.py:48] [44000] global_step=44000, grad_norm=1.03525, loss=2.59314
I0315 06:44:37.075486 139925059253440 submission.py:265] 44000) loss = 2.593, grad_norm = 1.035
I0315 06:48:22.498666 139896110970624 logging_writer.py:48] [44500] global_step=44500, grad_norm=1.09691, loss=2.65866
I0315 06:48:22.503161 139925059253440 submission.py:265] 44500) loss = 2.659, grad_norm = 1.097
I0315 06:49:39.381190 139925059253440 spec.py:321] Evaluating on the training split.
I0315 06:50:18.770443 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 06:50:59.827932 139925059253440 spec.py:349] Evaluating on the test split.
I0315 06:51:00.931466 139925059253440 submission_runner.py:469] Time since start: 33174.91s, 	Step: 44627, 	{'train/accuracy': 0.6926219706632653, 'train/loss': 1.3247127922213808, 'validation/accuracy': 0.6391, 'validation/loss': 1.553726875, 'validation/num_examples': 50000, 'test/accuracy': 0.4952, 'test/loss': 2.3022447265625, 'test/num_examples': 10000, 'score': 28085.30637216568, 'total_duration': 33174.90571689606, 'accumulated_submission_time': 28085.30637216568, 'accumulated_eval_time': 4910.135939836502, 'accumulated_logging_time': 2.2536253929138184}
I0315 06:51:00.945132 139896463251200 logging_writer.py:48] [44627] accumulated_eval_time=4910.14, accumulated_logging_time=2.25363, accumulated_submission_time=28085.3, global_step=44627, preemption_count=0, score=28085.3, test/accuracy=0.4952, test/loss=2.30224, test/num_examples=10000, total_duration=33174.9, train/accuracy=0.692622, train/loss=1.32471, validation/accuracy=0.6391, validation/loss=1.55373, validation/num_examples=50000
I0315 06:56:23.846218 139896110970624 logging_writer.py:48] [45000] global_step=45000, grad_norm=1.00859, loss=2.62616
I0315 06:56:23.860822 139925059253440 submission.py:265] 45000) loss = 2.626, grad_norm = 1.009
I0315 06:59:32.427997 139925059253440 spec.py:321] Evaluating on the training split.
I0315 07:00:13.453171 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 07:00:53.900592 139925059253440 spec.py:349] Evaluating on the test split.
I0315 07:00:55.004431 139925059253440 submission_runner.py:469] Time since start: 33768.98s, 	Step: 45403, 	{'train/accuracy': 0.6985809948979592, 'train/loss': 1.2860445295061385, 'validation/accuracy': 0.6464, 'validation/loss': 1.5270115625, 'validation/num_examples': 50000, 'test/accuracy': 0.5059, 'test/loss': 2.250443359375, 'test/num_examples': 10000, 'score': 28593.59709095955, 'total_duration': 33768.97868347168, 'accumulated_submission_time': 28593.59709095955, 'accumulated_eval_time': 4992.712544679642, 'accumulated_logging_time': 2.2759146690368652}
I0315 07:00:55.018211 139896463251200 logging_writer.py:48] [45403] accumulated_eval_time=4992.71, accumulated_logging_time=2.27591, accumulated_submission_time=28593.6, global_step=45403, preemption_count=0, score=28593.6, test/accuracy=0.5059, test/loss=2.25044, test/num_examples=10000, total_duration=33769, train/accuracy=0.698581, train/loss=1.28604, validation/accuracy=0.6464, validation/loss=1.52701, validation/num_examples=50000
I0315 07:01:43.574253 139896110970624 logging_writer.py:48] [45500] global_step=45500, grad_norm=1.06285, loss=2.67196
I0315 07:01:43.577993 139925059253440 submission.py:265] 45500) loss = 2.672, grad_norm = 1.063
I0315 07:06:39.434428 139896463251200 logging_writer.py:48] [46000] global_step=46000, grad_norm=1.05749, loss=2.67952
I0315 07:06:39.438794 139925059253440 submission.py:265] 46000) loss = 2.680, grad_norm = 1.057
I0315 07:09:27.049438 139925059253440 spec.py:321] Evaluating on the training split.
I0315 07:10:08.049272 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 07:10:50.144118 139925059253440 spec.py:349] Evaluating on the test split.
I0315 07:10:51.244269 139925059253440 submission_runner.py:469] Time since start: 34365.22s, 	Step: 46181, 	{'train/accuracy': 0.6937779017857143, 'train/loss': 1.3123371357820472, 'validation/accuracy': 0.64074, 'validation/loss': 1.54869140625, 'validation/num_examples': 50000, 'test/accuracy': 0.492, 'test/loss': 2.32313125, 'test/num_examples': 10000, 'score': 29102.42606306076, 'total_duration': 34365.21852350235, 'accumulated_submission_time': 29102.42606306076, 'accumulated_eval_time': 5076.907496213913, 'accumulated_logging_time': 2.2984142303466797}
I0315 07:10:51.301753 139896110970624 logging_writer.py:48] [46181] accumulated_eval_time=5076.91, accumulated_logging_time=2.29841, accumulated_submission_time=29102.4, global_step=46181, preemption_count=0, score=29102.4, test/accuracy=0.492, test/loss=2.32313, test/num_examples=10000, total_duration=34365.2, train/accuracy=0.693778, train/loss=1.31234, validation/accuracy=0.64074, validation/loss=1.54869, validation/num_examples=50000
I0315 07:14:10.622228 139896463251200 logging_writer.py:48] [46500] global_step=46500, grad_norm=1.07072, loss=2.67495
I0315 07:14:10.627024 139925059253440 submission.py:265] 46500) loss = 2.675, grad_norm = 1.071
I0315 07:18:02.409916 139896110970624 logging_writer.py:48] [47000] global_step=47000, grad_norm=1.05287, loss=2.66545
I0315 07:18:02.413944 139925059253440 submission.py:265] 47000) loss = 2.665, grad_norm = 1.053
I0315 07:19:23.605853 139925059253440 spec.py:321] Evaluating on the training split.
I0315 07:20:04.440852 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 07:20:45.031979 139925059253440 spec.py:349] Evaluating on the test split.
I0315 07:20:46.140061 139925059253440 submission_runner.py:469] Time since start: 34960.11s, 	Step: 47136, 	{'train/accuracy': 0.6956313775510204, 'train/loss': 1.3137384531449299, 'validation/accuracy': 0.64224, 'validation/loss': 1.54597421875, 'validation/num_examples': 50000, 'test/accuracy': 0.5068, 'test/loss': 2.257491015625, 'test/num_examples': 10000, 'score': 29611.385087013245, 'total_duration': 34960.11428308487, 'accumulated_submission_time': 29611.385087013245, 'accumulated_eval_time': 5159.4417724609375, 'accumulated_logging_time': 2.3720948696136475}
I0315 07:20:46.169754 139896463251200 logging_writer.py:48] [47136] accumulated_eval_time=5159.44, accumulated_logging_time=2.37209, accumulated_submission_time=29611.4, global_step=47136, preemption_count=0, score=29611.4, test/accuracy=0.5068, test/loss=2.25749, test/num_examples=10000, total_duration=34960.1, train/accuracy=0.695631, train/loss=1.31374, validation/accuracy=0.64224, validation/loss=1.54597, validation/num_examples=50000
I0315 07:26:09.011779 139896110970624 logging_writer.py:48] [47500] global_step=47500, grad_norm=1.04941, loss=2.54851
I0315 07:26:09.084741 139925059253440 submission.py:265] 47500) loss = 2.549, grad_norm = 1.049
I0315 07:29:18.194686 139925059253440 spec.py:321] Evaluating on the training split.
I0315 07:29:59.572598 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 07:30:41.218074 139925059253440 spec.py:349] Evaluating on the test split.
I0315 07:30:42.325127 139925059253440 submission_runner.py:469] Time since start: 35556.30s, 	Step: 47911, 	{'train/accuracy': 0.6983617665816326, 'train/loss': 1.3077904837472099, 'validation/accuracy': 0.64124, 'validation/loss': 1.55220796875, 'validation/num_examples': 50000, 'test/accuracy': 0.5083, 'test/loss': 2.2666205078125, 'test/num_examples': 10000, 'score': 30120.200031995773, 'total_duration': 35556.299412965775, 'accumulated_submission_time': 30120.200031995773, 'accumulated_eval_time': 5243.5723757743835, 'accumulated_logging_time': 2.410292148590088}
I0315 07:30:42.338904 139896463251200 logging_writer.py:48] [47911] accumulated_eval_time=5243.57, accumulated_logging_time=2.41029, accumulated_submission_time=30120.2, global_step=47911, preemption_count=0, score=30120.2, test/accuracy=0.5083, test/loss=2.26662, test/num_examples=10000, total_duration=35556.3, train/accuracy=0.698362, train/loss=1.30779, validation/accuracy=0.64124, validation/loss=1.55221, validation/num_examples=50000
I0315 07:31:25.724420 139896110970624 logging_writer.py:48] [48000] global_step=48000, grad_norm=0.997959, loss=2.53465
I0315 07:31:25.728395 139925059253440 submission.py:265] 48000) loss = 2.535, grad_norm = 0.998
I0315 07:36:15.981427 139896463251200 logging_writer.py:48] [48500] global_step=48500, grad_norm=1.08216, loss=2.6315
I0315 07:36:15.985765 139925059253440 submission.py:265] 48500) loss = 2.631, grad_norm = 1.082
I0315 07:39:14.285877 139925059253440 spec.py:321] Evaluating on the training split.
I0315 07:39:55.544947 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 07:40:39.328891 139925059253440 spec.py:349] Evaluating on the test split.
I0315 07:40:40.428868 139925059253440 submission_runner.py:469] Time since start: 36154.40s, 	Step: 48695, 	{'train/accuracy': 0.6983019770408163, 'train/loss': 1.3072027089644451, 'validation/accuracy': 0.64356, 'validation/loss': 1.54504625, 'validation/num_examples': 50000, 'test/accuracy': 0.4983, 'test/loss': 2.29508828125, 'test/num_examples': 10000, 'score': 30628.940316200256, 'total_duration': 36154.40313267708, 'accumulated_submission_time': 30628.940316200256, 'accumulated_eval_time': 5329.715517282486, 'accumulated_logging_time': 2.432955503463745}
I0315 07:40:40.513954 139896110970624 logging_writer.py:48] [48695] accumulated_eval_time=5329.72, accumulated_logging_time=2.43296, accumulated_submission_time=30628.9, global_step=48695, preemption_count=0, score=30628.9, test/accuracy=0.4983, test/loss=2.29509, test/num_examples=10000, total_duration=36154.4, train/accuracy=0.698302, train/loss=1.3072, validation/accuracy=0.64356, validation/loss=1.54505, validation/num_examples=50000
I0315 07:43:39.070563 139896463251200 logging_writer.py:48] [49000] global_step=49000, grad_norm=1.02223, loss=2.48778
I0315 07:43:39.074850 139925059253440 submission.py:265] 49000) loss = 2.488, grad_norm = 1.022
I0315 07:47:25.701228 139896110970624 logging_writer.py:48] [49500] global_step=49500, grad_norm=1.02339, loss=2.53642
I0315 07:47:25.705826 139925059253440 submission.py:265] 49500) loss = 2.536, grad_norm = 1.023
I0315 07:49:13.390846 139925059253440 spec.py:321] Evaluating on the training split.
I0315 07:49:54.394819 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 07:50:38.772085 139925059253440 spec.py:349] Evaluating on the test split.
I0315 07:50:39.877370 139925059253440 submission_runner.py:469] Time since start: 36753.85s, 	Step: 49678, 	{'train/accuracy': 0.6987603635204082, 'train/loss': 1.31502408397441, 'validation/accuracy': 0.64256, 'validation/loss': 1.551053125, 'validation/num_examples': 50000, 'test/accuracy': 0.5016, 'test/loss': 2.28402734375, 'test/num_examples': 10000, 'score': 31138.529881238937, 'total_duration': 36753.85166668892, 'accumulated_submission_time': 31138.529881238937, 'accumulated_eval_time': 5416.20216012001, 'accumulated_logging_time': 2.534764528274536}
I0315 07:50:39.932141 139896463251200 logging_writer.py:48] [49678] accumulated_eval_time=5416.2, accumulated_logging_time=2.53476, accumulated_submission_time=31138.5, global_step=49678, preemption_count=0, score=31138.5, test/accuracy=0.5016, test/loss=2.28403, test/num_examples=10000, total_duration=36753.9, train/accuracy=0.69876, train/loss=1.31502, validation/accuracy=0.64256, validation/loss=1.55105, validation/num_examples=50000
I0315 07:55:22.602225 139896110970624 logging_writer.py:48] [50000] global_step=50000, grad_norm=1.04717, loss=2.62365
I0315 07:55:22.637617 139925059253440 submission.py:265] 50000) loss = 2.624, grad_norm = 1.047
I0315 07:59:11.850320 139925059253440 spec.py:321] Evaluating on the training split.
I0315 07:59:53.481742 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 08:00:35.333400 139925059253440 spec.py:349] Evaluating on the test split.
I0315 08:00:36.433931 139925059253440 submission_runner.py:469] Time since start: 37350.41s, 	Step: 50493, 	{'train/accuracy': 0.6983816964285714, 'train/loss': 1.3140710324657208, 'validation/accuracy': 0.643, 'validation/loss': 1.55239171875, 'validation/num_examples': 50000, 'test/accuracy': 0.5121, 'test/loss': 2.25651796875, 'test/num_examples': 10000, 'score': 31647.38681125641, 'total_duration': 37350.40821313858, 'accumulated_submission_time': 31647.38681125641, 'accumulated_eval_time': 5500.786079883575, 'accumulated_logging_time': 2.598129987716675}
I0315 08:00:36.448019 139896463251200 logging_writer.py:48] [50493] accumulated_eval_time=5500.79, accumulated_logging_time=2.59813, accumulated_submission_time=31647.4, global_step=50493, preemption_count=0, score=31647.4, test/accuracy=0.5121, test/loss=2.25652, test/num_examples=10000, total_duration=37350.4, train/accuracy=0.698382, train/loss=1.31407, validation/accuracy=0.643, validation/loss=1.55239, validation/num_examples=50000
I0315 08:00:41.046463 139896110970624 logging_writer.py:48] [50500] global_step=50500, grad_norm=1.07193, loss=2.64311
I0315 08:00:41.050559 139925059253440 submission.py:265] 50500) loss = 2.643, grad_norm = 1.072
I0315 08:05:38.312709 139896463251200 logging_writer.py:48] [51000] global_step=51000, grad_norm=1.06274, loss=2.60642
I0315 08:05:38.316863 139925059253440 submission.py:265] 51000) loss = 2.606, grad_norm = 1.063
I0315 08:09:09.733063 139925059253440 spec.py:321] Evaluating on the training split.
I0315 08:09:53.496239 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 08:10:39.584376 139925059253440 spec.py:349] Evaluating on the test split.
I0315 08:10:40.701281 139925059253440 submission_runner.py:469] Time since start: 37954.68s, 	Step: 51227, 	{'train/accuracy': 0.6999960140306123, 'train/loss': 1.3031205936354033, 'validation/accuracy': 0.6446, 'validation/loss': 1.54074859375, 'validation/num_examples': 50000, 'test/accuracy': 0.5052, 'test/loss': 2.28093515625, 'test/num_examples': 10000, 'score': 32157.4347949028, 'total_duration': 37954.675266742706, 'accumulated_submission_time': 32157.4347949028, 'accumulated_eval_time': 5591.754167795181, 'accumulated_logging_time': 2.6208534240722656}
I0315 08:10:40.756037 139896110970624 logging_writer.py:48] [51227] accumulated_eval_time=5591.75, accumulated_logging_time=2.62085, accumulated_submission_time=32157.4, global_step=51227, preemption_count=0, score=32157.4, test/accuracy=0.5052, test/loss=2.28094, test/num_examples=10000, total_duration=37954.7, train/accuracy=0.699996, train/loss=1.30312, validation/accuracy=0.6446, validation/loss=1.54075, validation/num_examples=50000
I0315 08:13:06.142816 139896463251200 logging_writer.py:48] [51500] global_step=51500, grad_norm=1.07012, loss=2.52873
I0315 08:13:06.147112 139925059253440 submission.py:265] 51500) loss = 2.529, grad_norm = 1.070
I0315 08:16:56.858555 139896110970624 logging_writer.py:48] [52000] global_step=52000, grad_norm=1.14517, loss=2.65371
I0315 08:16:56.862807 139925059253440 submission.py:265] 52000) loss = 2.654, grad_norm = 1.145
I0315 08:19:12.289874 139925059253440 spec.py:321] Evaluating on the training split.
I0315 08:19:54.477620 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 08:20:39.523535 139925059253440 spec.py:349] Evaluating on the test split.
I0315 08:20:40.636194 139925059253440 submission_runner.py:469] Time since start: 38554.61s, 	Step: 52212, 	{'train/accuracy': 0.6955317283163265, 'train/loss': 1.3163114275251115, 'validation/accuracy': 0.6456, 'validation/loss': 1.5439534375, 'validation/num_examples': 50000, 'test/accuracy': 0.5168, 'test/loss': 2.2313359375, 'test/num_examples': 10000, 'score': 32665.361191511154, 'total_duration': 38554.61046457291, 'accumulated_submission_time': 32665.361191511154, 'accumulated_eval_time': 5680.100619792938, 'accumulated_logging_time': 2.750415563583374}
I0315 08:20:40.676688 139896463251200 logging_writer.py:48] [52212] accumulated_eval_time=5680.1, accumulated_logging_time=2.75042, accumulated_submission_time=32665.4, global_step=52212, preemption_count=0, score=32665.4, test/accuracy=0.5168, test/loss=2.23134, test/num_examples=10000, total_duration=38554.6, train/accuracy=0.695532, train/loss=1.31631, validation/accuracy=0.6456, validation/loss=1.54395, validation/num_examples=50000
I0315 08:25:06.318007 139896110970624 logging_writer.py:48] [52500] global_step=52500, grad_norm=1.07788, loss=2.67226
I0315 08:25:06.322122 139925059253440 submission.py:265] 52500) loss = 2.672, grad_norm = 1.078
I0315 08:29:01.888412 139896463251200 logging_writer.py:48] [53000] global_step=53000, grad_norm=1.04621, loss=2.58853
I0315 08:29:01.892265 139925059253440 submission.py:265] 53000) loss = 2.589, grad_norm = 1.046
I0315 08:29:12.388306 139925059253440 spec.py:321] Evaluating on the training split.
I0315 08:29:51.507353 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 08:30:32.828881 139925059253440 spec.py:349] Evaluating on the test split.
I0315 08:30:33.935473 139925059253440 submission_runner.py:469] Time since start: 39147.91s, 	Step: 53021, 	{'train/accuracy': 0.7030253507653061, 'train/loss': 1.3001296374262596, 'validation/accuracy': 0.65044, 'validation/loss': 1.53828109375, 'validation/num_examples': 50000, 'test/accuracy': 0.5051, 'test/loss': 2.26299921875, 'test/num_examples': 10000, 'score': 33173.703953027725, 'total_duration': 39147.90975546837, 'accumulated_submission_time': 33173.703953027725, 'accumulated_eval_time': 5761.648050785065, 'accumulated_logging_time': 2.799591541290283}
I0315 08:30:33.990951 139896110970624 logging_writer.py:48] [53021] accumulated_eval_time=5761.65, accumulated_logging_time=2.79959, accumulated_submission_time=33173.7, global_step=53021, preemption_count=0, score=33173.7, test/accuracy=0.5051, test/loss=2.263, test/num_examples=10000, total_duration=39147.9, train/accuracy=0.703025, train/loss=1.30013, validation/accuracy=0.65044, validation/loss=1.53828, validation/num_examples=50000
I0315 08:35:24.786192 139896463251200 logging_writer.py:48] [53500] global_step=53500, grad_norm=1.06719, loss=2.54998
I0315 08:35:24.806853 139925059253440 submission.py:265] 53500) loss = 2.550, grad_norm = 1.067
I0315 08:39:05.495375 139925059253440 spec.py:321] Evaluating on the training split.
I0315 08:39:48.140555 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 08:40:33.700594 139925059253440 spec.py:349] Evaluating on the test split.
I0315 08:40:34.804852 139925059253440 submission_runner.py:469] Time since start: 39748.78s, 	Step: 53736, 	{'train/accuracy': 0.7049984056122449, 'train/loss': 1.2837951037348534, 'validation/accuracy': 0.64732, 'validation/loss': 1.527440625, 'validation/num_examples': 50000, 'test/accuracy': 0.5059, 'test/loss': 2.2357134765625, 'test/num_examples': 10000, 'score': 33682.10593819618, 'total_duration': 39748.779153585434, 'accumulated_submission_time': 33682.10593819618, 'accumulated_eval_time': 5850.957741737366, 'accumulated_logging_time': 2.8631844520568848}
I0315 08:40:34.835659 139896110970624 logging_writer.py:48] [53736] accumulated_eval_time=5850.96, accumulated_logging_time=2.86318, accumulated_submission_time=33682.1, global_step=53736, preemption_count=0, score=33682.1, test/accuracy=0.5059, test/loss=2.23571, test/num_examples=10000, total_duration=39748.8, train/accuracy=0.704998, train/loss=1.2838, validation/accuracy=0.64732, validation/loss=1.52744, validation/num_examples=50000
I0315 08:42:53.587347 139896463251200 logging_writer.py:48] [54000] global_step=54000, grad_norm=1.15288, loss=2.64585
I0315 08:42:53.591464 139925059253440 submission.py:265] 54000) loss = 2.646, grad_norm = 1.153
I0315 08:46:42.738801 139896110970624 logging_writer.py:48] [54500] global_step=54500, grad_norm=1.07951, loss=2.63282
I0315 08:46:42.742878 139925059253440 submission.py:265] 54500) loss = 2.633, grad_norm = 1.080
I0315 08:49:07.385002 139925059253440 spec.py:321] Evaluating on the training split.
I0315 08:49:50.087512 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 08:50:34.090528 139925059253440 spec.py:349] Evaluating on the test split.
I0315 08:50:35.197371 139925059253440 submission_runner.py:469] Time since start: 40349.17s, 	Step: 54728, 	{'train/accuracy': 0.7034239477040817, 'train/loss': 1.2672743505361128, 'validation/accuracy': 0.6518, 'validation/loss': 1.50201546875, 'validation/num_examples': 50000, 'test/accuracy': 0.5001, 'test/loss': 2.2881654296875, 'test/num_examples': 10000, 'score': 34191.27315425873, 'total_duration': 40349.17148900032, 'accumulated_submission_time': 34191.27315425873, 'accumulated_eval_time': 5938.770181655884, 'accumulated_logging_time': 2.902539014816284}
I0315 08:50:35.211032 139896463251200 logging_writer.py:48] [54728] accumulated_eval_time=5938.77, accumulated_logging_time=2.90254, accumulated_submission_time=34191.3, global_step=54728, preemption_count=0, score=34191.3, test/accuracy=0.5001, test/loss=2.28817, test/num_examples=10000, total_duration=40349.2, train/accuracy=0.703424, train/loss=1.26727, validation/accuracy=0.6518, validation/loss=1.50202, validation/num_examples=50000
I0315 08:54:43.359483 139896110970624 logging_writer.py:48] [55000] global_step=55000, grad_norm=1.08977, loss=2.59743
I0315 08:54:43.363903 139925059253440 submission.py:265] 55000) loss = 2.597, grad_norm = 1.090
I0315 08:58:35.677125 139896463251200 logging_writer.py:48] [55500] global_step=55500, grad_norm=1.03419, loss=2.45909
I0315 08:58:35.681407 139925059253440 submission.py:265] 55500) loss = 2.459, grad_norm = 1.034
I0315 08:59:07.137003 139925059253440 spec.py:321] Evaluating on the training split.
I0315 08:59:49.272099 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 09:00:31.157762 139925059253440 spec.py:349] Evaluating on the test split.
I0315 09:00:32.256373 139925059253440 submission_runner.py:469] Time since start: 40946.23s, 	Step: 55565, 	{'train/accuracy': 0.7043008609693877, 'train/loss': 1.2780186400121571, 'validation/accuracy': 0.64646, 'validation/loss': 1.5250846875, 'validation/num_examples': 50000, 'test/accuracy': 0.4985, 'test/loss': 2.305669140625, 'test/num_examples': 10000, 'score': 34699.97894573212, 'total_duration': 40946.23064804077, 'accumulated_submission_time': 34699.97894573212, 'accumulated_eval_time': 6023.889732599258, 'accumulated_logging_time': 2.9767212867736816}
I0315 09:00:32.269996 139896110970624 logging_writer.py:48] [55565] accumulated_eval_time=6023.89, accumulated_logging_time=2.97672, accumulated_submission_time=34700, global_step=55565, preemption_count=0, score=34700, test/accuracy=0.4985, test/loss=2.30567, test/num_examples=10000, total_duration=40946.2, train/accuracy=0.704301, train/loss=1.27802, validation/accuracy=0.64646, validation/loss=1.52508, validation/num_examples=50000
I0315 09:04:58.813689 139896463251200 logging_writer.py:48] [56000] global_step=56000, grad_norm=1.07419, loss=2.49482
I0315 09:04:58.935029 139925059253440 submission.py:265] 56000) loss = 2.495, grad_norm = 1.074
I0315 09:09:04.979172 139925059253440 spec.py:321] Evaluating on the training split.
I0315 09:09:46.242251 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 09:10:29.510878 139925059253440 spec.py:349] Evaluating on the test split.
I0315 09:10:30.612063 139925059253440 submission_runner.py:469] Time since start: 41544.59s, 	Step: 56261, 	{'train/accuracy': 0.7045001594387755, 'train/loss': 1.272177637839804, 'validation/accuracy': 0.65194, 'validation/loss': 1.51737203125, 'validation/num_examples': 50000, 'test/accuracy': 0.5108, 'test/loss': 2.236665625, 'test/num_examples': 10000, 'score': 35209.52921295166, 'total_duration': 41544.58634305, 'accumulated_submission_time': 35209.52921295166, 'accumulated_eval_time': 6109.522987365723, 'accumulated_logging_time': 2.998589277267456}
I0315 09:10:30.639707 139896110970624 logging_writer.py:48] [56261] accumulated_eval_time=6109.52, accumulated_logging_time=2.99859, accumulated_submission_time=35209.5, global_step=56261, preemption_count=0, score=35209.5, test/accuracy=0.5108, test/loss=2.23667, test/num_examples=10000, total_duration=41544.6, train/accuracy=0.7045, train/loss=1.27218, validation/accuracy=0.65194, validation/loss=1.51737, validation/num_examples=50000
I0315 09:12:27.872087 139896463251200 logging_writer.py:48] [56500] global_step=56500, grad_norm=1.06449, loss=2.51243
I0315 09:12:27.877382 139925059253440 submission.py:265] 56500) loss = 2.512, grad_norm = 1.064
I0315 09:16:28.888849 139896110970624 logging_writer.py:48] [57000] global_step=57000, grad_norm=1.06583, loss=2.4433
I0315 09:16:28.893213 139925059253440 submission.py:265] 57000) loss = 2.443, grad_norm = 1.066
I0315 09:19:03.637952 139925059253440 spec.py:321] Evaluating on the training split.
I0315 09:19:45.279976 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 09:20:28.325909 139925059253440 spec.py:349] Evaluating on the test split.
I0315 09:20:29.426365 139925059253440 submission_runner.py:469] Time since start: 42143.40s, 	Step: 57226, 	{'train/accuracy': 0.7062539859693877, 'train/loss': 1.2667329749282525, 'validation/accuracy': 0.65206, 'validation/loss': 1.51621609375, 'validation/num_examples': 50000, 'test/accuracy': 0.4952, 'test/loss': 2.2860779296875, 'test/num_examples': 10000, 'score': 35719.222950935364, 'total_duration': 42143.40066361427, 'accumulated_submission_time': 35719.222950935364, 'accumulated_eval_time': 6195.311578273773, 'accumulated_logging_time': 3.0348992347717285}
I0315 09:20:29.458589 139896463251200 logging_writer.py:48] [57226] accumulated_eval_time=6195.31, accumulated_logging_time=3.0349, accumulated_submission_time=35719.2, global_step=57226, preemption_count=0, score=35719.2, test/accuracy=0.4952, test/loss=2.28608, test/num_examples=10000, total_duration=42143.4, train/accuracy=0.706254, train/loss=1.26673, validation/accuracy=0.65206, validation/loss=1.51622, validation/num_examples=50000
I0315 09:24:48.676293 139896110970624 logging_writer.py:48] [57500] global_step=57500, grad_norm=1.04595, loss=2.56167
I0315 09:24:48.680304 139925059253440 submission.py:265] 57500) loss = 2.562, grad_norm = 1.046
I0315 09:28:50.476379 139896463251200 logging_writer.py:48] [58000] global_step=58000, grad_norm=1.08614, loss=2.56933
I0315 09:28:50.480886 139925059253440 submission.py:265] 58000) loss = 2.569, grad_norm = 1.086
I0315 09:29:01.119730 139925059253440 spec.py:321] Evaluating on the training split.
I0315 09:29:41.817975 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 09:30:23.091218 139925059253440 spec.py:349] Evaluating on the test split.
I0315 09:30:24.197125 139925059253440 submission_runner.py:469] Time since start: 42738.17s, 	Step: 58019, 	{'train/accuracy': 0.7013313137755102, 'train/loss': 1.290224892752511, 'validation/accuracy': 0.64706, 'validation/loss': 1.525969375, 'validation/num_examples': 50000, 'test/accuracy': 0.5122, 'test/loss': 2.2366759765625, 'test/num_examples': 10000, 'score': 36227.54031133652, 'total_duration': 42738.17141819, 'accumulated_submission_time': 36227.54031133652, 'accumulated_eval_time': 6278.389216899872, 'accumulated_logging_time': 3.1000967025756836}
I0315 09:30:24.210904 139896110970624 logging_writer.py:48] [58019] accumulated_eval_time=6278.39, accumulated_logging_time=3.1001, accumulated_submission_time=36227.5, global_step=58019, preemption_count=0, score=36227.5, test/accuracy=0.5122, test/loss=2.23668, test/num_examples=10000, total_duration=42738.2, train/accuracy=0.701331, train/loss=1.29022, validation/accuracy=0.64706, validation/loss=1.52597, validation/num_examples=50000
I0315 09:35:08.580796 139896463251200 logging_writer.py:48] [58500] global_step=58500, grad_norm=1.15874, loss=2.75359
I0315 09:35:08.633468 139925059253440 submission.py:265] 58500) loss = 2.754, grad_norm = 1.159
I0315 09:38:55.637838 139925059253440 spec.py:321] Evaluating on the training split.
I0315 09:39:37.686909 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 09:40:21.271230 139925059253440 spec.py:349] Evaluating on the test split.
I0315 09:40:22.377453 139925059253440 submission_runner.py:469] Time since start: 43336.35s, 	Step: 58748, 	{'train/accuracy': 0.7054169323979592, 'train/loss': 1.2743050711495536, 'validation/accuracy': 0.6521, 'validation/loss': 1.51192171875, 'validation/num_examples': 50000, 'test/accuracy': 0.5048, 'test/loss': 2.26134296875, 'test/num_examples': 10000, 'score': 36735.76719522476, 'total_duration': 43336.351710796356, 'accumulated_submission_time': 36735.76719522476, 'accumulated_eval_time': 6365.129046916962, 'accumulated_logging_time': 3.121900796890259}
I0315 09:40:22.442322 139896110970624 logging_writer.py:48] [58748] accumulated_eval_time=6365.13, accumulated_logging_time=3.1219, accumulated_submission_time=36735.8, global_step=58748, preemption_count=0, score=36735.8, test/accuracy=0.5048, test/loss=2.26134, test/num_examples=10000, total_duration=43336.4, train/accuracy=0.705417, train/loss=1.27431, validation/accuracy=0.6521, validation/loss=1.51192, validation/num_examples=50000
I0315 09:42:39.031013 139896463251200 logging_writer.py:48] [59000] global_step=59000, grad_norm=1.07729, loss=2.57821
I0315 09:42:39.035470 139925059253440 submission.py:265] 59000) loss = 2.578, grad_norm = 1.077
I0315 09:46:33.473685 139896110970624 logging_writer.py:48] [59500] global_step=59500, grad_norm=1.05007, loss=2.5427
I0315 09:46:33.478128 139925059253440 submission.py:265] 59500) loss = 2.543, grad_norm = 1.050
I0315 09:48:55.787952 139925059253440 spec.py:321] Evaluating on the training split.
I0315 09:49:36.619501 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 09:50:19.896456 139925059253440 spec.py:349] Evaluating on the test split.
I0315 09:50:21.002990 139925059253440 submission_runner.py:469] Time since start: 43934.98s, 	Step: 59710, 	{'train/accuracy': 0.7064931441326531, 'train/loss': 1.2878023264359455, 'validation/accuracy': 0.6527, 'validation/loss': 1.5264784375, 'validation/num_examples': 50000, 'test/accuracy': 0.5107, 'test/loss': 2.2499158203125, 'test/num_examples': 10000, 'score': 37245.81012773514, 'total_duration': 43934.977206707, 'accumulated_submission_time': 37245.81012773514, 'accumulated_eval_time': 6450.344282627106, 'accumulated_logging_time': 3.1951725482940674}
I0315 09:50:21.016897 139896463251200 logging_writer.py:48] [59710] accumulated_eval_time=6450.34, accumulated_logging_time=3.19517, accumulated_submission_time=37245.8, global_step=59710, preemption_count=0, score=37245.8, test/accuracy=0.5107, test/loss=2.24992, test/num_examples=10000, total_duration=43935, train/accuracy=0.706493, train/loss=1.2878, validation/accuracy=0.6527, validation/loss=1.52648, validation/num_examples=50000
I0315 09:54:51.199376 139896110970624 logging_writer.py:48] [60000] global_step=60000, grad_norm=1.08641, loss=2.59822
I0315 09:54:51.203974 139925059253440 submission.py:265] 60000) loss = 2.598, grad_norm = 1.086
I0315 09:58:52.534381 139925059253440 spec.py:321] Evaluating on the training split.
I0315 09:59:34.415948 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 10:00:18.085883 139925059253440 spec.py:349] Evaluating on the test split.
I0315 10:00:19.195631 139925059253440 submission_runner.py:469] Time since start: 44533.17s, 	Step: 60495, 	{'train/accuracy': 0.7069316007653061, 'train/loss': 1.2822735844826212, 'validation/accuracy': 0.65258, 'validation/loss': 1.5207021875, 'validation/num_examples': 50000, 'test/accuracy': 0.5093, 'test/loss': 2.25282734375, 'test/num_examples': 10000, 'score': 37754.14407801628, 'total_duration': 44533.16983413696, 'accumulated_submission_time': 37754.14407801628, 'accumulated_eval_time': 6537.005597829819, 'accumulated_logging_time': 3.217559576034546}
I0315 10:00:19.223103 139896463251200 logging_writer.py:48] [60495] accumulated_eval_time=6537.01, accumulated_logging_time=3.21756, accumulated_submission_time=37754.1, global_step=60495, preemption_count=0, score=37754.1, test/accuracy=0.5093, test/loss=2.25283, test/num_examples=10000, total_duration=44533.2, train/accuracy=0.706932, train/loss=1.28227, validation/accuracy=0.65258, validation/loss=1.5207, validation/num_examples=50000
I0315 10:00:23.276053 139896110970624 logging_writer.py:48] [60500] global_step=60500, grad_norm=1.12312, loss=2.59196
I0315 10:00:23.279817 139925059253440 submission.py:265] 60500) loss = 2.592, grad_norm = 1.123
I0315 10:05:15.583616 139896463251200 logging_writer.py:48] [61000] global_step=61000, grad_norm=1.08268, loss=2.56902
I0315 10:05:15.587875 139925059253440 submission.py:265] 61000) loss = 2.569, grad_norm = 1.083
I0315 10:08:52.589433 139925059253440 spec.py:321] Evaluating on the training split.
I0315 10:09:33.912411 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 10:10:17.237610 139925059253440 spec.py:349] Evaluating on the test split.
I0315 10:10:18.342444 139925059253440 submission_runner.py:469] Time since start: 45132.32s, 	Step: 61229, 	{'train/accuracy': 0.7085857780612245, 'train/loss': 1.2402721327178332, 'validation/accuracy': 0.65348, 'validation/loss': 1.4874296875, 'validation/num_examples': 50000, 'test/accuracy': 0.5134, 'test/loss': 2.1998013671875, 'test/num_examples': 10000, 'score': 38264.19334220886, 'total_duration': 45132.31668829918, 'accumulated_submission_time': 38264.19334220886, 'accumulated_eval_time': 6622.758697986603, 'accumulated_logging_time': 3.3107011318206787}
I0315 10:10:18.384046 139896110970624 logging_writer.py:48] [61229] accumulated_eval_time=6622.76, accumulated_logging_time=3.3107, accumulated_submission_time=38264.2, global_step=61229, preemption_count=0, score=38264.2, test/accuracy=0.5134, test/loss=2.1998, test/num_examples=10000, total_duration=45132.3, train/accuracy=0.708586, train/loss=1.24027, validation/accuracy=0.65348, validation/loss=1.48743, validation/num_examples=50000
I0315 10:12:56.959068 139896463251200 logging_writer.py:48] [61500] global_step=61500, grad_norm=1.0436, loss=2.48398
I0315 10:12:56.963218 139925059253440 submission.py:265] 61500) loss = 2.484, grad_norm = 1.044
I0315 10:16:54.668773 139896110970624 logging_writer.py:48] [62000] global_step=62000, grad_norm=1.07985, loss=2.54447
I0315 10:16:54.672945 139925059253440 submission.py:265] 62000) loss = 2.544, grad_norm = 1.080
I0315 10:18:50.689177 139925059253440 spec.py:321] Evaluating on the training split.
I0315 10:19:32.232827 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 10:20:15.689717 139925059253440 spec.py:349] Evaluating on the test split.
I0315 10:20:16.794077 139925059253440 submission_runner.py:469] Time since start: 45730.77s, 	Step: 62180, 	{'train/accuracy': 0.7139269770408163, 'train/loss': 1.2369188581194197, 'validation/accuracy': 0.6567, 'validation/loss': 1.485054375, 'validation/num_examples': 50000, 'test/accuracy': 0.5172, 'test/loss': 2.19907109375, 'test/num_examples': 10000, 'score': 38773.152814626694, 'total_duration': 45730.7682621479, 'accumulated_submission_time': 38773.152814626694, 'accumulated_eval_time': 6708.863791704178, 'accumulated_logging_time': 3.3950448036193848}
I0315 10:20:16.808102 139896463251200 logging_writer.py:48] [62180] accumulated_eval_time=6708.86, accumulated_logging_time=3.39504, accumulated_submission_time=38773.2, global_step=62180, preemption_count=0, score=38773.2, test/accuracy=0.5172, test/loss=2.19907, test/num_examples=10000, total_duration=45730.8, train/accuracy=0.713927, train/loss=1.23692, validation/accuracy=0.6567, validation/loss=1.48505, validation/num_examples=50000
I0315 10:24:56.913484 139896110970624 logging_writer.py:48] [62500] global_step=62500, grad_norm=1.07427, loss=2.60302
I0315 10:24:56.934386 139925059253440 submission.py:265] 62500) loss = 2.603, grad_norm = 1.074
I0315 10:28:48.332973 139925059253440 spec.py:321] Evaluating on the training split.
I0315 10:29:29.211384 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 10:30:10.315104 139925059253440 spec.py:349] Evaluating on the test split.
I0315 10:30:11.422312 139925059253440 submission_runner.py:469] Time since start: 46325.40s, 	Step: 62986, 	{'train/accuracy': 0.7119339923469388, 'train/loss': 1.2434076581682478, 'validation/accuracy': 0.65794, 'validation/loss': 1.4797546875, 'validation/num_examples': 50000, 'test/accuracy': 0.5047, 'test/loss': 2.2628677734375, 'test/num_examples': 10000, 'score': 39281.3629488945, 'total_duration': 46325.39657306671, 'accumulated_submission_time': 39281.3629488945, 'accumulated_eval_time': 6791.95330119133, 'accumulated_logging_time': 3.417386531829834}
I0315 10:30:11.453235 139896463251200 logging_writer.py:48] [62986] accumulated_eval_time=6791.95, accumulated_logging_time=3.41739, accumulated_submission_time=39281.4, global_step=62986, preemption_count=0, score=39281.4, test/accuracy=0.5047, test/loss=2.26287, test/num_examples=10000, total_duration=46325.4, train/accuracy=0.711934, train/loss=1.24341, validation/accuracy=0.65794, validation/loss=1.47975, validation/num_examples=50000
I0315 10:30:18.503787 139896110970624 logging_writer.py:48] [63000] global_step=63000, grad_norm=1.10785, loss=2.52489
I0315 10:30:18.507499 139925059253440 submission.py:265] 63000) loss = 2.525, grad_norm = 1.108
I0315 10:34:44.955743 139896463251200 logging_writer.py:48] [63500] global_step=63500, grad_norm=1.07135, loss=2.53083
I0315 10:34:44.967777 139925059253440 submission.py:265] 63500) loss = 2.531, grad_norm = 1.071
I0315 10:38:43.659521 139925059253440 spec.py:321] Evaluating on the training split.
I0315 10:39:25.715063 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 10:40:08.915189 139925059253440 spec.py:349] Evaluating on the test split.
I0315 10:40:10.021119 139925059253440 submission_runner.py:469] Time since start: 46924.00s, 	Step: 63766, 	{'train/accuracy': 0.7117745535714286, 'train/loss': 1.2585198538643974, 'validation/accuracy': 0.65054, 'validation/loss': 1.50637515625, 'validation/num_examples': 50000, 'test/accuracy': 0.5096, 'test/loss': 2.238537890625, 'test/num_examples': 10000, 'score': 39790.39046597481, 'total_duration': 46923.99529361725, 'accumulated_submission_time': 39790.39046597481, 'accumulated_eval_time': 6878.3149654865265, 'accumulated_logging_time': 3.4573683738708496}
I0315 10:40:10.054914 139896110970624 logging_writer.py:48] [63766] accumulated_eval_time=6878.31, accumulated_logging_time=3.45737, accumulated_submission_time=39790.4, global_step=63766, preemption_count=0, score=39790.4, test/accuracy=0.5096, test/loss=2.23854, test/num_examples=10000, total_duration=46924, train/accuracy=0.711775, train/loss=1.25852, validation/accuracy=0.65054, validation/loss=1.50638, validation/num_examples=50000
I0315 10:42:02.004631 139896463251200 logging_writer.py:48] [64000] global_step=64000, grad_norm=1.08752, loss=2.50018
I0315 10:42:02.008889 139925059253440 submission.py:265] 64000) loss = 2.500, grad_norm = 1.088
I0315 10:45:44.339578 139896110970624 logging_writer.py:48] [64500] global_step=64500, grad_norm=1.13902, loss=2.59636
I0315 10:45:44.343618 139925059253440 submission.py:265] 64500) loss = 2.596, grad_norm = 1.139
I0315 10:48:41.526746 139925059253440 spec.py:321] Evaluating on the training split.
I0315 10:49:23.824187 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 10:50:08.915279 139925059253440 spec.py:349] Evaluating on the test split.
I0315 10:50:10.016878 139925059253440 submission_runner.py:469] Time since start: 47523.99s, 	Step: 64761, 	{'train/accuracy': 0.7140864158163265, 'train/loss': 1.24510535415338, 'validation/accuracy': 0.65852, 'validation/loss': 1.4887603125, 'validation/num_examples': 50000, 'test/accuracy': 0.5098, 'test/loss': 2.252995703125, 'test/num_examples': 10000, 'score': 40298.52786064148, 'total_duration': 47523.99117016792, 'accumulated_submission_time': 40298.52786064148, 'accumulated_eval_time': 6966.805249929428, 'accumulated_logging_time': 3.500828742980957}
I0315 10:50:10.030609 139896463251200 logging_writer.py:48] [64761] accumulated_eval_time=6966.81, accumulated_logging_time=3.50083, accumulated_submission_time=40298.5, global_step=64761, preemption_count=0, score=40298.5, test/accuracy=0.5098, test/loss=2.253, test/num_examples=10000, total_duration=47524, train/accuracy=0.714086, train/loss=1.24511, validation/accuracy=0.65852, validation/loss=1.48876, validation/num_examples=50000
I0315 10:53:44.478682 139896110970624 logging_writer.py:48] [65000] global_step=65000, grad_norm=1.1273, loss=2.59277
I0315 10:53:44.533222 139925059253440 submission.py:265] 65000) loss = 2.593, grad_norm = 1.127
I0315 10:57:37.246376 139896463251200 logging_writer.py:48] [65500] global_step=65500, grad_norm=1.08365, loss=2.50157
I0315 10:57:37.251185 139925059253440 submission.py:265] 65500) loss = 2.502, grad_norm = 1.084
I0315 10:58:41.660537 139925059253440 spec.py:321] Evaluating on the training split.
I0315 10:59:23.964252 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 11:00:08.165465 139925059253440 spec.py:349] Evaluating on the test split.
I0315 11:00:09.268979 139925059253440 submission_runner.py:469] Time since start: 48123.24s, 	Step: 65623, 	{'train/accuracy': 0.7114357461734694, 'train/loss': 1.2538537784498565, 'validation/accuracy': 0.65424, 'validation/loss': 1.4949375, 'validation/num_examples': 50000, 'test/accuracy': 0.5105, 'test/loss': 2.263198828125, 'test/num_examples': 10000, 'score': 40806.87891769409, 'total_duration': 48123.24325299263, 'accumulated_submission_time': 40806.87891769409, 'accumulated_eval_time': 7054.413929224014, 'accumulated_logging_time': 3.5231618881225586}
I0315 11:00:09.298289 139896110970624 logging_writer.py:48] [65623] accumulated_eval_time=7054.41, accumulated_logging_time=3.52316, accumulated_submission_time=40806.9, global_step=65623, preemption_count=0, score=40806.9, test/accuracy=0.5105, test/loss=2.2632, test/num_examples=10000, total_duration=48123.2, train/accuracy=0.711436, train/loss=1.25385, validation/accuracy=0.65424, validation/loss=1.49494, validation/num_examples=50000
I0315 11:04:45.390480 139896463251200 logging_writer.py:48] [66000] global_step=66000, grad_norm=1.14922, loss=2.7536
I0315 11:04:45.394623 139925059253440 submission.py:265] 66000) loss = 2.754, grad_norm = 1.149
I0315 11:08:41.370938 139925059253440 spec.py:321] Evaluating on the training split.
I0315 11:09:22.998185 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 11:10:06.616911 139925059253440 spec.py:349] Evaluating on the test split.
I0315 11:10:07.717741 139925059253440 submission_runner.py:469] Time since start: 48721.69s, 	Step: 66220, 	{'train/accuracy': 0.7114158163265306, 'train/loss': 1.225133856948541, 'validation/accuracy': 0.65754, 'validation/loss': 1.46540375, 'validation/num_examples': 50000, 'test/accuracy': 0.5175, 'test/loss': 2.1926892578125, 'test/num_examples': 10000, 'score': 41315.92387223244, 'total_duration': 48721.69203090668, 'accumulated_submission_time': 41315.92387223244, 'accumulated_eval_time': 7140.760954618454, 'accumulated_logging_time': 3.5609922409057617}
I0315 11:10:07.732693 139896110970624 logging_writer.py:48] [66220] accumulated_eval_time=7140.76, accumulated_logging_time=3.56099, accumulated_submission_time=41315.9, global_step=66220, preemption_count=0, score=41315.9, test/accuracy=0.5175, test/loss=2.19269, test/num_examples=10000, total_duration=48721.7, train/accuracy=0.711416, train/loss=1.22513, validation/accuracy=0.65754, validation/loss=1.4654, validation/num_examples=50000
I0315 11:13:16.840619 139896463251200 logging_writer.py:48] [66500] global_step=66500, grad_norm=1.1102, loss=2.57168
I0315 11:13:16.844908 139925059253440 submission.py:265] 66500) loss = 2.572, grad_norm = 1.110
I0315 11:17:37.020879 139896110970624 logging_writer.py:48] [67000] global_step=67000, grad_norm=1.10951, loss=2.56109
I0315 11:17:37.024963 139925059253440 submission.py:265] 67000) loss = 2.561, grad_norm = 1.110
I0315 11:18:39.424970 139925059253440 spec.py:321] Evaluating on the training split.
I0315 11:19:21.349807 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 11:20:05.611089 139925059253440 spec.py:349] Evaluating on the test split.
I0315 11:20:06.715075 139925059253440 submission_runner.py:469] Time since start: 49320.69s, 	Step: 67087, 	{'train/accuracy': 0.7170758928571429, 'train/loss': 1.231467577875877, 'validation/accuracy': 0.65954, 'validation/loss': 1.47842171875, 'validation/num_examples': 50000, 'test/accuracy': 0.5159, 'test/loss': 2.206418359375, 'test/num_examples': 10000, 'score': 41824.411314964294, 'total_duration': 49320.689351797104, 'accumulated_submission_time': 41824.411314964294, 'accumulated_eval_time': 7228.05131316185, 'accumulated_logging_time': 3.607471227645874}
I0315 11:20:06.761825 139896463251200 logging_writer.py:48] [67087] accumulated_eval_time=7228.05, accumulated_logging_time=3.60747, accumulated_submission_time=41824.4, global_step=67087, preemption_count=0, score=41824.4, test/accuracy=0.5159, test/loss=2.20642, test/num_examples=10000, total_duration=49320.7, train/accuracy=0.717076, train/loss=1.23147, validation/accuracy=0.65954, validation/loss=1.47842, validation/num_examples=50000
I0315 11:26:52.783256 139896110970624 logging_writer.py:48] [67500] global_step=67500, grad_norm=1.08554, loss=2.512
I0315 11:26:52.804896 139925059253440 submission.py:265] 67500) loss = 2.512, grad_norm = 1.086
I0315 11:28:38.280552 139925059253440 spec.py:321] Evaluating on the training split.
I0315 11:29:19.764878 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 11:30:00.771612 139925059253440 spec.py:349] Evaluating on the test split.
I0315 11:30:01.877390 139925059253440 submission_runner.py:469] Time since start: 49915.85s, 	Step: 67643, 	{'train/accuracy': 0.7196269132653061, 'train/loss': 1.2125687112613601, 'validation/accuracy': 0.65842, 'validation/loss': 1.47050171875, 'validation/num_examples': 50000, 'test/accuracy': 0.5129, 'test/loss': 2.246649609375, 'test/num_examples': 10000, 'score': 42332.84548997879, 'total_duration': 49915.851712465286, 'accumulated_submission_time': 42332.84548997879, 'accumulated_eval_time': 7311.648412227631, 'accumulated_logging_time': 3.662531852722168}
I0315 11:30:01.891130 139896463251200 logging_writer.py:48] [67643] accumulated_eval_time=7311.65, accumulated_logging_time=3.66253, accumulated_submission_time=42332.8, global_step=67643, preemption_count=0, score=42332.8, test/accuracy=0.5129, test/loss=2.24665, test/num_examples=10000, total_duration=49915.9, train/accuracy=0.719627, train/loss=1.21257, validation/accuracy=0.65842, validation/loss=1.4705, validation/num_examples=50000
I0315 11:32:45.641707 139896110970624 logging_writer.py:48] [68000] global_step=68000, grad_norm=1.09761, loss=2.56652
I0315 11:32:45.645972 139925059253440 submission.py:265] 68000) loss = 2.567, grad_norm = 1.098
I0315 11:38:01.012499 139896463251200 logging_writer.py:48] [68500] global_step=68500, grad_norm=1.09645, loss=2.57214
I0315 11:38:01.016986 139925059253440 submission.py:265] 68500) loss = 2.572, grad_norm = 1.096
I0315 11:38:33.453676 139925059253440 spec.py:321] Evaluating on the training split.
I0315 11:39:16.289167 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 11:40:01.007012 139925059253440 spec.py:349] Evaluating on the test split.
I0315 11:40:02.104754 139925059253440 submission_runner.py:469] Time since start: 50516.08s, 	Step: 68533, 	{'train/accuracy': 0.7189094387755102, 'train/loss': 1.2190224005251515, 'validation/accuracy': 0.66096, 'validation/loss': 1.46769375, 'validation/num_examples': 50000, 'test/accuracy': 0.5199, 'test/loss': 2.1974390625, 'test/num_examples': 10000, 'score': 42841.10268139839, 'total_duration': 50516.0788795948, 'accumulated_submission_time': 42841.10268139839, 'accumulated_eval_time': 7400.299445867538, 'accumulated_logging_time': 3.684558868408203}
I0315 11:40:02.123911 139896110970624 logging_writer.py:48] [68533] accumulated_eval_time=7400.3, accumulated_logging_time=3.68456, accumulated_submission_time=42841.1, global_step=68533, preemption_count=0, score=42841.1, test/accuracy=0.5199, test/loss=2.19744, test/num_examples=10000, total_duration=50516.1, train/accuracy=0.718909, train/loss=1.21902, validation/accuracy=0.66096, validation/loss=1.46769, validation/num_examples=50000
I0315 11:45:58.259855 139896463251200 logging_writer.py:48] [69000] global_step=69000, grad_norm=1.09593, loss=2.51998
I0315 11:45:58.263779 139925059253440 submission.py:265] 69000) loss = 2.520, grad_norm = 1.096
I0315 11:48:33.538617 139925059253440 spec.py:321] Evaluating on the training split.
I0315 11:49:15.513885 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 11:49:59.789661 139925059253440 spec.py:349] Evaluating on the test split.
I0315 11:50:00.904907 139925059253440 submission_runner.py:469] Time since start: 51114.88s, 	Step: 69334, 	{'train/accuracy': 0.7165776466836735, 'train/loss': 1.2206538453394054, 'validation/accuracy': 0.65908, 'validation/loss': 1.47681015625, 'validation/num_examples': 50000, 'test/accuracy': 0.5102, 'test/loss': 2.2502404296875, 'test/num_examples': 10000, 'score': 43349.19257426262, 'total_duration': 51114.878937244415, 'accumulated_submission_time': 43349.19257426262, 'accumulated_eval_time': 7487.665808916092, 'accumulated_logging_time': 3.7240045070648193}
I0315 11:50:00.989220 139896110970624 logging_writer.py:48] [69334] accumulated_eval_time=7487.67, accumulated_logging_time=3.724, accumulated_submission_time=43349.2, global_step=69334, preemption_count=0, score=43349.2, test/accuracy=0.5102, test/loss=2.25024, test/num_examples=10000, total_duration=51114.9, train/accuracy=0.716578, train/loss=1.22065, validation/accuracy=0.65908, validation/loss=1.47681, validation/num_examples=50000
I0315 11:51:31.067739 139896463251200 logging_writer.py:48] [69500] global_step=69500, grad_norm=1.1469, loss=2.5447
I0315 11:51:31.071619 139925059253440 submission.py:265] 69500) loss = 2.545, grad_norm = 1.147
I0315 11:58:32.546921 139925059253440 spec.py:321] Evaluating on the training split.
I0315 11:59:12.700893 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 12:00:05.353906 139925059253440 spec.py:349] Evaluating on the test split.
I0315 12:00:06.455991 139925059253440 submission_runner.py:469] Time since start: 51720.43s, 	Step: 70000, 	{'train/accuracy': 0.7119339923469388, 'train/loss': 1.229160230986926, 'validation/accuracy': 0.65756, 'validation/loss': 1.47442359375, 'validation/num_examples': 50000, 'test/accuracy': 0.5307, 'test/loss': 2.1368701171875, 'test/num_examples': 10000, 'score': 43857.49768638611, 'total_duration': 51720.430292367935, 'accumulated_submission_time': 43857.49768638611, 'accumulated_eval_time': 7581.574929237366, 'accumulated_logging_time': 3.8173158168792725}
I0315 12:00:06.521360 139896110970624 logging_writer.py:48] [70000] accumulated_eval_time=7581.57, accumulated_logging_time=3.81732, accumulated_submission_time=43857.5, global_step=70000, preemption_count=0, score=43857.5, test/accuracy=0.5307, test/loss=2.13687, test/num_examples=10000, total_duration=51720.4, train/accuracy=0.711934, train/loss=1.22916, validation/accuracy=0.65756, validation/loss=1.47442, validation/num_examples=50000
I0315 12:00:08.278743 139896463251200 logging_writer.py:48] [70000] global_step=70000, grad_norm=1.14034, loss=2.55824
I0315 12:00:08.281986 139925059253440 submission.py:265] 70000) loss = 2.558, grad_norm = 1.140
I0315 12:04:17.961515 139896110970624 logging_writer.py:48] [70500] global_step=70500, grad_norm=1.06965, loss=2.45376
I0315 12:04:17.966280 139925059253440 submission.py:265] 70500) loss = 2.454, grad_norm = 1.070
I0315 12:08:38.815152 139925059253440 spec.py:321] Evaluating on the training split.
I0315 12:09:20.338032 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 12:10:01.859086 139925059253440 spec.py:349] Evaluating on the test split.
I0315 12:10:02.962430 139925059253440 submission_runner.py:469] Time since start: 52316.94s, 	Step: 70941, 	{'train/accuracy': 0.7199059311224489, 'train/loss': 1.2056292319784359, 'validation/accuracy': 0.66434, 'validation/loss': 1.45818859375, 'validation/num_examples': 50000, 'test/accuracy': 0.5215, 'test/loss': 2.184435546875, 'test/num_examples': 10000, 'score': 44366.392253637314, 'total_duration': 52316.936707258224, 'accumulated_submission_time': 44366.392253637314, 'accumulated_eval_time': 7665.722358942032, 'accumulated_logging_time': 3.9152402877807617}
I0315 12:10:02.988725 139896463251200 logging_writer.py:48] [70941] accumulated_eval_time=7665.72, accumulated_logging_time=3.91524, accumulated_submission_time=44366.4, global_step=70941, preemption_count=0, score=44366.4, test/accuracy=0.5215, test/loss=2.18444, test/num_examples=10000, total_duration=52316.9, train/accuracy=0.719906, train/loss=1.20563, validation/accuracy=0.66434, validation/loss=1.45819, validation/num_examples=50000
I0315 12:10:48.958541 139896110970624 logging_writer.py:48] [71000] global_step=71000, grad_norm=1.13772, loss=2.54477
I0315 12:10:48.962611 139925059253440 submission.py:265] 71000) loss = 2.545, grad_norm = 1.138
I0315 12:17:13.870835 139896463251200 logging_writer.py:48] [71500] global_step=71500, grad_norm=1.139, loss=2.51445
I0315 12:17:13.875000 139925059253440 submission.py:265] 71500) loss = 2.514, grad_norm = 1.139
I0315 12:18:34.651672 139925059253440 spec.py:321] Evaluating on the training split.
I0315 12:19:16.227416 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 12:19:57.622374 139925059253440 spec.py:349] Evaluating on the test split.
I0315 12:19:58.726647 139925059253440 submission_runner.py:469] Time since start: 52912.70s, 	Step: 71684, 	{'train/accuracy': 0.7248883928571429, 'train/loss': 1.1886137358996334, 'validation/accuracy': 0.66394, 'validation/loss': 1.44206375, 'validation/num_examples': 50000, 'test/accuracy': 0.5292, 'test/loss': 2.149873046875, 'test/num_examples': 10000, 'score': 44874.85699701309, 'total_duration': 52912.700901031494, 'accumulated_submission_time': 44874.85699701309, 'accumulated_eval_time': 7749.797535419464, 'accumulated_logging_time': 3.9496002197265625}
I0315 12:19:58.742741 139896110970624 logging_writer.py:48] [71684] accumulated_eval_time=7749.8, accumulated_logging_time=3.9496, accumulated_submission_time=44874.9, global_step=71684, preemption_count=0, score=44874.9, test/accuracy=0.5292, test/loss=2.14987, test/num_examples=10000, total_duration=52912.7, train/accuracy=0.724888, train/loss=1.18861, validation/accuracy=0.66394, validation/loss=1.44206, validation/num_examples=50000
I0315 12:22:38.225415 139896463251200 logging_writer.py:48] [72000] global_step=72000, grad_norm=1.08308, loss=2.53798
I0315 12:22:38.229849 139925059253440 submission.py:265] 72000) loss = 2.538, grad_norm = 1.083
I0315 12:28:31.442049 139925059253440 spec.py:321] Evaluating on the training split.
I0315 12:29:13.764480 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 12:29:58.907214 139925059253440 spec.py:349] Evaluating on the test split.
I0315 12:30:00.014698 139925059253440 submission_runner.py:469] Time since start: 53513.99s, 	Step: 72435, 	{'train/accuracy': 0.7254264987244898, 'train/loss': 1.1759263641980229, 'validation/accuracy': 0.66826, 'validation/loss': 1.426800625, 'validation/num_examples': 50000, 'test/accuracy': 0.5264, 'test/loss': 2.152442578125, 'test/num_examples': 10000, 'score': 45384.40490436554, 'total_duration': 53513.98900389671, 'accumulated_submission_time': 45384.40490436554, 'accumulated_eval_time': 7838.370414495468, 'accumulated_logging_time': 3.974426507949829}
I0315 12:30:00.048542 139896110970624 logging_writer.py:48] [72435] accumulated_eval_time=7838.37, accumulated_logging_time=3.97443, accumulated_submission_time=45384.4, global_step=72435, preemption_count=0, score=45384.4, test/accuracy=0.5264, test/loss=2.15244, test/num_examples=10000, total_duration=53514, train/accuracy=0.725426, train/loss=1.17593, validation/accuracy=0.66826, validation/loss=1.4268, validation/num_examples=50000
I0315 12:31:05.565757 139896463251200 logging_writer.py:48] [72500] global_step=72500, grad_norm=1.12892, loss=2.48419
I0315 12:31:05.569507 139925059253440 submission.py:265] 72500) loss = 2.484, grad_norm = 1.129
I0315 12:35:21.569298 139896110970624 logging_writer.py:48] [73000] global_step=73000, grad_norm=1.0995, loss=2.52907
I0315 12:35:21.573742 139925059253440 submission.py:265] 73000) loss = 2.529, grad_norm = 1.100
I0315 12:38:31.516692 139925059253440 spec.py:321] Evaluating on the training split.
I0315 12:39:13.975126 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 12:40:00.803272 139925059253440 spec.py:349] Evaluating on the test split.
I0315 12:40:01.906248 139925059253440 submission_runner.py:469] Time since start: 54115.88s, 	Step: 73342, 	{'train/accuracy': 0.7194076849489796, 'train/loss': 1.1930418987663425, 'validation/accuracy': 0.66228, 'validation/loss': 1.44454609375, 'validation/num_examples': 50000, 'test/accuracy': 0.5214, 'test/loss': 2.18005625, 'test/num_examples': 10000, 'score': 45892.52161049843, 'total_duration': 54115.8805410862, 'accumulated_submission_time': 45892.52161049843, 'accumulated_eval_time': 7928.760132789612, 'accumulated_logging_time': 4.0580174922943115}
I0315 12:40:01.920553 139896463251200 logging_writer.py:48] [73342] accumulated_eval_time=7928.76, accumulated_logging_time=4.05802, accumulated_submission_time=45892.5, global_step=73342, preemption_count=0, score=45892.5, test/accuracy=0.5214, test/loss=2.18006, test/num_examples=10000, total_duration=54115.9, train/accuracy=0.719408, train/loss=1.19304, validation/accuracy=0.66228, validation/loss=1.44455, validation/num_examples=50000
I0315 12:41:58.100327 139896110970624 logging_writer.py:48] [73500] global_step=73500, grad_norm=1.12145, loss=2.46018
I0315 12:41:58.104260 139925059253440 submission.py:265] 73500) loss = 2.460, grad_norm = 1.121
I0315 12:48:33.682405 139925059253440 spec.py:321] Evaluating on the training split.
I0315 12:49:13.466040 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 12:49:54.179131 139925059253440 spec.py:349] Evaluating on the test split.
I0315 12:49:55.282425 139925059253440 submission_runner.py:469] Time since start: 54709.26s, 	Step: 73998, 	{'train/accuracy': 0.7271006058673469, 'train/loss': 1.195806853625239, 'validation/accuracy': 0.66712, 'validation/loss': 1.44891546875, 'validation/num_examples': 50000, 'test/accuracy': 0.5234, 'test/loss': 2.1723060546875, 'test/num_examples': 10000, 'score': 46401.121795892715, 'total_duration': 54709.256684303284, 'accumulated_submission_time': 46401.121795892715, 'accumulated_eval_time': 8010.360300064087, 'accumulated_logging_time': 4.080565690994263}
I0315 12:49:55.325049 139896463251200 logging_writer.py:48] [73998] accumulated_eval_time=8010.36, accumulated_logging_time=4.08057, accumulated_submission_time=46401.1, global_step=73998, preemption_count=0, score=46401.1, test/accuracy=0.5234, test/loss=2.17231, test/num_examples=10000, total_duration=54709.3, train/accuracy=0.727101, train/loss=1.19581, validation/accuracy=0.66712, validation/loss=1.44892, validation/num_examples=50000
I0315 12:49:58.028272 139896110970624 logging_writer.py:48] [74000] global_step=74000, grad_norm=1.10396, loss=2.42903
I0315 12:49:58.032237 139925059253440 submission.py:265] 74000) loss = 2.429, grad_norm = 1.104
I0315 12:53:57.372281 139896463251200 logging_writer.py:48] [74500] global_step=74500, grad_norm=1.14686, loss=2.61873
I0315 12:53:57.376612 139925059253440 submission.py:265] 74500) loss = 2.619, grad_norm = 1.147
I0315 12:58:26.944195 139925059253440 spec.py:321] Evaluating on the training split.
I0315 12:59:07.890364 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 12:59:51.342491 139925059253440 spec.py:349] Evaluating on the test split.
I0315 12:59:52.442940 139925059253440 submission_runner.py:469] Time since start: 55306.42s, 	Step: 74847, 	{'train/accuracy': 0.72265625, 'train/loss': 1.1901526159169722, 'validation/accuracy': 0.66512, 'validation/loss': 1.44919703125, 'validation/num_examples': 50000, 'test/accuracy': 0.5214, 'test/loss': 2.167185546875, 'test/num_examples': 10000, 'score': 46909.644025564194, 'total_duration': 55306.41723918915, 'accumulated_submission_time': 46909.644025564194, 'accumulated_eval_time': 8095.8592619895935, 'accumulated_logging_time': 4.208085298538208}
I0315 12:59:52.508597 139896110970624 logging_writer.py:48] [74847] accumulated_eval_time=8095.86, accumulated_logging_time=4.20809, accumulated_submission_time=46909.6, global_step=74847, preemption_count=0, score=46909.6, test/accuracy=0.5214, test/loss=2.16719, test/num_examples=10000, total_duration=55306.4, train/accuracy=0.722656, train/loss=1.19015, validation/accuracy=0.66512, validation/loss=1.4492, validation/num_examples=50000
I0315 13:02:21.599917 139896463251200 logging_writer.py:48] [75000] global_step=75000, grad_norm=1.14435, loss=2.56009
I0315 13:02:21.604518 139925059253440 submission.py:265] 75000) loss = 2.560, grad_norm = 1.144
I0315 13:06:35.574905 139896110970624 logging_writer.py:48] [75500] global_step=75500, grad_norm=1.13997, loss=2.56738
I0315 13:06:35.579725 139925059253440 submission.py:265] 75500) loss = 2.567, grad_norm = 1.140
I0315 13:08:24.614146 139925059253440 spec.py:321] Evaluating on the training split.
I0315 13:09:05.474988 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 13:09:47.228441 139925059253440 spec.py:349] Evaluating on the test split.
I0315 13:09:48.332201 139925059253440 submission_runner.py:469] Time since start: 55902.31s, 	Step: 75705, 	{'train/accuracy': 0.7220583545918368, 'train/loss': 1.1935030100296955, 'validation/accuracy': 0.66196, 'validation/loss': 1.44999828125, 'validation/num_examples': 50000, 'test/accuracy': 0.5214, 'test/loss': 2.1950318359375, 'test/num_examples': 10000, 'score': 47418.479996204376, 'total_duration': 55902.306443691254, 'accumulated_submission_time': 47418.479996204376, 'accumulated_eval_time': 8179.577390670776, 'accumulated_logging_time': 4.325294494628906}
I0315 13:09:48.385784 139896463251200 logging_writer.py:48] [75705] accumulated_eval_time=8179.58, accumulated_logging_time=4.32529, accumulated_submission_time=47418.5, global_step=75705, preemption_count=0, score=47418.5, test/accuracy=0.5214, test/loss=2.19503, test/num_examples=10000, total_duration=55902.3, train/accuracy=0.722058, train/loss=1.1935, validation/accuracy=0.66196, validation/loss=1.45, validation/num_examples=50000
I0315 13:13:14.972819 139896110970624 logging_writer.py:48] [76000] global_step=76000, grad_norm=1.10425, loss=2.50791
I0315 13:13:15.027647 139925059253440 submission.py:265] 76000) loss = 2.508, grad_norm = 1.104
I0315 13:18:19.955916 139925059253440 spec.py:321] Evaluating on the training split.
I0315 13:19:00.433636 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 13:19:45.016872 139925059253440 spec.py:349] Evaluating on the test split.
I0315 13:19:46.123513 139925059253440 submission_runner.py:469] Time since start: 56500.10s, 	Step: 76288, 	{'train/accuracy': 0.7211615114795918, 'train/loss': 1.1950575380909199, 'validation/accuracy': 0.66048, 'validation/loss': 1.450264375, 'validation/num_examples': 50000, 'test/accuracy': 0.5133, 'test/loss': 2.1993830078125, 'test/num_examples': 10000, 'score': 47926.98182821274, 'total_duration': 56500.09783697128, 'accumulated_submission_time': 47926.98182821274, 'accumulated_eval_time': 8265.745178461075, 'accumulated_logging_time': 4.387462139129639}
I0315 13:19:46.149599 139896463251200 logging_writer.py:48] [76288] accumulated_eval_time=8265.75, accumulated_logging_time=4.38746, accumulated_submission_time=47927, global_step=76288, preemption_count=0, score=47927, test/accuracy=0.5133, test/loss=2.19938, test/num_examples=10000, total_duration=56500.1, train/accuracy=0.721162, train/loss=1.19506, validation/accuracy=0.66048, validation/loss=1.45026, validation/num_examples=50000
I0315 13:21:28.204486 139896110970624 logging_writer.py:48] [76500] global_step=76500, grad_norm=1.13376, loss=2.54159
I0315 13:21:28.208817 139925059253440 submission.py:265] 76500) loss = 2.542, grad_norm = 1.134
I0315 13:25:32.506337 139896463251200 logging_writer.py:48] [77000] global_step=77000, grad_norm=1.17328, loss=2.5452
I0315 13:25:32.510716 139925059253440 submission.py:265] 77000) loss = 2.545, grad_norm = 1.173
I0315 13:28:18.195020 139925059253440 spec.py:321] Evaluating on the training split.
I0315 13:28:59.334549 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 13:29:43.391815 139925059253440 spec.py:349] Evaluating on the test split.
I0315 13:29:44.500183 139925059253440 submission_runner.py:469] Time since start: 57098.47s, 	Step: 77233, 	{'train/accuracy': 0.7316246811224489, 'train/loss': 1.1972606425382653, 'validation/accuracy': 0.6708, 'validation/loss': 1.441998125, 'validation/num_examples': 50000, 'test/accuracy': 0.5324, 'test/loss': 2.151702734375, 'test/num_examples': 10000, 'score': 48435.71149635315, 'total_duration': 57098.4744143486, 'accumulated_submission_time': 48435.71149635315, 'accumulated_eval_time': 8352.050523757935, 'accumulated_logging_time': 4.422235488891602}
I0315 13:29:44.515147 139896110970624 logging_writer.py:48] [77233] accumulated_eval_time=8352.05, accumulated_logging_time=4.42224, accumulated_submission_time=48435.7, global_step=77233, preemption_count=0, score=48435.7, test/accuracy=0.5324, test/loss=2.1517, test/num_examples=10000, total_duration=57098.5, train/accuracy=0.731625, train/loss=1.19726, validation/accuracy=0.6708, validation/loss=1.442, validation/num_examples=50000
I0315 13:34:07.995632 139896463251200 logging_writer.py:48] [77500] global_step=77500, grad_norm=1.14918, loss=2.58692
I0315 13:34:08.000137 139925059253440 submission.py:265] 77500) loss = 2.587, grad_norm = 1.149
I0315 13:38:16.376865 139925059253440 spec.py:321] Evaluating on the training split.
I0315 13:38:59.664750 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 13:39:45.068466 139925059253440 spec.py:349] Evaluating on the test split.
I0315 13:39:46.167401 139925059253440 submission_runner.py:469] Time since start: 57700.14s, 	Step: 77976, 	{'train/accuracy': 0.724968112244898, 'train/loss': 1.1847745934311225, 'validation/accuracy': 0.66172, 'validation/loss': 1.44341609375, 'validation/num_examples': 50000, 'test/accuracy': 0.5239, 'test/loss': 2.1868232421875, 'test/num_examples': 10000, 'score': 48944.28805708885, 'total_duration': 57700.14165306091, 'accumulated_submission_time': 48944.28805708885, 'accumulated_eval_time': 8441.841162204742, 'accumulated_logging_time': 4.5246193408966064}
I0315 13:39:46.184523 139896110970624 logging_writer.py:48] [77976] accumulated_eval_time=8441.84, accumulated_logging_time=4.52462, accumulated_submission_time=48944.3, global_step=77976, preemption_count=0, score=48944.3, test/accuracy=0.5239, test/loss=2.18682, test/num_examples=10000, total_duration=57700.1, train/accuracy=0.724968, train/loss=1.18477, validation/accuracy=0.66172, validation/loss=1.44342, validation/num_examples=50000
I0315 13:39:58.438879 139896463251200 logging_writer.py:48] [78000] global_step=78000, grad_norm=1.1334, loss=2.44205
I0315 13:39:58.442608 139925059253440 submission.py:265] 78000) loss = 2.442, grad_norm = 1.133
I0315 13:45:02.232751 139896110970624 logging_writer.py:48] [78500] global_step=78500, grad_norm=1.15267, loss=2.52612
I0315 13:45:02.265209 139925059253440 submission.py:265] 78500) loss = 2.526, grad_norm = 1.153
I0315 13:48:18.824662 139925059253440 spec.py:321] Evaluating on the training split.
I0315 13:48:59.582997 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 13:49:42.660297 139925059253440 spec.py:349] Evaluating on the test split.
I0315 13:49:43.765487 139925059253440 submission_runner.py:469] Time since start: 58297.74s, 	Step: 78698, 	{'train/accuracy': 0.7304886798469388, 'train/loss': 1.146804498166454, 'validation/accuracy': 0.67062, 'validation/loss': 1.4088153125, 'validation/num_examples': 50000, 'test/accuracy': 0.5277, 'test/loss': 2.131408984375, 'test/num_examples': 10000, 'score': 49453.76648449898, 'total_duration': 58297.73979258537, 'accumulated_submission_time': 49453.76648449898, 'accumulated_eval_time': 8526.782220840454, 'accumulated_logging_time': 4.550768613815308}
I0315 13:49:43.871393 139896463251200 logging_writer.py:48] [78698] accumulated_eval_time=8526.78, accumulated_logging_time=4.55077, accumulated_submission_time=49453.8, global_step=78698, preemption_count=0, score=49453.8, test/accuracy=0.5277, test/loss=2.13141, test/num_examples=10000, total_duration=58297.7, train/accuracy=0.730489, train/loss=1.1468, validation/accuracy=0.67062, validation/loss=1.40882, validation/num_examples=50000
I0315 13:53:03.526639 139896110970624 logging_writer.py:48] [79000] global_step=79000, grad_norm=1.14101, loss=2.50322
I0315 13:53:03.531270 139925059253440 submission.py:265] 79000) loss = 2.503, grad_norm = 1.141
I0315 13:57:02.654234 139896463251200 logging_writer.py:48] [79500] global_step=79500, grad_norm=1.17792, loss=2.46005
I0315 13:57:02.658371 139925059253440 submission.py:265] 79500) loss = 2.460, grad_norm = 1.178
I0315 13:58:15.768524 139925059253440 spec.py:321] Evaluating on the training split.
I0315 13:58:58.282468 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 13:59:42.488810 139925059253440 spec.py:349] Evaluating on the test split.
I0315 13:59:43.590924 139925059253440 submission_runner.py:469] Time since start: 58897.56s, 	Step: 79614, 	{'train/accuracy': 0.7254464285714286, 'train/loss': 1.180870601109096, 'validation/accuracy': 0.665, 'validation/loss': 1.43217265625, 'validation/num_examples': 50000, 'test/accuracy': 0.5295, 'test/loss': 2.115774609375, 'test/num_examples': 10000, 'score': 49962.444154024124, 'total_duration': 58897.56498336792, 'accumulated_submission_time': 49962.444154024124, 'accumulated_eval_time': 8614.604536294937, 'accumulated_logging_time': 4.665534973144531}
I0315 13:59:43.610814 139896110970624 logging_writer.py:48] [79614] accumulated_eval_time=8614.6, accumulated_logging_time=4.66553, accumulated_submission_time=49962.4, global_step=79614, preemption_count=0, score=49962.4, test/accuracy=0.5295, test/loss=2.11577, test/num_examples=10000, total_duration=58897.6, train/accuracy=0.725446, train/loss=1.18087, validation/accuracy=0.665, validation/loss=1.43217, validation/num_examples=50000
I0315 14:05:13.835023 139896463251200 logging_writer.py:48] [80000] global_step=80000, grad_norm=1.16433, loss=2.56286
I0315 14:05:13.839966 139925059253440 submission.py:265] 80000) loss = 2.563, grad_norm = 1.164
I0315 14:08:15.571664 139925059253440 spec.py:321] Evaluating on the training split.
I0315 14:08:58.584187 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 14:09:42.556496 139925059253440 spec.py:349] Evaluating on the test split.
I0315 14:09:43.657590 139925059253440 submission_runner.py:469] Time since start: 59497.63s, 	Step: 80343, 	{'train/accuracy': 0.730110012755102, 'train/loss': 1.162665775844029, 'validation/accuracy': 0.66994, 'validation/loss': 1.4261709375, 'validation/num_examples': 50000, 'test/accuracy': 0.5298, 'test/loss': 2.1213693359375, 'test/num_examples': 10000, 'score': 50470.87685275078, 'total_duration': 59497.63179850578, 'accumulated_submission_time': 50470.87685275078, 'accumulated_eval_time': 8702.690573215485, 'accumulated_logging_time': 4.8156750202178955}
I0315 14:09:43.674831 139896110970624 logging_writer.py:48] [80343] accumulated_eval_time=8702.69, accumulated_logging_time=4.81568, accumulated_submission_time=50470.9, global_step=80343, preemption_count=0, score=50470.9, test/accuracy=0.5298, test/loss=2.12137, test/num_examples=10000, total_duration=59497.6, train/accuracy=0.73011, train/loss=1.16267, validation/accuracy=0.66994, validation/loss=1.42617, validation/num_examples=50000
I0315 14:10:53.835614 139896463251200 logging_writer.py:48] [80500] global_step=80500, grad_norm=1.15831, loss=2.5114
I0315 14:10:53.839895 139925059253440 submission.py:265] 80500) loss = 2.511, grad_norm = 1.158
I0315 14:15:41.963746 139896110970624 logging_writer.py:48] [81000] global_step=81000, grad_norm=1.16782, loss=2.53272
I0315 14:15:42.031993 139925059253440 submission.py:265] 81000) loss = 2.533, grad_norm = 1.168
I0315 14:18:16.467721 139925059253440 spec.py:321] Evaluating on the training split.
I0315 14:18:57.573131 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 14:19:40.252513 139925059253440 spec.py:349] Evaluating on the test split.
I0315 14:19:41.353398 139925059253440 submission_runner.py:469] Time since start: 60095.33s, 	Step: 81161, 	{'train/accuracy': 0.7260243941326531, 'train/loss': 1.1754953034070073, 'validation/accuracy': 0.66732, 'validation/loss': 1.4286384375, 'validation/num_examples': 50000, 'test/accuracy': 0.5277, 'test/loss': 2.134926171875, 'test/num_examples': 10000, 'score': 50980.467859983444, 'total_duration': 60095.32768678665, 'accumulated_submission_time': 50980.467859983444, 'accumulated_eval_time': 8787.57639336586, 'accumulated_logging_time': 4.8416759967803955}
I0315 14:19:41.453344 139896463251200 logging_writer.py:48] [81161] accumulated_eval_time=8787.58, accumulated_logging_time=4.84168, accumulated_submission_time=50980.5, global_step=81161, preemption_count=0, score=50980.5, test/accuracy=0.5277, test/loss=2.13493, test/num_examples=10000, total_duration=60095.3, train/accuracy=0.726024, train/loss=1.1755, validation/accuracy=0.66732, validation/loss=1.42864, validation/num_examples=50000
I0315 14:23:36.641264 139896110970624 logging_writer.py:48] [81500] global_step=81500, grad_norm=1.10571, loss=2.34142
I0315 14:23:36.645747 139925059253440 submission.py:265] 81500) loss = 2.341, grad_norm = 1.106
I0315 14:27:36.100939 139896463251200 logging_writer.py:48] [82000] global_step=82000, grad_norm=1.16256, loss=2.546
I0315 14:27:36.105253 139925059253440 submission.py:265] 82000) loss = 2.546, grad_norm = 1.163
I0315 14:28:13.438974 139925059253440 spec.py:321] Evaluating on the training split.
I0315 14:28:55.217321 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 14:29:39.936844 139925059253440 spec.py:349] Evaluating on the test split.
I0315 14:29:41.043759 139925059253440 submission_runner.py:469] Time since start: 60695.02s, 	Step: 82057, 	{'train/accuracy': 0.7320432079081632, 'train/loss': 1.117764219945791, 'validation/accuracy': 0.66884, 'validation/loss': 1.3879290625, 'validation/num_examples': 50000, 'test/accuracy': 0.5316, 'test/loss': 2.1103025390625, 'test/num_examples': 10000, 'score': 51489.266177654266, 'total_duration': 60695.01804637909, 'accumulated_submission_time': 51489.266177654266, 'accumulated_eval_time': 8875.181381702423, 'accumulated_logging_time': 4.95021915435791}
I0315 14:29:41.070170 139896110970624 logging_writer.py:48] [82057] accumulated_eval_time=8875.18, accumulated_logging_time=4.95022, accumulated_submission_time=51489.3, global_step=82057, preemption_count=0, score=51489.3, test/accuracy=0.5316, test/loss=2.1103, test/num_examples=10000, total_duration=60695, train/accuracy=0.732043, train/loss=1.11776, validation/accuracy=0.66884, validation/loss=1.38793, validation/num_examples=50000
I0315 14:36:00.392190 139896463251200 logging_writer.py:48] [82500] global_step=82500, grad_norm=1.09677, loss=2.4324
I0315 14:36:00.396803 139925059253440 submission.py:265] 82500) loss = 2.432, grad_norm = 1.097
I0315 14:38:13.021967 139925059253440 spec.py:321] Evaluating on the training split.
I0315 14:38:52.917512 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 14:39:34.533848 139925059253440 spec.py:349] Evaluating on the test split.
I0315 14:39:35.640739 139925059253440 submission_runner.py:469] Time since start: 61289.62s, 	Step: 82700, 	{'train/accuracy': 0.7331792091836735, 'train/loss': 1.1564157447036432, 'validation/accuracy': 0.67092, 'validation/loss': 1.4211115625, 'validation/num_examples': 50000, 'test/accuracy': 0.532, 'test/loss': 2.132621484375, 'test/num_examples': 10000, 'score': 51998.14189243317, 'total_duration': 61289.615002155304, 'accumulated_submission_time': 51998.14189243317, 'accumulated_eval_time': 8957.8002576828, 'accumulated_logging_time': 4.984821319580078}
I0315 14:39:35.656486 139896110970624 logging_writer.py:48] [82700] accumulated_eval_time=8957.8, accumulated_logging_time=4.98482, accumulated_submission_time=51998.1, global_step=82700, preemption_count=0, score=51998.1, test/accuracy=0.532, test/loss=2.13262, test/num_examples=10000, total_duration=61289.6, train/accuracy=0.733179, train/loss=1.15642, validation/accuracy=0.67092, validation/loss=1.42111, validation/num_examples=50000
I0315 14:41:47.456504 139896463251200 logging_writer.py:48] [83000] global_step=83000, grad_norm=1.17964, loss=2.4753
I0315 14:41:47.460771 139925059253440 submission.py:265] 83000) loss = 2.475, grad_norm = 1.180
I0315 14:46:40.523828 139896110970624 logging_writer.py:48] [83500] global_step=83500, grad_norm=1.13419, loss=2.48048
I0315 14:46:40.527844 139925059253440 submission.py:265] 83500) loss = 2.480, grad_norm = 1.134
I0315 14:48:08.504650 139925059253440 spec.py:321] Evaluating on the training split.
I0315 14:48:50.301077 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 14:49:33.366394 139925059253440 spec.py:349] Evaluating on the test split.
I0315 14:49:34.472888 139925059253440 submission_runner.py:469] Time since start: 61888.45s, 	Step: 83591, 	{'train/accuracy': 0.7340760522959183, 'train/loss': 1.147738787592674, 'validation/accuracy': 0.67342, 'validation/loss': 1.41119140625, 'validation/num_examples': 50000, 'test/accuracy': 0.529, 'test/loss': 2.1350509765625, 'test/num_examples': 10000, 'score': 52507.69702744484, 'total_duration': 61888.44715166092, 'accumulated_submission_time': 52507.69702744484, 'accumulated_eval_time': 9043.768751621246, 'accumulated_logging_time': 5.024707794189453}
I0315 14:49:34.506420 139896463251200 logging_writer.py:48] [83591] accumulated_eval_time=9043.77, accumulated_logging_time=5.02471, accumulated_submission_time=52507.7, global_step=83591, preemption_count=0, score=52507.7, test/accuracy=0.529, test/loss=2.13505, test/num_examples=10000, total_duration=61888.4, train/accuracy=0.734076, train/loss=1.14774, validation/accuracy=0.67342, validation/loss=1.41119, validation/num_examples=50000
I0315 14:54:38.213296 139896110970624 logging_writer.py:48] [84000] global_step=84000, grad_norm=1.15644, loss=2.46881
I0315 14:54:38.217616 139925059253440 submission.py:265] 84000) loss = 2.469, grad_norm = 1.156
I0315 14:58:06.197672 139925059253440 spec.py:321] Evaluating on the training split.
I0315 14:58:48.025132 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 14:59:31.948569 139925059253440 spec.py:349] Evaluating on the test split.
I0315 14:59:33.050369 139925059253440 submission_runner.py:469] Time since start: 62487.02s, 	Step: 84440, 	{'train/accuracy': 0.7373644770408163, 'train/loss': 1.137249382174745, 'validation/accuracy': 0.6744, 'validation/loss': 1.408193125, 'validation/num_examples': 50000, 'test/accuracy': 0.5291, 'test/loss': 2.1501232421875, 'test/num_examples': 10000, 'score': 53016.152619838715, 'total_duration': 62487.024686574936, 'accumulated_submission_time': 53016.152619838715, 'accumulated_eval_time': 9130.621725797653, 'accumulated_logging_time': 5.093925714492798}
I0315 14:59:33.067605 139896463251200 logging_writer.py:48] [84440] accumulated_eval_time=9130.62, accumulated_logging_time=5.09393, accumulated_submission_time=53016.2, global_step=84440, preemption_count=0, score=53016.2, test/accuracy=0.5291, test/loss=2.15012, test/num_examples=10000, total_duration=62487, train/accuracy=0.737364, train/loss=1.13725, validation/accuracy=0.6744, validation/loss=1.40819, validation/num_examples=50000
I0315 15:00:05.643054 139896110970624 logging_writer.py:48] [84500] global_step=84500, grad_norm=1.19372, loss=2.50284
I0315 15:00:05.646863 139925059253440 submission.py:265] 84500) loss = 2.503, grad_norm = 1.194
I0315 15:06:47.268487 139896463251200 logging_writer.py:48] [85000] global_step=85000, grad_norm=1.15559, loss=2.45788
I0315 15:06:47.343441 139925059253440 submission.py:265] 85000) loss = 2.458, grad_norm = 1.156
I0315 15:08:05.142107 139925059253440 spec.py:321] Evaluating on the training split.
I0315 15:08:46.041988 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 15:09:28.997583 139925059253440 spec.py:349] Evaluating on the test split.
I0315 15:09:30.104799 139925059253440 submission_runner.py:469] Time since start: 63084.08s, 	Step: 85066, 	{'train/accuracy': 0.7372448979591837, 'train/loss': 1.147922438018176, 'validation/accuracy': 0.67294, 'validation/loss': 1.4120434375, 'validation/num_examples': 50000, 'test/accuracy': 0.5399, 'test/loss': 2.1077330078125, 'test/num_examples': 10000, 'score': 53525.05167865753, 'total_duration': 63084.0790374279, 'accumulated_submission_time': 53525.05167865753, 'accumulated_eval_time': 9215.584463596344, 'accumulated_logging_time': 5.119765043258667}
I0315 15:09:30.193249 139896110970624 logging_writer.py:48] [85066] accumulated_eval_time=9215.58, accumulated_logging_time=5.11977, accumulated_submission_time=53525.1, global_step=85066, preemption_count=0, score=53525.1, test/accuracy=0.5399, test/loss=2.10773, test/num_examples=10000, total_duration=63084.1, train/accuracy=0.737245, train/loss=1.14792, validation/accuracy=0.67294, validation/loss=1.41204, validation/num_examples=50000
I0315 15:12:36.250897 139896463251200 logging_writer.py:48] [85500] global_step=85500, grad_norm=1.16444, loss=2.42395
I0315 15:12:36.255272 139925059253440 submission.py:265] 85500) loss = 2.424, grad_norm = 1.164
I0315 15:17:38.746502 139896110970624 logging_writer.py:48] [86000] global_step=86000, grad_norm=1.14533, loss=2.42801
I0315 15:17:38.750617 139925059253440 submission.py:265] 86000) loss = 2.428, grad_norm = 1.145
I0315 15:18:04.062613 139925059253440 spec.py:321] Evaluating on the training split.
I0315 15:18:46.885910 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 15:19:31.719254 139925059253440 spec.py:349] Evaluating on the test split.
I0315 15:19:32.822220 139925059253440 submission_runner.py:469] Time since start: 63686.80s, 	Step: 86025, 	{'train/accuracy': 0.7367267219387755, 'train/loss': 1.1270853159378986, 'validation/accuracy': 0.6754, 'validation/loss': 1.383246875, 'validation/num_examples': 50000, 'test/accuracy': 0.5291, 'test/loss': 2.146016796875, 'test/num_examples': 10000, 'score': 54035.63076925278, 'total_duration': 63686.79652261734, 'accumulated_submission_time': 54035.63076925278, 'accumulated_eval_time': 9304.344275951385, 'accumulated_logging_time': 5.21688437461853}
I0315 15:19:32.837362 139896463251200 logging_writer.py:48] [86025] accumulated_eval_time=9304.34, accumulated_logging_time=5.21688, accumulated_submission_time=54035.6, global_step=86025, preemption_count=0, score=54035.6, test/accuracy=0.5291, test/loss=2.14602, test/num_examples=10000, total_duration=63686.8, train/accuracy=0.736727, train/loss=1.12709, validation/accuracy=0.6754, validation/loss=1.38325, validation/num_examples=50000
I0315 15:25:40.772031 139896110970624 logging_writer.py:48] [86500] global_step=86500, grad_norm=1.17033, loss=2.38865
I0315 15:25:40.776750 139925059253440 submission.py:265] 86500) loss = 2.389, grad_norm = 1.170
I0315 15:28:04.955668 139925059253440 spec.py:321] Evaluating on the training split.
I0315 15:28:45.144526 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 15:29:25.578207 139925059253440 spec.py:349] Evaluating on the test split.
I0315 15:29:26.684612 139925059253440 submission_runner.py:469] Time since start: 64280.66s, 	Step: 86808, 	{'train/accuracy': 0.7373844068877551, 'train/loss': 1.1188430007623167, 'validation/accuracy': 0.6747, 'validation/loss': 1.38522703125, 'validation/num_examples': 50000, 'test/accuracy': 0.5345, 'test/loss': 2.1115013671875, 'test/num_examples': 10000, 'score': 54544.54809474945, 'total_duration': 64280.65888643265, 'accumulated_submission_time': 54544.54809474945, 'accumulated_eval_time': 9386.073294639587, 'accumulated_logging_time': 5.279665231704712}
I0315 15:29:26.701516 139896463251200 logging_writer.py:48] [86808] accumulated_eval_time=9386.07, accumulated_logging_time=5.27967, accumulated_submission_time=54544.5, global_step=86808, preemption_count=0, score=54544.5, test/accuracy=0.5345, test/loss=2.1115, test/num_examples=10000, total_duration=64280.7, train/accuracy=0.737384, train/loss=1.11884, validation/accuracy=0.6747, validation/loss=1.38523, validation/num_examples=50000
I0315 15:31:09.612136 139896110970624 logging_writer.py:48] [87000] global_step=87000, grad_norm=1.2138, loss=2.46695
I0315 15:31:09.616606 139925059253440 submission.py:265] 87000) loss = 2.467, grad_norm = 1.214
I0315 15:37:58.948636 139925059253440 spec.py:321] Evaluating on the training split.
I0315 15:38:39.389579 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 15:39:22.004215 139925059253440 spec.py:349] Evaluating on the test split.
I0315 15:39:23.107081 139925059253440 submission_runner.py:469] Time since start: 64877.08s, 	Step: 87487, 	{'train/accuracy': 0.740593112244898, 'train/loss': 1.1042198648258132, 'validation/accuracy': 0.67582, 'validation/loss': 1.37915296875, 'validation/num_examples': 50000, 'test/accuracy': 0.5462, 'test/loss': 2.0562076171875, 'test/num_examples': 10000, 'score': 55053.72089076042, 'total_duration': 64877.081362724304, 'accumulated_submission_time': 55053.72089076042, 'accumulated_eval_time': 9470.231877088547, 'accumulated_logging_time': 5.305002689361572}
I0315 15:39:23.134079 139896463251200 logging_writer.py:48] [87487] accumulated_eval_time=9470.23, accumulated_logging_time=5.305, accumulated_submission_time=55053.7, global_step=87487, preemption_count=0, score=55053.7, test/accuracy=0.5462, test/loss=2.05621, test/num_examples=10000, total_duration=64877.1, train/accuracy=0.740593, train/loss=1.10422, validation/accuracy=0.67582, validation/loss=1.37915, validation/num_examples=50000
I0315 15:39:35.122705 139896110970624 logging_writer.py:48] [87500] global_step=87500, grad_norm=1.18321, loss=2.5452
I0315 15:39:35.126743 139925059253440 submission.py:265] 87500) loss = 2.545, grad_norm = 1.183
I0315 15:43:54.255094 139896463251200 logging_writer.py:48] [88000] global_step=88000, grad_norm=1.27449, loss=2.45635
I0315 15:43:54.259546 139925059253440 submission.py:265] 88000) loss = 2.456, grad_norm = 1.274
I0315 15:47:56.786900 139925059253440 spec.py:321] Evaluating on the training split.
I0315 15:48:39.219622 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 15:49:22.651638 139925059253440 spec.py:349] Evaluating on the test split.
I0315 15:49:23.755325 139925059253440 submission_runner.py:469] Time since start: 65477.73s, 	Step: 88420, 	{'train/accuracy': 0.737922512755102, 'train/loss': 1.1090524634536432, 'validation/accuracy': 0.6781, 'validation/loss': 1.3786184375, 'validation/num_examples': 50000, 'test/accuracy': 0.5428, 'test/loss': 2.0677953125, 'test/num_examples': 10000, 'score': 55564.215346336365, 'total_duration': 65477.72962474823, 'accumulated_submission_time': 55564.215346336365, 'accumulated_eval_time': 9557.200443029404, 'accumulated_logging_time': 5.369084358215332}
I0315 15:49:23.783196 139896110970624 logging_writer.py:48] [88420] accumulated_eval_time=9557.2, accumulated_logging_time=5.36908, accumulated_submission_time=55564.2, global_step=88420, preemption_count=0, score=55564.2, test/accuracy=0.5428, test/loss=2.0678, test/num_examples=10000, total_duration=65477.7, train/accuracy=0.737923, train/loss=1.10905, validation/accuracy=0.6781, validation/loss=1.37862, validation/num_examples=50000
I0315 15:50:24.978679 139896463251200 logging_writer.py:48] [88500] global_step=88500, grad_norm=1.17896, loss=2.48939
I0315 15:50:24.982506 139925059253440 submission.py:265] 88500) loss = 2.489, grad_norm = 1.179
I0315 15:57:02.066779 139896110970624 logging_writer.py:48] [89000] global_step=89000, grad_norm=1.14781, loss=2.40154
I0315 15:57:02.071098 139925059253440 submission.py:265] 89000) loss = 2.402, grad_norm = 1.148
I0315 15:57:55.395311 139925059253440 spec.py:321] Evaluating on the training split.
I0315 15:58:38.452038 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 15:59:20.514202 139925059253440 spec.py:349] Evaluating on the test split.
I0315 15:59:21.621873 139925059253440 submission_runner.py:469] Time since start: 66075.60s, 	Step: 89115, 	{'train/accuracy': 0.7392777423469388, 'train/loss': 1.1304620236766583, 'validation/accuracy': 0.67554, 'validation/loss': 1.40273109375, 'validation/num_examples': 50000, 'test/accuracy': 0.5442, 'test/loss': 2.10841796875, 'test/num_examples': 10000, 'score': 56072.602840423584, 'total_duration': 66075.59615468979, 'accumulated_submission_time': 56072.602840423584, 'accumulated_eval_time': 9643.427175998688, 'accumulated_logging_time': 5.405685186386108}
I0315 15:59:21.795334 139896463251200 logging_writer.py:48] [89115] accumulated_eval_time=9643.43, accumulated_logging_time=5.40569, accumulated_submission_time=56072.6, global_step=89115, preemption_count=0, score=56072.6, test/accuracy=0.5442, test/loss=2.10842, test/num_examples=10000, total_duration=66075.6, train/accuracy=0.739278, train/loss=1.13046, validation/accuracy=0.67554, validation/loss=1.40273, validation/num_examples=50000
I0315 16:02:30.725989 139896110970624 logging_writer.py:48] [89500] global_step=89500, grad_norm=1.19139, loss=2.44448
I0315 16:02:30.738348 139925059253440 submission.py:265] 89500) loss = 2.444, grad_norm = 1.191
I0315 16:07:54.329067 139925059253440 spec.py:321] Evaluating on the training split.
I0315 16:08:34.952999 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 16:09:17.248512 139925059253440 spec.py:349] Evaluating on the test split.
I0315 16:09:18.353300 139925059253440 submission_runner.py:469] Time since start: 66672.33s, 	Step: 89898, 	{'train/accuracy': 0.7395567602040817, 'train/loss': 1.1302991594587053, 'validation/accuracy': 0.6734, 'validation/loss': 1.408094375, 'validation/num_examples': 50000, 'test/accuracy': 0.5431, 'test/loss': 2.103957421875, 'test/num_examples': 10000, 'score': 56581.974061489105, 'total_duration': 66672.32760548592, 'accumulated_submission_time': 56581.974061489105, 'accumulated_eval_time': 9727.4516518116, 'accumulated_logging_time': 5.587733507156372}
I0315 16:09:18.407523 139896463251200 logging_writer.py:48] [89898] accumulated_eval_time=9727.45, accumulated_logging_time=5.58773, accumulated_submission_time=56582, global_step=89898, preemption_count=0, score=56582, test/accuracy=0.5431, test/loss=2.10396, test/num_examples=10000, total_duration=66672.3, train/accuracy=0.739557, train/loss=1.1303, validation/accuracy=0.6734, validation/loss=1.40809, validation/num_examples=50000
I0315 16:11:03.797872 139896110970624 logging_writer.py:48] [90000] global_step=90000, grad_norm=1.1844, loss=2.49387
I0315 16:11:03.802598 139925059253440 submission.py:265] 90000) loss = 2.494, grad_norm = 1.184
I0315 16:15:27.454845 139896463251200 logging_writer.py:48] [90500] global_step=90500, grad_norm=1.20635, loss=2.44086
I0315 16:15:27.480114 139925059253440 submission.py:265] 90500) loss = 2.441, grad_norm = 1.206
I0315 16:17:49.974457 139925059253440 spec.py:321] Evaluating on the training split.
I0315 16:18:32.858751 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 16:19:14.569010 139925059253440 spec.py:349] Evaluating on the test split.
I0315 16:19:15.673442 139925059253440 submission_runner.py:469] Time since start: 67269.65s, 	Step: 90761, 	{'train/accuracy': 0.7345344387755102, 'train/loss': 1.1588415807607222, 'validation/accuracy': 0.67594, 'validation/loss': 1.4197096875, 'validation/num_examples': 50000, 'test/accuracy': 0.5345, 'test/loss': 2.144025, 'test/num_examples': 10000, 'score': 57090.35734128952, 'total_duration': 67269.64769816399, 'accumulated_submission_time': 57090.35734128952, 'accumulated_eval_time': 9813.150824546814, 'accumulated_logging_time': 5.65074610710144}
I0315 16:19:15.689476 139896110970624 logging_writer.py:48] [90761] accumulated_eval_time=9813.15, accumulated_logging_time=5.65075, accumulated_submission_time=57090.4, global_step=90761, preemption_count=0, score=57090.4, test/accuracy=0.5345, test/loss=2.14403, test/num_examples=10000, total_duration=67269.6, train/accuracy=0.734534, train/loss=1.15884, validation/accuracy=0.67594, validation/loss=1.41971, validation/num_examples=50000
I0315 16:21:59.158457 139896463251200 logging_writer.py:48] [91000] global_step=91000, grad_norm=1.20452, loss=2.47004
I0315 16:21:59.162442 139925059253440 submission.py:265] 91000) loss = 2.470, grad_norm = 1.205
I0315 16:27:47.255356 139925059253440 spec.py:321] Evaluating on the training split.
I0315 16:28:30.079029 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 16:29:13.426599 139925059253440 spec.py:349] Evaluating on the test split.
I0315 16:29:14.527722 139925059253440 submission_runner.py:469] Time since start: 67868.50s, 	Step: 91352, 	{'train/accuracy': 0.7440210459183674, 'train/loss': 1.1022905622209822, 'validation/accuracy': 0.67894, 'validation/loss': 1.380045, 'validation/num_examples': 50000, 'test/accuracy': 0.5358, 'test/loss': 2.1094580078125, 'test/num_examples': 10000, 'score': 57598.8264901638, 'total_duration': 67868.50175857544, 'accumulated_submission_time': 57598.8264901638, 'accumulated_eval_time': 9900.42316865921, 'accumulated_logging_time': 5.675734996795654}
I0315 16:29:14.603731 139896110970624 logging_writer.py:48] [91352] accumulated_eval_time=9900.42, accumulated_logging_time=5.67573, accumulated_submission_time=57598.8, global_step=91352, preemption_count=0, score=57598.8, test/accuracy=0.5358, test/loss=2.10946, test/num_examples=10000, total_duration=67868.5, train/accuracy=0.744021, train/loss=1.10229, validation/accuracy=0.67894, validation/loss=1.38004, validation/num_examples=50000
I0315 16:30:13.916938 139896463251200 logging_writer.py:48] [91500] global_step=91500, grad_norm=1.23822, loss=2.48918
I0315 16:30:13.920864 139925059253440 submission.py:265] 91500) loss = 2.489, grad_norm = 1.238
I0315 16:34:07.470579 139896110970624 logging_writer.py:48] [92000] global_step=92000, grad_norm=1.18546, loss=2.34338
I0315 16:34:07.479781 139925059253440 submission.py:265] 92000) loss = 2.343, grad_norm = 1.185
I0315 16:37:45.940175 139925059253440 spec.py:321] Evaluating on the training split.
I0315 16:38:26.799846 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 16:39:10.116065 139925059253440 spec.py:349] Evaluating on the test split.
I0315 16:39:11.222817 139925059253440 submission_runner.py:469] Time since start: 68465.20s, 	Step: 92296, 	{'train/accuracy': 0.7448979591836735, 'train/loss': 1.1103506282884248, 'validation/accuracy': 0.68118, 'validation/loss': 1.3816403125, 'validation/num_examples': 50000, 'test/accuracy': 0.5458, 'test/loss': 2.0808310546875, 'test/num_examples': 10000, 'score': 58106.7379052639, 'total_duration': 68465.19710493088, 'accumulated_submission_time': 58106.7379052639, 'accumulated_eval_time': 9985.706042766571, 'accumulated_logging_time': 5.76312518119812}
I0315 16:39:11.296552 139896463251200 logging_writer.py:48] [92296] accumulated_eval_time=9985.71, accumulated_logging_time=5.76313, accumulated_submission_time=58106.7, global_step=92296, preemption_count=0, score=58106.7, test/accuracy=0.5458, test/loss=2.08083, test/num_examples=10000, total_duration=68465.2, train/accuracy=0.744898, train/loss=1.11035, validation/accuracy=0.68118, validation/loss=1.38164, validation/num_examples=50000
I0315 16:42:34.642826 139896110970624 logging_writer.py:48] [92500] global_step=92500, grad_norm=1.16493, loss=2.42129
I0315 16:42:34.647264 139925059253440 submission.py:265] 92500) loss = 2.421, grad_norm = 1.165
I0315 16:47:02.768625 139896463251200 logging_writer.py:48] [93000] global_step=93000, grad_norm=1.17089, loss=2.39393
I0315 16:47:02.790672 139925059253440 submission.py:265] 93000) loss = 2.394, grad_norm = 1.171
I0315 16:47:42.912279 139925059253440 spec.py:321] Evaluating on the training split.
I0315 16:48:23.009230 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 16:49:06.771761 139925059253440 spec.py:349] Evaluating on the test split.
I0315 16:49:07.879596 139925059253440 submission_runner.py:469] Time since start: 69061.85s, 	Step: 93077, 	{'train/accuracy': 0.7416294642857143, 'train/loss': 1.0909485330387039, 'validation/accuracy': 0.67874, 'validation/loss': 1.3622828125, 'validation/num_examples': 50000, 'test/accuracy': 0.5388, 'test/loss': 2.0869966796875, 'test/num_examples': 10000, 'score': 58615.145507097244, 'total_duration': 69061.85390591621, 'accumulated_submission_time': 58615.145507097244, 'accumulated_eval_time': 10070.673586130142, 'accumulated_logging_time': 5.845810890197754}
I0315 16:49:07.914690 139896110970624 logging_writer.py:48] [93077] accumulated_eval_time=10070.7, accumulated_logging_time=5.84581, accumulated_submission_time=58615.1, global_step=93077, preemption_count=0, score=58615.1, test/accuracy=0.5388, test/loss=2.087, test/num_examples=10000, total_duration=69061.9, train/accuracy=0.741629, train/loss=1.09095, validation/accuracy=0.67874, validation/loss=1.36228, validation/num_examples=50000
I0315 16:53:30.179122 139896463251200 logging_writer.py:48] [93500] global_step=93500, grad_norm=1.21563, loss=2.48528
I0315 16:53:30.183551 139925059253440 submission.py:265] 93500) loss = 2.485, grad_norm = 1.216
I0315 16:57:40.758456 139925059253440 spec.py:321] Evaluating on the training split.
I0315 16:58:22.074612 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 16:59:06.396194 139925059253440 spec.py:349] Evaluating on the test split.
I0315 16:59:07.500463 139925059253440 submission_runner.py:469] Time since start: 69661.47s, 	Step: 93746, 	{'train/accuracy': 0.7475087691326531, 'train/loss': 1.0901933008310747, 'validation/accuracy': 0.68298, 'validation/loss': 1.36890734375, 'validation/num_examples': 50000, 'test/accuracy': 0.5444, 'test/loss': 2.0680302734375, 'test/num_examples': 10000, 'score': 59124.9107503891, 'total_duration': 69661.47474598885, 'accumulated_submission_time': 59124.9107503891, 'accumulated_eval_time': 10157.415668487549, 'accumulated_logging_time': 5.889635324478149}
I0315 16:59:07.542480 139896110970624 logging_writer.py:48] [93746] accumulated_eval_time=10157.4, accumulated_logging_time=5.88964, accumulated_submission_time=59124.9, global_step=93746, preemption_count=0, score=59124.9, test/accuracy=0.5444, test/loss=2.06803, test/num_examples=10000, total_duration=69661.5, train/accuracy=0.747509, train/loss=1.09019, validation/accuracy=0.68298, validation/loss=1.36891, validation/num_examples=50000
I0315 17:01:42.986386 139896463251200 logging_writer.py:48] [94000] global_step=94000, grad_norm=1.18397, loss=2.38999
I0315 17:01:42.990666 139925059253440 submission.py:265] 94000) loss = 2.390, grad_norm = 1.184
I0315 17:05:42.026104 139896110970624 logging_writer.py:48] [94500] global_step=94500, grad_norm=1.17543, loss=2.46692
I0315 17:05:42.030605 139925059253440 submission.py:265] 94500) loss = 2.467, grad_norm = 1.175
I0315 17:07:39.589316 139925059253440 spec.py:321] Evaluating on the training split.
I0315 17:08:21.016657 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 17:09:04.974573 139925059253440 spec.py:349] Evaluating on the test split.
I0315 17:09:06.075809 139925059253440 submission_runner.py:469] Time since start: 70260.05s, 	Step: 94673, 	{'train/accuracy': 0.7524713010204082, 'train/loss': 1.044362126564493, 'validation/accuracy': 0.68344, 'validation/loss': 1.33407390625, 'validation/num_examples': 50000, 'test/accuracy': 0.5476, 'test/loss': 2.031074609375, 'test/num_examples': 10000, 'score': 59633.60502386093, 'total_duration': 70260.05012178421, 'accumulated_submission_time': 59633.60502386093, 'accumulated_eval_time': 10243.90254688263, 'accumulated_logging_time': 5.9661712646484375}
I0315 17:09:06.091855 139896463251200 logging_writer.py:48] [94673] accumulated_eval_time=10243.9, accumulated_logging_time=5.96617, accumulated_submission_time=59633.6, global_step=94673, preemption_count=0, score=59633.6, test/accuracy=0.5476, test/loss=2.03107, test/num_examples=10000, total_duration=70260.1, train/accuracy=0.752471, train/loss=1.04436, validation/accuracy=0.68344, validation/loss=1.33407, validation/num_examples=50000
I0315 17:14:14.514667 139896110970624 logging_writer.py:48] [95000] global_step=95000, grad_norm=1.20931, loss=2.35816
I0315 17:14:14.544271 139925059253440 submission.py:265] 95000) loss = 2.358, grad_norm = 1.209
I0315 17:17:38.116092 139925059253440 spec.py:321] Evaluating on the training split.
I0315 17:18:21.033941 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 17:19:06.994252 139925059253440 spec.py:349] Evaluating on the test split.
I0315 17:19:08.101102 139925059253440 submission_runner.py:469] Time since start: 70862.08s, 	Step: 95345, 	{'train/accuracy': 0.7509765625, 'train/loss': 1.0640417605030292, 'validation/accuracy': 0.68564, 'validation/loss': 1.34744640625, 'validation/num_examples': 50000, 'test/accuracy': 0.5448, 'test/loss': 2.0517556640625, 'test/num_examples': 10000, 'score': 60142.632432460785, 'total_duration': 70862.07512187958, 'accumulated_submission_time': 60142.632432460785, 'accumulated_eval_time': 10333.887432098389, 'accumulated_logging_time': 5.990764856338501}
I0315 17:19:08.119664 139896463251200 logging_writer.py:48] [95345] accumulated_eval_time=10333.9, accumulated_logging_time=5.99076, accumulated_submission_time=60142.6, global_step=95345, preemption_count=0, score=60142.6, test/accuracy=0.5448, test/loss=2.05176, test/num_examples=10000, total_duration=70862.1, train/accuracy=0.750977, train/loss=1.06404, validation/accuracy=0.68564, validation/loss=1.34745, validation/num_examples=50000
I0315 17:20:22.494125 139896110970624 logging_writer.py:48] [95500] global_step=95500, grad_norm=1.22554, loss=2.40297
I0315 17:20:22.498403 139925059253440 submission.py:265] 95500) loss = 2.403, grad_norm = 1.226
I0315 17:25:43.940528 139896463251200 logging_writer.py:48] [96000] global_step=96000, grad_norm=1.16229, loss=2.30733
I0315 17:25:43.944897 139925059253440 submission.py:265] 96000) loss = 2.307, grad_norm = 1.162
I0315 17:27:42.525689 139925059253440 spec.py:321] Evaluating on the training split.
I0315 17:28:25.945326 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 17:29:09.658057 139925059253440 spec.py:349] Evaluating on the test split.
I0315 17:29:10.766871 139925059253440 submission_runner.py:469] Time since start: 71464.74s, 	Step: 96113, 	{'train/accuracy': 0.746452487244898, 'train/loss': 1.0922692746532208, 'validation/accuracy': 0.68352, 'validation/loss': 1.3642578125, 'validation/num_examples': 50000, 'test/accuracy': 0.5448, 'test/loss': 2.069335546875, 'test/num_examples': 10000, 'score': 60653.78189921379, 'total_duration': 71464.74115133286, 'accumulated_submission_time': 60653.78189921379, 'accumulated_eval_time': 10422.128766059875, 'accumulated_logging_time': 6.0190749168396}
I0315 17:29:10.784003 139896110970624 logging_writer.py:48] [96113] accumulated_eval_time=10422.1, accumulated_logging_time=6.01907, accumulated_submission_time=60653.8, global_step=96113, preemption_count=0, score=60653.8, test/accuracy=0.5448, test/loss=2.06934, test/num_examples=10000, total_duration=71464.7, train/accuracy=0.746452, train/loss=1.09227, validation/accuracy=0.68352, validation/loss=1.36426, validation/num_examples=50000
I0315 17:34:20.982655 139896463251200 logging_writer.py:48] [96500] global_step=96500, grad_norm=1.20446, loss=2.34317
I0315 17:34:20.986979 139925059253440 submission.py:265] 96500) loss = 2.343, grad_norm = 1.204
I0315 17:37:42.298293 139925059253440 spec.py:321] Evaluating on the training split.
I0315 17:38:23.782937 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 17:39:06.722934 139925059253440 spec.py:349] Evaluating on the test split.
I0315 17:39:07.832876 139925059253440 submission_runner.py:469] Time since start: 72061.81s, 	Step: 96899, 	{'train/accuracy': 0.7526307397959183, 'train/loss': 1.0597182293327487, 'validation/accuracy': 0.68598, 'validation/loss': 1.3432396875, 'validation/num_examples': 50000, 'test/accuracy': 0.5356, 'test/loss': 2.1266451171875, 'test/num_examples': 10000, 'score': 61161.89777755737, 'total_duration': 72061.80718636513, 'accumulated_submission_time': 61161.89777755737, 'accumulated_eval_time': 10507.663512706757, 'accumulated_logging_time': 6.06110405921936}
I0315 17:39:07.850506 139896110970624 logging_writer.py:48] [96899] accumulated_eval_time=10507.7, accumulated_logging_time=6.0611, accumulated_submission_time=61161.9, global_step=96899, preemption_count=0, score=61161.9, test/accuracy=0.5356, test/loss=2.12665, test/num_examples=10000, total_duration=72061.8, train/accuracy=0.752631, train/loss=1.05972, validation/accuracy=0.68598, validation/loss=1.34324, validation/num_examples=50000
I0315 17:40:07.200767 139896463251200 logging_writer.py:48] [97000] global_step=97000, grad_norm=1.22869, loss=2.47423
I0315 17:40:07.205013 139925059253440 submission.py:265] 97000) loss = 2.474, grad_norm = 1.229
I0315 17:47:28.125406 139896110970624 logging_writer.py:48] [97500] global_step=97500, grad_norm=1.18555, loss=2.43529
I0315 17:47:28.129980 139925059253440 submission.py:265] 97500) loss = 2.435, grad_norm = 1.186
I0315 17:47:42.397594 139925059253440 spec.py:321] Evaluating on the training split.
I0315 17:48:23.830620 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 17:49:09.163136 139925059253440 spec.py:349] Evaluating on the test split.
I0315 17:49:10.264338 139925059253440 submission_runner.py:469] Time since start: 72664.24s, 	Step: 97512, 	{'train/accuracy': 0.7512555803571429, 'train/loss': 1.046175820486886, 'validation/accuracy': 0.68588, 'validation/loss': 1.334583125, 'validation/num_examples': 50000, 'test/accuracy': 0.5518, 'test/loss': 2.039416015625, 'test/num_examples': 10000, 'score': 61673.29435920715, 'total_duration': 72664.23859620094, 'accumulated_submission_time': 61673.29435920715, 'accumulated_eval_time': 10595.530426740646, 'accumulated_logging_time': 6.087907314300537}
I0315 17:49:10.280337 139896463251200 logging_writer.py:48] [97512] accumulated_eval_time=10595.5, accumulated_logging_time=6.08791, accumulated_submission_time=61673.3, global_step=97512, preemption_count=0, score=61673.3, test/accuracy=0.5518, test/loss=2.03942, test/num_examples=10000, total_duration=72664.2, train/accuracy=0.751256, train/loss=1.04618, validation/accuracy=0.68588, validation/loss=1.33458, validation/num_examples=50000
I0315 17:53:41.656655 139896110970624 logging_writer.py:48] [98000] global_step=98000, grad_norm=1.20301, loss=2.34789
I0315 17:53:41.676462 139925059253440 submission.py:265] 98000) loss = 2.348, grad_norm = 1.203
I0315 17:57:41.867995 139925059253440 spec.py:321] Evaluating on the training split.
I0315 17:58:24.977180 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 17:59:07.259801 139925059253440 spec.py:349] Evaluating on the test split.
I0315 17:59:08.372402 139925059253440 submission_runner.py:469] Time since start: 73262.35s, 	Step: 98398, 	{'train/accuracy': 0.7518933354591837, 'train/loss': 1.0568661592444595, 'validation/accuracy': 0.68408, 'validation/loss': 1.34511703125, 'validation/num_examples': 50000, 'test/accuracy': 0.5556, 'test/loss': 2.002987109375, 'test/num_examples': 10000, 'score': 62181.63513112068, 'total_duration': 73262.34638690948, 'accumulated_submission_time': 62181.63513112068, 'accumulated_eval_time': 10682.034760475159, 'accumulated_logging_time': 6.111863613128662}
I0315 17:59:08.394500 139896463251200 logging_writer.py:48] [98398] accumulated_eval_time=10682, accumulated_logging_time=6.11186, accumulated_submission_time=62181.6, global_step=98398, preemption_count=0, score=62181.6, test/accuracy=0.5556, test/loss=2.00299, test/num_examples=10000, total_duration=73262.3, train/accuracy=0.751893, train/loss=1.05687, validation/accuracy=0.68408, validation/loss=1.34512, validation/num_examples=50000
I0315 18:00:32.640197 139896110970624 logging_writer.py:48] [98500] global_step=98500, grad_norm=1.24255, loss=2.348
I0315 18:00:32.644535 139925059253440 submission.py:265] 98500) loss = 2.348, grad_norm = 1.243
I0315 18:07:40.007588 139925059253440 spec.py:321] Evaluating on the training split.
I0315 18:08:23.996190 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 18:09:09.391420 139925059253440 spec.py:349] Evaluating on the test split.
I0315 18:09:10.498992 139925059253440 submission_runner.py:469] Time since start: 73864.47s, 	Step: 99000, 	{'train/accuracy': 0.7571548150510204, 'train/loss': 1.0550947383958467, 'validation/accuracy': 0.68878, 'validation/loss': 1.33924015625, 'validation/num_examples': 50000, 'test/accuracy': 0.5564, 'test/loss': 2.014149609375, 'test/num_examples': 10000, 'score': 62690.1025352478, 'total_duration': 73864.47322750092, 'accumulated_submission_time': 62690.1025352478, 'accumulated_eval_time': 10772.526222705841, 'accumulated_logging_time': 6.144016265869141}
I0315 18:09:10.517196 139896463251200 logging_writer.py:48] [99000] accumulated_eval_time=10772.5, accumulated_logging_time=6.14402, accumulated_submission_time=62690.1, global_step=99000, preemption_count=0, score=62690.1, test/accuracy=0.5564, test/loss=2.01415, test/num_examples=10000, total_duration=73864.5, train/accuracy=0.757155, train/loss=1.05509, validation/accuracy=0.68878, validation/loss=1.33924, validation/num_examples=50000
I0315 18:09:12.319318 139896110970624 logging_writer.py:48] [99000] global_step=99000, grad_norm=1.21409, loss=2.30056
I0315 18:09:12.323065 139925059253440 submission.py:265] 99000) loss = 2.301, grad_norm = 1.214
I0315 18:13:19.911643 139896463251200 logging_writer.py:48] [99500] global_step=99500, grad_norm=1.20726, loss=2.39584
I0315 18:13:19.916353 139925059253440 submission.py:265] 99500) loss = 2.396, grad_norm = 1.207
I0315 18:17:43.022176 139925059253440 spec.py:321] Evaluating on the training split.
I0315 18:18:24.825810 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 18:19:07.882222 139925059253440 spec.py:349] Evaluating on the test split.
I0315 18:19:08.982052 139925059253440 submission_runner.py:469] Time since start: 74462.96s, 	Step: 99819, 	{'train/accuracy': 0.7549027423469388, 'train/loss': 1.048199867715641, 'validation/accuracy': 0.69152, 'validation/loss': 1.3317425, 'validation/num_examples': 50000, 'test/accuracy': 0.547, 'test/loss': 2.03245, 'test/num_examples': 10000, 'score': 63199.36242032051, 'total_duration': 74462.95632123947, 'accumulated_submission_time': 63199.36242032051, 'accumulated_eval_time': 10858.48649764061, 'accumulated_logging_time': 6.217069625854492}
I0315 18:19:08.999599 139896110970624 logging_writer.py:48] [99819] accumulated_eval_time=10858.5, accumulated_logging_time=6.21707, accumulated_submission_time=63199.4, global_step=99819, preemption_count=0, score=63199.4, test/accuracy=0.547, test/loss=2.03245, test/num_examples=10000, total_duration=74463, train/accuracy=0.754903, train/loss=1.0482, validation/accuracy=0.69152, validation/loss=1.33174, validation/num_examples=50000
I0315 18:22:28.400279 139896463251200 logging_writer.py:48] [100000] global_step=100000, grad_norm=1.20447, loss=2.40189
I0315 18:22:28.441458 139925059253440 submission.py:265] 100000) loss = 2.402, grad_norm = 1.204
I0315 18:27:19.510108 139896110970624 logging_writer.py:48] [100500] global_step=100500, grad_norm=1.22454, loss=2.30563
I0315 18:27:19.514296 139925059253440 submission.py:265] 100500) loss = 2.306, grad_norm = 1.225
I0315 18:27:40.587246 139925059253440 spec.py:321] Evaluating on the training split.
I0315 18:28:21.673240 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 18:29:01.822256 139925059253440 spec.py:349] Evaluating on the test split.
I0315 18:29:02.925514 139925059253440 submission_runner.py:469] Time since start: 75056.90s, 	Step: 100541, 	{'train/accuracy': 0.7578722895408163, 'train/loss': 1.0466530468999122, 'validation/accuracy': 0.68994, 'validation/loss': 1.33071125, 'validation/num_examples': 50000, 'test/accuracy': 0.5569, 'test/loss': 2.009091796875, 'test/num_examples': 10000, 'score': 63707.83634638786, 'total_duration': 75056.89981842041, 'accumulated_submission_time': 63707.83634638786, 'accumulated_eval_time': 10940.824963092804, 'accumulated_logging_time': 6.243232011795044}
I0315 18:29:02.941645 139896463251200 logging_writer.py:48] [100541] accumulated_eval_time=10940.8, accumulated_logging_time=6.24323, accumulated_submission_time=63707.8, global_step=100541, preemption_count=0, score=63707.8, test/accuracy=0.5569, test/loss=2.00909, test/num_examples=10000, total_duration=75056.9, train/accuracy=0.757872, train/loss=1.04665, validation/accuracy=0.68994, validation/loss=1.33071, validation/num_examples=50000
I0315 18:34:11.083112 139896110970624 logging_writer.py:48] [101000] global_step=101000, grad_norm=1.20499, loss=2.42562
I0315 18:34:11.087006 139925059253440 submission.py:265] 101000) loss = 2.426, grad_norm = 1.205
I0315 18:37:35.652484 139925059253440 spec.py:321] Evaluating on the training split.
I0315 18:38:17.475143 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 18:39:01.348956 139925059253440 spec.py:349] Evaluating on the test split.
I0315 18:39:02.451808 139925059253440 submission_runner.py:469] Time since start: 75656.43s, 	Step: 101188, 	{'train/accuracy': 0.7546635841836735, 'train/loss': 1.0558063740632972, 'validation/accuracy': 0.68846, 'validation/loss': 1.33621765625, 'validation/num_examples': 50000, 'test/accuracy': 0.5428, 'test/loss': 2.050808203125, 'test/num_examples': 10000, 'score': 64217.40668797493, 'total_duration': 75656.42604541779, 'accumulated_submission_time': 64217.40668797493, 'accumulated_eval_time': 11027.624455451965, 'accumulated_logging_time': 6.268279790878296}
I0315 18:39:02.469788 139896463251200 logging_writer.py:48] [101188] accumulated_eval_time=11027.6, accumulated_logging_time=6.26828, accumulated_submission_time=64217.4, global_step=101188, preemption_count=0, score=64217.4, test/accuracy=0.5428, test/loss=2.05081, test/num_examples=10000, total_duration=75656.4, train/accuracy=0.754664, train/loss=1.05581, validation/accuracy=0.68846, validation/loss=1.33622, validation/num_examples=50000
I0315 18:42:58.558836 139896110970624 logging_writer.py:48] [101500] global_step=101500, grad_norm=1.3274, loss=2.40634
I0315 18:42:58.563271 139925059253440 submission.py:265] 101500) loss = 2.406, grad_norm = 1.327
I0315 18:47:12.532305 139896463251200 logging_writer.py:48] [102000] global_step=102000, grad_norm=1.26421, loss=2.42709
I0315 18:47:12.537908 139925059253440 submission.py:265] 102000) loss = 2.427, grad_norm = 1.264
I0315 18:47:34.056062 139925059253440 spec.py:321] Evaluating on the training split.
I0315 18:48:18.008030 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 18:49:01.604269 139925059253440 spec.py:349] Evaluating on the test split.
I0315 18:49:02.707620 139925059253440 submission_runner.py:469] Time since start: 76256.68s, 	Step: 102036, 	{'train/accuracy': 0.7593072385204082, 'train/loss': 1.044384158387476, 'validation/accuracy': 0.69066, 'validation/loss': 1.32837, 'validation/num_examples': 50000, 'test/accuracy': 0.5489, 'test/loss': 2.0543220703125, 'test/num_examples': 10000, 'score': 64725.615175008774, 'total_duration': 76256.681879282, 'accumulated_submission_time': 64725.615175008774, 'accumulated_eval_time': 11116.276199102402, 'accumulated_logging_time': 6.340555191040039}
I0315 18:49:02.748136 139896110970624 logging_writer.py:48] [102036] accumulated_eval_time=11116.3, accumulated_logging_time=6.34056, accumulated_submission_time=64725.6, global_step=102036, preemption_count=0, score=64725.6, test/accuracy=0.5489, test/loss=2.05432, test/num_examples=10000, total_duration=76256.7, train/accuracy=0.759307, train/loss=1.04438, validation/accuracy=0.69066, validation/loss=1.32837, validation/num_examples=50000
I0315 18:55:55.766470 139896463251200 logging_writer.py:48] [102500] global_step=102500, grad_norm=1.2702, loss=2.35372
I0315 18:55:55.868152 139925059253440 submission.py:265] 102500) loss = 2.354, grad_norm = 1.270
I0315 18:57:35.106101 139925059253440 spec.py:321] Evaluating on the training split.
I0315 18:58:16.497283 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 18:58:56.856586 139925059253440 spec.py:349] Evaluating on the test split.
I0315 18:58:57.955697 139925059253440 submission_runner.py:469] Time since start: 76851.93s, 	Step: 102583, 	{'train/accuracy': 0.7557397959183674, 'train/loss': 1.0144896993831711, 'validation/accuracy': 0.69348, 'validation/loss': 1.3016171875, 'validation/num_examples': 50000, 'test/accuracy': 0.5579, 'test/loss': 1.979314453125, 'test/num_examples': 10000, 'score': 65234.94600749016, 'total_duration': 76851.92993474007, 'accumulated_submission_time': 65234.94600749016, 'accumulated_eval_time': 11199.125978469849, 'accumulated_logging_time': 6.3893883228302}
I0315 18:58:57.987838 139896110970624 logging_writer.py:48] [102583] accumulated_eval_time=11199.1, accumulated_logging_time=6.38939, accumulated_submission_time=65234.9, global_step=102583, preemption_count=0, score=65234.9, test/accuracy=0.5579, test/loss=1.97931, test/num_examples=10000, total_duration=76851.9, train/accuracy=0.75574, train/loss=1.01449, validation/accuracy=0.69348, validation/loss=1.30162, validation/num_examples=50000
I0315 19:02:04.092932 139896463251200 logging_writer.py:48] [103000] global_step=103000, grad_norm=1.22062, loss=2.34693
I0315 19:02:04.097449 139925059253440 submission.py:265] 103000) loss = 2.347, grad_norm = 1.221
I0315 19:07:18.433153 139896110970624 logging_writer.py:48] [103500] global_step=103500, grad_norm=1.2291, loss=2.35352
I0315 19:07:18.437623 139925059253440 submission.py:265] 103500) loss = 2.354, grad_norm = 1.229
I0315 19:07:31.196437 139925059253440 spec.py:321] Evaluating on the training split.
I0315 19:08:11.567537 139925059253440 spec.py:333] Evaluating on the validation split.
I0315 19:08:53.994771 139925059253440 spec.py:349] Evaluating on the test split.
I0315 19:08:55.099171 139925059253440 submission_runner.py:469] Time since start: 77449.07s, 	Step: 103513, 	{'train/accuracy': 0.7621372767857143, 'train/loss': 1.0281727849220743, 'validation/accuracy': 0.69392, 'validation/loss': 1.31733578125, 'validation/num_examples': 50000, 'test/accuracy': 0.5551, 'test/loss': 2.0342234375, 'test/num_examples': 10000, 'score': 65744.95452785492, 'total_duration': 77449.07344818115, 'accumulated_submission_time': 65744.95452785492, 'accumulated_eval_time': 11283.028980016708, 'accumulated_logging_time': 6.43008279800415}
I0315 19:08:55.115952 139896463251200 logging_writer.py:48] [103513] accumulated_eval_time=11283, accumulated_logging_time=6.43008, accumulated_submission_time=65745, global_step=103513, preemption_count=0, score=65745, test/accuracy=0.5551, test/loss=2.03422, test/num_examples=10000, total_duration=77449.1, train/accuracy=0.762137, train/loss=1.02817, validation/accuracy=0.69392, validation/loss=1.31734, validation/num_examples=50000
I0315 19:15:57.907770 139896110970624 logging_writer.py:48] [104000] global_step=104000, grad_norm=1.3295, loss=2.36254
I0315 19:15:57.912449 139925059253440 submission.py:265] 104000) loss = 2.363, grad_norm = 1.330
I0315 19:17:25.238296 139896463251200 logging_writer.py:48] [104187] global_step=104187, preemption_count=0, score=66253.3
I0315 19:17:26.706822 139925059253440 submission_runner.py:646] Tuning trial 3/5
I0315 19:17:26.707625 139925059253440 submission_runner.py:647] Hyperparameters: Hyperparameters(learning_rate=4.199449275251465, one_minus_beta1=1.0, one_minus_beta2=0.0023701743773090066, epsilon=1e-08, one_minus_momentum=0.03150207249544311, use_momentum=True, weight_decay=6.404237434173623e-05, max_preconditioner_dim=1024, precondition_frequency=100, start_preconditioning_step=-1, inv_root_override=0, exponent_multiplier=1.0, grafting_type='SGD', grafting_epsilon=1e-08, use_normalized_grafting=False, communication_dtype='FP32', communicate_params=True, use_cosine_decay=True, warmup_factor=0.02, label_smoothing=0.1, dropout_rate=0.0, use_nadam=False, step_hint_factor=1.0)
I0315 19:17:26.710027 139925059253440 submission_runner.py:648] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0009167729591836735, 'train/loss': 6.911649742904975, 'validation/accuracy': 0.00112, 'validation/loss': 6.911316875, 'validation/num_examples': 50000, 'test/accuracy': 0.0011, 'test/loss': 6.912528125, 'test/num_examples': 10000, 'score': 107.47067213058472, 'total_duration': 517.6241047382355, 'accumulated_submission_time': 107.47067213058472, 'accumulated_eval_time': 409.22225880622864, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (424, {'train/accuracy': 0.02961575255102041, 'train/loss': 6.223091592594069, 'validation/accuracy': 0.03048, 'validation/loss': 6.250234375, 'validation/num_examples': 50000, 'test/accuracy': 0.0197, 'test/loss': 6.37908125, 'test/num_examples': 10000, 'score': 616.5652029514313, 'total_duration': 1110.9168598651886, 'accumulated_submission_time': 616.5652029514313, 'accumulated_eval_time': 490.43212938308716, 'accumulated_logging_time': 0.01801776885986328, 'global_step': 424, 'preemption_count': 0}), (859, {'train/accuracy': 0.08175223214285714, 'train/loss': 5.420374033402424, 'validation/accuracy': 0.0739, 'validation/loss': 5.49067, 'validation/num_examples': 50000, 'test/accuracy': 0.0465, 'test/loss': 5.767450390625, 'test/num_examples': 10000, 'score': 1125.0643401145935, 'total_duration': 1702.825607061386, 'accumulated_submission_time': 1125.0643401145935, 'accumulated_eval_time': 570.7421221733093, 'accumulated_logging_time': 0.03578305244445801, 'global_step': 859, 'preemption_count': 0}), (1317, {'train/accuracy': 0.14174107142857142, 'train/loss': 4.709414735132334, 'validation/accuracy': 0.12564, 'validation/loss': 4.79989125, 'validation/num_examples': 50000, 'test/accuracy': 0.0827, 'test/loss': 5.2381140625, 'test/num_examples': 10000, 'score': 1633.6429414749146, 'total_duration': 2294.7907276153564, 'accumulated_submission_time': 1633.6429414749146, 'accumulated_eval_time': 651.02143907547, 'accumulated_logging_time': 0.11875700950622559, 'global_step': 1317, 'preemption_count': 0}), (2208, {'train/accuracy': 0.28029336734693877, 'train/loss': 3.538737394371811, 'validation/accuracy': 0.25768, 'validation/loss': 3.6894621875, 'validation/num_examples': 50000, 'test/accuracy': 0.1716, 'test/loss': 4.391719921875, 'test/num_examples': 10000, 'score': 2143.319287776947, 'total_duration': 2890.0272657871246, 'accumulated_submission_time': 2143.319287776947, 'accumulated_eval_time': 733.3403203487396, 'accumulated_logging_time': 0.1589193344116211, 'global_step': 2208, 'preemption_count': 0}), (2974, {'train/accuracy': 0.39026626275510207, 'train/loss': 2.9098031180245534, 'validation/accuracy': 0.36212, 'validation/loss': 3.0464159375, 'validation/num_examples': 50000, 'test/accuracy': 0.2563, 'test/loss': 3.72038671875, 'test/num_examples': 10000, 'score': 2651.5329144001007, 'total_duration': 3481.7453124523163, 'accumulated_submission_time': 2651.5329144001007, 'accumulated_eval_time': 813.6074542999268, 'accumulated_logging_time': 0.18682265281677246, 'global_step': 2974, 'preemption_count': 0}), (3754, {'train/accuracy': 0.4621532206632653, 'train/loss': 2.4937231881277904, 'validation/accuracy': 0.43042, 'validation/loss': 2.6436709375, 'validation/num_examples': 50000, 'test/accuracy': 0.3105, 'test/loss': 3.393751171875, 'test/num_examples': 10000, 'score': 3160.442153453827, 'total_duration': 4077.231496810913, 'accumulated_submission_time': 3160.442153453827, 'accumulated_eval_time': 896.9726026058197, 'accumulated_logging_time': 0.2058122158050537, 'global_step': 3754, 'preemption_count': 0}), (4718, {'train/accuracy': 0.5231784119897959, 'train/loss': 2.199096056879783, 'validation/accuracy': 0.48894, 'validation/loss': 2.3569846875, 'validation/num_examples': 50000, 'test/accuracy': 0.3532, 'test/loss': 3.1282423828125, 'test/num_examples': 10000, 'score': 3669.2544972896576, 'total_duration': 4671.530030012131, 'accumulated_submission_time': 3669.2544972896576, 'accumulated_eval_time': 979.1215584278107, 'accumulated_logging_time': 0.2772786617279053, 'global_step': 4718, 'preemption_count': 0}), (5569, {'train/accuracy': 0.5506218112244898, 'train/loss': 1.98255967120735, 'validation/accuracy': 0.5127, 'validation/loss': 2.16876578125, 'validation/num_examples': 50000, 'test/accuracy': 0.3872, 'test/loss': 2.8830830078125, 'test/num_examples': 10000, 'score': 4178.118154764175, 'total_duration': 5265.413460493088, 'accumulated_submission_time': 4178.118154764175, 'accumulated_eval_time': 1060.8057141304016, 'accumulated_logging_time': 0.3684208393096924, 'global_step': 5569, 'preemption_count': 0}), (6256, {'train/accuracy': 0.5708705357142857, 'train/loss': 1.9034056371572066, 'validation/accuracy': 0.53218, 'validation/loss': 2.07280328125, 'validation/num_examples': 50000, 'test/accuracy': 0.3986, 'test/loss': 2.849094140625, 'test/num_examples': 10000, 'score': 4687.382040262222, 'total_duration': 5860.358816385269, 'accumulated_submission_time': 4687.382040262222, 'accumulated_eval_time': 1143.2412989139557, 'accumulated_logging_time': 0.3878462314605713, 'global_step': 6256, 'preemption_count': 0}), (7265, {'train/accuracy': 0.5860770089285714, 'train/loss': 1.865480695452009, 'validation/accuracy': 0.54092, 'validation/loss': 2.0557559375, 'validation/num_examples': 50000, 'test/accuracy': 0.4006, 'test/loss': 2.8008642578125, 'test/num_examples': 10000, 'score': 5195.943376302719, 'total_duration': 6452.928684949875, 'accumulated_submission_time': 5195.943376302719, 'accumulated_eval_time': 1223.9414556026459, 'accumulated_logging_time': 0.4116635322570801, 'global_step': 7265, 'preemption_count': 0}), (8168, {'train/accuracy': 0.6065250318877551, 'train/loss': 1.7365006427375638, 'validation/accuracy': 0.56104, 'validation/loss': 1.9276584375, 'validation/num_examples': 50000, 'test/accuracy': 0.4234, 'test/loss': 2.697825390625, 'test/num_examples': 10000, 'score': 5704.216891288757, 'total_duration': 7046.32958483696, 'accumulated_submission_time': 5704.216891288757, 'accumulated_eval_time': 1305.745949268341, 'accumulated_logging_time': 0.4677109718322754, 'global_step': 8168, 'preemption_count': 0}), (8880, {'train/accuracy': 0.6073620854591837, 'train/loss': 1.7228887129803092, 'validation/accuracy': 0.56194, 'validation/loss': 1.9178409375, 'validation/num_examples': 50000, 'test/accuracy': 0.4119, 'test/loss': 2.74017890625, 'test/num_examples': 10000, 'score': 6212.764410734177, 'total_duration': 7638.551360845566, 'accumulated_submission_time': 6212.764410734177, 'accumulated_eval_time': 1386.2355909347534, 'accumulated_logging_time': 0.48870372772216797, 'global_step': 8880, 'preemption_count': 0}), (9865, {'train/accuracy': 0.6216916454081632, 'train/loss': 1.666939404545998, 'validation/accuracy': 0.57604, 'validation/loss': 1.87018359375, 'validation/num_examples': 50000, 'test/accuracy': 0.438, 'test/loss': 2.6048619140625, 'test/num_examples': 10000, 'score': 6721.821131229401, 'total_duration': 8234.588216304779, 'accumulated_submission_time': 6721.821131229401, 'accumulated_eval_time': 1469.8654177188873, 'accumulated_logging_time': 0.5521407127380371, 'global_step': 9865, 'preemption_count': 0}), (10765, {'train/accuracy': 0.6248405612244898, 'train/loss': 1.6267888594646842, 'validation/accuracy': 0.58006, 'validation/loss': 1.84031734375, 'validation/num_examples': 50000, 'test/accuracy': 0.4454, 'test/loss': 2.559526171875, 'test/num_examples': 10000, 'score': 7230.052751541138, 'total_duration': 8827.681890964508, 'accumulated_submission_time': 7230.052751541138, 'accumulated_eval_time': 1551.3239657878876, 'accumulated_logging_time': 0.6205580234527588, 'global_step': 10765, 'preemption_count': 0}), (11459, {'train/accuracy': 0.6271125637755102, 'train/loss': 1.6297088934450734, 'validation/accuracy': 0.57922, 'validation/loss': 1.838754375, 'validation/num_examples': 50000, 'test/accuracy': 0.454, 'test/loss': 2.5172078125, 'test/num_examples': 10000, 'score': 7738.480170965195, 'total_duration': 9420.371783971786, 'accumulated_submission_time': 7738.480170965195, 'accumulated_eval_time': 1632.3996999263763, 'accumulated_logging_time': 0.6392207145690918, 'global_step': 11459, 'preemption_count': 0}), (12323, {'train/accuracy': 0.6315768494897959, 'train/loss': 1.602774950922752, 'validation/accuracy': 0.58344, 'validation/loss': 1.82060375, 'validation/num_examples': 50000, 'test/accuracy': 0.4515, 'test/loss': 2.567936328125, 'test/num_examples': 10000, 'score': 8248.43051981926, 'total_duration': 10016.374151229858, 'accumulated_submission_time': 8248.43051981926, 'accumulated_eval_time': 1715.2075335979462, 'accumulated_logging_time': 0.6583881378173828, 'global_step': 12323, 'preemption_count': 0}), (13228, {'train/accuracy': 0.6381935586734694, 'train/loss': 1.603255914182079, 'validation/accuracy': 0.58996, 'validation/loss': 1.819635625, 'validation/num_examples': 50000, 'test/accuracy': 0.4529, 'test/loss': 2.5703978515625, 'test/num_examples': 10000, 'score': 8756.915067911148, 'total_duration': 10609.737285852432, 'accumulated_submission_time': 8756.915067911148, 'accumulated_eval_time': 1796.7290258407593, 'accumulated_logging_time': 0.697404146194458, 'global_step': 13228, 'preemption_count': 0}), (13885, {'train/accuracy': 0.6509885204081632, 'train/loss': 1.5312781820491868, 'validation/accuracy': 0.60114, 'validation/loss': 1.749699375, 'validation/num_examples': 50000, 'test/accuracy': 0.4654, 'test/loss': 2.4881814453125, 'test/num_examples': 10000, 'score': 9265.61754322052, 'total_duration': 11201.808292865753, 'accumulated_submission_time': 9265.61754322052, 'accumulated_eval_time': 1877.0836174488068, 'accumulated_logging_time': 0.7166333198547363, 'global_step': 13885, 'preemption_count': 0}), (14779, {'train/accuracy': 0.6494339923469388, 'train/loss': 1.501454411720743, 'validation/accuracy': 0.60028, 'validation/loss': 1.72192078125, 'validation/num_examples': 50000, 'test/accuracy': 0.4696, 'test/loss': 2.4237791015625, 'test/num_examples': 10000, 'score': 9775.070176839828, 'total_duration': 11795.629420518875, 'accumulated_submission_time': 9775.070176839828, 'accumulated_eval_time': 1958.262563943863, 'accumulated_logging_time': 0.7706775665283203, 'global_step': 14779, 'preemption_count': 0}), (15621, {'train/accuracy': 0.6496731505102041, 'train/loss': 1.5467003024354273, 'validation/accuracy': 0.60586, 'validation/loss': 1.75280125, 'validation/num_examples': 50000, 'test/accuracy': 0.4696, 'test/loss': 2.4984009765625, 'test/num_examples': 10000, 'score': 10283.316243886948, 'total_duration': 12388.611430644989, 'accumulated_submission_time': 10283.316243886948, 'accumulated_eval_time': 2039.7419390678406, 'accumulated_logging_time': 0.7911643981933594, 'global_step': 15621, 'preemption_count': 0}), (16248, {'train/accuracy': 0.6462651466836735, 'train/loss': 1.5586968246771364, 'validation/accuracy': 0.59826, 'validation/loss': 1.7781103125, 'validation/num_examples': 50000, 'test/accuracy': 0.4582, 'test/loss': 2.515841796875, 'test/num_examples': 10000, 'score': 10792.28248333931, 'total_duration': 12981.753015756607, 'accumulated_submission_time': 10792.28248333931, 'accumulated_eval_time': 2121.02946972847, 'accumulated_logging_time': 0.8111519813537598, 'global_step': 16248, 'preemption_count': 0}), (17214, {'train/accuracy': 0.6556521045918368, 'train/loss': 1.514524187360491, 'validation/accuracy': 0.6083, 'validation/loss': 1.72887, 'validation/num_examples': 50000, 'test/accuracy': 0.4717, 'test/loss': 2.4427814453125, 'test/num_examples': 10000, 'score': 11300.4684882164, 'total_duration': 13573.289619922638, 'accumulated_submission_time': 11300.4684882164, 'accumulated_eval_time': 2201.007009744644, 'accumulated_logging_time': 0.9038207530975342, 'global_step': 17214, 'preemption_count': 0}), (18008, {'train/accuracy': 0.6623684630102041, 'train/loss': 1.468217032296317, 'validation/accuracy': 0.6116, 'validation/loss': 1.6902753125, 'validation/num_examples': 50000, 'test/accuracy': 0.4662, 'test/loss': 2.4455240234375, 'test/num_examples': 10000, 'score': 11808.709686994553, 'total_duration': 14165.89183139801, 'accumulated_submission_time': 11808.709686994553, 'accumulated_eval_time': 2282.120290994644, 'accumulated_logging_time': 0.9232122898101807, 'global_step': 18008, 'preemption_count': 0}), (18697, {'train/accuracy': 0.6581632653061225, 'train/loss': 1.4852329176299426, 'validation/accuracy': 0.60772, 'validation/loss': 1.71311515625, 'validation/num_examples': 50000, 'test/accuracy': 0.4711, 'test/loss': 2.46288984375, 'test/num_examples': 10000, 'score': 12317.72209906578, 'total_duration': 14758.457606554031, 'accumulated_submission_time': 12317.72209906578, 'accumulated_eval_time': 2362.5193288326263, 'accumulated_logging_time': 0.9413371086120605, 'global_step': 18697, 'preemption_count': 0}), (19646, {'train/accuracy': 0.6605548469387755, 'train/loss': 1.499438071737484, 'validation/accuracy': 0.61188, 'validation/loss': 1.7142309375, 'validation/num_examples': 50000, 'test/accuracy': 0.4725, 'test/loss': 2.4208578125, 'test/num_examples': 10000, 'score': 12826.070837259293, 'total_duration': 15350.541978597641, 'accumulated_submission_time': 12826.070837259293, 'accumulated_eval_time': 2442.901951789856, 'accumulated_logging_time': 1.0455667972564697, 'global_step': 19646, 'preemption_count': 0}), (20398, {'train/accuracy': 0.6627471301020408, 'train/loss': 1.4753821236746651, 'validation/accuracy': 0.61246, 'validation/loss': 1.69695796875, 'validation/num_examples': 50000, 'test/accuracy': 0.4694, 'test/loss': 2.44257890625, 'test/num_examples': 10000, 'score': 13334.506560325623, 'total_duration': 15942.428157567978, 'accumulated_submission_time': 13334.506560325623, 'accumulated_eval_time': 2523.1072075366974, 'accumulated_logging_time': 1.0647289752960205, 'global_step': 20398, 'preemption_count': 0}), (21158, {'train/accuracy': 0.6602359693877551, 'train/loss': 1.4762596597476882, 'validation/accuracy': 0.61548, 'validation/loss': 1.68282984375, 'validation/num_examples': 50000, 'test/accuracy': 0.479, 'test/loss': 2.400184375, 'test/num_examples': 10000, 'score': 13843.056567668915, 'total_duration': 16534.05265522003, 'accumulated_submission_time': 13843.056567668915, 'accumulated_eval_time': 2603.0532104969025, 'accumulated_logging_time': 1.0839827060699463, 'global_step': 21158, 'preemption_count': 0}), (22082, {'train/accuracy': 0.6717753507653061, 'train/loss': 1.436492141412229, 'validation/accuracy': 0.61956, 'validation/loss': 1.651159375, 'validation/num_examples': 50000, 'test/accuracy': 0.4895, 'test/loss': 2.3626853515625, 'test/num_examples': 10000, 'score': 14351.371251821518, 'total_duration': 17127.379098653793, 'accumulated_submission_time': 14351.371251821518, 'accumulated_eval_time': 2684.751639842987, 'accumulated_logging_time': 1.1409130096435547, 'global_step': 22082, 'preemption_count': 0}), (22838, {'train/accuracy': 0.6655173788265306, 'train/loss': 1.4351305280412947, 'validation/accuracy': 0.6116, 'validation/loss': 1.66900625, 'validation/num_examples': 50000, 'test/accuracy': 0.4733, 'test/loss': 2.4145650390625, 'test/num_examples': 10000, 'score': 14859.782289743423, 'total_duration': 17719.865710496902, 'accumulated_submission_time': 14859.782289743423, 'accumulated_eval_time': 2765.5345017910004, 'accumulated_logging_time': 1.1996984481811523, 'global_step': 22838, 'preemption_count': 0}), (23636, {'train/accuracy': 0.6668526785714286, 'train/loss': 1.4203187592175541, 'validation/accuracy': 0.6147, 'validation/loss': 1.64922765625, 'validation/num_examples': 50000, 'test/accuracy': 0.4865, 'test/loss': 2.3957216796875, 'test/num_examples': 10000, 'score': 15368.868700265884, 'total_duration': 18316.21905040741, 'accumulated_submission_time': 15368.868700265884, 'accumulated_eval_time': 2849.6128475666046, 'accumulated_logging_time': 1.2188961505889893, 'global_step': 23636, 'preemption_count': 0}), (24564, {'train/accuracy': 0.6751434948979592, 'train/loss': 1.4067941782425861, 'validation/accuracy': 0.62564, 'validation/loss': 1.63091375, 'validation/num_examples': 50000, 'test/accuracy': 0.4958, 'test/loss': 2.331418359375, 'test/num_examples': 10000, 'score': 15877.069551229477, 'total_duration': 18909.924867630005, 'accumulated_submission_time': 15877.069551229477, 'accumulated_eval_time': 2931.844833612442, 'accumulated_logging_time': 1.2590551376342773, 'global_step': 24564, 'preemption_count': 0}), (25297, {'train/accuracy': 0.6753627232142857, 'train/loss': 1.4069919196926817, 'validation/accuracy': 0.6234, 'validation/loss': 1.63268734375, 'validation/num_examples': 50000, 'test/accuracy': 0.4854, 'test/loss': 2.36761640625, 'test/num_examples': 10000, 'score': 16385.77275443077, 'total_duration': 19501.482042074203, 'accumulated_submission_time': 16385.77275443077, 'accumulated_eval_time': 3011.691407442093, 'accumulated_logging_time': 1.2786266803741455, 'global_step': 25297, 'preemption_count': 0}), (26127, {'train/accuracy': 0.6723533163265306, 'train/loss': 1.4310687318140147, 'validation/accuracy': 0.61986, 'validation/loss': 1.66946625, 'validation/num_examples': 50000, 'test/accuracy': 0.4776, 'test/loss': 2.4187427734375, 'test/num_examples': 10000, 'score': 16894.242168426514, 'total_duration': 20097.576339244843, 'accumulated_submission_time': 16894.242168426514, 'accumulated_eval_time': 3096.0484907627106, 'accumulated_logging_time': 1.2984225749969482, 'global_step': 26127, 'preemption_count': 0}), (27068, {'train/accuracy': 0.6677295918367347, 'train/loss': 1.458228130729831, 'validation/accuracy': 0.61486, 'validation/loss': 1.68823765625, 'validation/num_examples': 50000, 'test/accuracy': 0.4896, 'test/loss': 2.373322265625, 'test/num_examples': 10000, 'score': 17402.449024677277, 'total_duration': 20692.264118433, 'accumulated_submission_time': 17402.449024677277, 'accumulated_eval_time': 3179.0582723617554, 'accumulated_logging_time': 1.3680493831634521, 'global_step': 27068, 'preemption_count': 0}), (27785, {'train/accuracy': 0.6789500956632653, 'train/loss': 1.3849358072086257, 'validation/accuracy': 0.62534, 'validation/loss': 1.61053296875, 'validation/num_examples': 50000, 'test/accuracy': 0.4859, 'test/loss': 2.3653490234375, 'test/num_examples': 10000, 'score': 17910.791379213333, 'total_duration': 21285.782597780228, 'accumulated_submission_time': 17910.791379213333, 'accumulated_eval_time': 3261.029375553131, 'accumulated_logging_time': 1.3880445957183838, 'global_step': 27785, 'preemption_count': 0}), (28604, {'train/accuracy': 0.6775550063775511, 'train/loss': 1.3980150806660554, 'validation/accuracy': 0.62682, 'validation/loss': 1.62477421875, 'validation/num_examples': 50000, 'test/accuracy': 0.4857, 'test/loss': 2.3713482421875, 'test/num_examples': 10000, 'score': 18420.026364326477, 'total_duration': 21882.843428373337, 'accumulated_submission_time': 18420.026364326477, 'accumulated_eval_time': 3345.543921470642, 'accumulated_logging_time': 1.4271376132965088, 'global_step': 28604, 'preemption_count': 0}), (29516, {'train/accuracy': 0.6743463010204082, 'train/loss': 1.4149400360730229, 'validation/accuracy': 0.61866, 'validation/loss': 1.64442296875, 'validation/num_examples': 50000, 'test/accuracy': 0.4805, 'test/loss': 2.3698986328125, 'test/num_examples': 10000, 'score': 18928.80771422386, 'total_duration': 22476.437198400497, 'accumulated_submission_time': 18928.80771422386, 'accumulated_eval_time': 3427.00976896286, 'accumulated_logging_time': 1.4611997604370117, 'global_step': 29516, 'preemption_count': 0}), (30201, {'train/accuracy': 0.6847496811224489, 'train/loss': 1.3504470513791453, 'validation/accuracy': 0.62966, 'validation/loss': 1.58175015625, 'validation/num_examples': 50000, 'test/accuracy': 0.4967, 'test/loss': 2.3175212890625, 'test/num_examples': 10000, 'score': 19437.373670101166, 'total_duration': 23070.180783510208, 'accumulated_submission_time': 19437.373670101166, 'accumulated_eval_time': 3508.993463754654, 'accumulated_logging_time': 1.4806747436523438, 'global_step': 30201, 'preemption_count': 0}), (31076, {'train/accuracy': 0.6782724808673469, 'train/loss': 1.416348204320791, 'validation/accuracy': 0.62634, 'validation/loss': 1.6418334375, 'validation/num_examples': 50000, 'test/accuracy': 0.4715, 'test/loss': 2.4357486328125, 'test/num_examples': 10000, 'score': 19946.700329065323, 'total_duration': 23667.30804347992, 'accumulated_submission_time': 19946.700329065323, 'accumulated_eval_time': 3593.494477033615, 'accumulated_logging_time': 1.5322413444519043, 'global_step': 31076, 'preemption_count': 0}), (31967, {'train/accuracy': 0.6802654655612245, 'train/loss': 1.3967951560507015, 'validation/accuracy': 0.62748, 'validation/loss': 1.62790921875, 'validation/num_examples': 50000, 'test/accuracy': 0.4812, 'test/loss': 2.380094140625, 'test/num_examples': 10000, 'score': 20454.862374782562, 'total_duration': 24260.17257642746, 'accumulated_submission_time': 20454.862374782562, 'accumulated_eval_time': 3674.8105189800262, 'accumulated_logging_time': 1.6078832149505615, 'global_step': 31967, 'preemption_count': 0}), (32644, {'train/accuracy': 0.6804049744897959, 'train/loss': 1.3772296516262754, 'validation/accuracy': 0.6288, 'validation/loss': 1.60769375, 'validation/num_examples': 50000, 'test/accuracy': 0.4993, 'test/loss': 2.300462890625, 'test/num_examples': 10000, 'score': 20963.299649715424, 'total_duration': 24853.169666290283, 'accumulated_submission_time': 20963.299649715424, 'accumulated_eval_time': 3756.1686868667603, 'accumulated_logging_time': 1.6278128623962402, 'global_step': 32644, 'preemption_count': 0}), (33542, {'train/accuracy': 0.6846500318877551, 'train/loss': 1.3918044421137596, 'validation/accuracy': 0.6324, 'validation/loss': 1.62516140625, 'validation/num_examples': 50000, 'test/accuracy': 0.4931, 'test/loss': 2.3363654296875, 'test/num_examples': 10000, 'score': 21471.59898543358, 'total_duration': 25449.56843471527, 'accumulated_submission_time': 21471.59898543358, 'accumulated_eval_time': 3841.030893087387, 'accumulated_logging_time': 1.6526682376861572, 'global_step': 33542, 'preemption_count': 0}), (34405, {'train/accuracy': 0.6848294005102041, 'train/loss': 1.3728070940290178, 'validation/accuracy': 0.63152, 'validation/loss': 1.60454546875, 'validation/num_examples': 50000, 'test/accuracy': 0.4886, 'test/loss': 2.3548595703125, 'test/num_examples': 10000, 'score': 21980.084597349167, 'total_duration': 26041.85134792328, 'accumulated_submission_time': 21980.084597349167, 'accumulated_eval_time': 3921.6838812828064, 'accumulated_logging_time': 1.6752574443817139, 'global_step': 34405, 'preemption_count': 0}), (35029, {'train/accuracy': 0.6837531887755102, 'train/loss': 1.392933903908243, 'validation/accuracy': 0.63382, 'validation/loss': 1.62121578125, 'validation/num_examples': 50000, 'test/accuracy': 0.4916, 'test/loss': 2.3459619140625, 'test/num_examples': 10000, 'score': 22490.10764169693, 'total_duration': 26635.983645677567, 'accumulated_submission_time': 22490.10764169693, 'accumulated_eval_time': 4002.665917158127, 'accumulated_logging_time': 1.7308950424194336, 'global_step': 35029, 'preemption_count': 0}), (35999, {'train/accuracy': 0.6826769770408163, 'train/loss': 1.3742189991230866, 'validation/accuracy': 0.62928, 'validation/loss': 1.600976875, 'validation/num_examples': 50000, 'test/accuracy': 0.4773, 'test/loss': 2.406099609375, 'test/num_examples': 10000, 'score': 22998.50823521614, 'total_duration': 27229.87111544609, 'accumulated_submission_time': 22998.50823521614, 'accumulated_eval_time': 4084.8041694164276, 'accumulated_logging_time': 1.7712891101837158, 'global_step': 35999, 'preemption_count': 0}), (36824, {'train/accuracy': 0.6836535395408163, 'train/loss': 1.373213631766183, 'validation/accuracy': 0.62994, 'validation/loss': 1.61262171875, 'validation/num_examples': 50000, 'test/accuracy': 0.492, 'test/loss': 2.357156640625, 'test/num_examples': 10000, 'score': 23507.14585995674, 'total_duration': 27823.3835375309, 'accumulated_submission_time': 23507.14585995674, 'accumulated_eval_time': 4166.369605541229, 'accumulated_logging_time': 1.8180444240570068, 'global_step': 36824, 'preemption_count': 0}), (37559, {'train/accuracy': 0.6880381058673469, 'train/loss': 1.3389895692163585, 'validation/accuracy': 0.63672, 'validation/loss': 1.5647571875, 'validation/num_examples': 50000, 'test/accuracy': 0.5016, 'test/loss': 2.264956640625, 'test/num_examples': 10000, 'score': 24015.681949853897, 'total_duration': 28416.720584630966, 'accumulated_submission_time': 24015.681949853897, 'accumulated_eval_time': 4248.014618873596, 'accumulated_logging_time': 1.8590383529663086, 'global_step': 37559, 'preemption_count': 0}), (38565, {'train/accuracy': 0.6847696109693877, 'train/loss': 1.3639415818817762, 'validation/accuracy': 0.63338, 'validation/loss': 1.5867365625, 'validation/num_examples': 50000, 'test/accuracy': 0.4894, 'test/loss': 2.3261671875, 'test/num_examples': 10000, 'score': 24523.739703178406, 'total_duration': 29013.454742193222, 'accumulated_submission_time': 24523.739703178406, 'accumulated_eval_time': 4333.284723520279, 'accumulated_logging_time': 1.924267292022705, 'global_step': 38565, 'preemption_count': 0}), (39488, {'train/accuracy': 0.6840521364795918, 'train/loss': 1.3641735777562978, 'validation/accuracy': 0.63022, 'validation/loss': 1.603979375, 'validation/num_examples': 50000, 'test/accuracy': 0.4801, 'test/loss': 2.38642421875, 'test/num_examples': 10000, 'score': 25031.940733909607, 'total_duration': 29604.93714618683, 'accumulated_submission_time': 25031.940733909607, 'accumulated_eval_time': 4413.220862150192, 'accumulated_logging_time': 1.978187084197998, 'global_step': 39488, 'preemption_count': 0}), (40231, {'train/accuracy': 0.6887356505102041, 'train/loss': 1.3279769274653221, 'validation/accuracy': 0.63304, 'validation/loss': 1.573351875, 'validation/num_examples': 50000, 'test/accuracy': 0.4873, 'test/loss': 2.347129296875, 'test/num_examples': 10000, 'score': 25540.251209020615, 'total_duration': 30196.318422317505, 'accumulated_submission_time': 25540.251209020615, 'accumulated_eval_time': 4493.12048125267, 'accumulated_logging_time': 1.999892234802246, 'global_step': 40231, 'preemption_count': 0}), (41131, {'train/accuracy': 0.6945551658163265, 'train/loss': 1.321434955207669, 'validation/accuracy': 0.64092, 'validation/loss': 1.55130453125, 'validation/num_examples': 50000, 'test/accuracy': 0.5009, 'test/loss': 2.2950310546875, 'test/num_examples': 10000, 'score': 26048.75089406967, 'total_duration': 30793.814932584763, 'accumulated_submission_time': 26048.75089406967, 'accumulated_eval_time': 4578.801331996918, 'accumulated_logging_time': 2.0206968784332275, 'global_step': 41131, 'preemption_count': 0}), (42080, {'train/accuracy': 0.6914461096938775, 'train/loss': 1.332809759646046, 'validation/accuracy': 0.63874, 'validation/loss': 1.56871875, 'validation/num_examples': 50000, 'test/accuracy': 0.4968, 'test/loss': 2.338083984375, 'test/num_examples': 10000, 'score': 26557.777857542038, 'total_duration': 31391.21298933029, 'accumulated_submission_time': 26557.777857542038, 'accumulated_eval_time': 4663.740928888321, 'accumulated_logging_time': 2.0621771812438965, 'global_step': 42080, 'preemption_count': 0}), (42834, {'train/accuracy': 0.6934789540816326, 'train/loss': 1.3194035121372767, 'validation/accuracy': 0.63886, 'validation/loss': 1.5643221875, 'validation/num_examples': 50000, 'test/accuracy': 0.4885, 'test/loss': 2.354053515625, 'test/num_examples': 10000, 'score': 27065.98811841011, 'total_duration': 31984.09667778015, 'accumulated_submission_time': 27065.98811841011, 'accumulated_eval_time': 4745.1008477211, 'accumulated_logging_time': 2.1435322761535645, 'global_step': 42834, 'preemption_count': 0}), (43660, {'train/accuracy': 0.6948142538265306, 'train/loss': 1.3406298890405772, 'validation/accuracy': 0.64046, 'validation/loss': 1.57015203125, 'validation/num_examples': 50000, 'test/accuracy': 0.4956, 'test/loss': 2.33862578125, 'test/num_examples': 10000, 'score': 27576.926027536392, 'total_duration': 32581.624357938766, 'accumulated_submission_time': 27576.926027536392, 'accumulated_eval_time': 4828.5853061676025, 'accumulated_logging_time': 2.1645400524139404, 'global_step': 43660, 'preemption_count': 0}), (44627, {'train/accuracy': 0.6926219706632653, 'train/loss': 1.3247127922213808, 'validation/accuracy': 0.6391, 'validation/loss': 1.553726875, 'validation/num_examples': 50000, 'test/accuracy': 0.4952, 'test/loss': 2.3022447265625, 'test/num_examples': 10000, 'score': 28085.30637216568, 'total_duration': 33174.90571689606, 'accumulated_submission_time': 28085.30637216568, 'accumulated_eval_time': 4910.135939836502, 'accumulated_logging_time': 2.2536253929138184, 'global_step': 44627, 'preemption_count': 0}), (45403, {'train/accuracy': 0.6985809948979592, 'train/loss': 1.2860445295061385, 'validation/accuracy': 0.6464, 'validation/loss': 1.5270115625, 'validation/num_examples': 50000, 'test/accuracy': 0.5059, 'test/loss': 2.250443359375, 'test/num_examples': 10000, 'score': 28593.59709095955, 'total_duration': 33768.97868347168, 'accumulated_submission_time': 28593.59709095955, 'accumulated_eval_time': 4992.712544679642, 'accumulated_logging_time': 2.2759146690368652, 'global_step': 45403, 'preemption_count': 0}), (46181, {'train/accuracy': 0.6937779017857143, 'train/loss': 1.3123371357820472, 'validation/accuracy': 0.64074, 'validation/loss': 1.54869140625, 'validation/num_examples': 50000, 'test/accuracy': 0.492, 'test/loss': 2.32313125, 'test/num_examples': 10000, 'score': 29102.42606306076, 'total_duration': 34365.21852350235, 'accumulated_submission_time': 29102.42606306076, 'accumulated_eval_time': 5076.907496213913, 'accumulated_logging_time': 2.2984142303466797, 'global_step': 46181, 'preemption_count': 0}), (47136, {'train/accuracy': 0.6956313775510204, 'train/loss': 1.3137384531449299, 'validation/accuracy': 0.64224, 'validation/loss': 1.54597421875, 'validation/num_examples': 50000, 'test/accuracy': 0.5068, 'test/loss': 2.257491015625, 'test/num_examples': 10000, 'score': 29611.385087013245, 'total_duration': 34960.11428308487, 'accumulated_submission_time': 29611.385087013245, 'accumulated_eval_time': 5159.4417724609375, 'accumulated_logging_time': 2.3720948696136475, 'global_step': 47136, 'preemption_count': 0}), (47911, {'train/accuracy': 0.6983617665816326, 'train/loss': 1.3077904837472099, 'validation/accuracy': 0.64124, 'validation/loss': 1.55220796875, 'validation/num_examples': 50000, 'test/accuracy': 0.5083, 'test/loss': 2.2666205078125, 'test/num_examples': 10000, 'score': 30120.200031995773, 'total_duration': 35556.299412965775, 'accumulated_submission_time': 30120.200031995773, 'accumulated_eval_time': 5243.5723757743835, 'accumulated_logging_time': 2.410292148590088, 'global_step': 47911, 'preemption_count': 0}), (48695, {'train/accuracy': 0.6983019770408163, 'train/loss': 1.3072027089644451, 'validation/accuracy': 0.64356, 'validation/loss': 1.54504625, 'validation/num_examples': 50000, 'test/accuracy': 0.4983, 'test/loss': 2.29508828125, 'test/num_examples': 10000, 'score': 30628.940316200256, 'total_duration': 36154.40313267708, 'accumulated_submission_time': 30628.940316200256, 'accumulated_eval_time': 5329.715517282486, 'accumulated_logging_time': 2.432955503463745, 'global_step': 48695, 'preemption_count': 0}), (49678, {'train/accuracy': 0.6987603635204082, 'train/loss': 1.31502408397441, 'validation/accuracy': 0.64256, 'validation/loss': 1.551053125, 'validation/num_examples': 50000, 'test/accuracy': 0.5016, 'test/loss': 2.28402734375, 'test/num_examples': 10000, 'score': 31138.529881238937, 'total_duration': 36753.85166668892, 'accumulated_submission_time': 31138.529881238937, 'accumulated_eval_time': 5416.20216012001, 'accumulated_logging_time': 2.534764528274536, 'global_step': 49678, 'preemption_count': 0}), (50493, {'train/accuracy': 0.6983816964285714, 'train/loss': 1.3140710324657208, 'validation/accuracy': 0.643, 'validation/loss': 1.55239171875, 'validation/num_examples': 50000, 'test/accuracy': 0.5121, 'test/loss': 2.25651796875, 'test/num_examples': 10000, 'score': 31647.38681125641, 'total_duration': 37350.40821313858, 'accumulated_submission_time': 31647.38681125641, 'accumulated_eval_time': 5500.786079883575, 'accumulated_logging_time': 2.598129987716675, 'global_step': 50493, 'preemption_count': 0}), (51227, {'train/accuracy': 0.6999960140306123, 'train/loss': 1.3031205936354033, 'validation/accuracy': 0.6446, 'validation/loss': 1.54074859375, 'validation/num_examples': 50000, 'test/accuracy': 0.5052, 'test/loss': 2.28093515625, 'test/num_examples': 10000, 'score': 32157.4347949028, 'total_duration': 37954.675266742706, 'accumulated_submission_time': 32157.4347949028, 'accumulated_eval_time': 5591.754167795181, 'accumulated_logging_time': 2.6208534240722656, 'global_step': 51227, 'preemption_count': 0}), (52212, {'train/accuracy': 0.6955317283163265, 'train/loss': 1.3163114275251115, 'validation/accuracy': 0.6456, 'validation/loss': 1.5439534375, 'validation/num_examples': 50000, 'test/accuracy': 0.5168, 'test/loss': 2.2313359375, 'test/num_examples': 10000, 'score': 32665.361191511154, 'total_duration': 38554.61046457291, 'accumulated_submission_time': 32665.361191511154, 'accumulated_eval_time': 5680.100619792938, 'accumulated_logging_time': 2.750415563583374, 'global_step': 52212, 'preemption_count': 0}), (53021, {'train/accuracy': 0.7030253507653061, 'train/loss': 1.3001296374262596, 'validation/accuracy': 0.65044, 'validation/loss': 1.53828109375, 'validation/num_examples': 50000, 'test/accuracy': 0.5051, 'test/loss': 2.26299921875, 'test/num_examples': 10000, 'score': 33173.703953027725, 'total_duration': 39147.90975546837, 'accumulated_submission_time': 33173.703953027725, 'accumulated_eval_time': 5761.648050785065, 'accumulated_logging_time': 2.799591541290283, 'global_step': 53021, 'preemption_count': 0}), (53736, {'train/accuracy': 0.7049984056122449, 'train/loss': 1.2837951037348534, 'validation/accuracy': 0.64732, 'validation/loss': 1.527440625, 'validation/num_examples': 50000, 'test/accuracy': 0.5059, 'test/loss': 2.2357134765625, 'test/num_examples': 10000, 'score': 33682.10593819618, 'total_duration': 39748.779153585434, 'accumulated_submission_time': 33682.10593819618, 'accumulated_eval_time': 5850.957741737366, 'accumulated_logging_time': 2.8631844520568848, 'global_step': 53736, 'preemption_count': 0}), (54728, {'train/accuracy': 0.7034239477040817, 'train/loss': 1.2672743505361128, 'validation/accuracy': 0.6518, 'validation/loss': 1.50201546875, 'validation/num_examples': 50000, 'test/accuracy': 0.5001, 'test/loss': 2.2881654296875, 'test/num_examples': 10000, 'score': 34191.27315425873, 'total_duration': 40349.17148900032, 'accumulated_submission_time': 34191.27315425873, 'accumulated_eval_time': 5938.770181655884, 'accumulated_logging_time': 2.902539014816284, 'global_step': 54728, 'preemption_count': 0}), (55565, {'train/accuracy': 0.7043008609693877, 'train/loss': 1.2780186400121571, 'validation/accuracy': 0.64646, 'validation/loss': 1.5250846875, 'validation/num_examples': 50000, 'test/accuracy': 0.4985, 'test/loss': 2.305669140625, 'test/num_examples': 10000, 'score': 34699.97894573212, 'total_duration': 40946.23064804077, 'accumulated_submission_time': 34699.97894573212, 'accumulated_eval_time': 6023.889732599258, 'accumulated_logging_time': 2.9767212867736816, 'global_step': 55565, 'preemption_count': 0}), (56261, {'train/accuracy': 0.7045001594387755, 'train/loss': 1.272177637839804, 'validation/accuracy': 0.65194, 'validation/loss': 1.51737203125, 'validation/num_examples': 50000, 'test/accuracy': 0.5108, 'test/loss': 2.236665625, 'test/num_examples': 10000, 'score': 35209.52921295166, 'total_duration': 41544.58634305, 'accumulated_submission_time': 35209.52921295166, 'accumulated_eval_time': 6109.522987365723, 'accumulated_logging_time': 2.998589277267456, 'global_step': 56261, 'preemption_count': 0}), (57226, {'train/accuracy': 0.7062539859693877, 'train/loss': 1.2667329749282525, 'validation/accuracy': 0.65206, 'validation/loss': 1.51621609375, 'validation/num_examples': 50000, 'test/accuracy': 0.4952, 'test/loss': 2.2860779296875, 'test/num_examples': 10000, 'score': 35719.222950935364, 'total_duration': 42143.40066361427, 'accumulated_submission_time': 35719.222950935364, 'accumulated_eval_time': 6195.311578273773, 'accumulated_logging_time': 3.0348992347717285, 'global_step': 57226, 'preemption_count': 0}), (58019, {'train/accuracy': 0.7013313137755102, 'train/loss': 1.290224892752511, 'validation/accuracy': 0.64706, 'validation/loss': 1.525969375, 'validation/num_examples': 50000, 'test/accuracy': 0.5122, 'test/loss': 2.2366759765625, 'test/num_examples': 10000, 'score': 36227.54031133652, 'total_duration': 42738.17141819, 'accumulated_submission_time': 36227.54031133652, 'accumulated_eval_time': 6278.389216899872, 'accumulated_logging_time': 3.1000967025756836, 'global_step': 58019, 'preemption_count': 0}), (58748, {'train/accuracy': 0.7054169323979592, 'train/loss': 1.2743050711495536, 'validation/accuracy': 0.6521, 'validation/loss': 1.51192171875, 'validation/num_examples': 50000, 'test/accuracy': 0.5048, 'test/loss': 2.26134296875, 'test/num_examples': 10000, 'score': 36735.76719522476, 'total_duration': 43336.351710796356, 'accumulated_submission_time': 36735.76719522476, 'accumulated_eval_time': 6365.129046916962, 'accumulated_logging_time': 3.121900796890259, 'global_step': 58748, 'preemption_count': 0}), (59710, {'train/accuracy': 0.7064931441326531, 'train/loss': 1.2878023264359455, 'validation/accuracy': 0.6527, 'validation/loss': 1.5264784375, 'validation/num_examples': 50000, 'test/accuracy': 0.5107, 'test/loss': 2.2499158203125, 'test/num_examples': 10000, 'score': 37245.81012773514, 'total_duration': 43934.977206707, 'accumulated_submission_time': 37245.81012773514, 'accumulated_eval_time': 6450.344282627106, 'accumulated_logging_time': 3.1951725482940674, 'global_step': 59710, 'preemption_count': 0}), (60495, {'train/accuracy': 0.7069316007653061, 'train/loss': 1.2822735844826212, 'validation/accuracy': 0.65258, 'validation/loss': 1.5207021875, 'validation/num_examples': 50000, 'test/accuracy': 0.5093, 'test/loss': 2.25282734375, 'test/num_examples': 10000, 'score': 37754.14407801628, 'total_duration': 44533.16983413696, 'accumulated_submission_time': 37754.14407801628, 'accumulated_eval_time': 6537.005597829819, 'accumulated_logging_time': 3.217559576034546, 'global_step': 60495, 'preemption_count': 0}), (61229, {'train/accuracy': 0.7085857780612245, 'train/loss': 1.2402721327178332, 'validation/accuracy': 0.65348, 'validation/loss': 1.4874296875, 'validation/num_examples': 50000, 'test/accuracy': 0.5134, 'test/loss': 2.1998013671875, 'test/num_examples': 10000, 'score': 38264.19334220886, 'total_duration': 45132.31668829918, 'accumulated_submission_time': 38264.19334220886, 'accumulated_eval_time': 6622.758697986603, 'accumulated_logging_time': 3.3107011318206787, 'global_step': 61229, 'preemption_count': 0}), (62180, {'train/accuracy': 0.7139269770408163, 'train/loss': 1.2369188581194197, 'validation/accuracy': 0.6567, 'validation/loss': 1.485054375, 'validation/num_examples': 50000, 'test/accuracy': 0.5172, 'test/loss': 2.19907109375, 'test/num_examples': 10000, 'score': 38773.152814626694, 'total_duration': 45730.7682621479, 'accumulated_submission_time': 38773.152814626694, 'accumulated_eval_time': 6708.863791704178, 'accumulated_logging_time': 3.3950448036193848, 'global_step': 62180, 'preemption_count': 0}), (62986, {'train/accuracy': 0.7119339923469388, 'train/loss': 1.2434076581682478, 'validation/accuracy': 0.65794, 'validation/loss': 1.4797546875, 'validation/num_examples': 50000, 'test/accuracy': 0.5047, 'test/loss': 2.2628677734375, 'test/num_examples': 10000, 'score': 39281.3629488945, 'total_duration': 46325.39657306671, 'accumulated_submission_time': 39281.3629488945, 'accumulated_eval_time': 6791.95330119133, 'accumulated_logging_time': 3.417386531829834, 'global_step': 62986, 'preemption_count': 0}), (63766, {'train/accuracy': 0.7117745535714286, 'train/loss': 1.2585198538643974, 'validation/accuracy': 0.65054, 'validation/loss': 1.50637515625, 'validation/num_examples': 50000, 'test/accuracy': 0.5096, 'test/loss': 2.238537890625, 'test/num_examples': 10000, 'score': 39790.39046597481, 'total_duration': 46923.99529361725, 'accumulated_submission_time': 39790.39046597481, 'accumulated_eval_time': 6878.3149654865265, 'accumulated_logging_time': 3.4573683738708496, 'global_step': 63766, 'preemption_count': 0}), (64761, {'train/accuracy': 0.7140864158163265, 'train/loss': 1.24510535415338, 'validation/accuracy': 0.65852, 'validation/loss': 1.4887603125, 'validation/num_examples': 50000, 'test/accuracy': 0.5098, 'test/loss': 2.252995703125, 'test/num_examples': 10000, 'score': 40298.52786064148, 'total_duration': 47523.99117016792, 'accumulated_submission_time': 40298.52786064148, 'accumulated_eval_time': 6966.805249929428, 'accumulated_logging_time': 3.500828742980957, 'global_step': 64761, 'preemption_count': 0}), (65623, {'train/accuracy': 0.7114357461734694, 'train/loss': 1.2538537784498565, 'validation/accuracy': 0.65424, 'validation/loss': 1.4949375, 'validation/num_examples': 50000, 'test/accuracy': 0.5105, 'test/loss': 2.263198828125, 'test/num_examples': 10000, 'score': 40806.87891769409, 'total_duration': 48123.24325299263, 'accumulated_submission_time': 40806.87891769409, 'accumulated_eval_time': 7054.413929224014, 'accumulated_logging_time': 3.5231618881225586, 'global_step': 65623, 'preemption_count': 0}), (66220, {'train/accuracy': 0.7114158163265306, 'train/loss': 1.225133856948541, 'validation/accuracy': 0.65754, 'validation/loss': 1.46540375, 'validation/num_examples': 50000, 'test/accuracy': 0.5175, 'test/loss': 2.1926892578125, 'test/num_examples': 10000, 'score': 41315.92387223244, 'total_duration': 48721.69203090668, 'accumulated_submission_time': 41315.92387223244, 'accumulated_eval_time': 7140.760954618454, 'accumulated_logging_time': 3.5609922409057617, 'global_step': 66220, 'preemption_count': 0}), (67087, {'train/accuracy': 0.7170758928571429, 'train/loss': 1.231467577875877, 'validation/accuracy': 0.65954, 'validation/loss': 1.47842171875, 'validation/num_examples': 50000, 'test/accuracy': 0.5159, 'test/loss': 2.206418359375, 'test/num_examples': 10000, 'score': 41824.411314964294, 'total_duration': 49320.689351797104, 'accumulated_submission_time': 41824.411314964294, 'accumulated_eval_time': 7228.05131316185, 'accumulated_logging_time': 3.607471227645874, 'global_step': 67087, 'preemption_count': 0}), (67643, {'train/accuracy': 0.7196269132653061, 'train/loss': 1.2125687112613601, 'validation/accuracy': 0.65842, 'validation/loss': 1.47050171875, 'validation/num_examples': 50000, 'test/accuracy': 0.5129, 'test/loss': 2.246649609375, 'test/num_examples': 10000, 'score': 42332.84548997879, 'total_duration': 49915.851712465286, 'accumulated_submission_time': 42332.84548997879, 'accumulated_eval_time': 7311.648412227631, 'accumulated_logging_time': 3.662531852722168, 'global_step': 67643, 'preemption_count': 0}), (68533, {'train/accuracy': 0.7189094387755102, 'train/loss': 1.2190224005251515, 'validation/accuracy': 0.66096, 'validation/loss': 1.46769375, 'validation/num_examples': 50000, 'test/accuracy': 0.5199, 'test/loss': 2.1974390625, 'test/num_examples': 10000, 'score': 42841.10268139839, 'total_duration': 50516.0788795948, 'accumulated_submission_time': 42841.10268139839, 'accumulated_eval_time': 7400.299445867538, 'accumulated_logging_time': 3.684558868408203, 'global_step': 68533, 'preemption_count': 0}), (69334, {'train/accuracy': 0.7165776466836735, 'train/loss': 1.2206538453394054, 'validation/accuracy': 0.65908, 'validation/loss': 1.47681015625, 'validation/num_examples': 50000, 'test/accuracy': 0.5102, 'test/loss': 2.2502404296875, 'test/num_examples': 10000, 'score': 43349.19257426262, 'total_duration': 51114.878937244415, 'accumulated_submission_time': 43349.19257426262, 'accumulated_eval_time': 7487.665808916092, 'accumulated_logging_time': 3.7240045070648193, 'global_step': 69334, 'preemption_count': 0}), (70000, {'train/accuracy': 0.7119339923469388, 'train/loss': 1.229160230986926, 'validation/accuracy': 0.65756, 'validation/loss': 1.47442359375, 'validation/num_examples': 50000, 'test/accuracy': 0.5307, 'test/loss': 2.1368701171875, 'test/num_examples': 10000, 'score': 43857.49768638611, 'total_duration': 51720.430292367935, 'accumulated_submission_time': 43857.49768638611, 'accumulated_eval_time': 7581.574929237366, 'accumulated_logging_time': 3.8173158168792725, 'global_step': 70000, 'preemption_count': 0}), (70941, {'train/accuracy': 0.7199059311224489, 'train/loss': 1.2056292319784359, 'validation/accuracy': 0.66434, 'validation/loss': 1.45818859375, 'validation/num_examples': 50000, 'test/accuracy': 0.5215, 'test/loss': 2.184435546875, 'test/num_examples': 10000, 'score': 44366.392253637314, 'total_duration': 52316.936707258224, 'accumulated_submission_time': 44366.392253637314, 'accumulated_eval_time': 7665.722358942032, 'accumulated_logging_time': 3.9152402877807617, 'global_step': 70941, 'preemption_count': 0}), (71684, {'train/accuracy': 0.7248883928571429, 'train/loss': 1.1886137358996334, 'validation/accuracy': 0.66394, 'validation/loss': 1.44206375, 'validation/num_examples': 50000, 'test/accuracy': 0.5292, 'test/loss': 2.149873046875, 'test/num_examples': 10000, 'score': 44874.85699701309, 'total_duration': 52912.700901031494, 'accumulated_submission_time': 44874.85699701309, 'accumulated_eval_time': 7749.797535419464, 'accumulated_logging_time': 3.9496002197265625, 'global_step': 71684, 'preemption_count': 0}), (72435, {'train/accuracy': 0.7254264987244898, 'train/loss': 1.1759263641980229, 'validation/accuracy': 0.66826, 'validation/loss': 1.426800625, 'validation/num_examples': 50000, 'test/accuracy': 0.5264, 'test/loss': 2.152442578125, 'test/num_examples': 10000, 'score': 45384.40490436554, 'total_duration': 53513.98900389671, 'accumulated_submission_time': 45384.40490436554, 'accumulated_eval_time': 7838.370414495468, 'accumulated_logging_time': 3.974426507949829, 'global_step': 72435, 'preemption_count': 0}), (73342, {'train/accuracy': 0.7194076849489796, 'train/loss': 1.1930418987663425, 'validation/accuracy': 0.66228, 'validation/loss': 1.44454609375, 'validation/num_examples': 50000, 'test/accuracy': 0.5214, 'test/loss': 2.18005625, 'test/num_examples': 10000, 'score': 45892.52161049843, 'total_duration': 54115.8805410862, 'accumulated_submission_time': 45892.52161049843, 'accumulated_eval_time': 7928.760132789612, 'accumulated_logging_time': 4.0580174922943115, 'global_step': 73342, 'preemption_count': 0}), (73998, {'train/accuracy': 0.7271006058673469, 'train/loss': 1.195806853625239, 'validation/accuracy': 0.66712, 'validation/loss': 1.44891546875, 'validation/num_examples': 50000, 'test/accuracy': 0.5234, 'test/loss': 2.1723060546875, 'test/num_examples': 10000, 'score': 46401.121795892715, 'total_duration': 54709.256684303284, 'accumulated_submission_time': 46401.121795892715, 'accumulated_eval_time': 8010.360300064087, 'accumulated_logging_time': 4.080565690994263, 'global_step': 73998, 'preemption_count': 0}), (74847, {'train/accuracy': 0.72265625, 'train/loss': 1.1901526159169722, 'validation/accuracy': 0.66512, 'validation/loss': 1.44919703125, 'validation/num_examples': 50000, 'test/accuracy': 0.5214, 'test/loss': 2.167185546875, 'test/num_examples': 10000, 'score': 46909.644025564194, 'total_duration': 55306.41723918915, 'accumulated_submission_time': 46909.644025564194, 'accumulated_eval_time': 8095.8592619895935, 'accumulated_logging_time': 4.208085298538208, 'global_step': 74847, 'preemption_count': 0}), (75705, {'train/accuracy': 0.7220583545918368, 'train/loss': 1.1935030100296955, 'validation/accuracy': 0.66196, 'validation/loss': 1.44999828125, 'validation/num_examples': 50000, 'test/accuracy': 0.5214, 'test/loss': 2.1950318359375, 'test/num_examples': 10000, 'score': 47418.479996204376, 'total_duration': 55902.306443691254, 'accumulated_submission_time': 47418.479996204376, 'accumulated_eval_time': 8179.577390670776, 'accumulated_logging_time': 4.325294494628906, 'global_step': 75705, 'preemption_count': 0}), (76288, {'train/accuracy': 0.7211615114795918, 'train/loss': 1.1950575380909199, 'validation/accuracy': 0.66048, 'validation/loss': 1.450264375, 'validation/num_examples': 50000, 'test/accuracy': 0.5133, 'test/loss': 2.1993830078125, 'test/num_examples': 10000, 'score': 47926.98182821274, 'total_duration': 56500.09783697128, 'accumulated_submission_time': 47926.98182821274, 'accumulated_eval_time': 8265.745178461075, 'accumulated_logging_time': 4.387462139129639, 'global_step': 76288, 'preemption_count': 0}), (77233, {'train/accuracy': 0.7316246811224489, 'train/loss': 1.1972606425382653, 'validation/accuracy': 0.6708, 'validation/loss': 1.441998125, 'validation/num_examples': 50000, 'test/accuracy': 0.5324, 'test/loss': 2.151702734375, 'test/num_examples': 10000, 'score': 48435.71149635315, 'total_duration': 57098.4744143486, 'accumulated_submission_time': 48435.71149635315, 'accumulated_eval_time': 8352.050523757935, 'accumulated_logging_time': 4.422235488891602, 'global_step': 77233, 'preemption_count': 0}), (77976, {'train/accuracy': 0.724968112244898, 'train/loss': 1.1847745934311225, 'validation/accuracy': 0.66172, 'validation/loss': 1.44341609375, 'validation/num_examples': 50000, 'test/accuracy': 0.5239, 'test/loss': 2.1868232421875, 'test/num_examples': 10000, 'score': 48944.28805708885, 'total_duration': 57700.14165306091, 'accumulated_submission_time': 48944.28805708885, 'accumulated_eval_time': 8441.841162204742, 'accumulated_logging_time': 4.5246193408966064, 'global_step': 77976, 'preemption_count': 0}), (78698, {'train/accuracy': 0.7304886798469388, 'train/loss': 1.146804498166454, 'validation/accuracy': 0.67062, 'validation/loss': 1.4088153125, 'validation/num_examples': 50000, 'test/accuracy': 0.5277, 'test/loss': 2.131408984375, 'test/num_examples': 10000, 'score': 49453.76648449898, 'total_duration': 58297.73979258537, 'accumulated_submission_time': 49453.76648449898, 'accumulated_eval_time': 8526.782220840454, 'accumulated_logging_time': 4.550768613815308, 'global_step': 78698, 'preemption_count': 0}), (79614, {'train/accuracy': 0.7254464285714286, 'train/loss': 1.180870601109096, 'validation/accuracy': 0.665, 'validation/loss': 1.43217265625, 'validation/num_examples': 50000, 'test/accuracy': 0.5295, 'test/loss': 2.115774609375, 'test/num_examples': 10000, 'score': 49962.444154024124, 'total_duration': 58897.56498336792, 'accumulated_submission_time': 49962.444154024124, 'accumulated_eval_time': 8614.604536294937, 'accumulated_logging_time': 4.665534973144531, 'global_step': 79614, 'preemption_count': 0}), (80343, {'train/accuracy': 0.730110012755102, 'train/loss': 1.162665775844029, 'validation/accuracy': 0.66994, 'validation/loss': 1.4261709375, 'validation/num_examples': 50000, 'test/accuracy': 0.5298, 'test/loss': 2.1213693359375, 'test/num_examples': 10000, 'score': 50470.87685275078, 'total_duration': 59497.63179850578, 'accumulated_submission_time': 50470.87685275078, 'accumulated_eval_time': 8702.690573215485, 'accumulated_logging_time': 4.8156750202178955, 'global_step': 80343, 'preemption_count': 0}), (81161, {'train/accuracy': 0.7260243941326531, 'train/loss': 1.1754953034070073, 'validation/accuracy': 0.66732, 'validation/loss': 1.4286384375, 'validation/num_examples': 50000, 'test/accuracy': 0.5277, 'test/loss': 2.134926171875, 'test/num_examples': 10000, 'score': 50980.467859983444, 'total_duration': 60095.32768678665, 'accumulated_submission_time': 50980.467859983444, 'accumulated_eval_time': 8787.57639336586, 'accumulated_logging_time': 4.8416759967803955, 'global_step': 81161, 'preemption_count': 0}), (82057, {'train/accuracy': 0.7320432079081632, 'train/loss': 1.117764219945791, 'validation/accuracy': 0.66884, 'validation/loss': 1.3879290625, 'validation/num_examples': 50000, 'test/accuracy': 0.5316, 'test/loss': 2.1103025390625, 'test/num_examples': 10000, 'score': 51489.266177654266, 'total_duration': 60695.01804637909, 'accumulated_submission_time': 51489.266177654266, 'accumulated_eval_time': 8875.181381702423, 'accumulated_logging_time': 4.95021915435791, 'global_step': 82057, 'preemption_count': 0}), (82700, {'train/accuracy': 0.7331792091836735, 'train/loss': 1.1564157447036432, 'validation/accuracy': 0.67092, 'validation/loss': 1.4211115625, 'validation/num_examples': 50000, 'test/accuracy': 0.532, 'test/loss': 2.132621484375, 'test/num_examples': 10000, 'score': 51998.14189243317, 'total_duration': 61289.615002155304, 'accumulated_submission_time': 51998.14189243317, 'accumulated_eval_time': 8957.8002576828, 'accumulated_logging_time': 4.984821319580078, 'global_step': 82700, 'preemption_count': 0}), (83591, {'train/accuracy': 0.7340760522959183, 'train/loss': 1.147738787592674, 'validation/accuracy': 0.67342, 'validation/loss': 1.41119140625, 'validation/num_examples': 50000, 'test/accuracy': 0.529, 'test/loss': 2.1350509765625, 'test/num_examples': 10000, 'score': 52507.69702744484, 'total_duration': 61888.44715166092, 'accumulated_submission_time': 52507.69702744484, 'accumulated_eval_time': 9043.768751621246, 'accumulated_logging_time': 5.024707794189453, 'global_step': 83591, 'preemption_count': 0}), (84440, {'train/accuracy': 0.7373644770408163, 'train/loss': 1.137249382174745, 'validation/accuracy': 0.6744, 'validation/loss': 1.408193125, 'validation/num_examples': 50000, 'test/accuracy': 0.5291, 'test/loss': 2.1501232421875, 'test/num_examples': 10000, 'score': 53016.152619838715, 'total_duration': 62487.024686574936, 'accumulated_submission_time': 53016.152619838715, 'accumulated_eval_time': 9130.621725797653, 'accumulated_logging_time': 5.093925714492798, 'global_step': 84440, 'preemption_count': 0}), (85066, {'train/accuracy': 0.7372448979591837, 'train/loss': 1.147922438018176, 'validation/accuracy': 0.67294, 'validation/loss': 1.4120434375, 'validation/num_examples': 50000, 'test/accuracy': 0.5399, 'test/loss': 2.1077330078125, 'test/num_examples': 10000, 'score': 53525.05167865753, 'total_duration': 63084.0790374279, 'accumulated_submission_time': 53525.05167865753, 'accumulated_eval_time': 9215.584463596344, 'accumulated_logging_time': 5.119765043258667, 'global_step': 85066, 'preemption_count': 0}), (86025, {'train/accuracy': 0.7367267219387755, 'train/loss': 1.1270853159378986, 'validation/accuracy': 0.6754, 'validation/loss': 1.383246875, 'validation/num_examples': 50000, 'test/accuracy': 0.5291, 'test/loss': 2.146016796875, 'test/num_examples': 10000, 'score': 54035.63076925278, 'total_duration': 63686.79652261734, 'accumulated_submission_time': 54035.63076925278, 'accumulated_eval_time': 9304.344275951385, 'accumulated_logging_time': 5.21688437461853, 'global_step': 86025, 'preemption_count': 0}), (86808, {'train/accuracy': 0.7373844068877551, 'train/loss': 1.1188430007623167, 'validation/accuracy': 0.6747, 'validation/loss': 1.38522703125, 'validation/num_examples': 50000, 'test/accuracy': 0.5345, 'test/loss': 2.1115013671875, 'test/num_examples': 10000, 'score': 54544.54809474945, 'total_duration': 64280.65888643265, 'accumulated_submission_time': 54544.54809474945, 'accumulated_eval_time': 9386.073294639587, 'accumulated_logging_time': 5.279665231704712, 'global_step': 86808, 'preemption_count': 0}), (87487, {'train/accuracy': 0.740593112244898, 'train/loss': 1.1042198648258132, 'validation/accuracy': 0.67582, 'validation/loss': 1.37915296875, 'validation/num_examples': 50000, 'test/accuracy': 0.5462, 'test/loss': 2.0562076171875, 'test/num_examples': 10000, 'score': 55053.72089076042, 'total_duration': 64877.081362724304, 'accumulated_submission_time': 55053.72089076042, 'accumulated_eval_time': 9470.231877088547, 'accumulated_logging_time': 5.305002689361572, 'global_step': 87487, 'preemption_count': 0}), (88420, {'train/accuracy': 0.737922512755102, 'train/loss': 1.1090524634536432, 'validation/accuracy': 0.6781, 'validation/loss': 1.3786184375, 'validation/num_examples': 50000, 'test/accuracy': 0.5428, 'test/loss': 2.0677953125, 'test/num_examples': 10000, 'score': 55564.215346336365, 'total_duration': 65477.72962474823, 'accumulated_submission_time': 55564.215346336365, 'accumulated_eval_time': 9557.200443029404, 'accumulated_logging_time': 5.369084358215332, 'global_step': 88420, 'preemption_count': 0}), (89115, {'train/accuracy': 0.7392777423469388, 'train/loss': 1.1304620236766583, 'validation/accuracy': 0.67554, 'validation/loss': 1.40273109375, 'validation/num_examples': 50000, 'test/accuracy': 0.5442, 'test/loss': 2.10841796875, 'test/num_examples': 10000, 'score': 56072.602840423584, 'total_duration': 66075.59615468979, 'accumulated_submission_time': 56072.602840423584, 'accumulated_eval_time': 9643.427175998688, 'accumulated_logging_time': 5.405685186386108, 'global_step': 89115, 'preemption_count': 0}), (89898, {'train/accuracy': 0.7395567602040817, 'train/loss': 1.1302991594587053, 'validation/accuracy': 0.6734, 'validation/loss': 1.408094375, 'validation/num_examples': 50000, 'test/accuracy': 0.5431, 'test/loss': 2.103957421875, 'test/num_examples': 10000, 'score': 56581.974061489105, 'total_duration': 66672.32760548592, 'accumulated_submission_time': 56581.974061489105, 'accumulated_eval_time': 9727.4516518116, 'accumulated_logging_time': 5.587733507156372, 'global_step': 89898, 'preemption_count': 0}), (90761, {'train/accuracy': 0.7345344387755102, 'train/loss': 1.1588415807607222, 'validation/accuracy': 0.67594, 'validation/loss': 1.4197096875, 'validation/num_examples': 50000, 'test/accuracy': 0.5345, 'test/loss': 2.144025, 'test/num_examples': 10000, 'score': 57090.35734128952, 'total_duration': 67269.64769816399, 'accumulated_submission_time': 57090.35734128952, 'accumulated_eval_time': 9813.150824546814, 'accumulated_logging_time': 5.65074610710144, 'global_step': 90761, 'preemption_count': 0}), (91352, {'train/accuracy': 0.7440210459183674, 'train/loss': 1.1022905622209822, 'validation/accuracy': 0.67894, 'validation/loss': 1.380045, 'validation/num_examples': 50000, 'test/accuracy': 0.5358, 'test/loss': 2.1094580078125, 'test/num_examples': 10000, 'score': 57598.8264901638, 'total_duration': 67868.50175857544, 'accumulated_submission_time': 57598.8264901638, 'accumulated_eval_time': 9900.42316865921, 'accumulated_logging_time': 5.675734996795654, 'global_step': 91352, 'preemption_count': 0}), (92296, {'train/accuracy': 0.7448979591836735, 'train/loss': 1.1103506282884248, 'validation/accuracy': 0.68118, 'validation/loss': 1.3816403125, 'validation/num_examples': 50000, 'test/accuracy': 0.5458, 'test/loss': 2.0808310546875, 'test/num_examples': 10000, 'score': 58106.7379052639, 'total_duration': 68465.19710493088, 'accumulated_submission_time': 58106.7379052639, 'accumulated_eval_time': 9985.706042766571, 'accumulated_logging_time': 5.76312518119812, 'global_step': 92296, 'preemption_count': 0}), (93077, {'train/accuracy': 0.7416294642857143, 'train/loss': 1.0909485330387039, 'validation/accuracy': 0.67874, 'validation/loss': 1.3622828125, 'validation/num_examples': 50000, 'test/accuracy': 0.5388, 'test/loss': 2.0869966796875, 'test/num_examples': 10000, 'score': 58615.145507097244, 'total_duration': 69061.85390591621, 'accumulated_submission_time': 58615.145507097244, 'accumulated_eval_time': 10070.673586130142, 'accumulated_logging_time': 5.845810890197754, 'global_step': 93077, 'preemption_count': 0}), (93746, {'train/accuracy': 0.7475087691326531, 'train/loss': 1.0901933008310747, 'validation/accuracy': 0.68298, 'validation/loss': 1.36890734375, 'validation/num_examples': 50000, 'test/accuracy': 0.5444, 'test/loss': 2.0680302734375, 'test/num_examples': 10000, 'score': 59124.9107503891, 'total_duration': 69661.47474598885, 'accumulated_submission_time': 59124.9107503891, 'accumulated_eval_time': 10157.415668487549, 'accumulated_logging_time': 5.889635324478149, 'global_step': 93746, 'preemption_count': 0}), (94673, {'train/accuracy': 0.7524713010204082, 'train/loss': 1.044362126564493, 'validation/accuracy': 0.68344, 'validation/loss': 1.33407390625, 'validation/num_examples': 50000, 'test/accuracy': 0.5476, 'test/loss': 2.031074609375, 'test/num_examples': 10000, 'score': 59633.60502386093, 'total_duration': 70260.05012178421, 'accumulated_submission_time': 59633.60502386093, 'accumulated_eval_time': 10243.90254688263, 'accumulated_logging_time': 5.9661712646484375, 'global_step': 94673, 'preemption_count': 0}), (95345, {'train/accuracy': 0.7509765625, 'train/loss': 1.0640417605030292, 'validation/accuracy': 0.68564, 'validation/loss': 1.34744640625, 'validation/num_examples': 50000, 'test/accuracy': 0.5448, 'test/loss': 2.0517556640625, 'test/num_examples': 10000, 'score': 60142.632432460785, 'total_duration': 70862.07512187958, 'accumulated_submission_time': 60142.632432460785, 'accumulated_eval_time': 10333.887432098389, 'accumulated_logging_time': 5.990764856338501, 'global_step': 95345, 'preemption_count': 0}), (96113, {'train/accuracy': 0.746452487244898, 'train/loss': 1.0922692746532208, 'validation/accuracy': 0.68352, 'validation/loss': 1.3642578125, 'validation/num_examples': 50000, 'test/accuracy': 0.5448, 'test/loss': 2.069335546875, 'test/num_examples': 10000, 'score': 60653.78189921379, 'total_duration': 71464.74115133286, 'accumulated_submission_time': 60653.78189921379, 'accumulated_eval_time': 10422.128766059875, 'accumulated_logging_time': 6.0190749168396, 'global_step': 96113, 'preemption_count': 0}), (96899, {'train/accuracy': 0.7526307397959183, 'train/loss': 1.0597182293327487, 'validation/accuracy': 0.68598, 'validation/loss': 1.3432396875, 'validation/num_examples': 50000, 'test/accuracy': 0.5356, 'test/loss': 2.1266451171875, 'test/num_examples': 10000, 'score': 61161.89777755737, 'total_duration': 72061.80718636513, 'accumulated_submission_time': 61161.89777755737, 'accumulated_eval_time': 10507.663512706757, 'accumulated_logging_time': 6.06110405921936, 'global_step': 96899, 'preemption_count': 0}), (97512, {'train/accuracy': 0.7512555803571429, 'train/loss': 1.046175820486886, 'validation/accuracy': 0.68588, 'validation/loss': 1.334583125, 'validation/num_examples': 50000, 'test/accuracy': 0.5518, 'test/loss': 2.039416015625, 'test/num_examples': 10000, 'score': 61673.29435920715, 'total_duration': 72664.23859620094, 'accumulated_submission_time': 61673.29435920715, 'accumulated_eval_time': 10595.530426740646, 'accumulated_logging_time': 6.087907314300537, 'global_step': 97512, 'preemption_count': 0}), (98398, {'train/accuracy': 0.7518933354591837, 'train/loss': 1.0568661592444595, 'validation/accuracy': 0.68408, 'validation/loss': 1.34511703125, 'validation/num_examples': 50000, 'test/accuracy': 0.5556, 'test/loss': 2.002987109375, 'test/num_examples': 10000, 'score': 62181.63513112068, 'total_duration': 73262.34638690948, 'accumulated_submission_time': 62181.63513112068, 'accumulated_eval_time': 10682.034760475159, 'accumulated_logging_time': 6.111863613128662, 'global_step': 98398, 'preemption_count': 0}), (99000, {'train/accuracy': 0.7571548150510204, 'train/loss': 1.0550947383958467, 'validation/accuracy': 0.68878, 'validation/loss': 1.33924015625, 'validation/num_examples': 50000, 'test/accuracy': 0.5564, 'test/loss': 2.014149609375, 'test/num_examples': 10000, 'score': 62690.1025352478, 'total_duration': 73864.47322750092, 'accumulated_submission_time': 62690.1025352478, 'accumulated_eval_time': 10772.526222705841, 'accumulated_logging_time': 6.144016265869141, 'global_step': 99000, 'preemption_count': 0}), (99819, {'train/accuracy': 0.7549027423469388, 'train/loss': 1.048199867715641, 'validation/accuracy': 0.69152, 'validation/loss': 1.3317425, 'validation/num_examples': 50000, 'test/accuracy': 0.547, 'test/loss': 2.03245, 'test/num_examples': 10000, 'score': 63199.36242032051, 'total_duration': 74462.95632123947, 'accumulated_submission_time': 63199.36242032051, 'accumulated_eval_time': 10858.48649764061, 'accumulated_logging_time': 6.217069625854492, 'global_step': 99819, 'preemption_count': 0}), (100541, {'train/accuracy': 0.7578722895408163, 'train/loss': 1.0466530468999122, 'validation/accuracy': 0.68994, 'validation/loss': 1.33071125, 'validation/num_examples': 50000, 'test/accuracy': 0.5569, 'test/loss': 2.009091796875, 'test/num_examples': 10000, 'score': 63707.83634638786, 'total_duration': 75056.89981842041, 'accumulated_submission_time': 63707.83634638786, 'accumulated_eval_time': 10940.824963092804, 'accumulated_logging_time': 6.243232011795044, 'global_step': 100541, 'preemption_count': 0}), (101188, {'train/accuracy': 0.7546635841836735, 'train/loss': 1.0558063740632972, 'validation/accuracy': 0.68846, 'validation/loss': 1.33621765625, 'validation/num_examples': 50000, 'test/accuracy': 0.5428, 'test/loss': 2.050808203125, 'test/num_examples': 10000, 'score': 64217.40668797493, 'total_duration': 75656.42604541779, 'accumulated_submission_time': 64217.40668797493, 'accumulated_eval_time': 11027.624455451965, 'accumulated_logging_time': 6.268279790878296, 'global_step': 101188, 'preemption_count': 0}), (102036, {'train/accuracy': 0.7593072385204082, 'train/loss': 1.044384158387476, 'validation/accuracy': 0.69066, 'validation/loss': 1.32837, 'validation/num_examples': 50000, 'test/accuracy': 0.5489, 'test/loss': 2.0543220703125, 'test/num_examples': 10000, 'score': 64725.615175008774, 'total_duration': 76256.681879282, 'accumulated_submission_time': 64725.615175008774, 'accumulated_eval_time': 11116.276199102402, 'accumulated_logging_time': 6.340555191040039, 'global_step': 102036, 'preemption_count': 0}), (102583, {'train/accuracy': 0.7557397959183674, 'train/loss': 1.0144896993831711, 'validation/accuracy': 0.69348, 'validation/loss': 1.3016171875, 'validation/num_examples': 50000, 'test/accuracy': 0.5579, 'test/loss': 1.979314453125, 'test/num_examples': 10000, 'score': 65234.94600749016, 'total_duration': 76851.92993474007, 'accumulated_submission_time': 65234.94600749016, 'accumulated_eval_time': 11199.125978469849, 'accumulated_logging_time': 6.3893883228302, 'global_step': 102583, 'preemption_count': 0}), (103513, {'train/accuracy': 0.7621372767857143, 'train/loss': 1.0281727849220743, 'validation/accuracy': 0.69392, 'validation/loss': 1.31733578125, 'validation/num_examples': 50000, 'test/accuracy': 0.5551, 'test/loss': 2.0342234375, 'test/num_examples': 10000, 'score': 65744.95452785492, 'total_duration': 77449.07344818115, 'accumulated_submission_time': 65744.95452785492, 'accumulated_eval_time': 11283.028980016708, 'accumulated_logging_time': 6.43008279800415, 'global_step': 103513, 'preemption_count': 0})], 'global_step': 104187}
I0315 19:17:26.710422 139925059253440 submission_runner.py:649] Timing: 66253.34895348549
I0315 19:17:26.710484 139925059253440 submission_runner.py:651] Total number of evals: 130
I0315 19:17:26.710518 139925059253440 submission_runner.py:652] ====================
I0315 19:17:26.710831 139925059253440 submission_runner.py:750] Final imagenet_resnet score: 2
