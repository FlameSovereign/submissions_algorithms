torchrun --redirects 1:0,2:0,3:0,4:0,5:0,6:0,7:0 --standalone --nnodes=1 --nproc_per_node=8 submission_runner.py --framework=pytorch --workload=imagenet_resnet --submission_path=submissions_algorithms/submissions/self_tuning/schedule_free_adamw_v2/submission.py --data_dir=/data/imagenet/pytorch --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=submissions/rolling_leaderboard/self_tuning/schedule_free_adamw_v2/study_1 --overwrite=True --save_checkpoints=False --rng_seed=652520557 --imagenet_v2_data_dir=/data/imagenet/pytorch --torch_compile=true --tuning_ruleset=self 2>&1 | tee -a /logs/imagenet_resnet_pytorch_03-18-2025-06-17-34.log
W0318 06:17:36.583000 9 site-packages/torch/distributed/run.py:793] 
W0318 06:17:36.583000 9 site-packages/torch/distributed/run.py:793] *****************************************
W0318 06:17:36.583000 9 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0318 06:17:36.583000 9 site-packages/torch/distributed/run.py:793] *****************************************
2025-03-18 06:17:37.678525: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-18 06:17:37.678525: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-18 06:17:37.678525: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-18 06:17:37.678532: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-18 06:17:37.678531: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-18 06:17:37.678523: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-18 06:17:37.678525: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-03-18 06:17:37.678667: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1742278657.699037      51 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1742278657.699036      49 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1742278657.699037      44 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1742278657.699040      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1742278657.699036      50 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1742278657.699037      45 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1742278657.699035      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1742278657.699204      46 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1742278657.705253      44 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1742278657.705253      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1742278657.705254      50 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1742278657.705252      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1742278657.705260      45 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1742278657.705264      49 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1742278657.705297      51 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1742278657.705450      46 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
ERROR:root:Unable to import wandb.
Traceback (most recent call last):
  File "/algorithmic-efficiency/algoperf/logger_utils.py", line 27, in <module>
    import wandb  # pylint: disable=g-import-not-at-top
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'wandb'
[rank4]:[W318 06:17:46.087801180 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank6]:[W318 06:17:46.089968876 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank0]:[W318 06:17:46.134149307 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank7]:[W318 06:17:46.201396002 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank2]:[W318 06:17:46.201812248 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank5]:[W318 06:17:46.202203339 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank3]:[W318 06:17:46.293328354 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank1]:[W318 06:17:46.352800853 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
I0318 06:17:48.093760 140042108409024 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/self_tuning/schedule_free_adamw_v2/study_1/imagenet_resnet_pytorch.
I0318 06:17:48.093760 139942788388032 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/self_tuning/schedule_free_adamw_v2/study_1/imagenet_resnet_pytorch.
I0318 06:17:48.093768 140626313229504 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/self_tuning/schedule_free_adamw_v2/study_1/imagenet_resnet_pytorch.
I0318 06:17:48.093766 139959261107392 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/self_tuning/schedule_free_adamw_v2/study_1/imagenet_resnet_pytorch.
I0318 06:17:48.093759 139687800071360 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/self_tuning/schedule_free_adamw_v2/study_1/imagenet_resnet_pytorch.
I0318 06:17:48.093767 139718179943616 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/self_tuning/schedule_free_adamw_v2/study_1/imagenet_resnet_pytorch.
I0318 06:17:48.093771 140520612607168 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/self_tuning/schedule_free_adamw_v2/study_1/imagenet_resnet_pytorch.
I0318 06:17:48.093839 140008515921088 logger_utils.py:81] Creating experiment directory at /experiment_runs/submissions/rolling_leaderboard/self_tuning/schedule_free_adamw_v2/study_1/imagenet_resnet_pytorch.
I0318 06:17:48.135191 139942788388032 submission_runner.py:665] Creating directory at /experiment_runs/submissions/rolling_leaderboard/self_tuning/schedule_free_adamw_v2/study_1/imagenet_resnet_pytorch/trial_1.
[rank2]: Traceback (most recent call last):
[rank2]:   File "/algorithmic-efficiency/submission_runner.py", line 766, in <module>
[rank2]:     app.run(main)
[rank2]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 308, in run
[rank2]:     _run_main(main, args)
[rank2]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 254, in _run_main
[rank2]:     sys.exit(main(argv))
[rank2]:              ^^^^^^^^^^
[rank2]:   File "/algorithmic-efficiency/submission_runner.py", line 734, in main
[rank2]:     score = score_submission_on_workload(
[rank2]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/algorithmic-efficiency/submission_runner.py", line 668, in score_submission_on_workload
[rank2]:     score, _ = train_once(
[rank2]:                ^^^^^^^^^^^
[rank2]:   File "/algorithmic-efficiency/submission_runner.py", line 223, in train_once
[rank2]:     with profiler.profile('Initializing dataset'):
[rank2]:          ^^^^^^^^^^^^^^^^
[rank2]: AttributeError: 'NoneType' object has no attribute 'profile'
I0318 06:17:48.477199 139942788388032 submission_runner.py:218] Initializing dataset.
[rank5]: Traceback (most recent call last):
[rank5]:   File "/algorithmic-efficiency/submission_runner.py", line 766, in <module>
[rank5]:     app.run(main)
[rank5]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 308, in run
[rank5]:     _run_main(main, args)
[rank5]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 254, in _run_main
[rank5]:     sys.exit(main(argv))
[rank5]:              ^^^^^^^^^^
[rank5]:   File "/algorithmic-efficiency/submission_runner.py", line 734, in main
[rank5]:     score = score_submission_on_workload(
[rank5]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank5]:   File "/algorithmic-efficiency/submission_runner.py", line 668, in score_submission_on_workload
[rank5]:     score, _ = train_once(
[rank5]:                ^^^^^^^^^^^
[rank5]:   File "/algorithmic-efficiency/submission_runner.py", line 223, in train_once
[rank5]:     with profiler.profile('Initializing dataset'):
[rank5]:          ^^^^^^^^^^^^^^^^
[rank5]: AttributeError: 'NoneType' object has no attribute 'profile'
[rank0]: Traceback (most recent call last):
[rank0]:   File "/algorithmic-efficiency/submission_runner.py", line 766, in <module>
[rank0]:     app.run(main)
[rank0]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 308, in run
[rank0]:     _run_main(main, args)
[rank0]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 254, in _run_main
[rank0]:     sys.exit(main(argv))
[rank0]:              ^^^^^^^^^^
[rank0]:   File "/algorithmic-efficiency/submission_runner.py", line 734, in main
[rank0]:     score = score_submission_on_workload(
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/algorithmic-efficiency/submission_runner.py", line 668, in score_submission_on_workload
[rank0]:     score, _ = train_once(
[rank0]:                ^^^^^^^^^^^
[rank0]:   File "/algorithmic-efficiency/submission_runner.py", line 223, in train_once
[rank0]:     with profiler.profile('Initializing dataset'):
[rank0]:          ^^^^^^^^^^^^^^^^
[rank0]: AttributeError: 'NoneType' object has no attribute 'profile'
[rank1]: Traceback (most recent call last):
[rank1]:   File "/algorithmic-efficiency/submission_runner.py", line 766, in <module>
[rank1]:     app.run(main)
[rank1]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 308, in run
[rank1]:     _run_main(main, args)
[rank1]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 254, in _run_main
[rank1]:     sys.exit(main(argv))
[rank1]:              ^^^^^^^^^^
[rank1]:   File "/algorithmic-efficiency/submission_runner.py", line 734, in main
[rank1]:     score = score_submission_on_workload(
[rank1]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/algorithmic-efficiency/submission_runner.py", line 668, in score_submission_on_workload
[rank1]:     score, _ = train_once(
[rank1]:                ^^^^^^^^^^^
[rank1]:   File "/algorithmic-efficiency/submission_runner.py", line 223, in train_once
[rank1]:     with profiler.profile('Initializing dataset'):
[rank1]:          ^^^^^^^^^^^^^^^^
[rank1]: AttributeError: 'NoneType' object has no attribute 'profile'
[rank6]: Traceback (most recent call last):
[rank6]:   File "/algorithmic-efficiency/submission_runner.py", line 766, in <module>
[rank6]:     app.run(main)
[rank6]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 308, in run
[rank6]:     _run_main(main, args)
[rank6]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 254, in _run_main
[rank6]:     sys.exit(main(argv))
[rank6]:              ^^^^^^^^^^
[rank6]:   File "/algorithmic-efficiency/submission_runner.py", line 734, in main
[rank6]:     score = score_submission_on_workload(
[rank6]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank6]:   File "/algorithmic-efficiency/submission_runner.py", line 668, in score_submission_on_workload
[rank6]:     score, _ = train_once(
[rank6]:                ^^^^^^^^^^^
[rank6]:   File "/algorithmic-efficiency/submission_runner.py", line 223, in train_once
[rank6]:     with profiler.profile('Initializing dataset'):
[rank6]:          ^^^^^^^^^^^^^^^^
[rank6]: AttributeError: 'NoneType' object has no attribute 'profile'
[rank3]: Traceback (most recent call last):
[rank3]:   File "/algorithmic-efficiency/submission_runner.py", line 766, in <module>
[rank3]:     app.run(main)
[rank3]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 308, in run
[rank3]:     _run_main(main, args)
[rank3]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 254, in _run_main
[rank3]:     sys.exit(main(argv))
[rank3]:              ^^^^^^^^^^
[rank3]:   File "/algorithmic-efficiency/submission_runner.py", line 734, in main
[rank3]:     score = score_submission_on_workload(
[rank3]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/algorithmic-efficiency/submission_runner.py", line 668, in score_submission_on_workload
[rank3]:     score, _ = train_once(
[rank3]:                ^^^^^^^^^^^
[rank3]:   File "/algorithmic-efficiency/submission_runner.py", line 223, in train_once
[rank3]:     with profiler.profile('Initializing dataset'):
[rank3]:          ^^^^^^^^^^^^^^^^
[rank3]: AttributeError: 'NoneType' object has no attribute 'profile'
[rank7]: Traceback (most recent call last):
[rank7]:   File "/algorithmic-efficiency/submission_runner.py", line 766, in <module>
[rank7]:     app.run(main)
[rank7]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 308, in run
[rank7]:     _run_main(main, args)
[rank7]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 254, in _run_main
[rank7]:     sys.exit(main(argv))
[rank7]:              ^^^^^^^^^^
[rank7]:   File "/algorithmic-efficiency/submission_runner.py", line 734, in main
[rank7]:     score = score_submission_on_workload(
[rank7]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank7]:   File "/algorithmic-efficiency/submission_runner.py", line 668, in score_submission_on_workload
[rank7]:     score, _ = train_once(
[rank7]:                ^^^^^^^^^^^
[rank7]:   File "/algorithmic-efficiency/submission_runner.py", line 223, in train_once
[rank7]:     with profiler.profile('Initializing dataset'):
[rank7]:          ^^^^^^^^^^^^^^^^
[rank7]: AttributeError: 'NoneType' object has no attribute 'profile'
[rank4]: Traceback (most recent call last):
[rank4]:   File "/algorithmic-efficiency/submission_runner.py", line 766, in <module>
[rank4]:     app.run(main)
[rank4]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 308, in run
[rank4]:     _run_main(main, args)
[rank4]:   File "/usr/local/lib/python3.11/site-packages/absl/app.py", line 254, in _run_main
[rank4]:     sys.exit(main(argv))
[rank4]:              ^^^^^^^^^^
[rank4]:   File "/algorithmic-efficiency/submission_runner.py", line 734, in main
[rank4]:     score = score_submission_on_workload(
[rank4]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank4]:   File "/algorithmic-efficiency/submission_runner.py", line 668, in score_submission_on_workload
[rank4]:     score, _ = train_once(
[rank4]:                ^^^^^^^^^^^
[rank4]:   File "/algorithmic-efficiency/submission_runner.py", line 223, in train_once
[rank4]:     with profiler.profile('Initializing dataset'):
[rank4]:          ^^^^^^^^^^^^^^^^
[rank4]: AttributeError: 'NoneType' object has no attribute 'profile'
[rank0]:[W318 06:17:49.256878239 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
W0318 06:17:50.619000 9 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 44 closing signal SIGTERM
W0318 06:17:50.620000 9 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 45 closing signal SIGTERM
W0318 06:17:50.620000 9 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 46 closing signal SIGTERM
W0318 06:17:50.620000 9 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 48 closing signal SIGTERM
W0318 06:17:50.621000 9 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 49 closing signal SIGTERM
W0318 06:17:50.621000 9 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 50 closing signal SIGTERM
W0318 06:17:50.621000 9 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 51 closing signal SIGTERM
E0318 06:17:51.282000 9 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 3 (pid: 47) of binary: /usr/local/bin/python3.11
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
submission_runner.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-03-18_06:17:50
  host      : 6cc4e095daf3
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 47)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
